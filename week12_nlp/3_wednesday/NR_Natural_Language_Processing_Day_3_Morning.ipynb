{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "NR Natural Language Processing Day 3 Morning",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0voemCtIvus"
      },
      "source": [
        "# Extracting Information from Text Data Assignment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNIoK-wzIvuv"
      },
      "source": [
        "import spacy\n",
        "import string\n",
        "import textacy\n",
        "import itertools\n",
        "from nltk import pos_tag\n",
        "from rake_nltk import Rake\n",
        "from nltk import sent_tokenize\n",
        "from nltk import word_tokenize\n",
        "from nltk import tree2conlltags\n",
        "from gensim.summarization import keywords\n",
        "from nltk.chunk.regexp import RegexpParser\n",
        "from nltk.corpus.reader.plaintext import PlaintextCorpusReader"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbB__zIWzob1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b18fdd88-da23-439d-8218-bf95b49d8d34"
      },
      "source": [
        "!pip install textacy --quiet\n",
        "!pip install rake_nltk --quiet"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 184kB 7.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 7.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 481kB 15.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.9MB 18.6MB/s \n",
            "\u001b[?25h  Building wheel for cytoolz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for rake-nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4M7RrWRKIvuy"
      },
      "source": [
        "### Read the CNN Lite plain text file articles into a corpus using the NLTK's PlaintextCorpusReader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMwqpeAmIvuz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "401689c9-f3f1-426f-bff7-44e1c8535216"
      },
      "source": [
        "path = 'cnn_articles/'\r\n",
        "doc_pattern = r'.*\\.txt'\r\n",
        "corpus = PlaintextCorpusReader(path, doc_pattern)\r\n",
        "corpus"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-b1f6c7321970>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cnn_articles/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdoc_pattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr'.*\\.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPlaintextCorpusReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_pattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/corpus/reader/plaintext.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, fileids, word_tokenizer, sent_tokenizer, para_block_reader, encoding)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mcorpus\u001b[0m \u001b[0minto\u001b[0m \u001b[0mparagraph\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \"\"\"\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mCorpusReader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_word_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sent_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent_tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/corpus/reader/api.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, fileids, encoding, tagset)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZipFilePathPointer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzipentry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFileSystemPathPointer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPathPointer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CorpusReader: expected a string or a PathPointer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/compat.py\u001b[0m in \u001b[0;36m_decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_py3_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minit_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_decorator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, _path)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No such file or directory: %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: No such file or directory: '/content/cnn_articles'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6Zp26sVIvu1"
      },
      "source": [
        "### Iterate through the fileids in the corpus, extract the raw text of each document, and store them in a list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yl15hykfIvu2"
      },
      "source": [
        "corpus.fileids()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_0p9s0L6S3o"
      },
      "source": [
        "docs = [corpus.raw(fileid) for fileid in corpus.fileids()]\r\n",
        "docs[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5LLM0YPIvu4"
      },
      "source": [
        "### Extract the top 5 keywords from every document in the corpus. Print them and compare the differences in keywords among the documents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "wcXEjv6FIvu4"
      },
      "source": [
        "keywords(docs[0], words=5, lemmatize=True).split('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-Wabd_M6fvm"
      },
      "source": [
        "for doc in docs:\r\n",
        "    print(keywords(doc, words=5, lemmatize=True).split('\\n'))\r\n",
        "    print('----------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6w50BcwMIvu6"
      },
      "source": [
        "### Extract the top 3 keyphrases from each document, print them, and compare the differences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M0PDiFwIvu7"
      },
      "source": [
        "r = Rake()\r\n",
        "r.extract_keywords_from_text(docs[0])\r\n",
        "r.get_ranked_phrases_with_scores()[:3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24JVv7z26jiw"
      },
      "source": [
        "for doc in docs:\r\n",
        "    r.extract_keywords_from_text(doc)\r\n",
        "    print(r.get_ranked_phrases_with_scores()[:3])\r\n",
        "    print('------------------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rev-FI9HIvu9"
      },
      "source": [
        "### Identify and extract the named entities in each document, filtering out the numeric types. Print them and compare the differences between documents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLs9TLMHIvu9"
      },
      "source": [
        "numeric = ['PERCENT', 'MONEY', 'QUANTITY', 'ORDINAL', 'CARDINAL']\r\n",
        "nlp = spacy.load('en_core_web_sm')\r\n",
        "spacy_doc = nlp(docs[0])\r\n",
        "for ent in spacy_doc.ents:\r\n",
        "    if ent.label_ not in numeric:\r\n",
        "        print(ent.text, '-', ent.label_)\r\n",
        "        print('-----')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RejpBa1u6oSa"
      },
      "source": [
        "for doc in docs:\r\n",
        "    spacy_doc = nlp(doc)\r\n",
        "    for ent in spacy_doc.ents:\r\n",
        "        if ent.label_ not in numeric:\r\n",
        "            print(ent.text, '-', ent.label_)\r\n",
        "    \r\n",
        "    print('-----')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwhH404sIvvB"
      },
      "source": [
        "### For every document in the corpus, iterate over every sentence, extract any SVO triples, print them, and compare."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03XLMyk1IvvC"
      },
      "source": [
        "results = []\r\n",
        "spacy_doc = nlp(docs[0])\r\n",
        "for sent in spacy_doc.sents:\r\n",
        "    svo = textacy.extract.subject_verb_object_triples(sent)\r\n",
        "    results += svo\r\n",
        "    \r\n",
        "results = list(set(results))\r\n",
        "for res in results:\r\n",
        "    print(res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CH_D-kYz6tl-"
      },
      "source": [
        "for doc in docs:\r\n",
        "    results = []\r\n",
        "    spacy_doc = nlp(doc)\r\n",
        "    for sent in spacy_doc.sents:\r\n",
        "        svo = textacy.extract.subject_verb_object_triples(sent)\r\n",
        "        results += svo\r\n",
        "\r\n",
        "    results = list(set(results))\r\n",
        "    for res in results:\r\n",
        "        print(res)\r\n",
        "    print('---------')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}