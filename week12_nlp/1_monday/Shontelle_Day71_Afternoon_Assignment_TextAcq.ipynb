{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "Shontelle_Day71_Afternoon_Assignment_TextAcq.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IihPCGvd34PH"
      },
      "source": [
        "# Text Acquisition & Ingestion Assignment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W30G5h_yDBRj"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sl4QLAzcDQHd",
        "outputId": "c2e4265b-9007-433b-cdc5-650316e84f3b"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTeB5-HutGbh",
        "outputId": "842930d4-513c-4267-ba81-3b65cb8dfb0c"
      },
      "source": [
        "!pip install feedparser"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting feedparser\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/21/faf1bac028662cc8adb2b5ef7a6f3999a765baa2835331df365289b0ca56/feedparser-6.0.2-py3-none-any.whl (80kB)\n",
            "\r\u001b[K     |████                            | 10kB 20.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 20kB 26.6MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 30kB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 40kB 19.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 51kB 15.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 61kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 71kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 6.8MB/s \n",
            "\u001b[?25hCollecting sgmllib3k\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/bd/3704a8c3e0942d711c1299ebf7b9091930adae6675d7c8f476a7ce48653c/sgmllib3k-1.0.0.tar.gz\n",
            "Building wheels for collected packages: sgmllib3k\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-cp36-none-any.whl size=6066 sha256=83bb86a631bf1a3b656a67dbaa178928653b8222b1a1597f4371e1c0303ea78b\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/80/5a/444ba08a550cdd241bd9baf8bae44be750efe370adb944506a\n",
            "Successfully built sgmllib3k\n",
            "Installing collected packages: sgmllib3k, feedparser\n",
            "Successfully installed feedparser-6.0.2 sgmllib3k-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhLA_w7p34PM"
      },
      "source": [
        "import json\n",
        "import requests\n",
        "import feedparser\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZ3ytdXA34PR"
      },
      "source": [
        "### Iterate through the list of article URLs below, scraping the text from each one and saving it to a text file. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDbZqPpT34PU"
      },
      "source": [
        "articles = ['http://lite.cnn.io/en/article/h_eac18760a7a7f9a1bf33616f1c4a336d',\n",
        "            'http://lite.cnn.io/en/article/h_de3f82f17d289680dd2b47c6413ebe7c',\n",
        "            'http://lite.cnn.io/en/article/h_72f4dc9d6f35458a89af014b62e625ad',\n",
        "            'http://lite.cnn.io/en/article/h_aa21fe6bf176071cb49e09d422c3adf0',\n",
        "            'http://lite.cnn.io/en/article/h_8ad34a532921c9076cdc9d7390d2f1bc',\n",
        "            'http://lite.cnn.io/en/article/h_84422c79110d9989177cfaf1c5f45fe7',\n",
        "            'http://lite.cnn.io/en/article/h_d010d9580abac3a44c6181ec6fb63d58',\n",
        "            'http://lite.cnn.io/en/article/h_fb11f4e9d7c5323e75b337d9e9e5e368',\n",
        "            'http://lite.cnn.io/en/article/h_7b27f0b131067f8ece6238ac559670ab',\n",
        "            'http://lite.cnn.io/en/article/h_8cae7f735fa9573d470f802063ceffe2',\n",
        "            'http://lite.cnn.io/en/article/h_72c3668280e82576fcc2602b0fa70c14',\n",
        "            'http://lite.cnn.io/en/article/h_d20658fb0e20212051cda0e0a7248c8a',\n",
        "            'http://lite.cnn.io/en/article/h_56611c43d7928120d2ae21666ccc7417',\n",
        "            'http://lite.cnn.io/en/article/h_bda0394e3c5ee7054ee65c022bca7695']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "tcryVWMm1nq4",
        "outputId": "1864cf4d-f537-49da-dc9b-7b29072e05e6"
      },
      "source": [
        "soup.find('div', {'class': 'afe4286c'}).get_text()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'How I became an all-American Muslim girlUpdated 9:43 AM ET, Thu November 14, 2019Editor\\'s Note: Nadine Jolie Courtney is the author of the novel \"All-American Muslim Girl.\" Her writing has appeared in Angeleno, O: The Oprah Magazine, Architectural Digest, Town & Country and elsewhere. The views expressed here are hers. Read more opinion on CNN. (CNN) - On January 27th, 2017, after President Donald Trump issued an executive order banning entry to the US by citizens of seven Muslim-majority countries (and indefinitely halting refugees from Syria), thousands of protesters stormed John F. Kennedy airport in New York City, and other airports around the country, proclaiming their solidarity with Muslims. Countless more, I among them, watched on television as the events unfolded.It was a watershed moment for American Muslims like me, who had grown up believing that people would judge us for our religion. The sky was blue, water was wet, and other Americans looked down on Islam. These were facts we internalized. It\\'s why for most of my life, I\\'ve lived as a white-passing, mixed-raced Muslim: green eyes, blonde hair, fair skin. Despite my father\\'s Middle Eastern and Asian ancestry, I look a lot like my white, Catholic-born mother: the basic girl-next-door.But for me, the day Trump instituted the travel ban and Americans from all walks of life fought back against it was doubly profound: it\\'s the day I stopped hiding. It\\'s the day I re-opened the word document on my computer and started writing the personal story I\\'d been too afraid to explore for 10 years. It\\'s the day I officially began writing my novel \"All-American Muslim Girl\" -- about Islamophobia, white privilege, identity and erasure. Because of my appearance, the Islamophobia I\\'ve experienced over the years is very different from that of my Muslim cousins, aunts and friends. People don\\'t stare at me at the grocery store or make comments about my appearance or lack of hijab while I\\'m working out. I don\\'t get told in parking lots to \"go back where I came from.\" I\\'ve never had somebody yell \"Allahu akbar!\" at me in the hallway at school. All of these things have happened to people I love. Unlike them, I almost never feel in danger because of my religion.  Instead, I\\'m subject to microaggressions: people\\'s jaws dropping when they find out I\\'m Muslim. Incredulous comments like, \"You? But you look so American!\" -- as if Muslims can\\'t be Americans, too. People staring at me quizzically, asking of my heritage, \"So, like...what are you?\" And, of course, the endless questions about whether I pray, whether I drink, whether I eat bacon, whether I support various international policies -- as if they\\'re trying to figure out whether they can trust me.It\\'s not just the comments. When I was in elementary school, in the thick of years spent keeping my family\\'s religion silent — a privilege obviously afforded to us by virtue of pale skin, stemming from my father\\'s Circassian heritage -- my best friend\\'s family didn\\'t know we were Muslims. Soon after my friend\\'s mother found out, my friend sheepishly told me I was no longer able to come over to her house. But why? I hadn\\'t done anything wrong: had never been impolite, had never broken anything or raised my voice. My friend shrugged, unable to provide an answer. Her mom just didn\\'t feel comfortable having me over any longer.Years of hiding has produced a tension between the two sides of myself: the side who \"came out\" after the Muslim ban and started enthusiastically, publicly claiming my \"Muslimness\"...and the side that had built a life where people were completely unaware of my religion, my heritage, and family, and the fact that, yes, I do actually pray every day. Yes, in Arabic.When those people -- the ones who I work with, who I regularly but casually chat with in the world — find out about the title of my book, I typically dread the reaction. It\\'s always the same:\"But...you\\'re not Muslim, right?\"Before writing the book, my father\\'s words would always ring in my ears: \"People will treat you differently if they know you\\'re Muslim...\"But I wanted people to know I was a Muslim. I\\'m proud of my heritage, and I feel honored to practice such a beautiful -- if wildly misunderstood -- religion. My novel debunks myths about Islam by gently educating people — through the eyes of a young white-passing 16-year-old who is exploring her family\\'s religion herself for the first time -- but it was important to me not to \"justify\" the religion for Western eyes. Ironically, after I started publicly identifying as Muslim, I was especially nervous about the reaction of the Muslim community. After all, I don\\'t wear a hijab, I\\'ve enjoyed many a bottle of Cabernet in my time, I rarely attend mosque and my mother-in-law is even an Episcopalian nun. (That\\'s a different story for another time.) Forget my appearance: my lifestyle disqualified me from being seen as a good Muslim. But then I realized I was falling into my own trap: the idea that Muslims are a monolith, and the idea that it\\'s okay for anybody to believe that because you\\'re a Muslim, you can only be one way.  There is no such thing as One Muslim. We are the world\\'s second-largest religion, and that includes Muslims of every nationality, skin color, ethnicity, lifestyle and background -- yes, even basic American girls.The worry that you\\'re not \"good enough\" is a pervasive one, and as I\\'ve formed bonds with Muslim sisters outside of my family, I\\'ve realized I\\'m not the only one who struggles with feeling caught between two worlds or who desperately wants to be accepted for who she is. Luckily, the support from the Muslim community for my book -- and for me -- has been heartening and wonderfully overwhelming.So, yes, I\\'m an all-American Muslim Girl. I know the lyrics to every Pearl Jam song, and I pray multiple times a day. I choose not to wear hijab, and I choose to eat as much of my Amto\\'s koosa as I can fit into my stomach when I\\'m home visiting family. Like my Muslim sisters, I am complex, and I am empowered and I adore my religion.I am enough, exactly as I am. '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpMFf09GHE0k"
      },
      "source": [
        "soup.get_text(se)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfDWUtDr34PX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8effd48a-85c4-40a8-f15f-e296bb896d19"
      },
      "source": [
        "len(articles)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKda-PyIET46"
      },
      "source": [
        "PATH = '/content/article_content'\n",
        "i = 0 #article names start at 0\n",
        "\n",
        "for article in articles:\n",
        "  response = requests.get(article)\n",
        "  content = response.text\n",
        "    #soup\n",
        "  soup = BeautifulSoup(content, 'html.parser')\n",
        "  text_list = [x.get_text(separator='\\n') for x in soup.find_all('div', {'class': 'afe4286c'})]\n",
        "\n",
        "  with open(PATH + f'article_{i}.txt', 'wb') as f:\n",
        "    f.write(str(text_list).encode())\n",
        "  i+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgGlAM2X34Pc"
      },
      "source": [
        "### Ingest the text files generated via web scraping into a corpus and print the corpus statistics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk-ZlwTo-M4W"
      },
      "source": [
        "def corpus_stats(corpus):\n",
        "  print('Corpus Statistics')\n",
        "  print('Number of documents: ' + str(len(corpus.fileids())))\n",
        "  print('Number of paragraphs: ' + str(len(corpus.paras())))\n",
        "  print('Number of sentences: ' + str(len(corpus.sents())))\n",
        "  print('Number of words: ' + str(len(corpus.words())))\n",
        "  print('Vocabulary: ' + str(len(set(w.lower() for w in corpus.words()))))\n",
        "  print('Avg chars per word: ' + str(round(len(corpus.raw())/len(corpus.words()),1)))\n",
        "  print('Avg words per sentence: ' + str(round(len(corpus.words())/len(corpus.sents()),1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmybAnNB34Pf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d62e594-1fc0-4260-873d-1e33256c3d15"
      },
      "source": [
        "DOC_PATTERN = r'.*\\.txt'\n",
        "art_corpus = PlaintextCorpusReader('/content/article_content', DOC_PATTERN)\n",
        "corpus_stats(art_corpus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corpus Statistics\n",
            "Number of documents: 14\n",
            "Number of paragraphs: 14\n",
            "Number of sentences: 395\n",
            "Number of words: 14102\n",
            "Vocabulary: 3058\n",
            "Avg chars per word: 5.0\n",
            "Avg words per sentence: 35.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGP_4yfR34Pi"
      },
      "source": [
        "### Parse the O'Reilly Radar RSS feed below, extract the text from each post, and save it to a text file.\n",
        "\n",
        "The content of each post contains HTML tags. Strip those out using the same approach you used for web scraping so that only text is saved to the files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDbqkFCF34Pl"
      },
      "source": [
        "feed = 'http://feeds.feedburner.com/oreilly/radar/atom'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-a9JgWH34Po"
      },
      "source": [
        "parsed = feedparser.parse(feed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZENggYIzAnz",
        "outputId": "4188aefe-391c-408e-db88-5fb3878b9eb0"
      },
      "source": [
        "len(parsed.entries)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmEicv0i3DKd",
        "outputId": "67b76167-e9b1-4ddd-c5c3-9e6b69719ed5"
      },
      "source": [
        "posts = parsed.entries\n",
        "posts[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'author': '',\n",
              " 'authors': [{}],\n",
              " 'comments': 'https://www.oreilly.com/radar/oreillys-top-20-live-online-training-courses-of-2020/#respond',\n",
              " 'content': [{'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
              "   'language': None,\n",
              "   'type': 'text/html',\n",
              "   'value': '<p>2020 has been a year of great challenges for so many, but it’s not all negative. Around the world, organizations and their workforces have risen to the occasion, recognizing the importance of expanding their knowledge, taking on new tasks, and bettering themselves both personally and professionally. With the uptick in virtual conferencing, remote work, and, for some, reentering the job market, new technology adoption was accelerated, driving the workforce to build new skills. While 2020 was the year of the global COVID-19 pandemic, it will also be commemorated as the year online learning prevailed. As vaccine development persists and life gets back to normal, with it will come a more future-proof workforce ready to share their new knowledge with the world.&nbsp;</p>\\n\\n\\n\\n<p>Since the onset of the pandemic, online courses and programs have seen dramatic spikes in consumption and enrollment, and O’Reilly has been no different. A big contributor to O’Reilly’s continued success during these unprecedented times has been its live virtual training courses. This year, more than 900,000 users have registered for live events through O’Reilly online learning—a 96% increase from last year. This functionality also allowed O’Reilly to introduce its <a href=\"https://www.oreilly.com/pub/pr/3299\">Superstream Series</a>, a new lineup of virtual conferences featuring expert speakers delivering talks and training sessions on the most important topics and emerging trends in technology.&nbsp;</p>\\n\\n\\n\\n<p>So what are the trends driving this uptick in learning? Companies are increasingly interested in understanding how to successfully adjust to remote work and effectively manage time. And individual O’Reilly members are looking to build and expand on their technical skills in everything from software architecture and microservices to AI and programming languages. But which topics are the brightest minds in technology most focused on? We’ve compiled the top 20 live online training courses of 2020 to shed some light on what those in the know want to know.</p>\\n\\n\\n\\n<p><strong>Top 20 live online training courses of 2020</strong></p>\\n\\n\\n\\n<ol><li>Software Architecture Superstream Series: Software Architecture Fundamentals</li><li>Microservice Fundamentals</li><li>Kubernetes in Three Weeks</li><li>O&#8217;Reilly Infrastructure &amp; Ops Superstream: SRE Edition</li><li>Fundamentals of Learning: Learn Faster and Better Using Neuroscience</li><li>Strata Data &amp; AI Superstream Series: Deep Learning</li><li>Microservices Architecture and Design</li><li>Machine Learning from Scratch</li><li>Leadership Communication Skills for Managers</li><li>Design Patterns Boot Camp</li><li>Strata Data and AI Superstream</li><li>Getting Started with Python 3</li><li>Python Data Science Full Throttle with Paul Deitel: Introductory Artificial Intelligence (AI), Big Data, and Cloud Case Studies</li><li>Getting Started with Amazon Web Services (AWS)</li><li>Architectural Katas</li><li>Introduction to Critical Thinking</li><li>Python Full Throttle with Paul Deitel</li><li>Microservice Collaboration</li><li>OSCON Open Source Software Superstream Series: Live Coding—Go, Rust, and Python</li><li>SOLID Principles of Object-Oriented and Agile Design</li></ol>\\n\\n\\n\\n<p>For a more in-depth analysis of the hot technology topics of 2020, based on data from O’Reilly online learning, stay tuned for our upcoming report, <em>Wrapping Up 2020 (and What to Expect for 2021): Trends on O’Reilly online learning</em>. </p>\\n<img alt=\"\" height=\"1\" src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/FiKCgaU6NNo\" width=\"1\" />'}],\n",
              " 'feedburner_origlink': 'https://www.oreilly.com/radar/oreillys-top-20-live-online-training-courses-of-2020/',\n",
              " 'guidislink': False,\n",
              " 'id': 'https://www.oreilly.com/radar/?p=13546',\n",
              " 'link': 'http://feedproxy.google.com/~r/oreilly/radar/atom/~3/FiKCgaU6NNo/',\n",
              " 'links': [{'href': 'http://feedproxy.google.com/~r/oreilly/radar/atom/~3/FiKCgaU6NNo/',\n",
              "   'rel': 'alternate',\n",
              "   'type': 'text/html'}],\n",
              " 'published': 'Wed, 09 Dec 2020 14:36:14 +0000',\n",
              " 'published_parsed': time.struct_time(tm_year=2020, tm_mon=12, tm_mday=9, tm_hour=14, tm_min=36, tm_sec=14, tm_wday=2, tm_yday=344, tm_isdst=0),\n",
              " 'slash_comments': '0',\n",
              " 'summary': '2020 has been a year of great challenges for so many, but it’s not all negative. Around the world, organizations and their workforces have risen to the occasion, recognizing the importance of expanding their knowledge, taking on new tasks, and bettering themselves both personally and professionally. With the uptick in virtual conferencing, remote work, and, [&#8230;]',\n",
              " 'summary_detail': {'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
              "  'language': None,\n",
              "  'type': 'text/html',\n",
              "  'value': '2020 has been a year of great challenges for so many, but it’s not all negative. Around the world, organizations and their workforces have risen to the occasion, recognizing the importance of expanding their knowledge, taking on new tasks, and bettering themselves both personally and professionally. With the uptick in virtual conferencing, remote work, and, [&#8230;]'},\n",
              " 'tags': [{'label': None, 'scheme': None, 'term': \"O'Reilly Insights\"},\n",
              "  {'label': None, 'scheme': None, 'term': \"O'Reilly Learning\"}],\n",
              " 'title': 'O’Reilly’s top 20 live online training courses of 2020',\n",
              " 'title_detail': {'base': 'http://feeds.feedburner.com/oreilly/radar/atom',\n",
              "  'language': None,\n",
              "  'type': 'text/plain',\n",
              "  'value': 'O’Reilly’s top 20 live online training courses of 2020'},\n",
              " 'wfw_commentrss': 'https://www.oreilly.com/radar/oreillys-top-20-live-online-training-courses-of-2020/feed/'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "fvaAWHEB5IbS",
        "outputId": "832cf827-1a0f-4258-84df-eeff1fa72600"
      },
      "source": [
        "posts[0].content[0].value"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<p>2020 has been a year of great challenges for so many, but it’s not all negative. Around the world, organizations and their workforces have risen to the occasion, recognizing the importance of expanding their knowledge, taking on new tasks, and bettering themselves both personally and professionally. With the uptick in virtual conferencing, remote work, and, for some, reentering the job market, new technology adoption was accelerated, driving the workforce to build new skills. While 2020 was the year of the global COVID-19 pandemic, it will also be commemorated as the year online learning prevailed. As vaccine development persists and life gets back to normal, with it will come a more future-proof workforce ready to share their new knowledge with the world.&nbsp;</p>\\n\\n\\n\\n<p>Since the onset of the pandemic, online courses and programs have seen dramatic spikes in consumption and enrollment, and O’Reilly has been no different. A big contributor to O’Reilly’s continued success during these unprecedented times has been its live virtual training courses. This year, more than 900,000 users have registered for live events through O’Reilly online learning—a 96% increase from last year. This functionality also allowed O’Reilly to introduce its <a href=\"https://www.oreilly.com/pub/pr/3299\">Superstream Series</a>, a new lineup of virtual conferences featuring expert speakers delivering talks and training sessions on the most important topics and emerging trends in technology.&nbsp;</p>\\n\\n\\n\\n<p>So what are the trends driving this uptick in learning? Companies are increasingly interested in understanding how to successfully adjust to remote work and effectively manage time. And individual O’Reilly members are looking to build and expand on their technical skills in everything from software architecture and microservices to AI and programming languages. But which topics are the brightest minds in technology most focused on? We’ve compiled the top 20 live online training courses of 2020 to shed some light on what those in the know want to know.</p>\\n\\n\\n\\n<p><strong>Top 20 live online training courses of 2020</strong></p>\\n\\n\\n\\n<ol><li>Software Architecture Superstream Series: Software Architecture Fundamentals</li><li>Microservice Fundamentals</li><li>Kubernetes in Three Weeks</li><li>O&#8217;Reilly Infrastructure &amp; Ops Superstream: SRE Edition</li><li>Fundamentals of Learning: Learn Faster and Better Using Neuroscience</li><li>Strata Data &amp; AI Superstream Series: Deep Learning</li><li>Microservices Architecture and Design</li><li>Machine Learning from Scratch</li><li>Leadership Communication Skills for Managers</li><li>Design Patterns Boot Camp</li><li>Strata Data and AI Superstream</li><li>Getting Started with Python 3</li><li>Python Data Science Full Throttle with Paul Deitel: Introductory Artificial Intelligence (AI), Big Data, and Cloud Case Studies</li><li>Getting Started with Amazon Web Services (AWS)</li><li>Architectural Katas</li><li>Introduction to Critical Thinking</li><li>Python Full Throttle with Paul Deitel</li><li>Microservice Collaboration</li><li>OSCON Open Source Software Superstream Series: Live Coding—Go, Rust, and Python</li><li>SOLID Principles of Object-Oriented and Agile Design</li></ol>\\n\\n\\n\\n<p>For a more in-depth analysis of the hot technology topics of 2020, based on data from O’Reilly online learning, stay tuned for our upcoming report, <em>Wrapping Up 2020 (and What to Expect for 2021): Trends on O’Reilly online learning</em>. </p>\\n<img alt=\"\" height=\"1\" src=\"http://feeds.feedburner.com/~r/oreilly/radar/atom/~4/FiKCgaU6NNo\" width=\"1\" />'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stKMvWwB3hDU"
      },
      "source": [
        "for post in posts:\n",
        "  print(post.summary)\n",
        "  print('--------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukwvQ4xL3uTn"
      },
      "source": [
        "PATH = '/content/rss_posts/'\n",
        "\n",
        "for i, post in enumerate(posts):\n",
        "  text = post.summary\n",
        "\n",
        "  with open(PATH + f'post_{i}.txt', 'wb') as f:\n",
        "    f.write(text.encode())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqK4w9sa34Pr"
      },
      "source": [
        "### Ingest the text files generated via RSS parsing into a corpus and print the corpus statistics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGIkaFtS9R-y"
      },
      "source": [
        "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
        "\n",
        "DOC_PATTERN = r'.*\\.txt'\n",
        "new_corpus = PlaintextCorpusReader('/content/rss_posts', DOC_PATTERN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd4x36-934Ps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebcae505-4563-4ed1-9a4f-ba3b1f7ffc84"
      },
      "source": [
        "corpus_stats(new_corpus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corpus Statistics\n",
            "Number of documents: 60\n",
            "Number of paragraphs: 60\n",
            "Number of sentences: 197\n",
            "Number of words: 4515\n",
            "Vocabulary: 1467\n",
            "Avg chars per word: 4.9\n",
            "Avg words per sentence: 22.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BDwjO8t34Pw"
      },
      "source": [
        "### Make an API call to the Hacker News API to retrieve their Ask, Show, and Job category items. \n",
        "\n",
        "- URL: https://hacker-news.firebaseio.com/v0/askstories.json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7vyWOSN34Px"
      },
      "source": [
        "url = 'https://hacker-news.firebaseio.com/v0/askstories.json'\n",
        "\n",
        "response = requests.get(url).json()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnywkuqcJIq9",
        "outputId": "35860e8e-4dba-4966-92f5-633b4ff0498d"
      },
      "source": [
        "len(response)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "92"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjPYWY0MLhtG",
        "outputId": "51684375-a353-417b-c305-72903fea5252"
      },
      "source": [
        "#need ask, show and job\n",
        "ids = []\n",
        "for cat in ['ask', 'show', 'job']:\n",
        "  url = f'https://hacker-news.firebaseio.com/v0/{cat}stories.json'\n",
        "  response = requests.get(url)\n",
        "  print(response)\n",
        "  print(f'Adding {len(response.json())}, from {cat}stories')\n",
        "  ids.extend(response.json())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Response [200]>\n",
            "Adding 92, from askstories\n",
            "<Response [200]>\n",
            "Adding 40, from showstories\n",
            "<Response [200]>\n",
            "Adding 60, from jobstories\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjFrvYsCREJL",
        "outputId": "d9df8932-0774-401a-d20a-73dab3d8f56a"
      },
      "source": [
        "len(ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "192"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEasqCkr34P0"
      },
      "source": [
        "### Once you have retrieved the item IDs from the URL above, retrieve each item by adding the item ID to the URL below, extract the item's text property, and save the text from each item to disk as its own document.\n",
        "\n",
        "- URL: https://hacker-news.firebaseio.com/v0/item/ITEM_ID_HERE.json\n",
        "\n",
        "The content of some items may contain HTML tags. Strip those out using the same approach you used for web scraping so that only text is saved to the files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "O17V33ggRg5X",
        "outputId": "2d887d7b-f6f0-402e-e33a-ec22058af818"
      },
      "source": [
        "url = f'https://hacker-news.firebaseio.com/v0/item/{ids[0]}.json'\n",
        "response = requests.get(url).json()\n",
        "soup = BeautifulSoup(response['text'])\n",
        "soup.text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I love asking new colleagues this question, figured I would open it here as well.What are you surprised isn’t being worked on more?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Vp7yfWB34P1"
      },
      "source": [
        "PATH = '/content/api_articles'\n",
        "\n",
        "for i, id_ in enumerate(ids):\n",
        "  url = f'https://hacker-news.firebaseio.com/v0/item/{id_}.json'\n",
        "  response = requests.get(url)\n",
        "  if 'text' in response.json().keys():\n",
        "    soup = BeautifulSoup(response.json()['text'], 'html.parser')\n",
        "    text = soup.text\n",
        "    with open(PATH + f'article_{i}.txt', 'wb') as f:\n",
        "      f.write(text.encode())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hw9-v8sK34P5"
      },
      "source": [
        "### Ingest the text files generated via API into a corpus and print the corpus statistics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcsiPdkx34P7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b871a39-626b-4bbf-fb72-528e9992cbab"
      },
      "source": [
        "DOC_PATTERN = r'.*\\.txt'\n",
        "corpus = PlaintextCorpusReader(PATH, DOC_PATTERN)\n",
        "corpus_stats(corpus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corpus Statistics\n",
            "Number of documents: 82\n",
            "Number of paragraphs: 82\n",
            "Number of sentences: 299\n",
            "Number of words: 8881\n",
            "Vocabulary: 2178\n",
            "Avg chars per word: 4.8\n",
            "Avg words per sentence: 29.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3woSphmRUHpK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}