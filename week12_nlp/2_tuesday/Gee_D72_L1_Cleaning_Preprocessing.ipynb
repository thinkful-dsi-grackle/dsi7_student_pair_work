{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "Gee_D72_L1_Cleaning_Preprocessing.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iCUbt7u4JIO"
      },
      "source": [
        "# Text Data Cleaning and Preprocessing Assignment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvkxhdpUhQ06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5370004c-f441-42ce-e221-7f6cc38edc2c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuqMJsi-4JIS"
      },
      "source": [
        "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
        "from nltk import sent_tokenize\n",
        "from nltk import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClSeqgAnjes4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f949d2af-133e-4272-ebb6-c4be8f58afc1"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('averaged_perceptron_tagger')\r\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCY5p4L54JIY"
      },
      "source": [
        "### Read the O'Reilly RSS plain text file articles into a corpus using the NLTK's PlaintextCorpusReader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmNkoVRZ4JIc"
      },
      "source": [
        "PATH = '/content/drive/MyDrive/python_for_data_scientists/rss_info'\r\n",
        "DOC_PATTERN = r'.*\\.txt'\r\n",
        "rss = PlaintextCorpusReader(PATH , DOC_PATTERN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJI6AbGA4JIg"
      },
      "source": [
        "### Iterate through the fileids in the corpus, extract the raw text of each document, and store them in a list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UL7Cjcby4JIi"
      },
      "source": [
        "docs = []\r\n",
        "for doc in rss.fileids():\r\n",
        "  doc = rss.raw(doc)\r\n",
        "  docs.append(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwJ4xVjkmBMO"
      },
      "source": [
        "docs1 = [rss.raw(fileid) for fileid in rss.fileids()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTHvyRuPOSC2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d24e04b-7e1f-4ed0-fcaa-5830b0268d3e"
      },
      "source": [
        "print(len(docs))\r\n",
        "print(len(docs1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60\n",
            "60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7JuwNTW4JIn"
      },
      "source": [
        "### Sentence tokenize each document in the list of documents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zbqurmN4JIp"
      },
      "source": [
        "sents = []\r\n",
        "for sent in docs:\r\n",
        "  sent = sent_tokenize(sent) \r\n",
        "  sents.append(sent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuRdkyPvmZ_0"
      },
      "source": [
        "sents1 = [sent_tokenize(doc) for doc in docs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3T0sNPTW9aS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60072afe-5bfb-478a-9cb3-6f9a2dfbb6ed"
      },
      "source": [
        "print(len(sents))\r\n",
        "print(len(sents1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60\n",
            "60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqT7V6zZ4JIu"
      },
      "source": [
        "### Word tokenize each sentence within each document.\n",
        "\n",
        "You should end up with a nested list structure where the outer list contains all the sentences in each document and the inner list contains the tokenized sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJEYPvTnmwRv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a977923-252d-45f6-a524-2239330eb6c8"
      },
      "source": [
        "sent = sents[0]\r\n",
        "tokenized = word_tokenize(sent[0])\r\n",
        "print(sent)\r\n",
        "print(tokenized)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['2020 has been a year of great challenges for so many, but it’s not all negative.', 'Around the world, organizations and their workforces have risen to the occasion, recognizing the importance of expanding their knowledge, taking on new tasks, and bettering themselves both personally and professionally.', 'With the uptick in virtual conferencing, remote work, and, [&#8230;]']\n",
            "['2020', 'has', 'been', 'a', 'year', 'of', 'great', 'challenges', 'for', 'so', 'many', ',', 'but', 'it', '’', 's', 'not', 'all', 'negative', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17JMEoHe4JIv"
      },
      "source": [
        "token_words = []\r\n",
        "for sent_ in sents:\r\n",
        "  temp = []\r\n",
        "  for sent in sent_:\r\n",
        "    temp.append(word_tokenize(sent))\r\n",
        "  token_words.append(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7Er4D4pmxhU"
      },
      "source": [
        "word_tokens = [[word_tokenize(sent) for sent in doc] for doc in sents]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjuLeZlqf3fN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74978599-172f-411a-fba0-5a1aeb561398"
      },
      "source": [
        "print(len(token_words))\r\n",
        "print(len(word_tokens))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60\n",
            "60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pk1r_y4C4JIz"
      },
      "source": [
        "### Tag each token with its part of speech."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmDs9hX6uWjp"
      },
      "source": [
        "tag = []\r\n",
        "for words in token_words:\r\n",
        "  temp = []\r\n",
        "  for word in words:\r\n",
        "    temp.append(pos_tag(word))\r\n",
        "  tag.append(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFj43vm6n6Ga"
      },
      "source": [
        "tag1 = [[pos_tag(word) for word in words] for words in word_tokens]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cAm5ch1p4jU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "441f06d4-e047-44c7-eeb5-f651b9c3f098"
      },
      "source": [
        "print(len(tag))\r\n",
        "print(len(tag1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60\n",
            "60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmIltOA44JI5"
      },
      "source": [
        "### Word tokenize the raw text of each document and remove stop words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVUcQFkJ4JI7"
      },
      "source": [
        "tok = tokenized[0]\r\n",
        "\r\n",
        "no_stop_ = []\r\n",
        "for word in tok:\r\n",
        "  lower = []\r\n",
        "  word = word.lower()\r\n",
        "  lower.append(word)\r\n",
        "  for low in lower:\r\n",
        "    if low not in stopwords.words('english'):\r\n",
        "      no_stop_.append(low)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ByAvzt51Cpy"
      },
      "source": [
        "no_stop = []\r\n",
        "for doc in docs:\r\n",
        "  temp = []\r\n",
        "  for token in word_tokenize(doc):\r\n",
        "    if token.lower() not in stopwords.words('english'):\r\n",
        "      temp.append(token)\r\n",
        "  no_stop.append(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpcPYaFW0rjg"
      },
      "source": [
        "no_stop1 = [[token.lower() for token in word_tokenize(doc) if token.lower() not in stopwords.words('english')] for doc in docs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaVsT1zP0-Ng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf8e4542-4684-4cff-f13d-3ace45a3e43e"
      },
      "source": [
        "print(len(no_stop))\r\n",
        "print(len(no_stop1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60\n",
            "60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAZggM574JI_"
      },
      "source": [
        "### For every document, stem all the words in the document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaP5e7Qy4DCb"
      },
      "source": [
        "stemmer = SnowballStemmer('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PE-dl2864E8h"
      },
      "source": [
        "stemmed = []\r\n",
        "for doc in docs:\r\n",
        "  temp = []\r\n",
        "  for token in word_tokenize(doc):\r\n",
        "    temp.append(stemmer.stem(token))\r\n",
        "  stemmed.append(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDCxYOsKDkCZ"
      },
      "source": [
        "stemmed1 = [[stemmer.stem(token) for token in word_tokenize(doc)] for doc in docs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgLS7PPD4JJB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15d7b742-11a9-4883-d255-e9a83e813539"
      },
      "source": [
        "print(len(stemmed))\r\n",
        "print(len(stemmed1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60\n",
            "60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2N4mHrZ4JJQ"
      },
      "source": [
        "### Iterate through each document, computing and printing the following document statistics for each.\n",
        "\n",
        "- Number of sentences\n",
        "- Average words per sentence\n",
        "- Vocabulary\n",
        "- Lexical Diversity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "7kBjbVZb4JJR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48ae155d-c5cf-41be-a1d1-f350affeec74"
      },
      "source": [
        "for doc in docs:\r\n",
        "  sents = sent_tokenize(doc)\r\n",
        "  word_tokens = [word_tokenize(sent) for sent in sents]\r\n",
        "  num_sents = len(sents)\r\n",
        "  avg_words_per_sent = round(sum([len(sent) for sent in word_tokens]) / num_sents,2)\r\n",
        "  vocab = len(set([word.lower() for word in word_tokenize(doc)]))\r\n",
        "  lex_div = round(vocab / len(word_tokenize(doc)),2)\r\n",
        "  print(f'Number of sentences:               {num_sents}')\r\n",
        "  print(f'Avg. number of words per sentence: {avg_words_per_sent}')\r\n",
        "  print(f'Vocabulary Count:                  {vocab}')\r\n",
        "  print(f'Lexicon diversity:                 {lex_div}')\r\n",
        "  print('*-*-*-*-*')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sentences:               3\n",
            "Avg. number of words per sentence: 24.33\n",
            "Vocabulary Count:                  57\n",
            "Lexicon diversity:                 0.78\n",
            "*-*-*-*-*\n",
            "Number of sentences:               3\n",
            "Avg. number of words per sentence: 25.0\n",
            "Vocabulary Count:                  58\n",
            "Lexicon diversity:                 0.77\n",
            "*-*-*-*-*\n",
            "Number of sentences:               13\n",
            "Avg. number of words per sentence: 7.62\n",
            "Vocabulary Count:                  57\n",
            "Lexicon diversity:                 0.58\n",
            "*-*-*-*-*\n",
            "Number of sentences:               3\n",
            "Avg. number of words per sentence: 31.67\n",
            "Vocabulary Count:                  53\n",
            "Lexicon diversity:                 0.56\n",
            "*-*-*-*-*\n",
            "Number of sentences:               3\n",
            "Avg. number of words per sentence: 25.0\n",
            "Vocabulary Count:                  53\n",
            "Lexicon diversity:                 0.71\n",
            "*-*-*-*-*\n",
            "Number of sentences:               4\n",
            "Avg. number of words per sentence: 20.25\n",
            "Vocabulary Count:                  53\n",
            "Lexicon diversity:                 0.65\n",
            "*-*-*-*-*\n",
            "Number of sentences:               2\n",
            "Avg. number of words per sentence: 35.0\n",
            "Vocabulary Count:                  53\n",
            "Lexicon diversity:                 0.76\n",
            "*-*-*-*-*\n",
            "Number of sentences:               2\n",
            "Avg. number of words per sentence: 35.0\n",
            "Vocabulary Count:                  56\n",
            "Lexicon diversity:                 0.8\n",
            "*-*-*-*-*\n",
            "Number of sentences:               3\n",
            "Avg. number of words per sentence: 22.33\n",
            "Vocabulary Count:                  57\n",
            "Lexicon diversity:                 0.85\n",
            "*-*-*-*-*\n",
            "Number of sentences:               2\n",
            "Avg. number of words per sentence: 40.5\n",
            "Vocabulary Count:                  60\n",
            "Lexicon diversity:                 0.74\n",
            "*-*-*-*-*\n",
            "Number of sentences:               1\n",
            "Avg. number of words per sentence: 111.0\n",
            "Vocabulary Count:                  61\n",
            "Lexicon diversity:                 0.55\n",
            "*-*-*-*-*\n",
            "Number of sentences:               4\n",
            "Avg. number of words per sentence: 19.25\n",
            "Vocabulary Count:                  59\n",
            "Lexicon diversity:                 0.77\n",
            "*-*-*-*-*\n",
            "Number of sentences:               3\n",
            "Avg. number of words per sentence: 27.33\n",
            "Vocabulary Count:                  59\n",
            "Lexicon diversity:                 0.72\n",
            "*-*-*-*-*\n",
            "Number of sentences:               4\n",
            "Avg. number of words per sentence: 21.75\n",
            "Vocabulary Count:                  58\n",
            "Lexicon diversity:                 0.67\n",
            "*-*-*-*-*\n",
            "Number of sentences:               2\n",
            "Avg. number of words per sentence: 35.5\n",
            "Vocabulary Count:                  57\n",
            "Lexicon diversity:                 0.8\n",
            "*-*-*-*-*\n",
            "Number of sentences:               3\n",
            "Avg. number of words per sentence: 22.0\n",
            "Vocabulary Count:                  47\n",
            "Lexicon diversity:                 0.71\n",
            "*-*-*-*-*\n",
            "Number of sentences:               2\n",
            "Avg. number of words per sentence: 34.5\n",
            "Vocabulary Count:                  52\n",
            "Lexicon diversity:                 0.75\n",
            "*-*-*-*-*\n",
            "Number of sentences:               2\n",
            "Avg. number of words per sentence: 45.5\n",
            "Vocabulary Count:                  56\n",
            "Lexicon diversity:                 0.62\n",
            "*-*-*-*-*\n",
            "Number of sentences:               3\n",
            "Avg. number of words per sentence: 23.33\n",
            "Vocabulary Count:                  54\n",
            "Lexicon diversity:                 0.77\n",
            "*-*-*-*-*\n",
            "Number of sentences:               2\n",
            "Avg. number of words per sentence: 36.5\n",
            "Vocabulary Count:                  54\n",
            "Lexicon diversity:                 0.74\n",
            "*-*-*-*-*\n",
            "Number of sentences:               4\n",
            "Avg. number of words per sentence: 17.25\n",
            "Vocabulary Count:                  52\n",
            "Lexicon diversity:                 0.75\n",
            "*-*-*-*-*\n",
            "Number of sentences:               4\n",
            "Avg. number of words per sentence: 18.5\n",
            "Vocabulary Count:                  60\n",
            "Lexicon diversity:                 0.81\n",
            "*-*-*-*-*\n",
            "Number of sentences:               3\n",
            "Avg. number of words per sentence: 25.0\n",
            "Vocabulary Count:                  54\n",
            "Lexicon diversity:                 0.72\n",
            "*-*-*-*-*\n",
            "Number of sentences:               3\n",
            "Avg. number of words per sentence: 25.33\n",
            "Vocabulary Count:                  59\n",
            "Lexicon diversity:                 0.78\n",
            "*-*-*-*-*\n",
            "Number of sentences:               2\n",
            "Avg. number of words per sentence: 38.5\n",
            "Vocabulary Count:                  54\n",
            "Lexicon diversity:                 0.7\n",
            "*-*-*-*-*\n",
            "Number of sentences:               3\n",
            "Avg. number of words per sentence: 24.0\n",
            "Vocabulary Count:                  58\n",
            "Lexicon diversity:                 0.81\n",
            "*-*-*-*-*\n",
            "Number of sentences:               3\n",
            "Avg. number of words per sentence: 22.67\n",
            "Vocabulary Count:                  51\n",
            "Lexicon diversity:                 0.75\n",
            "*-*-*-*-*\n",
            "Number of sentences:               4\n",
            "Avg. number of words per sentence: 22.0\n",
            "Vocabulary Count:                  56\n",
            "Lexicon diversity:                 0.64\n",
            "*-*-*-*-*\n",
            "Number of sentences:               2\n",
            "Avg. number of words per sentence: 41.0\n",
            "Vocabulary Count:                  56\n",
            "Lexicon diversity:                 0.68\n",
            "*-*-*-*-*\n",
            "Number of sentences:               4\n",
            "Avg. number of words per sentence: 17.0\n",
            "Vocabulary Count:                  52\n",
            "Lexicon diversity:                 0.76\n",
            "*-*-*-*-*\n",
            "Number of sentences:               3\n",
            "Avg. number of words per sentence: 26.33\n",
            "Vocabulary Count:                  50\n",
            "Lexicon diversity:                 0.63\n",
            "*-*-*-*-*\n",
            "Number of sentences:               5\n",
            "Avg. number of words per sentence: 15.4\n",
            "Vocabulary Count:                  56\n",
            "Lexicon diversity:                 0.73\n",
            "*-*-*-*-*\n",
            "Number of sentences:               4\n",
            "Avg. number of words per sentence: 18.5\n",
            "Vocabulary Count:                  57\n",
            "Lexicon diversity:                 0.77\n",
            "*-*-*-*-*\n",
            "Number of sentences:               4\n",
            "Avg. number of words per sentence: 21.5\n",
            "Vocabulary Count:                  61\n",
            "Lexicon diversity:                 0.71\n",
            "*-*-*-*-*\n",
            "Number of sentences:               4\n",
            "Avg. number of words per sentence: 19.0\n",
            "Vocabulary Count:                  56\n",
            "Lexicon diversity:                 0.74\n",
            "*-*-*-*-*\n",
            "Number of sentences:               1\n",
            "Avg. number of words per sentence: 89.0\n",
            "Vocabulary Count:                  59\n",
            "Lexicon diversity:                 0.66\n",
            "*-*-*-*-*\n",
            "Number of sentences:               4\n",
            "Avg. number of words per sentence: 21.0\n",
            "Vocabulary Count:                  57\n",
            "Lexicon diversity:                 0.68\n",
            "*-*-*-*-*\n",
            "Number of sentences:               4\n",
            "Avg. number of words per sentence: 19.5\n",
            "Vocabulary Count:                  50\n",
            "Lexicon diversity:                 0.64\n",
            "*-*-*-*-*\n",
            "Number of sentences:               1\n",
            "Avg. number of words per sentence: 79.0\n",
            "Vocabulary Count:                  55\n",
            "Lexicon diversity:                 0.7\n",
            "*-*-*-*-*\n",
            "Number of sentences:               3\n",
            "Avg. number of words per sentence: 28.0\n",
            "Vocabulary Count:                  58\n",
            "Lexicon diversity:                 0.69\n",
            "*-*-*-*-*\n",
            "Number of sentences:               3\n",
            "Avg. number of words per sentence: 23.33\n",
            "Vocabulary Count:                  51\n",
            "Lexicon diversity:                 0.73\n",
            "*-*-*-*-*\n",
            "Number of sentences:               3\n",
            "Avg. number of words per sentence: 29.33\n",
            "Vocabulary Count:                  60\n",
            "Lexicon diversity:                 0.68\n",
            "*-*-*-*-*\n",
            "Number of sentences:               5\n",
            "Avg. number of words per sentence: 16.0\n",
            "Vocabulary Count:                  56\n",
            "Lexicon diversity:                 0.7\n",
            "*-*-*-*-*\n",
            "Number of sentences:               3\n",
            "Avg. number of words per sentence: 23.0\n",
            "Vocabulary Count:                  53\n",
            "Lexicon diversity:                 0.77\n",
            "*-*-*-*-*\n",
            "Number of sentences:               4\n",
            "Avg. number of words per sentence: 19.5\n",
            "Vocabulary Count:                  57\n",
            "Lexicon diversity:                 0.73\n",
            "*-*-*-*-*\n",
            "Number of sentences:               3\n",
            "Avg. number of words per sentence: 31.33\n",
            "Vocabulary Count:                  55\n",
            "Lexicon diversity:                 0.59\n",
            "*-*-*-*-*\n",
            "Number of sentences:               4\n",
            "Avg. number of words per sentence: 19.75\n",
            "Vocabulary Count:                  59\n",
            "Lexicon diversity:                 0.75\n",
            "*-*-*-*-*\n",
            "Number of sentences:               3\n",
            "Avg. number of words per sentence: 26.0\n",
            "Vocabulary Count:                  59\n",
            "Lexicon diversity:                 0.76\n",
            "*-*-*-*-*\n",
            "Number of sentences:               4\n",
            "Avg. number of words per sentence: 20.75\n",
            "Vocabulary Count:                  52\n",
            "Lexicon diversity:                 0.63\n",
            "*-*-*-*-*\n",
            "Number of sentences:               4\n",
            "Avg. number of words per sentence: 18.5\n",
            "Vocabulary Count:                  51\n",
            "Lexicon diversity:                 0.69\n",
            "*-*-*-*-*\n",
            "Number of sentences:               3\n",
            "Avg. number of words per sentence: 23.0\n",
            "Vocabulary Count:                  45\n",
            "Lexicon diversity:                 0.65\n",
            "*-*-*-*-*\n",
            "Number of sentences:               3\n",
            "Avg. number of words per sentence: 27.0\n",
            "Vocabulary Count:                  55\n",
            "Lexicon diversity:                 0.68\n",
            "*-*-*-*-*\n",
            "Number of sentences:               3\n",
            "Avg. number of words per sentence: 24.67\n",
            "Vocabulary Count:                  54\n",
            "Lexicon diversity:                 0.73\n",
            "*-*-*-*-*\n",
            "Number of sentences:               2\n",
            "Avg. number of words per sentence: 38.0\n",
            "Vocabulary Count:                  54\n",
            "Lexicon diversity:                 0.71\n",
            "*-*-*-*-*\n",
            "Number of sentences:               3\n",
            "Avg. number of words per sentence: 22.67\n",
            "Vocabulary Count:                  54\n",
            "Lexicon diversity:                 0.79\n",
            "*-*-*-*-*\n",
            "Number of sentences:               3\n",
            "Avg. number of words per sentence: 25.67\n",
            "Vocabulary Count:                  58\n",
            "Lexicon diversity:                 0.75\n",
            "*-*-*-*-*\n",
            "Number of sentences:               4\n",
            "Avg. number of words per sentence: 20.75\n",
            "Vocabulary Count:                  58\n",
            "Lexicon diversity:                 0.7\n",
            "*-*-*-*-*\n",
            "Number of sentences:               5\n",
            "Avg. number of words per sentence: 18.2\n",
            "Vocabulary Count:                  56\n",
            "Lexicon diversity:                 0.62\n",
            "*-*-*-*-*\n",
            "Number of sentences:               4\n",
            "Avg. number of words per sentence: 16.75\n",
            "Vocabulary Count:                  53\n",
            "Lexicon diversity:                 0.79\n",
            "*-*-*-*-*\n",
            "Number of sentences:               2\n",
            "Avg. number of words per sentence: 35.0\n",
            "Vocabulary Count:                  52\n",
            "Lexicon diversity:                 0.74\n",
            "*-*-*-*-*\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}