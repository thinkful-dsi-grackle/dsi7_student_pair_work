{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "Copy of Day 29 Lecture 2 Assignment kalika barrett.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRVfAWX8cTwI"
      },
      "source": [
        "## Day 29 Lecture 2 Assignment\n",
        "\n",
        "In this assignment, we will learn about entropy and information gain in the ID3 algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KufburMWcTwI"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MiCqim1cTwK"
      },
      "source": [
        "tennis = pd.read_csv('https://tf-assets-prod.s3.amazonaws.com/tf-curric/data-science/tennis_decision.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ugm_tVeDcTwM",
        "outputId": "335eeb6c-adf3-4803-ee98-e14943a93c7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "tennis.count().T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Day         14\n",
              "Outlook     14\n",
              "Temp.       14\n",
              "Humidity    14\n",
              "Wind        14\n",
              "Decision    14\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42CeoZiTcTwN"
      },
      "source": [
        "Write a function to compute entropy given an input of a sequence of probabilities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPfNGt2vcTwO"
      },
      "source": [
        "#answer below:\n",
        "\n",
        "from math import log2\n",
        "\n",
        "# EXAMPLE SOLUTION\n",
        "def entropy_calc(df):\n",
        "  \n",
        "  dfSum = df['Yes'].sum()\n",
        "  dfTrue = dfSum\n",
        "  #probability of true\n",
        "  prob_yes =  df['Yes']['Overcast'] / dfSum * _\n",
        "  log2(df['Yes']['Overcast'] / dfSum) + df['Yes']['Sunny'] / dfSum * log2(dfSum / df['Yes']['Sunny']) + df['Yes']['Rain'] / dfSum * log2(dfSum / df['Yes']['Rain'] )\n",
        "  \n",
        "  dfDiff = df['No'].sum()\n",
        "  #probability of false\n",
        "  prob_not = dfTrue / dfDiff * log2(dfDiff / dfTrue) + df['Yes']['Sunny'] / dfDiff * log2(dfDiff / df['Yes']['Sunny'] + df['Yes']['Rain']) / dfDiff * log2(dfDiff / df['Yes']['Rain'] )\n",
        "\n",
        "  tot = dfSum + dfDiff\n",
        "  entropy = dfSum / tot * prob_yes + dfSum / dfDiff * prob_not\n",
        "  return entropy \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsTiwQkVcTwQ"
      },
      "source": [
        "Aggregate the tennis decision table for each value of each column. Start with Outlook below. Compute the weighted mean of the entropy for outlook (the weighted mean of the yes decision and the no decision)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "go7-SO9scTwR",
        "outputId": "90d46a7e-50fb-4e2c-970c-49153543baf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# answer below:\n",
        "a = pd.crosstab(tennis['Outlook'], tennis['Decision'])\n",
        "print(entropy_calc(a))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decision        No       Yes\n",
            "Outlook                     \n",
            "Overcast -2.486508 -1.343650\n",
            "Rain     -1.915079 -1.629365\n",
            "Sunny    -1.629365 -1.915079\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ARSIriLlRVM",
        "outputId": "30b94ba1-3954-4213-a953-8956459407b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "ID3_entropies(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "No     0.918296\n",
              "Yes    0.918296\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-t3UYlacTwS"
      },
      "source": [
        "Compute the weighted mean of the entropy for temperature, humidity and wind as well and decide based on these values which should be the first variable chosen for a split."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQybr84mk0k0"
      },
      "source": [
        "The Day should be the first node for our tree. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YJV05SKj0lZ",
        "outputId": "3ba84b89-8ab3-4707-d71c-ac4b884ce4ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "entropy_df = tennis.drop(columns='Decision')\n",
        "ID3_entropies(entropy_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Day         0.371232\n",
              "Outlook     0.918239\n",
              "Temp.       0.915452\n",
              "Humidity    1.000000\n",
              "Wind        0.985228\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbyWxoo4jO0R"
      },
      "source": [
        "# Github ID3_entropies retrieved from: https://gist.github.com/whitehaven/bbd408edca38de93637635b52d2bba89\n",
        "from collections import Counter\n",
        "\n",
        "def ID3_entropies(data_df):\n",
        "    \"\"\"\n",
        "    Takes pandas.DataFrame and returns a series with all non-index schemas' entropies calculated.\n",
        "    \n",
        "    It supports non-binary field types by calculating average entropy. Result series starts with the most productive decision level.\n",
        "    \"\"\"\n",
        "    def entropy_for_field(field):\n",
        "        entropy = 0\n",
        "        field_entry_count = len(field)\n",
        "\n",
        "        # get count of unique\n",
        "        field_counter = Counter(field)\n",
        "\n",
        "        # E( Si/S * E(pi*log2(pi)) )\n",
        "        for trait, count in field_counter.items():\n",
        "            p_T = count / field_entry_count\n",
        "            p_F = (field_entry_count - count) / field_entry_count\n",
        "\n",
        "            if p_T == 0 or p_F == 0:\n",
        "                entropy = 0\n",
        "                break\n",
        "            # Si/S * E(pi*log2(pi))\n",
        "            entropy += count / field_entry_count * (- (p_T * log2(p_T)) - (p_F * log2(p_F)))\n",
        "        return entropy\n",
        "    \n",
        "    data_df_entropy = {}\n",
        "    for field in data_df:\n",
        "        entropy_this_field = entropy_for_field(data_df[field])\n",
        "        data_df_entropy[field] = entropy_this_field\n",
        "\n",
        "    data_df_entropy_se = pd.Series(data_df_entropy)\n",
        "    #data_df_entropy_se.sort(inplace=True)\n",
        "    return data_df_entropy_se"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}