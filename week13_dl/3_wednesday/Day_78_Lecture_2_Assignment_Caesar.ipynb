{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "Day 78 Lecture 2 Assignment_Caesar.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vEszfzSgGvb"
      },
      "source": [
        "## Day 78 Lecture 2 Assignment\n",
        "\n",
        "In this assignment, we will learn about other optimization algorithms. We will create a neural network and try out the different optimization algorithms and compare their performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grVMFvpMgGvd"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJfwGXExgGvf"
      },
      "source": [
        "In this assignment, we will be using the cancer data that we have worked with in previous lessons. The pre-processed data is loaded below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itA0U381gGvg"
      },
      "source": [
        "cancer = pd.read_csv('https://tf-assets-prod.s3.amazonaws.com/tf-curric/data-science/cancer_processed.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocNzndc-gGvi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "3316f78f-769a-4963-b4c9-d1f6aa320db1"
      },
      "source": [
        "cancer.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>diagnosis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   radius_mean  texture_mean  ...  fractal_dimension_mean  diagnosis\n",
              "0        17.99         10.38  ...                 0.07871          M\n",
              "1        20.57         17.77  ...                 0.05667          M\n",
              "2        19.69         21.25  ...                 0.05999          M\n",
              "3        11.42         20.38  ...                 0.09744          M\n",
              "4        20.29         14.34  ...                 0.05883          M\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMyeFkQTgGvm"
      },
      "source": [
        "As you may recall, diagnosis is the target variable. One hot encode the diagnosis column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tCQR6LjgGvn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "afb36d0c-a01f-4ee3-9cb2-4768c0c64b20"
      },
      "source": [
        "# Answer below:\n",
        "cancer = pd.get_dummies(cancer, columns=[\"diagnosis\"], drop_first=True)\n",
        "cancer.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>diagnosis_M</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   radius_mean  texture_mean  ...  fractal_dimension_mean  diagnosis_M\n",
              "0        17.99         10.38  ...                 0.07871            1\n",
              "1        20.57         17.77  ...                 0.05667            1\n",
              "2        19.69         21.25  ...                 0.05999            1\n",
              "3        11.42         20.38  ...                 0.09744            1\n",
              "4        20.29         14.34  ...                 0.05883            1\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iI1eKNiACcjS",
        "outputId": "8fe1516a-d170-4d38-8d94-660863a9bdad"
      },
      "source": [
        "cancer.isnull().mean()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "radius_mean               0.0\n",
              "texture_mean              0.0\n",
              "perimeter_mean            0.0\n",
              "area_mean                 0.0\n",
              "smoothness_mean           0.0\n",
              "compactness_mean          0.0\n",
              "concavity_mean            0.0\n",
              "concave points_mean       0.0\n",
              "symmetry_mean             0.0\n",
              "fractal_dimension_mean    0.0\n",
              "diagnosis_M               0.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcJDxAb7gGvp"
      },
      "source": [
        "Split the data into train and test with 20% of the data in test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9DgU09lgGvq"
      },
      "source": [
        "# Answer below\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "\n",
        "x = cancer.drop(columns=[\"diagnosis_M\"])\n",
        "y = cancer.diagnosis_M\n",
        "\n",
        "X_train, X_test, y_train, y_test = tts(x, y, test_size=0.2)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eghtF43gGvk"
      },
      "source": [
        "Scale all other variables using the standard scaler."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7cjZatEgGvk"
      },
      "source": [
        "# Answer below:\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_ = scaler.fit_transform(X_train)\n",
        "X_test_ = scaler.transform(X_test)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0yacuVlCaiB",
        "outputId": "3cc85c72-3578-4bf9-eead-136c1c25a5cc"
      },
      "source": [
        "X_train_"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.7920755 ,  3.38089176, -0.83827145, ..., -1.07526553,\n",
              "         0.10654909, -0.64903418],\n",
              "       [-0.00646562, -0.77532424, -0.07162208, ..., -0.49304156,\n",
              "        -0.36015127, -0.55230755],\n",
              "       [ 0.11611181,  0.50207698,  0.10883725, ...,  0.01158966,\n",
              "         0.92594666, -0.91434151],\n",
              "       ...,\n",
              "       [-0.39369886, -0.26482995, -0.357854  , ...,  0.04600784,\n",
              "        -0.62022093,  0.76870187],\n",
              "       [ 0.093825  ,  1.79113331,  0.02809482, ..., -0.79850289,\n",
              "        -0.38508945, -1.19484874],\n",
              "       [ 0.14397031,  0.51839415,  0.23641028, ...,  0.9846624 ,\n",
              "         1.55652653,  0.86542851]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTOKHMqrgGvr"
      },
      "source": [
        "Generate a sequential model consisting of 5 layers. The layers should be of size 128, 64, 32, 32, 1. Use the appropriate activation for the output layer based on the type of prediction algorithm we are producing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuLbt7X2gGvs"
      },
      "source": [
        "# Answer below\n",
        "def build_model(opt, loss):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, activation=\"relu\", input_dim=X_train_.shape[1]))\n",
        "    model.add(Dense(64, activation=\"relu\"))\n",
        "    model.add(Dense(32, activation=\"relu\"))\n",
        "    model.add(Dense(32, activation=\"relu\"))\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "    model.compile(loss=loss, optimizer=opt, metrics=['msle', 'accuracy'])\n",
        "    return model"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLyq5KXtgGvt"
      },
      "source": [
        "Initialize a SGD optimizer with learning rate 0.05 and momentum 0.9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlNXLxoUgGvu"
      },
      "source": [
        "# Answer below:\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "sgd = SGD(learning_rate=0.05, momentum=0.9)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-O0YHk_gGvv"
      },
      "source": [
        "Compile and fit the model using the appropriate loss function and metric and use the optimizers defined above.\n",
        "\n",
        "batch size = 100, epochs = 200"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N17SrvYMHT1W"
      },
      "source": [
        "import time"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD9IZdHMgGvw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "529d5f12-a7b8-42ca-fe0e-1f2951a836b8"
      },
      "source": [
        "# Answer below:\n",
        "start = time.time()\n",
        "model_1 = build_model(opt=sgd, loss=\"mse\")\n",
        "m1_hist = model_1.fit(X_train_, y_train, epochs=200, batch_size=100, \n",
        "          verbose=1, validation_data=(X_test_, y_test))\n",
        "m1_time = time.time() - start"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "5/5 [==============================] - 1s 55ms/step - loss: 0.2572 - msle: 0.1375 - accuracy: 0.3593 - val_loss: 0.2355 - val_msle: 0.1252 - val_accuracy: 0.7807\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.2268 - msle: 0.1210 - accuracy: 0.8136 - val_loss: 0.2027 - val_msle: 0.1059 - val_accuracy: 0.7982\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1886 - msle: 0.0999 - accuracy: 0.8279 - val_loss: 0.1596 - val_msle: 0.0810 - val_accuracy: 0.8421\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1395 - msle: 0.0711 - accuracy: 0.8820 - val_loss: 0.1046 - val_msle: 0.0526 - val_accuracy: 0.9123\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.0877 - msle: 0.0441 - accuracy: 0.9417 - val_loss: 0.0670 - val_msle: 0.0341 - val_accuracy: 0.9211\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0550 - msle: 0.0280 - accuracy: 0.9364 - val_loss: 0.0557 - val_msle: 0.0283 - val_accuracy: 0.9298\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0455 - msle: 0.0228 - accuracy: 0.9446 - val_loss: 0.0529 - val_msle: 0.0267 - val_accuracy: 0.9211\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0401 - msle: 0.0197 - accuracy: 0.9452 - val_loss: 0.0520 - val_msle: 0.0262 - val_accuracy: 0.9211\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0359 - msle: 0.0177 - accuracy: 0.9491 - val_loss: 0.0507 - val_msle: 0.0253 - val_accuracy: 0.9211\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0309 - msle: 0.0151 - accuracy: 0.9584 - val_loss: 0.0494 - val_msle: 0.0245 - val_accuracy: 0.9211\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0374 - msle: 0.0188 - accuracy: 0.9507 - val_loss: 0.0482 - val_msle: 0.0237 - val_accuracy: 0.9211\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0293 - msle: 0.0144 - accuracy: 0.9631 - val_loss: 0.0483 - val_msle: 0.0240 - val_accuracy: 0.9298\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0354 - msle: 0.0174 - accuracy: 0.9550 - val_loss: 0.0475 - val_msle: 0.0232 - val_accuracy: 0.9298\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0294 - msle: 0.0140 - accuracy: 0.9579 - val_loss: 0.0469 - val_msle: 0.0226 - val_accuracy: 0.9298\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0268 - msle: 0.0133 - accuracy: 0.9644 - val_loss: 0.0471 - val_msle: 0.0224 - val_accuracy: 0.9386\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0306 - msle: 0.0146 - accuracy: 0.9603 - val_loss: 0.0465 - val_msle: 0.0223 - val_accuracy: 0.9298\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0254 - msle: 0.0123 - accuracy: 0.9704 - val_loss: 0.0461 - val_msle: 0.0220 - val_accuracy: 0.9298\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0278 - msle: 0.0136 - accuracy: 0.9662 - val_loss: 0.0461 - val_msle: 0.0219 - val_accuracy: 0.9298\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0209 - msle: 0.0104 - accuracy: 0.9760 - val_loss: 0.0463 - val_msle: 0.0219 - val_accuracy: 0.9298\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0263 - msle: 0.0134 - accuracy: 0.9691 - val_loss: 0.0465 - val_msle: 0.0219 - val_accuracy: 0.9386\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0298 - msle: 0.0145 - accuracy: 0.9645 - val_loss: 0.0459 - val_msle: 0.0219 - val_accuracy: 0.9474\n",
            "Epoch 22/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0296 - msle: 0.0144 - accuracy: 0.9562 - val_loss: 0.0457 - val_msle: 0.0218 - val_accuracy: 0.9474\n",
            "Epoch 23/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0283 - msle: 0.0140 - accuracy: 0.9624 - val_loss: 0.0461 - val_msle: 0.0217 - val_accuracy: 0.9561\n",
            "Epoch 24/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0275 - msle: 0.0133 - accuracy: 0.9689 - val_loss: 0.0461 - val_msle: 0.0217 - val_accuracy: 0.9474\n",
            "Epoch 25/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0233 - msle: 0.0114 - accuracy: 0.9712 - val_loss: 0.0460 - val_msle: 0.0217 - val_accuracy: 0.9561\n",
            "Epoch 26/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0274 - msle: 0.0136 - accuracy: 0.9676 - val_loss: 0.0453 - val_msle: 0.0216 - val_accuracy: 0.9474\n",
            "Epoch 27/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0210 - msle: 0.0106 - accuracy: 0.9714 - val_loss: 0.0452 - val_msle: 0.0216 - val_accuracy: 0.9474\n",
            "Epoch 28/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0218 - msle: 0.0111 - accuracy: 0.9719 - val_loss: 0.0454 - val_msle: 0.0216 - val_accuracy: 0.9561\n",
            "Epoch 29/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0200 - msle: 0.0098 - accuracy: 0.9746 - val_loss: 0.0452 - val_msle: 0.0215 - val_accuracy: 0.9561\n",
            "Epoch 30/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0233 - msle: 0.0115 - accuracy: 0.9736 - val_loss: 0.0451 - val_msle: 0.0214 - val_accuracy: 0.9561\n",
            "Epoch 31/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0229 - msle: 0.0112 - accuracy: 0.9749 - val_loss: 0.0446 - val_msle: 0.0213 - val_accuracy: 0.9561\n",
            "Epoch 32/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0206 - msle: 0.0105 - accuracy: 0.9799 - val_loss: 0.0448 - val_msle: 0.0214 - val_accuracy: 0.9561\n",
            "Epoch 33/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0232 - msle: 0.0112 - accuracy: 0.9733 - val_loss: 0.0449 - val_msle: 0.0216 - val_accuracy: 0.9561\n",
            "Epoch 34/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0229 - msle: 0.0111 - accuracy: 0.9708 - val_loss: 0.0451 - val_msle: 0.0214 - val_accuracy: 0.9561\n",
            "Epoch 35/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0218 - msle: 0.0103 - accuracy: 0.9762 - val_loss: 0.0449 - val_msle: 0.0213 - val_accuracy: 0.9561\n",
            "Epoch 36/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0229 - msle: 0.0112 - accuracy: 0.9747 - val_loss: 0.0446 - val_msle: 0.0212 - val_accuracy: 0.9561\n",
            "Epoch 37/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0193 - msle: 0.0093 - accuracy: 0.9759 - val_loss: 0.0444 - val_msle: 0.0213 - val_accuracy: 0.9561\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0196 - msle: 0.0096 - accuracy: 0.9768 - val_loss: 0.0445 - val_msle: 0.0213 - val_accuracy: 0.9561\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0195 - msle: 0.0095 - accuracy: 0.9755 - val_loss: 0.0447 - val_msle: 0.0212 - val_accuracy: 0.9561\n",
            "Epoch 40/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0196 - msle: 0.0096 - accuracy: 0.9785 - val_loss: 0.0444 - val_msle: 0.0212 - val_accuracy: 0.9561\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0224 - msle: 0.0106 - accuracy: 0.9707 - val_loss: 0.0440 - val_msle: 0.0212 - val_accuracy: 0.9561\n",
            "Epoch 42/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0206 - msle: 0.0104 - accuracy: 0.9739 - val_loss: 0.0443 - val_msle: 0.0212 - val_accuracy: 0.9561\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0204 - msle: 0.0097 - accuracy: 0.9719 - val_loss: 0.0443 - val_msle: 0.0212 - val_accuracy: 0.9561\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0210 - msle: 0.0102 - accuracy: 0.9723 - val_loss: 0.0441 - val_msle: 0.0211 - val_accuracy: 0.9561\n",
            "Epoch 45/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0192 - msle: 0.0092 - accuracy: 0.9749 - val_loss: 0.0440 - val_msle: 0.0211 - val_accuracy: 0.9561\n",
            "Epoch 46/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0207 - msle: 0.0102 - accuracy: 0.9729 - val_loss: 0.0440 - val_msle: 0.0210 - val_accuracy: 0.9561\n",
            "Epoch 47/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0182 - msle: 0.0087 - accuracy: 0.9774 - val_loss: 0.0437 - val_msle: 0.0209 - val_accuracy: 0.9561\n",
            "Epoch 48/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0216 - msle: 0.0102 - accuracy: 0.9708 - val_loss: 0.0434 - val_msle: 0.0209 - val_accuracy: 0.9561\n",
            "Epoch 49/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0204 - msle: 0.0100 - accuracy: 0.9717 - val_loss: 0.0437 - val_msle: 0.0209 - val_accuracy: 0.9561\n",
            "Epoch 50/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0221 - msle: 0.0105 - accuracy: 0.9692 - val_loss: 0.0435 - val_msle: 0.0208 - val_accuracy: 0.9474\n",
            "Epoch 51/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0188 - msle: 0.0089 - accuracy: 0.9777 - val_loss: 0.0437 - val_msle: 0.0209 - val_accuracy: 0.9561\n",
            "Epoch 52/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0214 - msle: 0.0103 - accuracy: 0.9743 - val_loss: 0.0436 - val_msle: 0.0209 - val_accuracy: 0.9561\n",
            "Epoch 53/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0211 - msle: 0.0104 - accuracy: 0.9736 - val_loss: 0.0428 - val_msle: 0.0206 - val_accuracy: 0.9561\n",
            "Epoch 54/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0198 - msle: 0.0101 - accuracy: 0.9770 - val_loss: 0.0430 - val_msle: 0.0206 - val_accuracy: 0.9561\n",
            "Epoch 55/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0162 - msle: 0.0082 - accuracy: 0.9832 - val_loss: 0.0429 - val_msle: 0.0206 - val_accuracy: 0.9561\n",
            "Epoch 56/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0188 - msle: 0.0093 - accuracy: 0.9759 - val_loss: 0.0430 - val_msle: 0.0208 - val_accuracy: 0.9561\n",
            "Epoch 57/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0178 - msle: 0.0087 - accuracy: 0.9782 - val_loss: 0.0431 - val_msle: 0.0208 - val_accuracy: 0.9561\n",
            "Epoch 58/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0157 - msle: 0.0076 - accuracy: 0.9774 - val_loss: 0.0429 - val_msle: 0.0206 - val_accuracy: 0.9561\n",
            "Epoch 59/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0153 - msle: 0.0072 - accuracy: 0.9811 - val_loss: 0.0428 - val_msle: 0.0206 - val_accuracy: 0.9561\n",
            "Epoch 60/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0164 - msle: 0.0077 - accuracy: 0.9787 - val_loss: 0.0429 - val_msle: 0.0206 - val_accuracy: 0.9561\n",
            "Epoch 61/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0130 - msle: 0.0064 - accuracy: 0.9839 - val_loss: 0.0427 - val_msle: 0.0207 - val_accuracy: 0.9561\n",
            "Epoch 62/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0227 - msle: 0.0112 - accuracy: 0.9719 - val_loss: 0.0425 - val_msle: 0.0206 - val_accuracy: 0.9561\n",
            "Epoch 63/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0157 - msle: 0.0077 - accuracy: 0.9781 - val_loss: 0.0424 - val_msle: 0.0205 - val_accuracy: 0.9561\n",
            "Epoch 64/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0214 - msle: 0.0102 - accuracy: 0.9738 - val_loss: 0.0422 - val_msle: 0.0203 - val_accuracy: 0.9561\n",
            "Epoch 65/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0119 - msle: 0.0058 - accuracy: 0.9880 - val_loss: 0.0422 - val_msle: 0.0204 - val_accuracy: 0.9561\n",
            "Epoch 66/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0135 - msle: 0.0066 - accuracy: 0.9838 - val_loss: 0.0422 - val_msle: 0.0205 - val_accuracy: 0.9561\n",
            "Epoch 67/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0145 - msle: 0.0072 - accuracy: 0.9791 - val_loss: 0.0423 - val_msle: 0.0206 - val_accuracy: 0.9561\n",
            "Epoch 68/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0179 - msle: 0.0090 - accuracy: 0.9799 - val_loss: 0.0422 - val_msle: 0.0205 - val_accuracy: 0.9561\n",
            "Epoch 69/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0139 - msle: 0.0066 - accuracy: 0.9791 - val_loss: 0.0419 - val_msle: 0.0203 - val_accuracy: 0.9561\n",
            "Epoch 70/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0143 - msle: 0.0071 - accuracy: 0.9866 - val_loss: 0.0418 - val_msle: 0.0204 - val_accuracy: 0.9561\n",
            "Epoch 71/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0158 - msle: 0.0080 - accuracy: 0.9853 - val_loss: 0.0415 - val_msle: 0.0203 - val_accuracy: 0.9561\n",
            "Epoch 72/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0140 - msle: 0.0071 - accuracy: 0.9867 - val_loss: 0.0418 - val_msle: 0.0205 - val_accuracy: 0.9561\n",
            "Epoch 73/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0175 - msle: 0.0086 - accuracy: 0.9825 - val_loss: 0.0416 - val_msle: 0.0204 - val_accuracy: 0.9561\n",
            "Epoch 74/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0135 - msle: 0.0070 - accuracy: 0.9871 - val_loss: 0.0414 - val_msle: 0.0201 - val_accuracy: 0.9561\n",
            "Epoch 75/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0151 - msle: 0.0072 - accuracy: 0.9842 - val_loss: 0.0414 - val_msle: 0.0203 - val_accuracy: 0.9561\n",
            "Epoch 76/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0192 - msle: 0.0096 - accuracy: 0.9814 - val_loss: 0.0413 - val_msle: 0.0202 - val_accuracy: 0.9561\n",
            "Epoch 77/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0156 - msle: 0.0076 - accuracy: 0.9842 - val_loss: 0.0414 - val_msle: 0.0201 - val_accuracy: 0.9561\n",
            "Epoch 78/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0165 - msle: 0.0079 - accuracy: 0.9808 - val_loss: 0.0416 - val_msle: 0.0203 - val_accuracy: 0.9561\n",
            "Epoch 79/200\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 0.0181 - msle: 0.0087 - accuracy: 0.9762 - val_loss: 0.0413 - val_msle: 0.0203 - val_accuracy: 0.9561\n",
            "Epoch 80/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0163 - msle: 0.0081 - accuracy: 0.9842 - val_loss: 0.0407 - val_msle: 0.0198 - val_accuracy: 0.9561\n",
            "Epoch 81/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0136 - msle: 0.0065 - accuracy: 0.9860 - val_loss: 0.0408 - val_msle: 0.0198 - val_accuracy: 0.9561\n",
            "Epoch 82/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0130 - msle: 0.0063 - accuracy: 0.9870 - val_loss: 0.0414 - val_msle: 0.0204 - val_accuracy: 0.9561\n",
            "Epoch 83/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0160 - msle: 0.0082 - accuracy: 0.9840 - val_loss: 0.0410 - val_msle: 0.0203 - val_accuracy: 0.9561\n",
            "Epoch 84/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0108 - msle: 0.0056 - accuracy: 0.9923 - val_loss: 0.0409 - val_msle: 0.0201 - val_accuracy: 0.9561\n",
            "Epoch 85/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0129 - msle: 0.0063 - accuracy: 0.9874 - val_loss: 0.0408 - val_msle: 0.0200 - val_accuracy: 0.9561\n",
            "Epoch 86/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0145 - msle: 0.0072 - accuracy: 0.9820 - val_loss: 0.0409 - val_msle: 0.0202 - val_accuracy: 0.9561\n",
            "Epoch 87/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0132 - msle: 0.0068 - accuracy: 0.9881 - val_loss: 0.0409 - val_msle: 0.0203 - val_accuracy: 0.9561\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0125 - msle: 0.0062 - accuracy: 0.9887 - val_loss: 0.0411 - val_msle: 0.0202 - val_accuracy: 0.9561\n",
            "Epoch 89/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0128 - msle: 0.0062 - accuracy: 0.9857 - val_loss: 0.0407 - val_msle: 0.0201 - val_accuracy: 0.9561\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0086 - msle: 0.0044 - accuracy: 0.9940 - val_loss: 0.0407 - val_msle: 0.0202 - val_accuracy: 0.9561\n",
            "Epoch 91/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0112 - msle: 0.0056 - accuracy: 0.9912 - val_loss: 0.0417 - val_msle: 0.0207 - val_accuracy: 0.9561\n",
            "Epoch 92/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0090 - msle: 0.0043 - accuracy: 0.9931 - val_loss: 0.0415 - val_msle: 0.0205 - val_accuracy: 0.9561\n",
            "Epoch 93/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0137 - msle: 0.0065 - accuracy: 0.9865 - val_loss: 0.0402 - val_msle: 0.0200 - val_accuracy: 0.9561\n",
            "Epoch 94/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0136 - msle: 0.0065 - accuracy: 0.9840 - val_loss: 0.0402 - val_msle: 0.0200 - val_accuracy: 0.9561\n",
            "Epoch 95/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0150 - msle: 0.0072 - accuracy: 0.9823 - val_loss: 0.0402 - val_msle: 0.0200 - val_accuracy: 0.9561\n",
            "Epoch 96/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0117 - msle: 0.0056 - accuracy: 0.9884 - val_loss: 0.0403 - val_msle: 0.0201 - val_accuracy: 0.9561\n",
            "Epoch 97/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0114 - msle: 0.0057 - accuracy: 0.9895 - val_loss: 0.0408 - val_msle: 0.0204 - val_accuracy: 0.9561\n",
            "Epoch 98/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0114 - msle: 0.0057 - accuracy: 0.9928 - val_loss: 0.0407 - val_msle: 0.0203 - val_accuracy: 0.9561\n",
            "Epoch 99/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0137 - msle: 0.0067 - accuracy: 0.9872 - val_loss: 0.0406 - val_msle: 0.0202 - val_accuracy: 0.9561\n",
            "Epoch 100/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0105 - msle: 0.0052 - accuracy: 0.9907 - val_loss: 0.0413 - val_msle: 0.0207 - val_accuracy: 0.9561\n",
            "Epoch 101/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0121 - msle: 0.0061 - accuracy: 0.9882 - val_loss: 0.0418 - val_msle: 0.0210 - val_accuracy: 0.9474\n",
            "Epoch 102/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0110 - msle: 0.0057 - accuracy: 0.9870 - val_loss: 0.0395 - val_msle: 0.0197 - val_accuracy: 0.9474\n",
            "Epoch 103/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0077 - msle: 0.0039 - accuracy: 0.9922 - val_loss: 0.0405 - val_msle: 0.0203 - val_accuracy: 0.9561\n",
            "Epoch 104/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0104 - msle: 0.0052 - accuracy: 0.9924 - val_loss: 0.0427 - val_msle: 0.0216 - val_accuracy: 0.9474\n",
            "Epoch 105/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0110 - msle: 0.0056 - accuracy: 0.9925 - val_loss: 0.0408 - val_msle: 0.0204 - val_accuracy: 0.9386\n",
            "Epoch 106/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0101 - msle: 0.0045 - accuracy: 0.9922 - val_loss: 0.0396 - val_msle: 0.0196 - val_accuracy: 0.9474\n",
            "Epoch 107/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0074 - msle: 0.0034 - accuracy: 0.9944 - val_loss: 0.0399 - val_msle: 0.0200 - val_accuracy: 0.9474\n",
            "Epoch 108/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0124 - msle: 0.0062 - accuracy: 0.9891 - val_loss: 0.0420 - val_msle: 0.0212 - val_accuracy: 0.9474\n",
            "Epoch 109/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0092 - msle: 0.0049 - accuracy: 0.9932 - val_loss: 0.0406 - val_msle: 0.0203 - val_accuracy: 0.9474\n",
            "Epoch 110/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0067 - msle: 0.0033 - accuracy: 0.9954 - val_loss: 0.0395 - val_msle: 0.0197 - val_accuracy: 0.9386\n",
            "Epoch 111/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0080 - msle: 0.0038 - accuracy: 0.9946 - val_loss: 0.0407 - val_msle: 0.0204 - val_accuracy: 0.9474\n",
            "Epoch 112/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0065 - msle: 0.0034 - accuracy: 0.9954 - val_loss: 0.0415 - val_msle: 0.0208 - val_accuracy: 0.9474\n",
            "Epoch 113/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0099 - msle: 0.0050 - accuracy: 0.9916 - val_loss: 0.0404 - val_msle: 0.0203 - val_accuracy: 0.9386\n",
            "Epoch 114/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0073 - msle: 0.0037 - accuracy: 0.9943 - val_loss: 0.0398 - val_msle: 0.0200 - val_accuracy: 0.9474\n",
            "Epoch 115/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0057 - msle: 0.0029 - accuracy: 0.9956 - val_loss: 0.0393 - val_msle: 0.0195 - val_accuracy: 0.9386\n",
            "Epoch 116/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0083 - msle: 0.0040 - accuracy: 0.9949 - val_loss: 0.0402 - val_msle: 0.0203 - val_accuracy: 0.9474\n",
            "Epoch 117/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0095 - msle: 0.0050 - accuracy: 0.9933 - val_loss: 0.0401 - val_msle: 0.0204 - val_accuracy: 0.9474\n",
            "Epoch 118/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0096 - msle: 0.0050 - accuracy: 0.9941 - val_loss: 0.0396 - val_msle: 0.0197 - val_accuracy: 0.9386\n",
            "Epoch 119/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0070 - msle: 0.0032 - accuracy: 0.9971 - val_loss: 0.0418 - val_msle: 0.0210 - val_accuracy: 0.9386\n",
            "Epoch 120/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0075 - msle: 0.0038 - accuracy: 0.9949 - val_loss: 0.0410 - val_msle: 0.0205 - val_accuracy: 0.9386\n",
            "Epoch 121/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0067 - msle: 0.0035 - accuracy: 0.9967 - val_loss: 0.0392 - val_msle: 0.0195 - val_accuracy: 0.9474\n",
            "Epoch 122/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0074 - msle: 0.0038 - accuracy: 0.9958 - val_loss: 0.0389 - val_msle: 0.0194 - val_accuracy: 0.9386\n",
            "Epoch 123/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0065 - msle: 0.0034 - accuracy: 0.9963 - val_loss: 0.0406 - val_msle: 0.0204 - val_accuracy: 0.9474\n",
            "Epoch 124/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0083 - msle: 0.0043 - accuracy: 0.9941 - val_loss: 0.0405 - val_msle: 0.0203 - val_accuracy: 0.9386\n",
            "Epoch 125/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0049 - msle: 0.0025 - accuracy: 0.9977 - val_loss: 0.0390 - val_msle: 0.0193 - val_accuracy: 0.9474\n",
            "Epoch 126/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0084 - msle: 0.0040 - accuracy: 0.9941 - val_loss: 0.0390 - val_msle: 0.0194 - val_accuracy: 0.9474\n",
            "Epoch 127/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0082 - msle: 0.0040 - accuracy: 0.9941 - val_loss: 0.0397 - val_msle: 0.0199 - val_accuracy: 0.9386\n",
            "Epoch 128/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0086 - msle: 0.0043 - accuracy: 0.9933 - val_loss: 0.0400 - val_msle: 0.0201 - val_accuracy: 0.9474\n",
            "Epoch 129/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0073 - msle: 0.0038 - accuracy: 0.9951 - val_loss: 0.0394 - val_msle: 0.0198 - val_accuracy: 0.9386\n",
            "Epoch 130/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0070 - msle: 0.0035 - accuracy: 0.9946 - val_loss: 0.0386 - val_msle: 0.0193 - val_accuracy: 0.9386\n",
            "Epoch 131/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0047 - msle: 0.0023 - accuracy: 0.9971 - val_loss: 0.0391 - val_msle: 0.0196 - val_accuracy: 0.9386\n",
            "Epoch 132/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0076 - msle: 0.0037 - accuracy: 0.9941 - val_loss: 0.0396 - val_msle: 0.0198 - val_accuracy: 0.9386\n",
            "Epoch 133/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0046 - msle: 0.0023 - accuracy: 0.9971 - val_loss: 0.0395 - val_msle: 0.0197 - val_accuracy: 0.9386\n",
            "Epoch 134/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0071 - msle: 0.0035 - accuracy: 0.9946 - val_loss: 0.0391 - val_msle: 0.0196 - val_accuracy: 0.9386\n",
            "Epoch 135/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0075 - msle: 0.0038 - accuracy: 0.9941 - val_loss: 0.0387 - val_msle: 0.0193 - val_accuracy: 0.9474\n",
            "Epoch 136/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0058 - msle: 0.0029 - accuracy: 0.9958 - val_loss: 0.0398 - val_msle: 0.0199 - val_accuracy: 0.9386\n",
            "Epoch 137/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0041 - msle: 0.0021 - accuracy: 0.9976 - val_loss: 0.0394 - val_msle: 0.0197 - val_accuracy: 0.9386\n",
            "Epoch 138/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0032 - msle: 0.0017 - accuracy: 0.9985 - val_loss: 0.0390 - val_msle: 0.0194 - val_accuracy: 0.9474\n",
            "Epoch 139/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0057 - msle: 0.0029 - accuracy: 0.9958 - val_loss: 0.0386 - val_msle: 0.0192 - val_accuracy: 0.9474\n",
            "Epoch 140/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0070 - msle: 0.0034 - accuracy: 0.9941 - val_loss: 0.0394 - val_msle: 0.0196 - val_accuracy: 0.9474\n",
            "Epoch 141/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0036 - msle: 0.0018 - accuracy: 0.9976 - val_loss: 0.0395 - val_msle: 0.0196 - val_accuracy: 0.9474\n",
            "Epoch 142/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0071 - msle: 0.0035 - accuracy: 0.9941 - val_loss: 0.0397 - val_msle: 0.0198 - val_accuracy: 0.9474\n",
            "Epoch 143/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0035 - msle: 0.0018 - accuracy: 0.9977 - val_loss: 0.0398 - val_msle: 0.0198 - val_accuracy: 0.9474\n",
            "Epoch 144/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0070 - msle: 0.0034 - accuracy: 0.9941 - val_loss: 0.0392 - val_msle: 0.0194 - val_accuracy: 0.9474\n",
            "Epoch 145/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0062 - msle: 0.0031 - accuracy: 0.9951 - val_loss: 0.0389 - val_msle: 0.0193 - val_accuracy: 0.9474\n",
            "Epoch 146/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0072 - msle: 0.0035 - accuracy: 0.9941 - val_loss: 0.0398 - val_msle: 0.0198 - val_accuracy: 0.9386\n",
            "Epoch 147/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0063 - msle: 0.0033 - accuracy: 0.9949 - val_loss: 0.0393 - val_msle: 0.0195 - val_accuracy: 0.9474\n",
            "Epoch 148/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0043 - msle: 0.0022 - accuracy: 0.9967 - val_loss: 0.0389 - val_msle: 0.0192 - val_accuracy: 0.9474\n",
            "Epoch 149/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0068 - msle: 0.0033 - accuracy: 0.9941 - val_loss: 0.0391 - val_msle: 0.0193 - val_accuracy: 0.9474\n",
            "Epoch 150/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0034 - msle: 0.0017 - accuracy: 0.9977 - val_loss: 0.0390 - val_msle: 0.0193 - val_accuracy: 0.9474\n",
            "Epoch 151/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0038 - msle: 0.0019 - accuracy: 0.9971 - val_loss: 0.0390 - val_msle: 0.0193 - val_accuracy: 0.9474\n",
            "Epoch 152/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0033 - msle: 0.0017 - accuracy: 0.9976 - val_loss: 0.0384 - val_msle: 0.0190 - val_accuracy: 0.9474\n",
            "Epoch 153/200\n",
            "5/5 [==============================] - 0s 54ms/step - loss: 0.0067 - msle: 0.0033 - accuracy: 0.9941 - val_loss: 0.0382 - val_msle: 0.0189 - val_accuracy: 0.9474\n",
            "Epoch 154/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0030 - msle: 0.0015 - accuracy: 0.9981 - val_loss: 0.0384 - val_msle: 0.0189 - val_accuracy: 0.9474\n",
            "Epoch 155/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0092 - msle: 0.0045 - accuracy: 0.9916 - val_loss: 0.0388 - val_msle: 0.0191 - val_accuracy: 0.9474\n",
            "Epoch 156/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0060 - msle: 0.0029 - accuracy: 0.9946 - val_loss: 0.0393 - val_msle: 0.0195 - val_accuracy: 0.9474\n",
            "Epoch 157/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0044 - msle: 0.0023 - accuracy: 0.9963 - val_loss: 0.0389 - val_msle: 0.0193 - val_accuracy: 0.9474\n",
            "Epoch 158/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0050 - msle: 0.0025 - accuracy: 0.9958 - val_loss: 0.0386 - val_msle: 0.0190 - val_accuracy: 0.9474\n",
            "Epoch 159/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0033 - msle: 0.0018 - accuracy: 0.9976 - val_loss: 0.0385 - val_msle: 0.0189 - val_accuracy: 0.9474\n",
            "Epoch 160/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0061 - msle: 0.0029 - accuracy: 0.9946 - val_loss: 0.0388 - val_msle: 0.0191 - val_accuracy: 0.9474\n",
            "Epoch 161/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0056 - msle: 0.0027 - accuracy: 0.9949 - val_loss: 0.0388 - val_msle: 0.0192 - val_accuracy: 0.9474\n",
            "Epoch 162/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0060 - msle: 0.0030 - accuracy: 0.9946 - val_loss: 0.0388 - val_msle: 0.0191 - val_accuracy: 0.9474\n",
            "Epoch 163/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0042 - msle: 0.0021 - accuracy: 0.9966 - val_loss: 0.0385 - val_msle: 0.0189 - val_accuracy: 0.9474\n",
            "Epoch 164/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0064 - msle: 0.0031 - accuracy: 0.9941 - val_loss: 0.0386 - val_msle: 0.0190 - val_accuracy: 0.9474\n",
            "Epoch 165/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0030 - msle: 0.0015 - accuracy: 0.9977 - val_loss: 0.0389 - val_msle: 0.0192 - val_accuracy: 0.9474\n",
            "Epoch 166/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0065 - msle: 0.0032 - accuracy: 0.9941 - val_loss: 0.0391 - val_msle: 0.0193 - val_accuracy: 0.9474\n",
            "Epoch 167/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0042 - msle: 0.0021 - accuracy: 0.9963 - val_loss: 0.0389 - val_msle: 0.0191 - val_accuracy: 0.9474\n",
            "Epoch 168/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0089 - msle: 0.0043 - accuracy: 0.9916 - val_loss: 0.0391 - val_msle: 0.0193 - val_accuracy: 0.9474\n",
            "Epoch 169/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0060 - msle: 0.0029 - accuracy: 0.9946 - val_loss: 0.0390 - val_msle: 0.0192 - val_accuracy: 0.9474\n",
            "Epoch 170/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0040 - msle: 0.0020 - accuracy: 0.9967 - val_loss: 0.0387 - val_msle: 0.0190 - val_accuracy: 0.9474\n",
            "Epoch 171/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0037 - msle: 0.0018 - accuracy: 0.9967 - val_loss: 0.0387 - val_msle: 0.0190 - val_accuracy: 0.9474\n",
            "Epoch 172/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0043 - msle: 0.0021 - accuracy: 0.9963 - val_loss: 0.0387 - val_msle: 0.0190 - val_accuracy: 0.9474\n",
            "Epoch 173/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0064 - msle: 0.0032 - accuracy: 0.9941 - val_loss: 0.0388 - val_msle: 0.0190 - val_accuracy: 0.9474\n",
            "Epoch 174/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0035 - msle: 0.0017 - accuracy: 0.9971 - val_loss: 0.0389 - val_msle: 0.0191 - val_accuracy: 0.9474\n",
            "Epoch 175/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0038 - msle: 0.0019 - accuracy: 0.9967 - val_loss: 0.0390 - val_msle: 0.0191 - val_accuracy: 0.9474\n",
            "Epoch 176/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0063 - msle: 0.0031 - accuracy: 0.9941 - val_loss: 0.0389 - val_msle: 0.0191 - val_accuracy: 0.9474\n",
            "Epoch 177/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0055 - msle: 0.0027 - accuracy: 0.9949 - val_loss: 0.0390 - val_msle: 0.0191 - val_accuracy: 0.9474\n",
            "Epoch 178/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0047 - msle: 0.0023 - accuracy: 0.9958 - val_loss: 0.0392 - val_msle: 0.0193 - val_accuracy: 0.9474\n",
            "Epoch 179/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0072 - msle: 0.0035 - accuracy: 0.9933 - val_loss: 0.0392 - val_msle: 0.0193 - val_accuracy: 0.9474\n",
            "Epoch 180/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0039 - msle: 0.0019 - accuracy: 0.9966 - val_loss: 0.0394 - val_msle: 0.0193 - val_accuracy: 0.9474\n",
            "Epoch 181/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0063 - msle: 0.0031 - accuracy: 0.9941 - val_loss: 0.0393 - val_msle: 0.0193 - val_accuracy: 0.9474\n",
            "Epoch 182/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0071 - msle: 0.0035 - accuracy: 0.9933 - val_loss: 0.0390 - val_msle: 0.0192 - val_accuracy: 0.9474\n",
            "Epoch 183/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0055 - msle: 0.0027 - accuracy: 0.9949 - val_loss: 0.0392 - val_msle: 0.0192 - val_accuracy: 0.9474\n",
            "Epoch 184/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0057 - msle: 0.0028 - accuracy: 0.9946 - val_loss: 0.0395 - val_msle: 0.0194 - val_accuracy: 0.9474\n",
            "Epoch 185/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0063 - msle: 0.0031 - accuracy: 0.9941 - val_loss: 0.0395 - val_msle: 0.0194 - val_accuracy: 0.9474\n",
            "Epoch 186/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0019 - msle: 9.4008e-04 - accuracy: 0.9985 - val_loss: 0.0393 - val_msle: 0.0192 - val_accuracy: 0.9474\n",
            "Epoch 187/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0040 - msle: 0.0019 - accuracy: 0.9963 - val_loss: 0.0392 - val_msle: 0.0192 - val_accuracy: 0.9474\n",
            "Epoch 188/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0062 - msle: 0.0030 - accuracy: 0.9941 - val_loss: 0.0396 - val_msle: 0.0194 - val_accuracy: 0.9474\n",
            "Epoch 189/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0054 - msle: 0.0027 - accuracy: 0.9949 - val_loss: 0.0395 - val_msle: 0.0194 - val_accuracy: 0.9474\n",
            "Epoch 190/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0062 - msle: 0.0030 - accuracy: 0.9941 - val_loss: 0.0394 - val_msle: 0.0193 - val_accuracy: 0.9474\n",
            "Epoch 191/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0022 - msle: 0.0011 - accuracy: 0.9981 - val_loss: 0.0395 - val_msle: 0.0194 - val_accuracy: 0.9474\n",
            "Epoch 192/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0057 - msle: 0.0028 - accuracy: 0.9946 - val_loss: 0.0396 - val_msle: 0.0194 - val_accuracy: 0.9474\n",
            "Epoch 193/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0052 - msle: 0.0026 - accuracy: 0.9951 - val_loss: 0.0396 - val_msle: 0.0193 - val_accuracy: 0.9474\n",
            "Epoch 194/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0040 - msle: 0.0020 - accuracy: 0.9963 - val_loss: 0.0396 - val_msle: 0.0194 - val_accuracy: 0.9474\n",
            "Epoch 195/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0058 - msle: 0.0028 - accuracy: 0.9946 - val_loss: 0.0399 - val_msle: 0.0196 - val_accuracy: 0.9474\n",
            "Epoch 196/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0057 - msle: 0.0028 - accuracy: 0.9946 - val_loss: 0.0399 - val_msle: 0.0196 - val_accuracy: 0.9474\n",
            "Epoch 197/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0057 - msle: 0.0028 - accuracy: 0.9946 - val_loss: 0.0399 - val_msle: 0.0195 - val_accuracy: 0.9474\n",
            "Epoch 198/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0071 - msle: 0.0034 - accuracy: 0.9933 - val_loss: 0.0398 - val_msle: 0.0195 - val_accuracy: 0.9474\n",
            "Epoch 199/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0045 - msle: 0.0022 - accuracy: 0.9958 - val_loss: 0.0399 - val_msle: 0.0195 - val_accuracy: 0.9474\n",
            "Epoch 200/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0070 - msle: 0.0034 - accuracy: 0.9933 - val_loss: 0.0399 - val_msle: 0.0195 - val_accuracy: 0.9474\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sRBwGzsgGvx"
      },
      "source": [
        "Define the RMSprop optimizer with a learning rate of 0.05."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odyJo-kugGvy"
      },
      "source": [
        "# Answer below:\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "rmsprop = RMSprop(learning_rate=0.05)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7GaEJGugGvz"
      },
      "source": [
        "Compile and fit the model using the optimizer defined above. What do you notice about the accuracy?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "477zsxjvgGv0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecb41970-9f51-4b1f-c7de-9e5e08480f0d"
      },
      "source": [
        "# Answer below:\n",
        "start = time.time()\n",
        "model_2 = build_model(opt=rmsprop, loss=\"mse\")\n",
        "m2_hist = model_2.fit(X_train_, y_train, epochs=200, batch_size=100, \n",
        "          verbose=1, validation_data=(X_test_, y_test))\n",
        "m2_time = time.time() - start"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "5/5 [==============================] - 1s 54ms/step - loss: 0.3126 - msle: 0.1573 - accuracy: 0.5730 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3621 - msle: 0.1740 - accuracy: 0.6379 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3842 - msle: 0.1846 - accuracy: 0.6158 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3420 - msle: 0.1643 - accuracy: 0.6580 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3693 - msle: 0.1774 - accuracy: 0.6307 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3410 - msle: 0.1638 - accuracy: 0.6590 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3790 - msle: 0.1821 - accuracy: 0.6210 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3690 - msle: 0.1773 - accuracy: 0.6310 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3618 - msle: 0.1738 - accuracy: 0.6382 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3777 - msle: 0.1814 - accuracy: 0.6223 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3754 - msle: 0.1804 - accuracy: 0.6246 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3720 - msle: 0.1787 - accuracy: 0.6280 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 0.3738 - msle: 0.1796 - accuracy: 0.6262 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3728 - msle: 0.1791 - accuracy: 0.6272 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3610 - msle: 0.1734 - accuracy: 0.6390 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3878 - msle: 0.1863 - accuracy: 0.6122 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3525 - msle: 0.1694 - accuracy: 0.6475 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3839 - msle: 0.1845 - accuracy: 0.6161 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3413 - msle: 0.1640 - accuracy: 0.6587 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3807 - msle: 0.1829 - accuracy: 0.6193 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3856 - msle: 0.1853 - accuracy: 0.6144 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 22/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3824 - msle: 0.1837 - accuracy: 0.6176 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 23/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3636 - msle: 0.1747 - accuracy: 0.6364 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 24/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3378 - msle: 0.1623 - accuracy: 0.6622 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 25/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3799 - msle: 0.1825 - accuracy: 0.6201 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 26/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3549 - msle: 0.1705 - accuracy: 0.6451 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 27/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3579 - msle: 0.1720 - accuracy: 0.6421 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 28/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3715 - msle: 0.1785 - accuracy: 0.6285 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 29/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3782 - msle: 0.1817 - accuracy: 0.6218 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 30/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3575 - msle: 0.1718 - accuracy: 0.6425 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 31/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3524 - msle: 0.1693 - accuracy: 0.6476 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 32/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3499 - msle: 0.1681 - accuracy: 0.6501 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 33/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3693 - msle: 0.1774 - accuracy: 0.6307 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 34/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3795 - msle: 0.1823 - accuracy: 0.6205 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 35/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3789 - msle: 0.1820 - accuracy: 0.6211 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 36/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3821 - msle: 0.1836 - accuracy: 0.6179 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 37/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3947 - msle: 0.1897 - accuracy: 0.6053 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3511 - msle: 0.1687 - accuracy: 0.6489 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3614 - msle: 0.1736 - accuracy: 0.6386 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 40/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3650 - msle: 0.1754 - accuracy: 0.6350 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3649 - msle: 0.1753 - accuracy: 0.6351 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 42/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3690 - msle: 0.1773 - accuracy: 0.6310 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3750 - msle: 0.1802 - accuracy: 0.6250 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3931 - msle: 0.1889 - accuracy: 0.6069 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 45/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3535 - msle: 0.1698 - accuracy: 0.6465 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 46/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3674 - msle: 0.1765 - accuracy: 0.6326 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 47/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3647 - msle: 0.1752 - accuracy: 0.6353 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 48/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3504 - msle: 0.1684 - accuracy: 0.6496 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 49/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3534 - msle: 0.1698 - accuracy: 0.6466 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 50/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3650 - msle: 0.1754 - accuracy: 0.6350 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 51/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3920 - msle: 0.1883 - accuracy: 0.6080 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 52/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3709 - msle: 0.1782 - accuracy: 0.6291 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 53/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3695 - msle: 0.1775 - accuracy: 0.6305 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 54/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3782 - msle: 0.1817 - accuracy: 0.6218 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 55/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3635 - msle: 0.1746 - accuracy: 0.6365 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 56/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3529 - msle: 0.1696 - accuracy: 0.6471 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 57/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3811 - msle: 0.1831 - accuracy: 0.6189 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 58/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3703 - msle: 0.1779 - accuracy: 0.6297 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 59/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3589 - msle: 0.1724 - accuracy: 0.6411 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 60/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3674 - msle: 0.1765 - accuracy: 0.6326 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 61/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3635 - msle: 0.1746 - accuracy: 0.6365 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 62/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3600 - msle: 0.1730 - accuracy: 0.6400 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 63/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3793 - msle: 0.1822 - accuracy: 0.6207 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 64/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3685 - msle: 0.1770 - accuracy: 0.6315 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 65/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3753 - msle: 0.1803 - accuracy: 0.6247 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 66/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3795 - msle: 0.1823 - accuracy: 0.6205 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 67/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3725 - msle: 0.1790 - accuracy: 0.6275 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 68/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3721 - msle: 0.1788 - accuracy: 0.6279 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 69/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3377 - msle: 0.1622 - accuracy: 0.6623 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 70/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3868 - msle: 0.1859 - accuracy: 0.6132 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 71/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3628 - msle: 0.1743 - accuracy: 0.6372 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 72/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3720 - msle: 0.1787 - accuracy: 0.6280 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 73/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3502 - msle: 0.1682 - accuracy: 0.6498 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 74/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3899 - msle: 0.1873 - accuracy: 0.6101 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 75/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3617 - msle: 0.1738 - accuracy: 0.6383 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 76/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3854 - msle: 0.1852 - accuracy: 0.6146 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 77/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3745 - msle: 0.1799 - accuracy: 0.6255 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 78/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3710 - msle: 0.1782 - accuracy: 0.6290 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 79/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3802 - msle: 0.1826 - accuracy: 0.6198 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 80/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3781 - msle: 0.1816 - accuracy: 0.6219 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 81/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3743 - msle: 0.1798 - accuracy: 0.6257 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 82/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3667 - msle: 0.1762 - accuracy: 0.6333 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 83/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3577 - msle: 0.1718 - accuracy: 0.6423 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 84/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3859 - msle: 0.1854 - accuracy: 0.6141 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 85/200\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.3642 - msle: 0.1750 - accuracy: 0.6358 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 86/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3492 - msle: 0.1678 - accuracy: 0.6508 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 87/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3779 - msle: 0.1816 - accuracy: 0.6221 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3631 - msle: 0.1744 - accuracy: 0.6369 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 89/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3631 - msle: 0.1744 - accuracy: 0.6369 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3609 - msle: 0.1734 - accuracy: 0.6391 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 91/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3525 - msle: 0.1694 - accuracy: 0.6475 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 92/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3685 - msle: 0.1770 - accuracy: 0.6315 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 93/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3895 - msle: 0.1871 - accuracy: 0.6105 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 94/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3720 - msle: 0.1787 - accuracy: 0.6280 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 95/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3957 - msle: 0.1901 - accuracy: 0.6043 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 96/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3703 - msle: 0.1779 - accuracy: 0.6297 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 97/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3678 - msle: 0.1767 - accuracy: 0.6322 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 98/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3588 - msle: 0.1724 - accuracy: 0.6412 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 99/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3672 - msle: 0.1764 - accuracy: 0.6328 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 100/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3949 - msle: 0.1897 - accuracy: 0.6051 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 101/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3557 - msle: 0.1709 - accuracy: 0.6443 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 102/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3554 - msle: 0.1708 - accuracy: 0.6446 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 103/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3617 - msle: 0.1738 - accuracy: 0.6383 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 104/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3703 - msle: 0.1779 - accuracy: 0.6297 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 105/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3768 - msle: 0.1810 - accuracy: 0.6232 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 106/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3838 - msle: 0.1844 - accuracy: 0.6162 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 107/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3825 - msle: 0.1838 - accuracy: 0.6175 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 108/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3656 - msle: 0.1756 - accuracy: 0.6344 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 109/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3503 - msle: 0.1683 - accuracy: 0.6497 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 110/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3539 - msle: 0.1700 - accuracy: 0.6461 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 111/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3759 - msle: 0.1806 - accuracy: 0.6241 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 112/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3682 - msle: 0.1769 - accuracy: 0.6318 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 113/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3689 - msle: 0.1772 - accuracy: 0.6311 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 114/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3682 - msle: 0.1769 - accuracy: 0.6318 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 115/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3732 - msle: 0.1793 - accuracy: 0.6268 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 116/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3727 - msle: 0.1790 - accuracy: 0.6273 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 117/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3642 - msle: 0.1750 - accuracy: 0.6358 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 118/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3500 - msle: 0.1682 - accuracy: 0.6500 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 119/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3713 - msle: 0.1784 - accuracy: 0.6287 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 120/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3889 - msle: 0.1869 - accuracy: 0.6111 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 121/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3827 - msle: 0.1839 - accuracy: 0.6173 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 122/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3615 - msle: 0.1737 - accuracy: 0.6385 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 123/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3674 - msle: 0.1765 - accuracy: 0.6326 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 124/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3881 - msle: 0.1865 - accuracy: 0.6119 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 125/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3636 - msle: 0.1747 - accuracy: 0.6364 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 126/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3746 - msle: 0.1800 - accuracy: 0.6254 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 127/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3684 - msle: 0.1770 - accuracy: 0.6316 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 128/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3509 - msle: 0.1686 - accuracy: 0.6491 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 129/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3717 - msle: 0.1786 - accuracy: 0.6283 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 130/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3774 - msle: 0.1813 - accuracy: 0.6226 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 131/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3868 - msle: 0.1859 - accuracy: 0.6132 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 132/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3860 - msle: 0.1855 - accuracy: 0.6140 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 133/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3827 - msle: 0.1839 - accuracy: 0.6173 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 134/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3590 - msle: 0.1725 - accuracy: 0.6410 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 135/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3600 - msle: 0.1730 - accuracy: 0.6400 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 136/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3614 - msle: 0.1736 - accuracy: 0.6386 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 137/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3822 - msle: 0.1837 - accuracy: 0.6178 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 138/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3609 - msle: 0.1734 - accuracy: 0.6391 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 139/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3672 - msle: 0.1764 - accuracy: 0.6328 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 140/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3660 - msle: 0.1758 - accuracy: 0.6340 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 141/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3570 - msle: 0.1715 - accuracy: 0.6430 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 142/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3831 - msle: 0.1841 - accuracy: 0.6169 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 143/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3570 - msle: 0.1715 - accuracy: 0.6430 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 144/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3778 - msle: 0.1815 - accuracy: 0.6222 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 145/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3472 - msle: 0.1668 - accuracy: 0.6528 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 146/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3835 - msle: 0.1843 - accuracy: 0.6165 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 147/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3772 - msle: 0.1812 - accuracy: 0.6228 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 148/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3635 - msle: 0.1746 - accuracy: 0.6365 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 149/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3520 - msle: 0.1691 - accuracy: 0.6480 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 150/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3824 - msle: 0.1837 - accuracy: 0.6176 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 151/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3736 - msle: 0.1795 - accuracy: 0.6264 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 152/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3689 - msle: 0.1772 - accuracy: 0.6311 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 153/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3639 - msle: 0.1748 - accuracy: 0.6361 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 154/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3827 - msle: 0.1839 - accuracy: 0.6173 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 155/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3564 - msle: 0.1712 - accuracy: 0.6436 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 156/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3534 - msle: 0.1698 - accuracy: 0.6466 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 157/200\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 0.3807 - msle: 0.1829 - accuracy: 0.6193 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 158/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3378 - msle: 0.1623 - accuracy: 0.6622 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 159/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3670 - msle: 0.1763 - accuracy: 0.6330 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 160/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3549 - msle: 0.1705 - accuracy: 0.6451 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 161/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3704 - msle: 0.1780 - accuracy: 0.6296 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 162/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3784 - msle: 0.1818 - accuracy: 0.6216 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 163/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3575 - msle: 0.1718 - accuracy: 0.6425 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 164/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3843 - msle: 0.1847 - accuracy: 0.6157 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 165/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3800 - msle: 0.1826 - accuracy: 0.6200 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 166/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3689 - msle: 0.1772 - accuracy: 0.6311 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 167/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3615 - msle: 0.1737 - accuracy: 0.6385 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 168/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4047 - msle: 0.1945 - accuracy: 0.5953 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 169/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3635 - msle: 0.1746 - accuracy: 0.6365 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 170/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3868 - msle: 0.1859 - accuracy: 0.6132 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 171/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3861 - msle: 0.1855 - accuracy: 0.6139 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 172/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3895 - msle: 0.1871 - accuracy: 0.6105 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 173/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3570 - msle: 0.1715 - accuracy: 0.6430 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 174/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3722 - msle: 0.1788 - accuracy: 0.6278 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 175/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3684 - msle: 0.1770 - accuracy: 0.6316 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 176/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3554 - msle: 0.1708 - accuracy: 0.6446 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 177/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3690 - msle: 0.1773 - accuracy: 0.6310 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 178/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3799 - msle: 0.1825 - accuracy: 0.6201 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 179/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3675 - msle: 0.1766 - accuracy: 0.6325 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 180/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3590 - msle: 0.1725 - accuracy: 0.6410 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 181/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3649 - msle: 0.1753 - accuracy: 0.6351 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 182/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3804 - msle: 0.1828 - accuracy: 0.6196 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 183/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3868 - msle: 0.1859 - accuracy: 0.6132 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 184/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3899 - msle: 0.1873 - accuracy: 0.6101 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 185/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3940 - msle: 0.1893 - accuracy: 0.6060 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 186/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3729 - msle: 0.1792 - accuracy: 0.6271 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 187/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3754 - msle: 0.1804 - accuracy: 0.6246 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 188/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3485 - msle: 0.1674 - accuracy: 0.6515 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 189/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3885 - msle: 0.1867 - accuracy: 0.6115 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 190/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3672 - msle: 0.1764 - accuracy: 0.6328 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 191/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3692 - msle: 0.1774 - accuracy: 0.6308 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 192/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3642 - msle: 0.1750 - accuracy: 0.6358 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 193/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3747 - msle: 0.1800 - accuracy: 0.6253 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 194/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3845 - msle: 0.1847 - accuracy: 0.6155 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 195/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3678 - msle: 0.1767 - accuracy: 0.6322 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 196/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3689 - msle: 0.1772 - accuracy: 0.6311 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 197/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3802 - msle: 0.1826 - accuracy: 0.6198 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 198/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3597 - msle: 0.1728 - accuracy: 0.6403 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 199/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3910 - msle: 0.1879 - accuracy: 0.6090 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 200/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3614 - msle: 0.1736 - accuracy: 0.6386 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuT0dQdiEJrp"
      },
      "source": [
        "The accuracy with RMSProp is significantly worse than SGD's at the same learning rate due to the exponential decay of learning rate as opposed to SGD with momentum that allows for faster optimization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3KhWb3igGv1"
      },
      "source": [
        "Define the Adam optimizer with learning rate 0.01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnxqbb7CgGv3"
      },
      "source": [
        "Compile and fit the model using the optimizer defined above. How does the peformance differ with this optimizer?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewtmWJI3gGv1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3771b356-5d6b-4c99-9b97-d8f9442b09dd"
      },
      "source": [
        "# Answer below:\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "start = time.time()\n",
        "adam = Adam(learning_rate=0.01)\n",
        "model_3 = build_model(opt=adam, loss=\"mse\")\n",
        "m3_hist = model_3.fit(X_train_, y_train, epochs=200, batch_size=100,\n",
        "            verbose=1, validation_data=(X_test_, y_test))\n",
        "m3_time = time.time() - start"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "5/5 [==============================] - 1s 54ms/step - loss: 0.1842 - msle: 0.0977 - accuracy: 0.7579 - val_loss: 0.0568 - val_msle: 0.0270 - val_accuracy: 0.9298\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0515 - msle: 0.0244 - accuracy: 0.9267 - val_loss: 0.0469 - val_msle: 0.0217 - val_accuracy: 0.9298\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0391 - msle: 0.0189 - accuracy: 0.9532 - val_loss: 0.0597 - val_msle: 0.0273 - val_accuracy: 0.9211\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0353 - msle: 0.0170 - accuracy: 0.9605 - val_loss: 0.0461 - val_msle: 0.0211 - val_accuracy: 0.9386\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0321 - msle: 0.0148 - accuracy: 0.9557 - val_loss: 0.0403 - val_msle: 0.0194 - val_accuracy: 0.9561\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0438 - msle: 0.0218 - accuracy: 0.9482 - val_loss: 0.0513 - val_msle: 0.0239 - val_accuracy: 0.9386\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0350 - msle: 0.0160 - accuracy: 0.9552 - val_loss: 0.0482 - val_msle: 0.0221 - val_accuracy: 0.9298\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0368 - msle: 0.0179 - accuracy: 0.9546 - val_loss: 0.0488 - val_msle: 0.0223 - val_accuracy: 0.9386\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0232 - msle: 0.0106 - accuracy: 0.9707 - val_loss: 0.0484 - val_msle: 0.0222 - val_accuracy: 0.9386\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0211 - msle: 0.0104 - accuracy: 0.9761 - val_loss: 0.0460 - val_msle: 0.0214 - val_accuracy: 0.9474\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0213 - msle: 0.0103 - accuracy: 0.9728 - val_loss: 0.0479 - val_msle: 0.0220 - val_accuracy: 0.9386\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0222 - msle: 0.0102 - accuracy: 0.9719 - val_loss: 0.0460 - val_msle: 0.0212 - val_accuracy: 0.9474\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0233 - msle: 0.0115 - accuracy: 0.9713 - val_loss: 0.0427 - val_msle: 0.0200 - val_accuracy: 0.9474\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0177 - msle: 0.0089 - accuracy: 0.9806 - val_loss: 0.0433 - val_msle: 0.0202 - val_accuracy: 0.9474\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0172 - msle: 0.0082 - accuracy: 0.9789 - val_loss: 0.0423 - val_msle: 0.0199 - val_accuracy: 0.9561\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0177 - msle: 0.0089 - accuracy: 0.9820 - val_loss: 0.0425 - val_msle: 0.0199 - val_accuracy: 0.9561\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - 0s 58ms/step - loss: 0.0161 - msle: 0.0077 - accuracy: 0.9815 - val_loss: 0.0416 - val_msle: 0.0195 - val_accuracy: 0.9474\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0224 - msle: 0.0105 - accuracy: 0.9714 - val_loss: 0.0384 - val_msle: 0.0188 - val_accuracy: 0.9561\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0173 - msle: 0.0092 - accuracy: 0.9805 - val_loss: 0.0428 - val_msle: 0.0205 - val_accuracy: 0.9474\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0154 - msle: 0.0074 - accuracy: 0.9817 - val_loss: 0.0436 - val_msle: 0.0208 - val_accuracy: 0.9474\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0129 - msle: 0.0069 - accuracy: 0.9858 - val_loss: 0.0358 - val_msle: 0.0173 - val_accuracy: 0.9561\n",
            "Epoch 22/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0184 - msle: 0.0095 - accuracy: 0.9780 - val_loss: 0.0438 - val_msle: 0.0204 - val_accuracy: 0.9561\n",
            "Epoch 23/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0247 - msle: 0.0112 - accuracy: 0.9663 - val_loss: 0.0454 - val_msle: 0.0220 - val_accuracy: 0.9474\n",
            "Epoch 24/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0226 - msle: 0.0117 - accuracy: 0.9695 - val_loss: 0.0423 - val_msle: 0.0210 - val_accuracy: 0.9561\n",
            "Epoch 25/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0206 - msle: 0.0100 - accuracy: 0.9789 - val_loss: 0.0412 - val_msle: 0.0197 - val_accuracy: 0.9561\n",
            "Epoch 26/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0227 - msle: 0.0103 - accuracy: 0.9741 - val_loss: 0.0406 - val_msle: 0.0197 - val_accuracy: 0.9561\n",
            "Epoch 27/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0143 - msle: 0.0067 - accuracy: 0.9813 - val_loss: 0.0406 - val_msle: 0.0199 - val_accuracy: 0.9561\n",
            "Epoch 28/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0156 - msle: 0.0080 - accuracy: 0.9807 - val_loss: 0.0382 - val_msle: 0.0185 - val_accuracy: 0.9649\n",
            "Epoch 29/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0126 - msle: 0.0060 - accuracy: 0.9874 - val_loss: 0.0379 - val_msle: 0.0181 - val_accuracy: 0.9561\n",
            "Epoch 30/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0123 - msle: 0.0061 - accuracy: 0.9855 - val_loss: 0.0327 - val_msle: 0.0159 - val_accuracy: 0.9737\n",
            "Epoch 31/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0072 - msle: 0.0037 - accuracy: 0.9926 - val_loss: 0.0356 - val_msle: 0.0169 - val_accuracy: 0.9649\n",
            "Epoch 32/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0102 - msle: 0.0050 - accuracy: 0.9891 - val_loss: 0.0367 - val_msle: 0.0175 - val_accuracy: 0.9649\n",
            "Epoch 33/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0051 - msle: 0.0026 - accuracy: 0.9945 - val_loss: 0.0377 - val_msle: 0.0184 - val_accuracy: 0.9649\n",
            "Epoch 34/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0106 - msle: 0.0052 - accuracy: 0.9853 - val_loss: 0.0406 - val_msle: 0.0197 - val_accuracy: 0.9561\n",
            "Epoch 35/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0145 - msle: 0.0066 - accuracy: 0.9828 - val_loss: 0.0504 - val_msle: 0.0247 - val_accuracy: 0.9386\n",
            "Epoch 36/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0183 - msle: 0.0086 - accuracy: 0.9791 - val_loss: 0.0603 - val_msle: 0.0296 - val_accuracy: 0.9298\n",
            "Epoch 37/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0237 - msle: 0.0110 - accuracy: 0.9697 - val_loss: 0.0553 - val_msle: 0.0272 - val_accuracy: 0.9386\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0179 - msle: 0.0090 - accuracy: 0.9771 - val_loss: 0.0544 - val_msle: 0.0265 - val_accuracy: 0.9474\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0246 - msle: 0.0115 - accuracy: 0.9746 - val_loss: 0.0484 - val_msle: 0.0229 - val_accuracy: 0.9474\n",
            "Epoch 40/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0405 - msle: 0.0190 - accuracy: 0.9574 - val_loss: 0.0484 - val_msle: 0.0232 - val_accuracy: 0.9386\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0271 - msle: 0.0131 - accuracy: 0.9661 - val_loss: 0.0536 - val_msle: 0.0255 - val_accuracy: 0.9386\n",
            "Epoch 42/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0222 - msle: 0.0102 - accuracy: 0.9759 - val_loss: 0.0552 - val_msle: 0.0271 - val_accuracy: 0.9298\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0277 - msle: 0.0135 - accuracy: 0.9655 - val_loss: 0.0605 - val_msle: 0.0300 - val_accuracy: 0.9298\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0177 - msle: 0.0088 - accuracy: 0.9774 - val_loss: 0.0563 - val_msle: 0.0284 - val_accuracy: 0.9123\n",
            "Epoch 45/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0212 - msle: 0.0113 - accuracy: 0.9732 - val_loss: 0.0544 - val_msle: 0.0269 - val_accuracy: 0.9298\n",
            "Epoch 46/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0187 - msle: 0.0092 - accuracy: 0.9786 - val_loss: 0.0513 - val_msle: 0.0257 - val_accuracy: 0.9386\n",
            "Epoch 47/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0154 - msle: 0.0084 - accuracy: 0.9753 - val_loss: 0.0560 - val_msle: 0.0273 - val_accuracy: 0.9386\n",
            "Epoch 48/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0106 - msle: 0.0052 - accuracy: 0.9870 - val_loss: 0.0523 - val_msle: 0.0256 - val_accuracy: 0.9474\n",
            "Epoch 49/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0089 - msle: 0.0042 - accuracy: 0.9899 - val_loss: 0.0507 - val_msle: 0.0250 - val_accuracy: 0.9386\n",
            "Epoch 50/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0049 - msle: 0.0025 - accuracy: 0.9947 - val_loss: 0.0496 - val_msle: 0.0240 - val_accuracy: 0.9474\n",
            "Epoch 51/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0038 - msle: 0.0017 - accuracy: 0.9971 - val_loss: 0.0522 - val_msle: 0.0252 - val_accuracy: 0.9386\n",
            "Epoch 52/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0068 - msle: 0.0034 - accuracy: 0.9941 - val_loss: 0.0492 - val_msle: 0.0237 - val_accuracy: 0.9474\n",
            "Epoch 53/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0039 - msle: 0.0018 - accuracy: 0.9957 - val_loss: 0.0497 - val_msle: 0.0246 - val_accuracy: 0.9474\n",
            "Epoch 54/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0040 - msle: 0.0022 - accuracy: 0.9964 - val_loss: 0.0596 - val_msle: 0.0288 - val_accuracy: 0.9386\n",
            "Epoch 55/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0080 - msle: 0.0043 - accuracy: 0.9912 - val_loss: 0.0523 - val_msle: 0.0258 - val_accuracy: 0.9474\n",
            "Epoch 56/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0060 - msle: 0.0027 - accuracy: 0.9938 - val_loss: 0.0553 - val_msle: 0.0265 - val_accuracy: 0.9386\n",
            "Epoch 57/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0048 - msle: 0.0027 - accuracy: 0.9950 - val_loss: 0.0572 - val_msle: 0.0274 - val_accuracy: 0.9386\n",
            "Epoch 58/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0127 - msle: 0.0056 - accuracy: 0.9823 - val_loss: 0.0598 - val_msle: 0.0288 - val_accuracy: 0.9386\n",
            "Epoch 59/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0036 - msle: 0.0020 - accuracy: 0.9960 - val_loss: 0.0602 - val_msle: 0.0291 - val_accuracy: 0.9386\n",
            "Epoch 60/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0058 - msle: 0.0028 - accuracy: 0.9941 - val_loss: 0.0574 - val_msle: 0.0280 - val_accuracy: 0.9386\n",
            "Epoch 61/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0096 - msle: 0.0045 - accuracy: 0.9898 - val_loss: 0.0602 - val_msle: 0.0290 - val_accuracy: 0.9386\n",
            "Epoch 62/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0082 - msle: 0.0043 - accuracy: 0.9921 - val_loss: 0.0593 - val_msle: 0.0287 - val_accuracy: 0.9386\n",
            "Epoch 63/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0048 - msle: 0.0023 - accuracy: 0.9946 - val_loss: 0.0551 - val_msle: 0.0268 - val_accuracy: 0.9386\n",
            "Epoch 64/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0063 - msle: 0.0029 - accuracy: 0.9939 - val_loss: 0.0530 - val_msle: 0.0261 - val_accuracy: 0.9386\n",
            "Epoch 65/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0100 - msle: 0.0050 - accuracy: 0.9891 - val_loss: 0.0522 - val_msle: 0.0256 - val_accuracy: 0.9474\n",
            "Epoch 66/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0124 - msle: 0.0057 - accuracy: 0.9871 - val_loss: 0.0498 - val_msle: 0.0246 - val_accuracy: 0.9386\n",
            "Epoch 67/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0079 - msle: 0.0037 - accuracy: 0.9930 - val_loss: 0.0510 - val_msle: 0.0247 - val_accuracy: 0.9474\n",
            "Epoch 68/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0201 - msle: 0.0097 - accuracy: 0.9799 - val_loss: 0.0514 - val_msle: 0.0249 - val_accuracy: 0.9474\n",
            "Epoch 69/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0163 - msle: 0.0078 - accuracy: 0.9836 - val_loss: 0.0516 - val_msle: 0.0249 - val_accuracy: 0.9474\n",
            "Epoch 70/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0118 - msle: 0.0057 - accuracy: 0.9882 - val_loss: 0.0517 - val_msle: 0.0250 - val_accuracy: 0.9474\n",
            "Epoch 71/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0103 - msle: 0.0049 - accuracy: 0.9899 - val_loss: 0.0517 - val_msle: 0.0250 - val_accuracy: 0.9474\n",
            "Epoch 72/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0129 - msle: 0.0062 - accuracy: 0.9872 - val_loss: 0.0517 - val_msle: 0.0250 - val_accuracy: 0.9474\n",
            "Epoch 73/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0217 - msle: 0.0104 - accuracy: 0.9783 - val_loss: 0.0517 - val_msle: 0.0250 - val_accuracy: 0.9474\n",
            "Epoch 74/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0148 - msle: 0.0071 - accuracy: 0.9853 - val_loss: 0.0517 - val_msle: 0.0250 - val_accuracy: 0.9474\n",
            "Epoch 75/200\n",
            "5/5 [==============================] - 0s 55ms/step - loss: 0.0134 - msle: 0.0064 - accuracy: 0.9867 - val_loss: 0.0517 - val_msle: 0.0250 - val_accuracy: 0.9474\n",
            "Epoch 76/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0168 - msle: 0.0081 - accuracy: 0.9832 - val_loss: 0.0517 - val_msle: 0.0250 - val_accuracy: 0.9474\n",
            "Epoch 77/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0161 - msle: 0.0077 - accuracy: 0.9839 - val_loss: 0.0518 - val_msle: 0.0250 - val_accuracy: 0.9474\n",
            "Epoch 78/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0158 - msle: 0.0076 - accuracy: 0.9842 - val_loss: 0.0518 - val_msle: 0.0250 - val_accuracy: 0.9474\n",
            "Epoch 79/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0183 - msle: 0.0088 - accuracy: 0.9817 - val_loss: 0.0518 - val_msle: 0.0250 - val_accuracy: 0.9474\n",
            "Epoch 80/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0187 - msle: 0.0090 - accuracy: 0.9813 - val_loss: 0.0518 - val_msle: 0.0250 - val_accuracy: 0.9474\n",
            "Epoch 81/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0177 - msle: 0.0085 - accuracy: 0.9822 - val_loss: 0.0518 - val_msle: 0.0250 - val_accuracy: 0.9474\n",
            "Epoch 82/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0136 - msle: 0.0065 - accuracy: 0.9864 - val_loss: 0.0518 - val_msle: 0.0250 - val_accuracy: 0.9474\n",
            "Epoch 83/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0145 - msle: 0.0070 - accuracy: 0.9854 - val_loss: 0.0518 - val_msle: 0.0250 - val_accuracy: 0.9474\n",
            "Epoch 84/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0192 - msle: 0.0092 - accuracy: 0.9807 - val_loss: 0.0518 - val_msle: 0.0250 - val_accuracy: 0.9474\n",
            "Epoch 85/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0154 - msle: 0.0074 - accuracy: 0.9845 - val_loss: 0.0519 - val_msle: 0.0250 - val_accuracy: 0.9474\n",
            "Epoch 86/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0158 - msle: 0.0076 - accuracy: 0.9839 - val_loss: 0.0521 - val_msle: 0.0253 - val_accuracy: 0.9474\n",
            "Epoch 87/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0093 - msle: 0.0044 - accuracy: 0.9899 - val_loss: 0.0546 - val_msle: 0.0268 - val_accuracy: 0.9386\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0081 - msle: 0.0040 - accuracy: 0.9914 - val_loss: 0.0533 - val_msle: 0.0260 - val_accuracy: 0.9474\n",
            "Epoch 89/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0104 - msle: 0.0049 - accuracy: 0.9895 - val_loss: 0.0518 - val_msle: 0.0250 - val_accuracy: 0.9474\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0146 - msle: 0.0069 - accuracy: 0.9857 - val_loss: 0.0536 - val_msle: 0.0256 - val_accuracy: 0.9474\n",
            "Epoch 91/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0165 - msle: 0.0080 - accuracy: 0.9825 - val_loss: 0.0521 - val_msle: 0.0252 - val_accuracy: 0.9474\n",
            "Epoch 92/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0201 - msle: 0.0097 - accuracy: 0.9790 - val_loss: 0.0532 - val_msle: 0.0257 - val_accuracy: 0.9474\n",
            "Epoch 93/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0234 - msle: 0.0113 - accuracy: 0.9736 - val_loss: 0.0537 - val_msle: 0.0257 - val_accuracy: 0.9474\n",
            "Epoch 94/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0243 - msle: 0.0114 - accuracy: 0.9735 - val_loss: 0.0528 - val_msle: 0.0254 - val_accuracy: 0.9474\n",
            "Epoch 95/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0166 - msle: 0.0078 - accuracy: 0.9821 - val_loss: 0.0544 - val_msle: 0.0265 - val_accuracy: 0.9474\n",
            "Epoch 96/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0144 - msle: 0.0072 - accuracy: 0.9859 - val_loss: 0.0574 - val_msle: 0.0274 - val_accuracy: 0.9386\n",
            "Epoch 97/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0146 - msle: 0.0071 - accuracy: 0.9858 - val_loss: 0.0602 - val_msle: 0.0288 - val_accuracy: 0.9298\n",
            "Epoch 98/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0050 - msle: 0.0024 - accuracy: 0.9951 - val_loss: 0.0593 - val_msle: 0.0283 - val_accuracy: 0.9386\n",
            "Epoch 99/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0148 - msle: 0.0070 - accuracy: 0.9848 - val_loss: 0.0598 - val_msle: 0.0287 - val_accuracy: 0.9386\n",
            "Epoch 100/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0095 - msle: 0.0046 - accuracy: 0.9904 - val_loss: 0.0582 - val_msle: 0.0283 - val_accuracy: 0.9298\n",
            "Epoch 101/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0073 - msle: 0.0036 - accuracy: 0.9929 - val_loss: 0.0512 - val_msle: 0.0247 - val_accuracy: 0.9386\n",
            "Epoch 102/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0038 - msle: 0.0019 - accuracy: 0.9964 - val_loss: 0.0513 - val_msle: 0.0244 - val_accuracy: 0.9386\n",
            "Epoch 103/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0087 - msle: 0.0042 - accuracy: 0.9916 - val_loss: 0.0522 - val_msle: 0.0247 - val_accuracy: 0.9386\n",
            "Epoch 104/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0069 - msle: 0.0033 - accuracy: 0.9932 - val_loss: 0.0531 - val_msle: 0.0250 - val_accuracy: 0.9386\n",
            "Epoch 105/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0071 - msle: 0.0034 - accuracy: 0.9929 - val_loss: 0.0536 - val_msle: 0.0252 - val_accuracy: 0.9386\n",
            "Epoch 106/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0061 - msle: 0.0030 - accuracy: 0.9939 - val_loss: 0.0538 - val_msle: 0.0253 - val_accuracy: 0.9298\n",
            "Epoch 107/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0054 - msle: 0.0026 - accuracy: 0.9946 - val_loss: 0.0538 - val_msle: 0.0253 - val_accuracy: 0.9298\n",
            "Epoch 108/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0085 - msle: 0.0041 - accuracy: 0.9916 - val_loss: 0.0536 - val_msle: 0.0252 - val_accuracy: 0.9386\n",
            "Epoch 109/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0060 - msle: 0.0029 - accuracy: 0.9941 - val_loss: 0.0535 - val_msle: 0.0252 - val_accuracy: 0.9386\n",
            "Epoch 110/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0079 - msle: 0.0038 - accuracy: 0.9921 - val_loss: 0.0533 - val_msle: 0.0252 - val_accuracy: 0.9386\n",
            "Epoch 111/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0054 - msle: 0.0026 - accuracy: 0.9946 - val_loss: 0.0533 - val_msle: 0.0252 - val_accuracy: 0.9386\n",
            "Epoch 112/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0071 - msle: 0.0034 - accuracy: 0.9929 - val_loss: 0.0532 - val_msle: 0.0251 - val_accuracy: 0.9386\n",
            "Epoch 113/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0071 - msle: 0.0034 - accuracy: 0.9929 - val_loss: 0.0531 - val_msle: 0.0251 - val_accuracy: 0.9386\n",
            "Epoch 114/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0110 - msle: 0.0053 - accuracy: 0.9891 - val_loss: 0.0530 - val_msle: 0.0251 - val_accuracy: 0.9386\n",
            "Epoch 115/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0060 - msle: 0.0029 - accuracy: 0.9941 - val_loss: 0.0530 - val_msle: 0.0251 - val_accuracy: 0.9386\n",
            "Epoch 116/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0071 - msle: 0.0034 - accuracy: 0.9929 - val_loss: 0.0529 - val_msle: 0.0251 - val_accuracy: 0.9386\n",
            "Epoch 117/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0085 - msle: 0.0041 - accuracy: 0.9916 - val_loss: 0.0529 - val_msle: 0.0251 - val_accuracy: 0.9386\n",
            "Epoch 118/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0068 - msle: 0.0033 - accuracy: 0.9932 - val_loss: 0.0528 - val_msle: 0.0251 - val_accuracy: 0.9386\n",
            "Epoch 119/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0051 - msle: 0.0025 - accuracy: 0.9949 - val_loss: 0.0528 - val_msle: 0.0251 - val_accuracy: 0.9386\n",
            "Epoch 120/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0054 - msle: 0.0026 - accuracy: 0.9946 - val_loss: 0.0527 - val_msle: 0.0250 - val_accuracy: 0.9386\n",
            "Epoch 121/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0096 - msle: 0.0046 - accuracy: 0.9904 - val_loss: 0.0527 - val_msle: 0.0250 - val_accuracy: 0.9386\n",
            "Epoch 122/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0079 - msle: 0.0038 - accuracy: 0.9921 - val_loss: 0.0526 - val_msle: 0.0250 - val_accuracy: 0.9386\n",
            "Epoch 123/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0079 - msle: 0.0038 - accuracy: 0.9921 - val_loss: 0.0526 - val_msle: 0.0250 - val_accuracy: 0.9386\n",
            "Epoch 124/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0068 - msle: 0.0033 - accuracy: 0.9932 - val_loss: 0.0525 - val_msle: 0.0250 - val_accuracy: 0.9386\n",
            "Epoch 125/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0075 - msle: 0.0036 - accuracy: 0.9925 - val_loss: 0.0525 - val_msle: 0.0250 - val_accuracy: 0.9386\n",
            "Epoch 126/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0068 - msle: 0.0033 - accuracy: 0.9932 - val_loss: 0.0524 - val_msle: 0.0250 - val_accuracy: 0.9386\n",
            "Epoch 127/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0068 - msle: 0.0033 - accuracy: 0.9932 - val_loss: 0.0523 - val_msle: 0.0250 - val_accuracy: 0.9386\n",
            "Epoch 128/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0040 - msle: 0.0019 - accuracy: 0.9960 - val_loss: 0.0523 - val_msle: 0.0250 - val_accuracy: 0.9386\n",
            "Epoch 129/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0070 - msle: 0.0034 - accuracy: 0.9929 - val_loss: 0.0523 - val_msle: 0.0249 - val_accuracy: 0.9386\n",
            "Epoch 130/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0101 - msle: 0.0048 - accuracy: 0.9899 - val_loss: 0.0522 - val_msle: 0.0249 - val_accuracy: 0.9386\n",
            "Epoch 131/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0084 - msle: 0.0040 - accuracy: 0.9916 - val_loss: 0.0522 - val_msle: 0.0250 - val_accuracy: 0.9386\n",
            "Epoch 132/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0044 - msle: 0.0021 - accuracy: 0.9956 - val_loss: 0.0522 - val_msle: 0.0250 - val_accuracy: 0.9386\n",
            "Epoch 133/200\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.0109 - msle: 0.0052 - accuracy: 0.9891 - val_loss: 0.0522 - val_msle: 0.0250 - val_accuracy: 0.9386\n",
            "Epoch 134/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0050 - msle: 0.0024 - accuracy: 0.9950 - val_loss: 0.0523 - val_msle: 0.0251 - val_accuracy: 0.9386\n",
            "Epoch 135/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0084 - msle: 0.0040 - accuracy: 0.9916 - val_loss: 0.0525 - val_msle: 0.0251 - val_accuracy: 0.9386\n",
            "Epoch 136/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0073 - msle: 0.0035 - accuracy: 0.9925 - val_loss: 0.0526 - val_msle: 0.0252 - val_accuracy: 0.9386\n",
            "Epoch 137/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0055 - msle: 0.0026 - accuracy: 0.9942 - val_loss: 0.0534 - val_msle: 0.0256 - val_accuracy: 0.9474\n",
            "Epoch 138/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0061 - msle: 0.0029 - accuracy: 0.9937 - val_loss: 0.0590 - val_msle: 0.0285 - val_accuracy: 0.9386\n",
            "Epoch 139/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0147 - msle: 0.0070 - accuracy: 0.9859 - val_loss: 0.0596 - val_msle: 0.0291 - val_accuracy: 0.9386\n",
            "Epoch 140/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0154 - msle: 0.0074 - accuracy: 0.9846 - val_loss: 0.0556 - val_msle: 0.0263 - val_accuracy: 0.9386\n",
            "Epoch 141/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0170 - msle: 0.0082 - accuracy: 0.9831 - val_loss: 0.0478 - val_msle: 0.0227 - val_accuracy: 0.9474\n",
            "Epoch 142/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0112 - msle: 0.0054 - accuracy: 0.9888 - val_loss: 0.0438 - val_msle: 0.0211 - val_accuracy: 0.9474\n",
            "Epoch 143/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0119 - msle: 0.0057 - accuracy: 0.9881 - val_loss: 0.0453 - val_msle: 0.0218 - val_accuracy: 0.9474\n",
            "Epoch 144/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0098 - msle: 0.0047 - accuracy: 0.9901 - val_loss: 0.0457 - val_msle: 0.0219 - val_accuracy: 0.9561\n",
            "Epoch 145/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0123 - msle: 0.0059 - accuracy: 0.9876 - val_loss: 0.0452 - val_msle: 0.0220 - val_accuracy: 0.9561\n",
            "Epoch 146/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0138 - msle: 0.0065 - accuracy: 0.9858 - val_loss: 0.0474 - val_msle: 0.0232 - val_accuracy: 0.9474\n",
            "Epoch 147/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0068 - msle: 0.0032 - accuracy: 0.9926 - val_loss: 0.0506 - val_msle: 0.0245 - val_accuracy: 0.9474\n",
            "Epoch 148/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0129 - msle: 0.0062 - accuracy: 0.9873 - val_loss: 0.0523 - val_msle: 0.0252 - val_accuracy: 0.9474\n",
            "Epoch 149/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0093 - msle: 0.0045 - accuracy: 0.9904 - val_loss: 0.0525 - val_msle: 0.0252 - val_accuracy: 0.9474\n",
            "Epoch 150/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0127 - msle: 0.0061 - accuracy: 0.9873 - val_loss: 0.0532 - val_msle: 0.0254 - val_accuracy: 0.9474\n",
            "Epoch 151/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0147 - msle: 0.0070 - accuracy: 0.9845 - val_loss: 0.0514 - val_msle: 0.0247 - val_accuracy: 0.9386\n",
            "Epoch 152/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0066 - msle: 0.0032 - accuracy: 0.9935 - val_loss: 0.0506 - val_msle: 0.0245 - val_accuracy: 0.9474\n",
            "Epoch 153/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0117 - msle: 0.0056 - accuracy: 0.9883 - val_loss: 0.0509 - val_msle: 0.0246 - val_accuracy: 0.9474\n",
            "Epoch 154/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0103 - msle: 0.0050 - accuracy: 0.9897 - val_loss: 0.0511 - val_msle: 0.0248 - val_accuracy: 0.9474\n",
            "Epoch 155/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0074 - msle: 0.0035 - accuracy: 0.9926 - val_loss: 0.0513 - val_msle: 0.0248 - val_accuracy: 0.9474\n",
            "Epoch 156/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0079 - msle: 0.0038 - accuracy: 0.9921 - val_loss: 0.0514 - val_msle: 0.0248 - val_accuracy: 0.9474\n",
            "Epoch 157/200\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0052 - msle: 0.0025 - accuracy: 0.9948 - val_loss: 0.0514 - val_msle: 0.0248 - val_accuracy: 0.9474\n",
            "Epoch 158/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0079 - msle: 0.0038 - accuracy: 0.9921 - val_loss: 0.0514 - val_msle: 0.0248 - val_accuracy: 0.9474\n",
            "Epoch 159/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0100 - msle: 0.0048 - accuracy: 0.9900 - val_loss: 0.0514 - val_msle: 0.0248 - val_accuracy: 0.9474\n",
            "Epoch 160/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0053 - msle: 0.0025 - accuracy: 0.9947 - val_loss: 0.0514 - val_msle: 0.0248 - val_accuracy: 0.9474\n",
            "Epoch 161/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0135 - msle: 0.0065 - accuracy: 0.9865 - val_loss: 0.0514 - val_msle: 0.0248 - val_accuracy: 0.9474\n",
            "Epoch 162/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0096 - msle: 0.0046 - accuracy: 0.9904 - val_loss: 0.0514 - val_msle: 0.0248 - val_accuracy: 0.9474\n",
            "Epoch 163/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0096 - msle: 0.0046 - accuracy: 0.9904 - val_loss: 0.0514 - val_msle: 0.0248 - val_accuracy: 0.9474\n",
            "Epoch 164/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0075 - msle: 0.0036 - accuracy: 0.9925 - val_loss: 0.0513 - val_msle: 0.0248 - val_accuracy: 0.9474\n",
            "Epoch 165/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0110 - msle: 0.0053 - accuracy: 0.9890 - val_loss: 0.0513 - val_msle: 0.0248 - val_accuracy: 0.9474\n",
            "Epoch 166/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0118 - msle: 0.0057 - accuracy: 0.9882 - val_loss: 0.0513 - val_msle: 0.0248 - val_accuracy: 0.9474\n",
            "Epoch 167/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0096 - msle: 0.0046 - accuracy: 0.9904 - val_loss: 0.0513 - val_msle: 0.0248 - val_accuracy: 0.9474\n",
            "Epoch 168/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0052 - msle: 0.0025 - accuracy: 0.9948 - val_loss: 0.0513 - val_msle: 0.0248 - val_accuracy: 0.9474\n",
            "Epoch 169/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0103 - msle: 0.0049 - accuracy: 0.9897 - val_loss: 0.0513 - val_msle: 0.0248 - val_accuracy: 0.9474\n",
            "Epoch 170/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0068 - msle: 0.0033 - accuracy: 0.9932 - val_loss: 0.0513 - val_msle: 0.0248 - val_accuracy: 0.9474\n",
            "Epoch 171/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0110 - msle: 0.0053 - accuracy: 0.9890 - val_loss: 0.0513 - val_msle: 0.0248 - val_accuracy: 0.9474\n",
            "Epoch 172/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0133 - msle: 0.0064 - accuracy: 0.9867 - val_loss: 0.0513 - val_msle: 0.0248 - val_accuracy: 0.9474\n",
            "Epoch 173/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0113 - msle: 0.0054 - accuracy: 0.9887 - val_loss: 0.0513 - val_msle: 0.0248 - val_accuracy: 0.9474\n",
            "Epoch 174/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0110 - msle: 0.0053 - accuracy: 0.9890 - val_loss: 0.0513 - val_msle: 0.0248 - val_accuracy: 0.9474\n",
            "Epoch 175/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0152 - msle: 0.0073 - accuracy: 0.9848 - val_loss: 0.0513 - val_msle: 0.0248 - val_accuracy: 0.9474\n",
            "Epoch 176/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0057 - msle: 0.0027 - accuracy: 0.9943 - val_loss: 0.0513 - val_msle: 0.0248 - val_accuracy: 0.9474\n",
            "Epoch 177/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0085 - msle: 0.0041 - accuracy: 0.9915 - val_loss: 0.0513 - val_msle: 0.0248 - val_accuracy: 0.9474\n",
            "Epoch 178/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0067 - msle: 0.0032 - accuracy: 0.9933 - val_loss: 0.0514 - val_msle: 0.0248 - val_accuracy: 0.9474\n",
            "Epoch 179/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0127 - msle: 0.0061 - accuracy: 0.9873 - val_loss: 0.0514 - val_msle: 0.0248 - val_accuracy: 0.9474\n",
            "Epoch 180/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0143 - msle: 0.0069 - accuracy: 0.9857 - val_loss: 0.0514 - val_msle: 0.0248 - val_accuracy: 0.9474\n",
            "Epoch 181/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0061 - msle: 0.0029 - accuracy: 0.9939 - val_loss: 0.0514 - val_msle: 0.0248 - val_accuracy: 0.9474\n",
            "Epoch 182/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0102 - msle: 0.0049 - accuracy: 0.9898 - val_loss: 0.0514 - val_msle: 0.0248 - val_accuracy: 0.9474\n",
            "Epoch 183/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0061 - msle: 0.0029 - accuracy: 0.9939 - val_loss: 0.0514 - val_msle: 0.0249 - val_accuracy: 0.9474\n",
            "Epoch 184/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0071 - msle: 0.0034 - accuracy: 0.9929 - val_loss: 0.0514 - val_msle: 0.0249 - val_accuracy: 0.9474\n",
            "Epoch 185/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0086 - msle: 0.0041 - accuracy: 0.9914 - val_loss: 0.0515 - val_msle: 0.0249 - val_accuracy: 0.9474\n",
            "Epoch 186/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0088 - msle: 0.0042 - accuracy: 0.9912 - val_loss: 0.0515 - val_msle: 0.0249 - val_accuracy: 0.9474\n",
            "Epoch 187/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0061 - msle: 0.0029 - accuracy: 0.9939 - val_loss: 0.0515 - val_msle: 0.0249 - val_accuracy: 0.9474\n",
            "Epoch 188/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0082 - msle: 0.0039 - accuracy: 0.9918 - val_loss: 0.0515 - val_msle: 0.0249 - val_accuracy: 0.9474\n",
            "Epoch 189/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0117 - msle: 0.0056 - accuracy: 0.9883 - val_loss: 0.0516 - val_msle: 0.0249 - val_accuracy: 0.9474\n",
            "Epoch 190/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0086 - msle: 0.0041 - accuracy: 0.9914 - val_loss: 0.0516 - val_msle: 0.0249 - val_accuracy: 0.9474\n",
            "Epoch 191/200\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.0108 - msle: 0.0052 - accuracy: 0.9892 - val_loss: 0.0517 - val_msle: 0.0250 - val_accuracy: 0.9474\n",
            "Epoch 192/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0108 - msle: 0.0052 - accuracy: 0.9892 - val_loss: 0.0518 - val_msle: 0.0250 - val_accuracy: 0.9474\n",
            "Epoch 193/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0086 - msle: 0.0041 - accuracy: 0.9914 - val_loss: 0.0519 - val_msle: 0.0250 - val_accuracy: 0.9474\n",
            "Epoch 194/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0093 - msle: 0.0045 - accuracy: 0.9907 - val_loss: 0.0519 - val_msle: 0.0250 - val_accuracy: 0.9474\n",
            "Epoch 195/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0042 - msle: 0.0020 - accuracy: 0.9958 - val_loss: 0.0520 - val_msle: 0.0251 - val_accuracy: 0.9474\n",
            "Epoch 196/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0109 - msle: 0.0052 - accuracy: 0.9890 - val_loss: 0.0522 - val_msle: 0.0251 - val_accuracy: 0.9474\n",
            "Epoch 197/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0087 - msle: 0.0042 - accuracy: 0.9912 - val_loss: 0.0523 - val_msle: 0.0252 - val_accuracy: 0.9474\n",
            "Epoch 198/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0116 - msle: 0.0055 - accuracy: 0.9879 - val_loss: 0.0524 - val_msle: 0.0252 - val_accuracy: 0.9474\n",
            "Epoch 199/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0048 - msle: 0.0023 - accuracy: 0.9943 - val_loss: 0.0522 - val_msle: 0.0251 - val_accuracy: 0.9474\n",
            "Epoch 200/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0096 - msle: 0.0047 - accuracy: 0.9907 - val_loss: 0.0522 - val_msle: 0.0251 - val_accuracy: 0.9474\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Agwv6GddE1KB"
      },
      "source": [
        "Adam w/ LR=0.01 did better than RMSProp w/ LR=0.05. It performed close to SGD w/LR=0.05 & M=0.9."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1opnI2qCgGv5"
      },
      "source": [
        "Now change the learning rate to 0.1 in your Adam optimizer and compare the results (both speed and accuracy)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIGTzU1DgGv6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df5a299a-613e-4c04-b94a-10141baab706"
      },
      "source": [
        "# Answer below:\n",
        "start = time.time()\n",
        "adam = Adam(0.1)\n",
        "model_4 = build_model(opt=adam, loss=\"mse\")\n",
        "m4_hist = model_4.fit(X_train_, y_train, epochs=200, batch_size=100,\n",
        "            verbose=1, validation_data=(X_test_, y_test))\n",
        "m4_time = time.time() - start"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "5/5 [==============================] - 1s 55ms/step - loss: 0.2192 - msle: 0.1104 - accuracy: 0.7390 - val_loss: 0.0702 - val_msle: 0.0337 - val_accuracy: 0.9298\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2493 - msle: 0.1198 - accuracy: 0.7506 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3606 - msle: 0.1732 - accuracy: 0.6394 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3738 - msle: 0.1796 - accuracy: 0.6262 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3631 - msle: 0.1744 - accuracy: 0.6369 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3463 - msle: 0.1664 - accuracy: 0.6537 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3677 - msle: 0.1766 - accuracy: 0.6323 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3585 - msle: 0.1722 - accuracy: 0.6415 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3742 - msle: 0.1798 - accuracy: 0.6258 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3572 - msle: 0.1716 - accuracy: 0.6428 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3760 - msle: 0.1806 - accuracy: 0.6240 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3782 - msle: 0.1817 - accuracy: 0.6218 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3403 - msle: 0.1635 - accuracy: 0.6597 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3627 - msle: 0.1742 - accuracy: 0.6373 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3809 - msle: 0.1830 - accuracy: 0.6191 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3768 - msle: 0.1810 - accuracy: 0.6232 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3647 - msle: 0.1752 - accuracy: 0.6353 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3659 - msle: 0.1758 - accuracy: 0.6341 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3464 - msle: 0.1664 - accuracy: 0.6536 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3770 - msle: 0.1811 - accuracy: 0.6230 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3807 - msle: 0.1829 - accuracy: 0.6193 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 22/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3681 - msle: 0.1768 - accuracy: 0.6319 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 23/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3665 - msle: 0.1761 - accuracy: 0.6335 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 24/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3621 - msle: 0.1740 - accuracy: 0.6379 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 25/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3635 - msle: 0.1746 - accuracy: 0.6365 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 26/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3825 - msle: 0.1838 - accuracy: 0.6175 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 27/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3417 - msle: 0.1642 - accuracy: 0.6583 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 28/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3577 - msle: 0.1718 - accuracy: 0.6423 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 29/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3597 - msle: 0.1728 - accuracy: 0.6403 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 30/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3654 - msle: 0.1756 - accuracy: 0.6346 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 31/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3745 - msle: 0.1799 - accuracy: 0.6255 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 32/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3853 - msle: 0.1851 - accuracy: 0.6147 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 33/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3696 - msle: 0.1776 - accuracy: 0.6304 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 34/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3654 - msle: 0.1756 - accuracy: 0.6346 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 35/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3747 - msle: 0.1800 - accuracy: 0.6253 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 36/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3570 - msle: 0.1715 - accuracy: 0.6430 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 37/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3659 - msle: 0.1758 - accuracy: 0.6341 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3836 - msle: 0.1843 - accuracy: 0.6164 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3759 - msle: 0.1806 - accuracy: 0.6241 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 40/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3709 - msle: 0.1782 - accuracy: 0.6291 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3778 - msle: 0.1815 - accuracy: 0.6222 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 42/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3809 - msle: 0.1830 - accuracy: 0.6191 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - 0s 59ms/step - loss: 0.3714 - msle: 0.1784 - accuracy: 0.6286 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3865 - msle: 0.1857 - accuracy: 0.6135 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 45/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3559 - msle: 0.1710 - accuracy: 0.6441 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 46/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3739 - msle: 0.1796 - accuracy: 0.6261 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 47/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3424 - msle: 0.1645 - accuracy: 0.6576 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 48/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3593 - msle: 0.1726 - accuracy: 0.6407 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 49/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3820 - msle: 0.1835 - accuracy: 0.6180 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 50/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3567 - msle: 0.1714 - accuracy: 0.6433 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 51/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4047 - msle: 0.1945 - accuracy: 0.5953 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 52/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3715 - msle: 0.1785 - accuracy: 0.6285 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 53/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3685 - msle: 0.1770 - accuracy: 0.6315 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 54/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3642 - msle: 0.1750 - accuracy: 0.6358 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 55/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3472 - msle: 0.1668 - accuracy: 0.6528 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 56/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3502 - msle: 0.1682 - accuracy: 0.6498 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 57/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3581 - msle: 0.1720 - accuracy: 0.6419 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 58/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3763 - msle: 0.1808 - accuracy: 0.6237 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 59/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3628 - msle: 0.1743 - accuracy: 0.6372 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 60/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3803 - msle: 0.1827 - accuracy: 0.6197 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 61/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3604 - msle: 0.1732 - accuracy: 0.6396 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 62/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3477 - msle: 0.1670 - accuracy: 0.6523 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 63/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3889 - msle: 0.1869 - accuracy: 0.6111 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 64/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3625 - msle: 0.1742 - accuracy: 0.6375 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 65/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3871 - msle: 0.1860 - accuracy: 0.6129 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 66/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3820 - msle: 0.1835 - accuracy: 0.6180 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 67/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3770 - msle: 0.1811 - accuracy: 0.6230 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 68/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3590 - msle: 0.1725 - accuracy: 0.6410 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 69/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3684 - msle: 0.1770 - accuracy: 0.6316 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 70/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3947 - msle: 0.1897 - accuracy: 0.6053 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 71/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3720 - msle: 0.1787 - accuracy: 0.6280 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 72/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3578 - msle: 0.1719 - accuracy: 0.6422 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 73/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3681 - msle: 0.1768 - accuracy: 0.6319 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 74/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3386 - msle: 0.1627 - accuracy: 0.6614 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 75/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3471 - msle: 0.1668 - accuracy: 0.6529 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 76/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3774 - msle: 0.1813 - accuracy: 0.6226 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 77/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3645 - msle: 0.1751 - accuracy: 0.6355 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 78/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3767 - msle: 0.1810 - accuracy: 0.6233 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 79/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3797 - msle: 0.1824 - accuracy: 0.6203 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 80/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3743 - msle: 0.1798 - accuracy: 0.6257 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 81/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3860 - msle: 0.1855 - accuracy: 0.6140 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 82/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3675 - msle: 0.1766 - accuracy: 0.6325 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 83/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3925 - msle: 0.1886 - accuracy: 0.6075 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 84/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3834 - msle: 0.1842 - accuracy: 0.6166 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 85/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3539 - msle: 0.1700 - accuracy: 0.6461 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 86/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3914 - msle: 0.1881 - accuracy: 0.6086 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 87/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3663 - msle: 0.1760 - accuracy: 0.6337 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3802 - msle: 0.1826 - accuracy: 0.6198 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 89/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3677 - msle: 0.1766 - accuracy: 0.6323 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3722 - msle: 0.1788 - accuracy: 0.6278 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 91/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3771 - msle: 0.1812 - accuracy: 0.6229 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 92/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3731 - msle: 0.1792 - accuracy: 0.6269 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 93/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3665 - msle: 0.1761 - accuracy: 0.6335 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 94/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3768 - msle: 0.1810 - accuracy: 0.6232 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 95/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3590 - msle: 0.1725 - accuracy: 0.6410 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 96/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3599 - msle: 0.1729 - accuracy: 0.6401 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 97/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3695 - msle: 0.1775 - accuracy: 0.6305 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 98/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3861 - msle: 0.1855 - accuracy: 0.6139 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 99/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3615 - msle: 0.1737 - accuracy: 0.6385 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 100/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3652 - msle: 0.1754 - accuracy: 0.6348 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 101/200\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.3695 - msle: 0.1775 - accuracy: 0.6305 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 102/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3722 - msle: 0.1788 - accuracy: 0.6278 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 103/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3552 - msle: 0.1706 - accuracy: 0.6448 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 104/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3706 - msle: 0.1780 - accuracy: 0.6294 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 105/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3752 - msle: 0.1802 - accuracy: 0.6248 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 106/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3763 - msle: 0.1808 - accuracy: 0.6237 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 107/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3645 - msle: 0.1751 - accuracy: 0.6355 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 108/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3667 - msle: 0.1762 - accuracy: 0.6333 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 109/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3727 - msle: 0.1790 - accuracy: 0.6273 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 110/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3556 - msle: 0.1708 - accuracy: 0.6444 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 111/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3561 - msle: 0.1711 - accuracy: 0.6439 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 112/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3734 - msle: 0.1794 - accuracy: 0.6266 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 113/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3568 - msle: 0.1714 - accuracy: 0.6432 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 114/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3610 - msle: 0.1734 - accuracy: 0.6390 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 115/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3747 - msle: 0.1800 - accuracy: 0.6253 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 116/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3675 - msle: 0.1766 - accuracy: 0.6325 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 117/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3507 - msle: 0.1685 - accuracy: 0.6493 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 118/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3811 - msle: 0.1831 - accuracy: 0.6189 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 119/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3964 - msle: 0.1905 - accuracy: 0.6036 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 120/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3860 - msle: 0.1855 - accuracy: 0.6140 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 121/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3711 - msle: 0.1783 - accuracy: 0.6289 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 122/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3793 - msle: 0.1822 - accuracy: 0.6207 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 123/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3846 - msle: 0.1848 - accuracy: 0.6154 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 124/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3263 - msle: 0.1568 - accuracy: 0.6737 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 125/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3599 - msle: 0.1729 - accuracy: 0.6401 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 126/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3831 - msle: 0.1841 - accuracy: 0.6169 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 127/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3910 - msle: 0.1879 - accuracy: 0.6090 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 128/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3574 - msle: 0.1717 - accuracy: 0.6426 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 129/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3646 - msle: 0.1752 - accuracy: 0.6354 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 130/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3706 - msle: 0.1780 - accuracy: 0.6294 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 131/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3703 - msle: 0.1779 - accuracy: 0.6297 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 132/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3727 - msle: 0.1790 - accuracy: 0.6273 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 133/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3586 - msle: 0.1723 - accuracy: 0.6414 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 134/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3742 - msle: 0.1798 - accuracy: 0.6258 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 135/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3759 - msle: 0.1806 - accuracy: 0.6241 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 136/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3515 - msle: 0.1689 - accuracy: 0.6485 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 137/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3504 - msle: 0.1684 - accuracy: 0.6496 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 138/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3647 - msle: 0.1752 - accuracy: 0.6353 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 139/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3686 - msle: 0.1771 - accuracy: 0.6314 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 140/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3642 - msle: 0.1750 - accuracy: 0.6358 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 141/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3821 - msle: 0.1836 - accuracy: 0.6179 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 142/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3421 - msle: 0.1644 - accuracy: 0.6579 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 143/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3556 - msle: 0.1708 - accuracy: 0.6444 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 144/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3789 - msle: 0.1820 - accuracy: 0.6211 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 145/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3629 - msle: 0.1744 - accuracy: 0.6371 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 146/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3913 - msle: 0.1880 - accuracy: 0.6087 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 147/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3647 - msle: 0.1752 - accuracy: 0.6353 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 148/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3667 - msle: 0.1762 - accuracy: 0.6333 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 149/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3595 - msle: 0.1727 - accuracy: 0.6405 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 150/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3736 - msle: 0.1795 - accuracy: 0.6264 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 151/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3709 - msle: 0.1782 - accuracy: 0.6291 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 152/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3714 - msle: 0.1784 - accuracy: 0.6286 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 153/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3627 - msle: 0.1742 - accuracy: 0.6373 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 154/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3707 - msle: 0.1781 - accuracy: 0.6293 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 155/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3854 - msle: 0.1852 - accuracy: 0.6146 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 156/200\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.3785 - msle: 0.1818 - accuracy: 0.6215 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 157/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3647 - msle: 0.1752 - accuracy: 0.6353 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 158/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.4060 - msle: 0.1951 - accuracy: 0.5940 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 159/200\n",
            "5/5 [==============================] - 0s 51ms/step - loss: 0.3538 - msle: 0.1700 - accuracy: 0.6462 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 160/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3667 - msle: 0.1762 - accuracy: 0.6333 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 161/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3678 - msle: 0.1767 - accuracy: 0.6322 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 162/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3649 - msle: 0.1753 - accuracy: 0.6351 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 163/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3809 - msle: 0.1830 - accuracy: 0.6191 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 164/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3771 - msle: 0.1812 - accuracy: 0.6229 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 165/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3417 - msle: 0.1642 - accuracy: 0.6583 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 166/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3822 - msle: 0.1837 - accuracy: 0.6178 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 167/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3639 - msle: 0.1748 - accuracy: 0.6361 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 168/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3556 - msle: 0.1708 - accuracy: 0.6444 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 169/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3763 - msle: 0.1808 - accuracy: 0.6237 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 170/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3681 - msle: 0.1768 - accuracy: 0.6319 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 171/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3875 - msle: 0.1862 - accuracy: 0.6125 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 172/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3663 - msle: 0.1760 - accuracy: 0.6337 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 173/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3589 - msle: 0.1724 - accuracy: 0.6411 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 174/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3629 - msle: 0.1744 - accuracy: 0.6371 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 175/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3556 - msle: 0.1708 - accuracy: 0.6444 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 176/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3770 - msle: 0.1811 - accuracy: 0.6230 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 177/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3664 - msle: 0.1760 - accuracy: 0.6336 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 178/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3499 - msle: 0.1681 - accuracy: 0.6501 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 179/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3561 - msle: 0.1711 - accuracy: 0.6439 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 180/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3524 - msle: 0.1693 - accuracy: 0.6476 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 181/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3784 - msle: 0.1818 - accuracy: 0.6216 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 182/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3753 - msle: 0.1803 - accuracy: 0.6247 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 183/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3622 - msle: 0.1740 - accuracy: 0.6378 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 184/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3859 - msle: 0.1854 - accuracy: 0.6141 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 185/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3593 - msle: 0.1726 - accuracy: 0.6407 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 186/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3779 - msle: 0.1816 - accuracy: 0.6221 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 187/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3870 - msle: 0.1859 - accuracy: 0.6130 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 188/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3615 - msle: 0.1737 - accuracy: 0.6385 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 189/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3722 - msle: 0.1788 - accuracy: 0.6278 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 190/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3807 - msle: 0.1829 - accuracy: 0.6193 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 191/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3824 - msle: 0.1837 - accuracy: 0.6176 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 192/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3746 - msle: 0.1800 - accuracy: 0.6254 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 193/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3697 - msle: 0.1776 - accuracy: 0.6303 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 194/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3600 - msle: 0.1730 - accuracy: 0.6400 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 195/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3471 - msle: 0.1668 - accuracy: 0.6529 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 196/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3988 - msle: 0.1916 - accuracy: 0.6012 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 197/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3756 - msle: 0.1804 - accuracy: 0.6244 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 198/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3559 - msle: 0.1710 - accuracy: 0.6441 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 199/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3515 - msle: 0.1689 - accuracy: 0.6485 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n",
            "Epoch 200/200\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.3754 - msle: 0.1804 - accuracy: 0.6246 - val_loss: 0.3860 - val_msle: 0.1854 - val_accuracy: 0.6140\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "pnwzKrHBGLer",
        "outputId": "bc3c96e6-0a5a-44f8-cf4b-99635dc752e5"
      },
      "source": [
        "pd.DataFrame(m1_hist.history)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>msle</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_msle</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.246292</td>\n",
              "      <td>0.131009</td>\n",
              "      <td>0.665934</td>\n",
              "      <td>0.231629</td>\n",
              "      <td>0.122619</td>\n",
              "      <td>0.771930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.212634</td>\n",
              "      <td>0.114468</td>\n",
              "      <td>0.887912</td>\n",
              "      <td>0.187915</td>\n",
              "      <td>0.100635</td>\n",
              "      <td>0.894737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.163784</td>\n",
              "      <td>0.089048</td>\n",
              "      <td>0.927473</td>\n",
              "      <td>0.131158</td>\n",
              "      <td>0.070602</td>\n",
              "      <td>0.912281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.106132</td>\n",
              "      <td>0.057481</td>\n",
              "      <td>0.940659</td>\n",
              "      <td>0.080544</td>\n",
              "      <td>0.043411</td>\n",
              "      <td>0.912281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.065268</td>\n",
              "      <td>0.034131</td>\n",
              "      <td>0.940659</td>\n",
              "      <td>0.060520</td>\n",
              "      <td>0.031073</td>\n",
              "      <td>0.938596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>0.004619</td>\n",
              "      <td>0.002238</td>\n",
              "      <td>0.995604</td>\n",
              "      <td>0.042195</td>\n",
              "      <td>0.021365</td>\n",
              "      <td>0.938596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>0.004612</td>\n",
              "      <td>0.002239</td>\n",
              "      <td>0.995604</td>\n",
              "      <td>0.042903</td>\n",
              "      <td>0.021684</td>\n",
              "      <td>0.938596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>0.004603</td>\n",
              "      <td>0.002242</td>\n",
              "      <td>0.995604</td>\n",
              "      <td>0.042636</td>\n",
              "      <td>0.021576</td>\n",
              "      <td>0.938596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>0.004598</td>\n",
              "      <td>0.002235</td>\n",
              "      <td>0.995604</td>\n",
              "      <td>0.042610</td>\n",
              "      <td>0.021572</td>\n",
              "      <td>0.938596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>0.004599</td>\n",
              "      <td>0.002229</td>\n",
              "      <td>0.995604</td>\n",
              "      <td>0.042455</td>\n",
              "      <td>0.021504</td>\n",
              "      <td>0.938596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss      msle  accuracy  val_loss  val_msle  val_accuracy\n",
              "0    0.246292  0.131009  0.665934  0.231629  0.122619      0.771930\n",
              "1    0.212634  0.114468  0.887912  0.187915  0.100635      0.894737\n",
              "2    0.163784  0.089048  0.927473  0.131158  0.070602      0.912281\n",
              "3    0.106132  0.057481  0.940659  0.080544  0.043411      0.912281\n",
              "4    0.065268  0.034131  0.940659  0.060520  0.031073      0.938596\n",
              "..        ...       ...       ...       ...       ...           ...\n",
              "195  0.004619  0.002238  0.995604  0.042195  0.021365      0.938596\n",
              "196  0.004612  0.002239  0.995604  0.042903  0.021684      0.938596\n",
              "197  0.004603  0.002242  0.995604  0.042636  0.021576      0.938596\n",
              "198  0.004598  0.002235  0.995604  0.042610  0.021572      0.938596\n",
              "199  0.004599  0.002229  0.995604  0.042455  0.021504      0.938596\n",
              "\n",
              "[200 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY_dPdAuFm8J"
      },
      "source": [
        "d = {\"SGD_accuracy\" : m1_hist.history[\"accuracy\"],\r\n",
        "     \"RMSProp_accuracy\" : m2_hist.history[\"accuracy\"],\r\n",
        "     \"Adam0.01_accuracy\" : m3_hist.history[\"accuracy\"],\r\n",
        "     \"Adam0.1_accuracy\" : m4_hist.history[\"accuracy\"]}\r\n",
        "results = pd.DataFrame(\r\n",
        "    data=d)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "nigck4gNGwgS",
        "outputId": "31ad3c1a-9167-4579-a547-d08cf3a2561a"
      },
      "source": [
        "results.tail()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SGD_accuracy</th>\n",
              "      <th>RMSProp_accuracy</th>\n",
              "      <th>Adam0.01_accuracy</th>\n",
              "      <th>Adam0.1_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>0.995604</td>\n",
              "      <td>0.630769</td>\n",
              "      <td>0.991209</td>\n",
              "      <td>0.630769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>0.995604</td>\n",
              "      <td>0.630769</td>\n",
              "      <td>0.991209</td>\n",
              "      <td>0.630769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>0.995604</td>\n",
              "      <td>0.630769</td>\n",
              "      <td>0.991209</td>\n",
              "      <td>0.630769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>0.995604</td>\n",
              "      <td>0.630769</td>\n",
              "      <td>0.991209</td>\n",
              "      <td>0.630769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>0.995604</td>\n",
              "      <td>0.630769</td>\n",
              "      <td>0.993407</td>\n",
              "      <td>0.630769</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     SGD_accuracy  RMSProp_accuracy  Adam0.01_accuracy  Adam0.1_accuracy\n",
              "195      0.995604          0.630769           0.991209          0.630769\n",
              "196      0.995604          0.630769           0.991209          0.630769\n",
              "197      0.995604          0.630769           0.991209          0.630769\n",
              "198      0.995604          0.630769           0.991209          0.630769\n",
              "199      0.995604          0.630769           0.993407          0.630769"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "FMiilBsPG0iz",
        "outputId": "e9772ce5-f0ed-4b57-e242-06e1d767eeac"
      },
      "source": [
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "plt.figure(figsize=(12,8))\r\n",
        "plt.title(\"Accuracy\")\r\n",
        "sns.lineplot(data=results)\r\n",
        "plt.show()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "n3mmbV6iIM6B",
        "outputId": "374ea1b2-d40c-4f7e-971a-ed2cdb1f07de"
      },
      "source": [
        "runtime = pd.DataFrame(index=[\"SGD\", \"RMSProp\", \"Adam0.01\", \"Adam0.1\"],\r\n",
        "                       data={\"runtime\" : [m1_time, m2_time, m3_time, m4_time]})\r\n",
        "runtime.head()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>runtime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>SGD</th>\n",
              "      <td>13.589209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RMSProp</th>\n",
              "      <td>13.921492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam0.01</th>\n",
              "      <td>14.046503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adam0.1</th>\n",
              "      <td>13.907092</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            runtime\n",
              "SGD       13.589209\n",
              "RMSProp   13.921492\n",
              "Adam0.01  14.046503\n",
              "Adam0.1   13.907092"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHaN1cLZKXhn"
      },
      "source": [
        "The runtimes of the four models are not too different. Noticeably, SGD is the fastest while also giving the best accuracy. For this classification task, SGD performs the best with the least runtime needed to get to 200 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGBto2s7Kh0t",
        "outputId": "6c8a538c-4922-40d4-855c-ea1209ab4432"
      },
      "source": [
        "results.loc[50]"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGD_accuracy         0.978022\n",
              "RMSProp_accuracy     0.630769\n",
              "Adam0.01_accuracy    0.995604\n",
              "Adam0.1_accuracy     0.630769\n",
              "Name: 50, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksD5xleGKu9Y"
      },
      "source": [
        "However, if say, we were to look at earlier epochs well before 200, SGD doesn't come out as the best. At 50 epoch, Adam with a 0.01 LR actually achieves the accuracy SGD converges to later 150 more epochs down the line."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B3hbni0LAJF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}