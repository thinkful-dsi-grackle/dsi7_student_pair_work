{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "Day_78_L1_Assignment_Barrettipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqtxiRasgEsb"
      },
      "source": [
        "## Gradient Descent and Backpropagation\n",
        "\n",
        "In this assignment, we will learn about gradient descent and backpropagation algorithms. We will create a neural network and tweak some of the parameters in SGD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOd2GWD5gEsd"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "%matplotlib inline\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "661suxNdgEsg"
      },
      "source": [
        "Let's use the data we processed in the titanic assigment and load it below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvmZdYdEgEsg"
      },
      "source": [
        "titanic = pd.read_csv('https://tf-assets-prod.s3.amazonaws.com/tf-curric/data-science/titanic_processed.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSpXsYXpgEsi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "29161e11-dd72-4077-9dc0-0ada4803c2ef"
      },
      "source": [
        "titanic.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Pclass_1</th>\n",
              "      <th>Pclass_2</th>\n",
              "      <th>Pclass_3</th>\n",
              "      <th>Sex_female</th>\n",
              "      <th>Sex_male</th>\n",
              "      <th>Embarked_C</th>\n",
              "      <th>Embarked_Q</th>\n",
              "      <th>Embarked_S</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Survived  SibSp  Parch  ...  Embarked_C  Embarked_Q  Embarked_S\n",
              "0         0      1      0  ...           0           0           1\n",
              "1         1      1      0  ...           1           0           0\n",
              "2         1      0      0  ...           0           0           1\n",
              "3         1      1      0  ...           0           0           1\n",
              "4         0      0      0  ...           0           0           1\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc_uypIkgEsk"
      },
      "source": [
        "Split the data into train and test with 20% of data in test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RP9pCPlNgEsl"
      },
      "source": [
        "# Answer below\n",
        "X = titanic.drop('Survived', 1)\n",
        "y = titanic['Survived']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QBmGKEpgEsm"
      },
      "source": [
        "Create a model with 5 layers - The first layer should be of unit size 128 and input shape with the shape of the input and the last layer should be of size 1. The hidden layers should be of size 64, 32, and 32, respectively. Use a sigmoid activation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVefZBONgEsn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9bb963b-3487-4e92-f9f2-0b59745d92de"
      },
      "source": [
        "# Answer below\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 128)               1408      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 12,833\n",
            "Trainable params: 12,833\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IADHujAgEso"
      },
      "source": [
        "Initialize an SGD optimizer with learning rate 0.05. Note that in older versions of keras, we use `lr` instead of `learning_rate`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhM1nLP1gEsp"
      },
      "source": [
        "# Answer below:\n",
        "sgd = SGD(lr=0.05)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6cVa2JHgEsq"
      },
      "source": [
        "compile and fit the model using the optimizer you initialized above. Use a batch size of 100 and 50 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AbyqTAigEsr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6b21958-240f-4c62-a362-21e9fe60ac8b"
      },
      "source": [
        "# Answer below:\n",
        "model.compile(optimizer=sgd, loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, batch_size=100, epochs=50,\n",
        "                    validation_data = (X_test, y_test), verbose=1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "8/8 [==============================] - 2s 64ms/step - loss: 0.6800 - accuracy: 0.5975 - val_loss: 0.6513 - val_accuracy: 0.6629\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6536 - accuracy: 0.6160 - val_loss: 0.6297 - val_accuracy: 0.6629\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6308 - accuracy: 0.6176 - val_loss: 0.6188 - val_accuracy: 0.6742\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6261 - accuracy: 0.6097 - val_loss: 0.6041 - val_accuracy: 0.6910\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5999 - accuracy: 0.6792 - val_loss: 0.5885 - val_accuracy: 0.7360\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5975 - accuracy: 0.6772 - val_loss: 0.5718 - val_accuracy: 0.7640\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5731 - accuracy: 0.7433 - val_loss: 0.5536 - val_accuracy: 0.7921\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5652 - accuracy: 0.7753 - val_loss: 0.5371 - val_accuracy: 0.7921\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5282 - accuracy: 0.8129 - val_loss: 0.5255 - val_accuracy: 0.7921\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5198 - accuracy: 0.7990 - val_loss: 0.5135 - val_accuracy: 0.7921\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4925 - accuracy: 0.8191 - val_loss: 0.5097 - val_accuracy: 0.7921\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4927 - accuracy: 0.8016 - val_loss: 0.5074 - val_accuracy: 0.7978\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4847 - accuracy: 0.8137 - val_loss: 0.4957 - val_accuracy: 0.7865\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4878 - accuracy: 0.7867 - val_loss: 0.4916 - val_accuracy: 0.8090\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.4644 - accuracy: 0.8084 - val_loss: 0.4989 - val_accuracy: 0.7809\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4643 - accuracy: 0.7966 - val_loss: 0.4852 - val_accuracy: 0.8034\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4532 - accuracy: 0.8076 - val_loss: 0.4841 - val_accuracy: 0.7978\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4365 - accuracy: 0.8231 - val_loss: 0.5130 - val_accuracy: 0.7528\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4635 - accuracy: 0.7894 - val_loss: 0.4789 - val_accuracy: 0.8034\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4348 - accuracy: 0.8132 - val_loss: 0.4764 - val_accuracy: 0.7921\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4256 - accuracy: 0.8253 - val_loss: 0.5000 - val_accuracy: 0.7528\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4464 - accuracy: 0.8015 - val_loss: 0.4794 - val_accuracy: 0.7978\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4535 - accuracy: 0.7968 - val_loss: 0.4803 - val_accuracy: 0.7865\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4245 - accuracy: 0.8233 - val_loss: 0.4756 - val_accuracy: 0.7865\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4301 - accuracy: 0.8152 - val_loss: 0.4750 - val_accuracy: 0.7865\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3899 - accuracy: 0.8473 - val_loss: 0.4820 - val_accuracy: 0.7584\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4245 - accuracy: 0.8196 - val_loss: 0.4719 - val_accuracy: 0.7978\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4405 - accuracy: 0.8095 - val_loss: 0.4708 - val_accuracy: 0.8090\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4250 - accuracy: 0.8241 - val_loss: 0.4723 - val_accuracy: 0.7978\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4211 - accuracy: 0.8155 - val_loss: 0.4842 - val_accuracy: 0.7753\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4270 - accuracy: 0.8159 - val_loss: 0.4760 - val_accuracy: 0.8090\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4142 - accuracy: 0.8182 - val_loss: 0.4721 - val_accuracy: 0.8090\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4180 - accuracy: 0.8205 - val_loss: 0.4808 - val_accuracy: 0.7809\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4281 - accuracy: 0.8049 - val_loss: 0.4746 - val_accuracy: 0.7865\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3943 - accuracy: 0.8379 - val_loss: 0.4772 - val_accuracy: 0.8090\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4052 - accuracy: 0.8297 - val_loss: 0.4891 - val_accuracy: 0.7753\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3920 - accuracy: 0.8184 - val_loss: 0.4784 - val_accuracy: 0.8090\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.4206 - accuracy: 0.8138 - val_loss: 0.4736 - val_accuracy: 0.7921\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3963 - accuracy: 0.8278 - val_loss: 0.4757 - val_accuracy: 0.7865\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.4169 - accuracy: 0.8171 - val_loss: 0.5103 - val_accuracy: 0.7584\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.4106 - accuracy: 0.8172 - val_loss: 0.4770 - val_accuracy: 0.8090\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4234 - accuracy: 0.8118 - val_loss: 0.4787 - val_accuracy: 0.7865\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3908 - accuracy: 0.8281 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.4120 - accuracy: 0.8247 - val_loss: 0.4734 - val_accuracy: 0.7865\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3997 - accuracy: 0.8276 - val_loss: 0.4930 - val_accuracy: 0.7640\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.3931 - accuracy: 0.8190 - val_loss: 0.5029 - val_accuracy: 0.7640\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4081 - accuracy: 0.8159 - val_loss: 0.5295 - val_accuracy: 0.7640\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.4104 - accuracy: 0.8066 - val_loss: 0.4972 - val_accuracy: 0.7640\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4139 - accuracy: 0.8124 - val_loss: 0.4979 - val_accuracy: 0.7640\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3774 - accuracy: 0.8202 - val_loss: 0.5251 - val_accuracy: 0.7640\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlldKBDFbTeQ",
        "outputId": "f12dbc83-8007-49ec-b017-b50ae87afd7d"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5251 - accuracy: 0.7640\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5251257419586182, 0.7640449404716492]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRoBkaAkgEss"
      },
      "source": [
        "Now use the same batch size, but fit your model using 500 epochs. Is there a difference in performance?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp9JQJDTgEst",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "407a28bc-8762-416e-8022-491c8a6b7e7e"
      },
      "source": [
        "# Answer below:\n",
        "model.compile(optimizer=sgd, loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, batch_size=100, epochs=500,\n",
        "                    validation_data = (X_test, y_test), verbose=1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "8/8 [==============================] - 1s 39ms/step - loss: 0.4005 - accuracy: 0.8086 - val_loss: 0.5068 - val_accuracy: 0.7472\n",
            "Epoch 2/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3942 - accuracy: 0.8110 - val_loss: 0.4898 - val_accuracy: 0.7865\n",
            "Epoch 3/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.4005 - accuracy: 0.8225 - val_loss: 0.5145 - val_accuracy: 0.8034\n",
            "Epoch 4/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.4344 - accuracy: 0.8065 - val_loss: 0.4890 - val_accuracy: 0.7921\n",
            "Epoch 5/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4145 - accuracy: 0.8179 - val_loss: 0.5251 - val_accuracy: 0.7416\n",
            "Epoch 6/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3998 - accuracy: 0.8131 - val_loss: 0.4958 - val_accuracy: 0.7697\n",
            "Epoch 7/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3991 - accuracy: 0.8190 - val_loss: 0.5565 - val_accuracy: 0.6966\n",
            "Epoch 8/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4000 - accuracy: 0.8244 - val_loss: 0.5198 - val_accuracy: 0.7640\n",
            "Epoch 9/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.4024 - accuracy: 0.8073 - val_loss: 0.5072 - val_accuracy: 0.7978\n",
            "Epoch 10/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3854 - accuracy: 0.8337 - val_loss: 0.5326 - val_accuracy: 0.7416\n",
            "Epoch 11/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3872 - accuracy: 0.8260 - val_loss: 0.5081 - val_accuracy: 0.7697\n",
            "Epoch 12/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4102 - accuracy: 0.8209 - val_loss: 0.5190 - val_accuracy: 0.7528\n",
            "Epoch 13/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3758 - accuracy: 0.8356 - val_loss: 0.5257 - val_accuracy: 0.7865\n",
            "Epoch 14/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4134 - accuracy: 0.8366 - val_loss: 0.5417 - val_accuracy: 0.7360\n",
            "Epoch 15/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3828 - accuracy: 0.8205 - val_loss: 0.5074 - val_accuracy: 0.7753\n",
            "Epoch 16/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3904 - accuracy: 0.8253 - val_loss: 0.5243 - val_accuracy: 0.7360\n",
            "Epoch 17/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3952 - accuracy: 0.8201 - val_loss: 0.5039 - val_accuracy: 0.7753\n",
            "Epoch 18/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3800 - accuracy: 0.8320 - val_loss: 0.5263 - val_accuracy: 0.7584\n",
            "Epoch 19/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3809 - accuracy: 0.8296 - val_loss: 0.5093 - val_accuracy: 0.7697\n",
            "Epoch 20/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3807 - accuracy: 0.8333 - val_loss: 0.5136 - val_accuracy: 0.7697\n",
            "Epoch 21/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.4005 - accuracy: 0.8196 - val_loss: 0.5778 - val_accuracy: 0.6742\n",
            "Epoch 22/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.4325 - accuracy: 0.7927 - val_loss: 0.5169 - val_accuracy: 0.8034\n",
            "Epoch 23/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3987 - accuracy: 0.8143 - val_loss: 0.5112 - val_accuracy: 0.7753\n",
            "Epoch 24/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3849 - accuracy: 0.8384 - val_loss: 0.5367 - val_accuracy: 0.7416\n",
            "Epoch 25/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3866 - accuracy: 0.8333 - val_loss: 0.5298 - val_accuracy: 0.7528\n",
            "Epoch 26/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3767 - accuracy: 0.8293 - val_loss: 0.5229 - val_accuracy: 0.7584\n",
            "Epoch 27/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3990 - accuracy: 0.8249 - val_loss: 0.5351 - val_accuracy: 0.7472\n",
            "Epoch 28/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3995 - accuracy: 0.8196 - val_loss: 0.5173 - val_accuracy: 0.7640\n",
            "Epoch 29/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3901 - accuracy: 0.8269 - val_loss: 0.5113 - val_accuracy: 0.7865\n",
            "Epoch 30/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3787 - accuracy: 0.8306 - val_loss: 0.5161 - val_accuracy: 0.7809\n",
            "Epoch 31/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4161 - accuracy: 0.8216 - val_loss: 0.5604 - val_accuracy: 0.7191\n",
            "Epoch 32/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4103 - accuracy: 0.8255 - val_loss: 0.5274 - val_accuracy: 0.7640\n",
            "Epoch 33/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3889 - accuracy: 0.8347 - val_loss: 0.5177 - val_accuracy: 0.7753\n",
            "Epoch 34/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3564 - accuracy: 0.8527 - val_loss: 0.5309 - val_accuracy: 0.7809\n",
            "Epoch 35/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3797 - accuracy: 0.8377 - val_loss: 0.5337 - val_accuracy: 0.7978\n",
            "Epoch 36/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4135 - accuracy: 0.8264 - val_loss: 0.5134 - val_accuracy: 0.7640\n",
            "Epoch 37/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.4109 - accuracy: 0.8123 - val_loss: 0.5203 - val_accuracy: 0.7584\n",
            "Epoch 38/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4126 - accuracy: 0.8074 - val_loss: 0.5173 - val_accuracy: 0.7584\n",
            "Epoch 39/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.4001 - accuracy: 0.8251 - val_loss: 0.5271 - val_accuracy: 0.7809\n",
            "Epoch 40/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3811 - accuracy: 0.8415 - val_loss: 0.5592 - val_accuracy: 0.7865\n",
            "Epoch 41/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3804 - accuracy: 0.8404 - val_loss: 0.5231 - val_accuracy: 0.7640\n",
            "Epoch 42/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3814 - accuracy: 0.8327 - val_loss: 0.5305 - val_accuracy: 0.7921\n",
            "Epoch 43/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.4029 - accuracy: 0.8284 - val_loss: 0.5170 - val_accuracy: 0.7697\n",
            "Epoch 44/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3942 - accuracy: 0.8190 - val_loss: 0.5181 - val_accuracy: 0.7865\n",
            "Epoch 45/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3883 - accuracy: 0.8331 - val_loss: 0.5447 - val_accuracy: 0.7865\n",
            "Epoch 46/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4126 - accuracy: 0.8275 - val_loss: 0.5222 - val_accuracy: 0.7697\n",
            "Epoch 47/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3689 - accuracy: 0.8385 - val_loss: 0.5642 - val_accuracy: 0.7135\n",
            "Epoch 48/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3838 - accuracy: 0.8294 - val_loss: 0.6324 - val_accuracy: 0.7022\n",
            "Epoch 49/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3841 - accuracy: 0.8323 - val_loss: 0.5154 - val_accuracy: 0.7640\n",
            "Epoch 50/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3959 - accuracy: 0.8291 - val_loss: 0.5163 - val_accuracy: 0.7865\n",
            "Epoch 51/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3759 - accuracy: 0.8441 - val_loss: 0.5241 - val_accuracy: 0.7640\n",
            "Epoch 52/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3961 - accuracy: 0.8204 - val_loss: 0.5204 - val_accuracy: 0.7640\n",
            "Epoch 53/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3716 - accuracy: 0.8453 - val_loss: 0.5283 - val_accuracy: 0.7640\n",
            "Epoch 54/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3753 - accuracy: 0.8355 - val_loss: 0.5559 - val_accuracy: 0.7978\n",
            "Epoch 55/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4429 - accuracy: 0.8113 - val_loss: 0.5413 - val_accuracy: 0.7472\n",
            "Epoch 56/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4006 - accuracy: 0.8289 - val_loss: 0.5265 - val_accuracy: 0.7865\n",
            "Epoch 57/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4150 - accuracy: 0.8053 - val_loss: 0.5263 - val_accuracy: 0.7640\n",
            "Epoch 58/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3654 - accuracy: 0.8500 - val_loss: 0.5705 - val_accuracy: 0.6910\n",
            "Epoch 59/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3983 - accuracy: 0.8088 - val_loss: 0.5366 - val_accuracy: 0.7472\n",
            "Epoch 60/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3877 - accuracy: 0.8381 - val_loss: 0.6427 - val_accuracy: 0.6854\n",
            "Epoch 61/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3951 - accuracy: 0.8172 - val_loss: 0.5264 - val_accuracy: 0.7640\n",
            "Epoch 62/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3850 - accuracy: 0.8376 - val_loss: 0.5265 - val_accuracy: 0.7640\n",
            "Epoch 63/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.3880 - accuracy: 0.8321 - val_loss: 0.5311 - val_accuracy: 0.7640\n",
            "Epoch 64/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3775 - accuracy: 0.8330 - val_loss: 0.5387 - val_accuracy: 0.7640\n",
            "Epoch 65/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3756 - accuracy: 0.8286 - val_loss: 0.5370 - val_accuracy: 0.7753\n",
            "Epoch 66/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3930 - accuracy: 0.8357 - val_loss: 0.6019 - val_accuracy: 0.7697\n",
            "Epoch 67/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4166 - accuracy: 0.8125 - val_loss: 0.5419 - val_accuracy: 0.7303\n",
            "Epoch 68/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3636 - accuracy: 0.8367 - val_loss: 0.5842 - val_accuracy: 0.7079\n",
            "Epoch 69/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4053 - accuracy: 0.8050 - val_loss: 0.5340 - val_accuracy: 0.7640\n",
            "Epoch 70/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3981 - accuracy: 0.8263 - val_loss: 0.5347 - val_accuracy: 0.7640\n",
            "Epoch 71/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3984 - accuracy: 0.8189 - val_loss: 0.5680 - val_accuracy: 0.7247\n",
            "Epoch 72/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3807 - accuracy: 0.8381 - val_loss: 0.5493 - val_accuracy: 0.7584\n",
            "Epoch 73/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3564 - accuracy: 0.8559 - val_loss: 0.5595 - val_accuracy: 0.7303\n",
            "Epoch 74/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3690 - accuracy: 0.8355 - val_loss: 0.5802 - val_accuracy: 0.7135\n",
            "Epoch 75/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3719 - accuracy: 0.8463 - val_loss: 0.5455 - val_accuracy: 0.7753\n",
            "Epoch 76/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3917 - accuracy: 0.8188 - val_loss: 0.5395 - val_accuracy: 0.7640\n",
            "Epoch 77/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3810 - accuracy: 0.8395 - val_loss: 0.5655 - val_accuracy: 0.7472\n",
            "Epoch 78/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.4074 - accuracy: 0.8183 - val_loss: 0.5504 - val_accuracy: 0.7640\n",
            "Epoch 79/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3879 - accuracy: 0.8357 - val_loss: 0.5383 - val_accuracy: 0.7640\n",
            "Epoch 80/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3983 - accuracy: 0.8262 - val_loss: 0.5455 - val_accuracy: 0.7640\n",
            "Epoch 81/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3641 - accuracy: 0.8536 - val_loss: 0.5498 - val_accuracy: 0.7640\n",
            "Epoch 82/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3744 - accuracy: 0.8426 - val_loss: 0.5473 - val_accuracy: 0.7640\n",
            "Epoch 83/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3884 - accuracy: 0.8335 - val_loss: 0.5653 - val_accuracy: 0.7135\n",
            "Epoch 84/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3729 - accuracy: 0.8409 - val_loss: 0.5382 - val_accuracy: 0.7416\n",
            "Epoch 85/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3911 - accuracy: 0.8254 - val_loss: 0.5421 - val_accuracy: 0.7640\n",
            "Epoch 86/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3864 - accuracy: 0.8471 - val_loss: 0.5491 - val_accuracy: 0.7528\n",
            "Epoch 87/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3969 - accuracy: 0.8245 - val_loss: 0.5498 - val_accuracy: 0.7640\n",
            "Epoch 88/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3769 - accuracy: 0.8291 - val_loss: 0.5476 - val_accuracy: 0.7640\n",
            "Epoch 89/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3840 - accuracy: 0.8377 - val_loss: 0.5626 - val_accuracy: 0.7584\n",
            "Epoch 90/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3805 - accuracy: 0.8384 - val_loss: 0.5512 - val_accuracy: 0.7472\n",
            "Epoch 91/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3780 - accuracy: 0.8309 - val_loss: 0.5803 - val_accuracy: 0.7360\n",
            "Epoch 92/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3781 - accuracy: 0.8450 - val_loss: 0.5943 - val_accuracy: 0.7303\n",
            "Epoch 93/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3898 - accuracy: 0.8245 - val_loss: 0.7295 - val_accuracy: 0.6629\n",
            "Epoch 94/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4164 - accuracy: 0.7993 - val_loss: 0.5629 - val_accuracy: 0.7472\n",
            "Epoch 95/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3747 - accuracy: 0.8384 - val_loss: 0.6153 - val_accuracy: 0.7022\n",
            "Epoch 96/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3807 - accuracy: 0.8258 - val_loss: 0.5617 - val_accuracy: 0.7303\n",
            "Epoch 97/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3942 - accuracy: 0.8374 - val_loss: 0.6180 - val_accuracy: 0.7303\n",
            "Epoch 98/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3846 - accuracy: 0.8261 - val_loss: 0.5612 - val_accuracy: 0.7697\n",
            "Epoch 99/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4045 - accuracy: 0.8240 - val_loss: 0.5626 - val_accuracy: 0.7528\n",
            "Epoch 100/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3693 - accuracy: 0.8515 - val_loss: 0.5659 - val_accuracy: 0.7640\n",
            "Epoch 101/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3875 - accuracy: 0.8281 - val_loss: 0.5675 - val_accuracy: 0.7640\n",
            "Epoch 102/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3633 - accuracy: 0.8594 - val_loss: 0.5499 - val_accuracy: 0.7640\n",
            "Epoch 103/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3781 - accuracy: 0.8346 - val_loss: 0.6355 - val_accuracy: 0.6685\n",
            "Epoch 104/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.7992 - val_loss: 0.5537 - val_accuracy: 0.7528\n",
            "Epoch 105/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3804 - accuracy: 0.8238 - val_loss: 0.5725 - val_accuracy: 0.7472\n",
            "Epoch 106/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3617 - accuracy: 0.8515 - val_loss: 0.5704 - val_accuracy: 0.7528\n",
            "Epoch 107/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3735 - accuracy: 0.8390 - val_loss: 0.5946 - val_accuracy: 0.7921\n",
            "Epoch 108/500\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.4457 - accuracy: 0.8210 - val_loss: 0.5511 - val_accuracy: 0.7584\n",
            "Epoch 109/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4205 - accuracy: 0.8120 - val_loss: 0.5589 - val_accuracy: 0.7640\n",
            "Epoch 110/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3924 - accuracy: 0.8314 - val_loss: 0.5498 - val_accuracy: 0.7640\n",
            "Epoch 111/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4122 - accuracy: 0.8203 - val_loss: 0.5633 - val_accuracy: 0.7528\n",
            "Epoch 112/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4084 - accuracy: 0.8214 - val_loss: 0.5497 - val_accuracy: 0.7640\n",
            "Epoch 113/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3969 - accuracy: 0.8309 - val_loss: 0.5526 - val_accuracy: 0.7640\n",
            "Epoch 114/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3562 - accuracy: 0.8478 - val_loss: 0.5541 - val_accuracy: 0.7640\n",
            "Epoch 115/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3935 - accuracy: 0.8211 - val_loss: 0.5621 - val_accuracy: 0.7697\n",
            "Epoch 116/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4102 - accuracy: 0.8194 - val_loss: 0.6464 - val_accuracy: 0.6798\n",
            "Epoch 117/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3690 - accuracy: 0.8392 - val_loss: 0.6293 - val_accuracy: 0.6798\n",
            "Epoch 118/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3916 - accuracy: 0.8193 - val_loss: 0.5887 - val_accuracy: 0.6854\n",
            "Epoch 119/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3882 - accuracy: 0.8228 - val_loss: 0.5566 - val_accuracy: 0.7472\n",
            "Epoch 120/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3569 - accuracy: 0.8437 - val_loss: 0.5685 - val_accuracy: 0.7528\n",
            "Epoch 121/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3910 - accuracy: 0.8303 - val_loss: 0.5860 - val_accuracy: 0.7303\n",
            "Epoch 122/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3763 - accuracy: 0.8276 - val_loss: 0.5588 - val_accuracy: 0.7640\n",
            "Epoch 123/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3727 - accuracy: 0.8366 - val_loss: 0.5718 - val_accuracy: 0.7416\n",
            "Epoch 124/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3930 - accuracy: 0.8271 - val_loss: 0.5612 - val_accuracy: 0.7584\n",
            "Epoch 125/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3958 - accuracy: 0.8234 - val_loss: 0.5663 - val_accuracy: 0.7640\n",
            "Epoch 126/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3841 - accuracy: 0.8197 - val_loss: 0.7828 - val_accuracy: 0.6517\n",
            "Epoch 127/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4196 - accuracy: 0.7959 - val_loss: 0.5633 - val_accuracy: 0.7528\n",
            "Epoch 128/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3832 - accuracy: 0.8371 - val_loss: 0.5935 - val_accuracy: 0.7416\n",
            "Epoch 129/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3629 - accuracy: 0.8409 - val_loss: 0.5822 - val_accuracy: 0.7472\n",
            "Epoch 130/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3769 - accuracy: 0.8360 - val_loss: 0.5635 - val_accuracy: 0.7416\n",
            "Epoch 131/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8097 - val_loss: 0.6003 - val_accuracy: 0.7809\n",
            "Epoch 132/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4008 - accuracy: 0.8345 - val_loss: 0.5859 - val_accuracy: 0.7472\n",
            "Epoch 133/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3605 - accuracy: 0.8432 - val_loss: 0.6267 - val_accuracy: 0.6742\n",
            "Epoch 134/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3818 - accuracy: 0.8433 - val_loss: 0.5553 - val_accuracy: 0.7528\n",
            "Epoch 135/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3696 - accuracy: 0.8322 - val_loss: 0.6788 - val_accuracy: 0.6629\n",
            "Epoch 136/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4295 - accuracy: 0.8021 - val_loss: 0.5745 - val_accuracy: 0.7528\n",
            "Epoch 137/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3767 - accuracy: 0.8319 - val_loss: 0.6090 - val_accuracy: 0.7135\n",
            "Epoch 138/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3735 - accuracy: 0.8445 - val_loss: 0.5708 - val_accuracy: 0.7640\n",
            "Epoch 139/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3787 - accuracy: 0.8379 - val_loss: 0.5954 - val_accuracy: 0.7303\n",
            "Epoch 140/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3956 - accuracy: 0.8289 - val_loss: 0.5675 - val_accuracy: 0.7528\n",
            "Epoch 141/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3611 - accuracy: 0.8439 - val_loss: 0.6232 - val_accuracy: 0.6854\n",
            "Epoch 142/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3921 - accuracy: 0.8262 - val_loss: 0.5414 - val_accuracy: 0.7640\n",
            "Epoch 143/500\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 0.3732 - accuracy: 0.8310 - val_loss: 0.6107 - val_accuracy: 0.7191\n",
            "Epoch 144/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3903 - accuracy: 0.8292 - val_loss: 0.6153 - val_accuracy: 0.6798\n",
            "Epoch 145/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3926 - accuracy: 0.8270 - val_loss: 0.5785 - val_accuracy: 0.7191\n",
            "Epoch 146/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3601 - accuracy: 0.8434 - val_loss: 0.7707 - val_accuracy: 0.6685\n",
            "Epoch 147/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4356 - accuracy: 0.8106 - val_loss: 0.5546 - val_accuracy: 0.7640\n",
            "Epoch 148/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3760 - accuracy: 0.8457 - val_loss: 0.5957 - val_accuracy: 0.7416\n",
            "Epoch 149/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3527 - accuracy: 0.8480 - val_loss: 0.5663 - val_accuracy: 0.7528\n",
            "Epoch 150/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3675 - accuracy: 0.8316 - val_loss: 0.5490 - val_accuracy: 0.7640\n",
            "Epoch 151/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3639 - accuracy: 0.8547 - val_loss: 0.5733 - val_accuracy: 0.7640\n",
            "Epoch 152/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3745 - accuracy: 0.8361 - val_loss: 0.6036 - val_accuracy: 0.7022\n",
            "Epoch 153/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3816 - accuracy: 0.8317 - val_loss: 0.5999 - val_accuracy: 0.7303\n",
            "Epoch 154/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3738 - accuracy: 0.8352 - val_loss: 0.5641 - val_accuracy: 0.7472\n",
            "Epoch 155/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3647 - accuracy: 0.8443 - val_loss: 0.5644 - val_accuracy: 0.7640\n",
            "Epoch 156/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3547 - accuracy: 0.8398 - val_loss: 0.5765 - val_accuracy: 0.7640\n",
            "Epoch 157/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3666 - accuracy: 0.8381 - val_loss: 0.6033 - val_accuracy: 0.7472\n",
            "Epoch 158/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3725 - accuracy: 0.8237 - val_loss: 0.5821 - val_accuracy: 0.7528\n",
            "Epoch 159/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3744 - accuracy: 0.8326 - val_loss: 0.5826 - val_accuracy: 0.7472\n",
            "Epoch 160/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4137 - accuracy: 0.8170 - val_loss: 0.5705 - val_accuracy: 0.7640\n",
            "Epoch 161/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3637 - accuracy: 0.8519 - val_loss: 0.5642 - val_accuracy: 0.7472\n",
            "Epoch 162/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3901 - accuracy: 0.8185 - val_loss: 0.6051 - val_accuracy: 0.7416\n",
            "Epoch 163/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3879 - accuracy: 0.8469 - val_loss: 0.6886 - val_accuracy: 0.7697\n",
            "Epoch 164/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.4190 - accuracy: 0.8094 - val_loss: 0.5625 - val_accuracy: 0.7640\n",
            "Epoch 165/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3486 - accuracy: 0.8569 - val_loss: 0.5783 - val_accuracy: 0.7640\n",
            "Epoch 166/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4013 - accuracy: 0.8176 - val_loss: 0.5664 - val_accuracy: 0.7472\n",
            "Epoch 167/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3887 - accuracy: 0.8289 - val_loss: 0.5543 - val_accuracy: 0.7640\n",
            "Epoch 168/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3888 - accuracy: 0.8393 - val_loss: 0.5635 - val_accuracy: 0.7584\n",
            "Epoch 169/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3779 - accuracy: 0.8432 - val_loss: 0.5752 - val_accuracy: 0.7528\n",
            "Epoch 170/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3547 - accuracy: 0.8529 - val_loss: 0.5744 - val_accuracy: 0.7528\n",
            "Epoch 171/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3780 - accuracy: 0.8397 - val_loss: 0.5680 - val_accuracy: 0.7640\n",
            "Epoch 172/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3762 - accuracy: 0.8345 - val_loss: 0.6020 - val_accuracy: 0.7303\n",
            "Epoch 173/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3664 - accuracy: 0.8422 - val_loss: 0.5684 - val_accuracy: 0.7697\n",
            "Epoch 174/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3754 - accuracy: 0.8417 - val_loss: 0.5643 - val_accuracy: 0.7640\n",
            "Epoch 175/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3877 - accuracy: 0.8366 - val_loss: 0.5644 - val_accuracy: 0.7584\n",
            "Epoch 176/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3501 - accuracy: 0.8422 - val_loss: 0.5900 - val_accuracy: 0.7303\n",
            "Epoch 177/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3271 - accuracy: 0.8740 - val_loss: 0.8290 - val_accuracy: 0.6685\n",
            "Epoch 178/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4283 - accuracy: 0.7992 - val_loss: 0.5772 - val_accuracy: 0.7472\n",
            "Epoch 179/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3673 - accuracy: 0.8279 - val_loss: 0.5970 - val_accuracy: 0.7416\n",
            "Epoch 180/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3932 - accuracy: 0.8240 - val_loss: 0.5694 - val_accuracy: 0.7528\n",
            "Epoch 181/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3805 - accuracy: 0.8228 - val_loss: 0.5722 - val_accuracy: 0.7640\n",
            "Epoch 182/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3604 - accuracy: 0.8508 - val_loss: 0.6078 - val_accuracy: 0.7528\n",
            "Epoch 183/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4119 - accuracy: 0.8215 - val_loss: 0.5590 - val_accuracy: 0.7640\n",
            "Epoch 184/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3641 - accuracy: 0.8467 - val_loss: 0.5748 - val_accuracy: 0.7640\n",
            "Epoch 185/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3542 - accuracy: 0.8472 - val_loss: 0.5832 - val_accuracy: 0.7303\n",
            "Epoch 186/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3912 - accuracy: 0.8244 - val_loss: 0.6906 - val_accuracy: 0.6517\n",
            "Epoch 187/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4043 - accuracy: 0.8207 - val_loss: 0.5910 - val_accuracy: 0.7472\n",
            "Epoch 188/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3582 - accuracy: 0.8490 - val_loss: 0.5870 - val_accuracy: 0.7472\n",
            "Epoch 189/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3607 - accuracy: 0.8398 - val_loss: 0.5719 - val_accuracy: 0.7472\n",
            "Epoch 190/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3923 - accuracy: 0.8309 - val_loss: 0.6306 - val_accuracy: 0.7303\n",
            "Epoch 191/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3654 - accuracy: 0.8444 - val_loss: 0.5974 - val_accuracy: 0.7472\n",
            "Epoch 192/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3629 - accuracy: 0.8313 - val_loss: 1.3638 - val_accuracy: 0.6348\n",
            "Epoch 193/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.7275 - accuracy: 0.7700 - val_loss: 0.5484 - val_accuracy: 0.7640\n",
            "Epoch 194/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3596 - accuracy: 0.8547 - val_loss: 0.5556 - val_accuracy: 0.7472\n",
            "Epoch 195/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3778 - accuracy: 0.8323 - val_loss: 0.5543 - val_accuracy: 0.7472\n",
            "Epoch 196/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3778 - accuracy: 0.8297 - val_loss: 0.5582 - val_accuracy: 0.7584\n",
            "Epoch 197/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3784 - accuracy: 0.8379 - val_loss: 0.5841 - val_accuracy: 0.7416\n",
            "Epoch 198/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3721 - accuracy: 0.8461 - val_loss: 0.5559 - val_accuracy: 0.7584\n",
            "Epoch 199/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4018 - accuracy: 0.8240 - val_loss: 0.5692 - val_accuracy: 0.7584\n",
            "Epoch 200/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3747 - accuracy: 0.8352 - val_loss: 0.5775 - val_accuracy: 0.7528\n",
            "Epoch 201/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3710 - accuracy: 0.8480 - val_loss: 0.5677 - val_accuracy: 0.7528\n",
            "Epoch 202/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3760 - accuracy: 0.8334 - val_loss: 0.5668 - val_accuracy: 0.7584\n",
            "Epoch 203/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3670 - accuracy: 0.8371 - val_loss: 0.5690 - val_accuracy: 0.7584\n",
            "Epoch 204/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3775 - accuracy: 0.8468 - val_loss: 0.5858 - val_accuracy: 0.7416\n",
            "Epoch 205/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3421 - accuracy: 0.8510 - val_loss: 0.6109 - val_accuracy: 0.7135\n",
            "Epoch 206/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3451 - accuracy: 0.8535 - val_loss: 0.6121 - val_accuracy: 0.7191\n",
            "Epoch 207/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3694 - accuracy: 0.8297 - val_loss: 0.5873 - val_accuracy: 0.7528\n",
            "Epoch 208/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.3657 - accuracy: 0.8394 - val_loss: 0.6992 - val_accuracy: 0.6742\n",
            "Epoch 209/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3854 - accuracy: 0.8223 - val_loss: 0.5903 - val_accuracy: 0.7584\n",
            "Epoch 210/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3778 - accuracy: 0.8365 - val_loss: 0.5843 - val_accuracy: 0.7472\n",
            "Epoch 211/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3574 - accuracy: 0.8495 - val_loss: 0.5661 - val_accuracy: 0.7640\n",
            "Epoch 212/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3916 - accuracy: 0.8378 - val_loss: 0.5637 - val_accuracy: 0.7640\n",
            "Epoch 213/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3655 - accuracy: 0.8447 - val_loss: 0.9111 - val_accuracy: 0.6629\n",
            "Epoch 214/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4119 - accuracy: 0.8117 - val_loss: 0.6026 - val_accuracy: 0.7584\n",
            "Epoch 215/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3548 - accuracy: 0.8394 - val_loss: 0.5864 - val_accuracy: 0.7528\n",
            "Epoch 216/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3979 - accuracy: 0.8333 - val_loss: 0.5821 - val_accuracy: 0.7640\n",
            "Epoch 217/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3486 - accuracy: 0.8487 - val_loss: 0.5663 - val_accuracy: 0.7640\n",
            "Epoch 218/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3711 - accuracy: 0.8550 - val_loss: 0.5671 - val_accuracy: 0.7640\n",
            "Epoch 219/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3854 - accuracy: 0.8342 - val_loss: 0.6616 - val_accuracy: 0.7697\n",
            "Epoch 220/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4235 - accuracy: 0.8210 - val_loss: 0.7237 - val_accuracy: 0.6629\n",
            "Epoch 221/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3832 - accuracy: 0.8206 - val_loss: 0.5997 - val_accuracy: 0.7416\n",
            "Epoch 222/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3854 - accuracy: 0.8283 - val_loss: 0.6003 - val_accuracy: 0.7416\n",
            "Epoch 223/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3736 - accuracy: 0.8319 - val_loss: 0.5765 - val_accuracy: 0.7472\n",
            "Epoch 224/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3698 - accuracy: 0.8365 - val_loss: 0.5815 - val_accuracy: 0.7697\n",
            "Epoch 225/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3603 - accuracy: 0.8466 - val_loss: 0.5972 - val_accuracy: 0.7303\n",
            "Epoch 226/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3599 - accuracy: 0.8529 - val_loss: 0.5763 - val_accuracy: 0.7584\n",
            "Epoch 227/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3608 - accuracy: 0.8459 - val_loss: 0.6701 - val_accuracy: 0.6798\n",
            "Epoch 228/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3849 - accuracy: 0.8309 - val_loss: 0.5851 - val_accuracy: 0.7472\n",
            "Epoch 229/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3681 - accuracy: 0.8428 - val_loss: 0.5830 - val_accuracy: 0.7584\n",
            "Epoch 230/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3932 - accuracy: 0.8192 - val_loss: 0.5901 - val_accuracy: 0.7303\n",
            "Epoch 231/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3725 - accuracy: 0.8426 - val_loss: 0.5763 - val_accuracy: 0.7640\n",
            "Epoch 232/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3611 - accuracy: 0.8415 - val_loss: 0.6083 - val_accuracy: 0.7303\n",
            "Epoch 233/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3886 - accuracy: 0.8301 - val_loss: 0.5887 - val_accuracy: 0.7584\n",
            "Epoch 234/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3537 - accuracy: 0.8511 - val_loss: 0.5896 - val_accuracy: 0.7584\n",
            "Epoch 235/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3681 - accuracy: 0.8367 - val_loss: 0.5891 - val_accuracy: 0.7528\n",
            "Epoch 236/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3831 - accuracy: 0.8345 - val_loss: 0.5989 - val_accuracy: 0.7472\n",
            "Epoch 237/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3568 - accuracy: 0.8283 - val_loss: 0.5973 - val_accuracy: 0.7584\n",
            "Epoch 238/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3838 - accuracy: 0.8387 - val_loss: 0.6723 - val_accuracy: 0.6854\n",
            "Epoch 239/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3611 - accuracy: 0.8289 - val_loss: 0.5840 - val_accuracy: 0.7640\n",
            "Epoch 240/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3846 - accuracy: 0.8312 - val_loss: 0.6148 - val_accuracy: 0.7360\n",
            "Epoch 241/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3596 - accuracy: 0.8514 - val_loss: 0.5966 - val_accuracy: 0.7640\n",
            "Epoch 242/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3657 - accuracy: 0.8422 - val_loss: 0.6180 - val_accuracy: 0.7472\n",
            "Epoch 243/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3689 - accuracy: 0.8323 - val_loss: 0.5926 - val_accuracy: 0.7584\n",
            "Epoch 244/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3789 - accuracy: 0.8364 - val_loss: 0.5741 - val_accuracy: 0.7640\n",
            "Epoch 245/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3485 - accuracy: 0.8460 - val_loss: 0.6281 - val_accuracy: 0.7191\n",
            "Epoch 246/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3752 - accuracy: 0.8314 - val_loss: 0.6365 - val_accuracy: 0.7303\n",
            "Epoch 247/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3617 - accuracy: 0.8501 - val_loss: 0.5898 - val_accuracy: 0.7584\n",
            "Epoch 248/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3722 - accuracy: 0.8436 - val_loss: 0.5897 - val_accuracy: 0.7528\n",
            "Epoch 249/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3647 - accuracy: 0.8502 - val_loss: 0.5830 - val_accuracy: 0.7640\n",
            "Epoch 250/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3787 - accuracy: 0.8409 - val_loss: 0.5837 - val_accuracy: 0.7584\n",
            "Epoch 251/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3645 - accuracy: 0.8461 - val_loss: 0.5745 - val_accuracy: 0.7697\n",
            "Epoch 252/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4006 - accuracy: 0.8339 - val_loss: 0.5627 - val_accuracy: 0.7640\n",
            "Epoch 253/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3895 - accuracy: 0.8398 - val_loss: 0.5702 - val_accuracy: 0.7697\n",
            "Epoch 254/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3847 - accuracy: 0.8249 - val_loss: 0.6474 - val_accuracy: 0.7022\n",
            "Epoch 255/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3535 - accuracy: 0.8285 - val_loss: 0.5922 - val_accuracy: 0.7640\n",
            "Epoch 256/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3553 - accuracy: 0.8500 - val_loss: 0.6162 - val_accuracy: 0.7416\n",
            "Epoch 257/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3556 - accuracy: 0.8510 - val_loss: 0.5845 - val_accuracy: 0.7640\n",
            "Epoch 258/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3835 - accuracy: 0.8225 - val_loss: 0.5998 - val_accuracy: 0.7472\n",
            "Epoch 259/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3707 - accuracy: 0.8341 - val_loss: 0.5976 - val_accuracy: 0.7472\n",
            "Epoch 260/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3851 - accuracy: 0.8334 - val_loss: 0.5786 - val_accuracy: 0.7640\n",
            "Epoch 261/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3850 - accuracy: 0.8368 - val_loss: 0.6080 - val_accuracy: 0.7416\n",
            "Epoch 262/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.3867 - accuracy: 0.8295 - val_loss: 0.5729 - val_accuracy: 0.7472\n",
            "Epoch 263/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3752 - accuracy: 0.8418 - val_loss: 0.5695 - val_accuracy: 0.7697\n",
            "Epoch 264/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3876 - accuracy: 0.8279 - val_loss: 0.5773 - val_accuracy: 0.7640\n",
            "Epoch 265/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3657 - accuracy: 0.8454 - val_loss: 0.6086 - val_accuracy: 0.7472\n",
            "Epoch 266/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3893 - accuracy: 0.8201 - val_loss: 0.6819 - val_accuracy: 0.6854\n",
            "Epoch 267/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3868 - accuracy: 0.8296 - val_loss: 0.6460 - val_accuracy: 0.7191\n",
            "Epoch 268/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3841 - accuracy: 0.8285 - val_loss: 0.6023 - val_accuracy: 0.7472\n",
            "Epoch 269/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3446 - accuracy: 0.8461 - val_loss: 0.5930 - val_accuracy: 0.7472\n",
            "Epoch 270/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3578 - accuracy: 0.8454 - val_loss: 0.5937 - val_accuracy: 0.7528\n",
            "Epoch 271/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3628 - accuracy: 0.8344 - val_loss: 0.6004 - val_accuracy: 0.7416\n",
            "Epoch 272/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3545 - accuracy: 0.8463 - val_loss: 0.5711 - val_accuracy: 0.7528\n",
            "Epoch 273/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3779 - accuracy: 0.8367 - val_loss: 0.5920 - val_accuracy: 0.7472\n",
            "Epoch 274/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3522 - accuracy: 0.8490 - val_loss: 0.6342 - val_accuracy: 0.6854\n",
            "Epoch 275/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3810 - accuracy: 0.8338 - val_loss: 0.5849 - val_accuracy: 0.7640\n",
            "Epoch 276/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3467 - accuracy: 0.8474 - val_loss: 0.6215 - val_accuracy: 0.7022\n",
            "Epoch 277/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3499 - accuracy: 0.8466 - val_loss: 0.5907 - val_accuracy: 0.7640\n",
            "Epoch 278/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3523 - accuracy: 0.8472 - val_loss: 0.6126 - val_accuracy: 0.7416\n",
            "Epoch 279/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4098 - accuracy: 0.8355 - val_loss: 0.5857 - val_accuracy: 0.7247\n",
            "Epoch 280/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3770 - accuracy: 0.8359 - val_loss: 0.5722 - val_accuracy: 0.7640\n",
            "Epoch 281/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3506 - accuracy: 0.8421 - val_loss: 0.5936 - val_accuracy: 0.7584\n",
            "Epoch 282/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3896 - accuracy: 0.8242 - val_loss: 0.5889 - val_accuracy: 0.7640\n",
            "Epoch 283/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3655 - accuracy: 0.8360 - val_loss: 0.6362 - val_accuracy: 0.7191\n",
            "Epoch 284/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3794 - accuracy: 0.8201 - val_loss: 0.6015 - val_accuracy: 0.7528\n",
            "Epoch 285/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3889 - accuracy: 0.8225 - val_loss: 0.5946 - val_accuracy: 0.7640\n",
            "Epoch 286/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3447 - accuracy: 0.8562 - val_loss: 0.6183 - val_accuracy: 0.7472\n",
            "Epoch 287/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3660 - accuracy: 0.8341 - val_loss: 0.5922 - val_accuracy: 0.7640\n",
            "Epoch 288/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3476 - accuracy: 0.8476 - val_loss: 0.5899 - val_accuracy: 0.7303\n",
            "Epoch 289/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3474 - accuracy: 0.8568 - val_loss: 0.6136 - val_accuracy: 0.7472\n",
            "Epoch 290/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3720 - accuracy: 0.8286 - val_loss: 0.5789 - val_accuracy: 0.7697\n",
            "Epoch 291/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3488 - accuracy: 0.8489 - val_loss: 0.6125 - val_accuracy: 0.7360\n",
            "Epoch 292/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3686 - accuracy: 0.8373 - val_loss: 0.6921 - val_accuracy: 0.6966\n",
            "Epoch 293/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4088 - accuracy: 0.8264 - val_loss: 0.6179 - val_accuracy: 0.7303\n",
            "Epoch 294/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3972 - accuracy: 0.8293 - val_loss: 0.6143 - val_accuracy: 0.7416\n",
            "Epoch 295/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3699 - accuracy: 0.8450 - val_loss: 0.5918 - val_accuracy: 0.7640\n",
            "Epoch 296/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3476 - accuracy: 0.8517 - val_loss: 0.6003 - val_accuracy: 0.7416\n",
            "Epoch 297/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3730 - accuracy: 0.8250 - val_loss: 0.5857 - val_accuracy: 0.7584\n",
            "Epoch 298/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3519 - accuracy: 0.8547 - val_loss: 0.5845 - val_accuracy: 0.7584\n",
            "Epoch 299/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3756 - accuracy: 0.8398 - val_loss: 0.5911 - val_accuracy: 0.7640\n",
            "Epoch 300/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3845 - accuracy: 0.8321 - val_loss: 0.5942 - val_accuracy: 0.7697\n",
            "Epoch 301/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3614 - accuracy: 0.8359 - val_loss: 0.6551 - val_accuracy: 0.7191\n",
            "Epoch 302/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3770 - accuracy: 0.8397 - val_loss: 0.5924 - val_accuracy: 0.7640\n",
            "Epoch 303/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3745 - accuracy: 0.8393 - val_loss: 0.5848 - val_accuracy: 0.7528\n",
            "Epoch 304/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3694 - accuracy: 0.8332 - val_loss: 0.6301 - val_accuracy: 0.6966\n",
            "Epoch 305/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3775 - accuracy: 0.8364 - val_loss: 0.6091 - val_accuracy: 0.7697\n",
            "Epoch 306/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.3569 - accuracy: 0.8582 - val_loss: 0.6253 - val_accuracy: 0.7079\n",
            "Epoch 307/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3637 - accuracy: 0.8327 - val_loss: 0.7507 - val_accuracy: 0.6966\n",
            "Epoch 308/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4172 - accuracy: 0.8079 - val_loss: 0.6017 - val_accuracy: 0.7528\n",
            "Epoch 309/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3688 - accuracy: 0.8351 - val_loss: 0.6121 - val_accuracy: 0.7360\n",
            "Epoch 310/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3547 - accuracy: 0.8510 - val_loss: 0.5945 - val_accuracy: 0.7640\n",
            "Epoch 311/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3546 - accuracy: 0.8520 - val_loss: 0.5903 - val_accuracy: 0.7640\n",
            "Epoch 312/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3654 - accuracy: 0.8314 - val_loss: 0.6030 - val_accuracy: 0.7303\n",
            "Epoch 313/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3731 - accuracy: 0.8348 - val_loss: 0.6331 - val_accuracy: 0.7416\n",
            "Epoch 314/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3753 - accuracy: 0.8358 - val_loss: 0.6028 - val_accuracy: 0.7584\n",
            "Epoch 315/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3647 - accuracy: 0.8469 - val_loss: 0.5951 - val_accuracy: 0.7472\n",
            "Epoch 316/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3406 - accuracy: 0.8565 - val_loss: 0.6304 - val_accuracy: 0.7472\n",
            "Epoch 317/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3564 - accuracy: 0.8331 - val_loss: 0.6251 - val_accuracy: 0.7472\n",
            "Epoch 318/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3665 - accuracy: 0.8448 - val_loss: 0.6052 - val_accuracy: 0.7528\n",
            "Epoch 319/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3706 - accuracy: 0.8341 - val_loss: 0.5832 - val_accuracy: 0.7753\n",
            "Epoch 320/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3435 - accuracy: 0.8501 - val_loss: 0.5881 - val_accuracy: 0.7697\n",
            "Epoch 321/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3748 - accuracy: 0.8440 - val_loss: 0.6318 - val_accuracy: 0.7360\n",
            "Epoch 322/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3786 - accuracy: 0.8242 - val_loss: 0.6030 - val_accuracy: 0.7584\n",
            "Epoch 323/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3947 - accuracy: 0.8211 - val_loss: 0.6240 - val_accuracy: 0.7416\n",
            "Epoch 324/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3560 - accuracy: 0.8555 - val_loss: 0.8173 - val_accuracy: 0.6629\n",
            "Epoch 325/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4206 - accuracy: 0.8124 - val_loss: 0.5963 - val_accuracy: 0.7360\n",
            "Epoch 326/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3500 - accuracy: 0.8528 - val_loss: 0.5976 - val_accuracy: 0.7640\n",
            "Epoch 327/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3742 - accuracy: 0.8333 - val_loss: 0.6316 - val_accuracy: 0.7472\n",
            "Epoch 328/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3758 - accuracy: 0.8300 - val_loss: 0.6007 - val_accuracy: 0.7640\n",
            "Epoch 329/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3601 - accuracy: 0.8410 - val_loss: 0.6541 - val_accuracy: 0.7079\n",
            "Epoch 330/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3775 - accuracy: 0.8365 - val_loss: 0.6069 - val_accuracy: 0.7640\n",
            "Epoch 331/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3581 - accuracy: 0.8241 - val_loss: 0.6309 - val_accuracy: 0.7247\n",
            "Epoch 332/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3966 - accuracy: 0.8357 - val_loss: 0.6711 - val_accuracy: 0.7191\n",
            "Epoch 333/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3794 - accuracy: 0.8298 - val_loss: 0.6098 - val_accuracy: 0.7416\n",
            "Epoch 334/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3664 - accuracy: 0.8450 - val_loss: 0.6066 - val_accuracy: 0.7584\n",
            "Epoch 335/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3910 - accuracy: 0.8149 - val_loss: 0.6085 - val_accuracy: 0.7584\n",
            "Epoch 336/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3546 - accuracy: 0.8493 - val_loss: 0.6169 - val_accuracy: 0.7416\n",
            "Epoch 337/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3932 - accuracy: 0.8257 - val_loss: 0.6031 - val_accuracy: 0.7360\n",
            "Epoch 338/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3762 - accuracy: 0.8287 - val_loss: 0.5986 - val_accuracy: 0.7472\n",
            "Epoch 339/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3627 - accuracy: 0.8483 - val_loss: 0.5830 - val_accuracy: 0.7697\n",
            "Epoch 340/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3702 - accuracy: 0.8436 - val_loss: 0.5958 - val_accuracy: 0.7528\n",
            "Epoch 341/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3527 - accuracy: 0.8562 - val_loss: 0.5843 - val_accuracy: 0.7640\n",
            "Epoch 342/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3546 - accuracy: 0.8433 - val_loss: 0.6550 - val_accuracy: 0.7360\n",
            "Epoch 343/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3923 - accuracy: 0.8347 - val_loss: 0.5895 - val_accuracy: 0.7697\n",
            "Epoch 344/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3640 - accuracy: 0.8387 - val_loss: 0.5944 - val_accuracy: 0.7697\n",
            "Epoch 345/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3664 - accuracy: 0.8303 - val_loss: 0.6017 - val_accuracy: 0.7697\n",
            "Epoch 346/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3695 - accuracy: 0.8464 - val_loss: 0.6341 - val_accuracy: 0.7360\n",
            "Epoch 347/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3537 - accuracy: 0.8525 - val_loss: 0.5992 - val_accuracy: 0.7640\n",
            "Epoch 348/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3931 - accuracy: 0.8307 - val_loss: 0.6381 - val_accuracy: 0.7303\n",
            "Epoch 349/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3620 - accuracy: 0.8480 - val_loss: 0.6679 - val_accuracy: 0.7135\n",
            "Epoch 350/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3726 - accuracy: 0.8355 - val_loss: 0.6212 - val_accuracy: 0.7191\n",
            "Epoch 351/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3361 - accuracy: 0.8542 - val_loss: 0.7083 - val_accuracy: 0.7135\n",
            "Epoch 352/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3868 - accuracy: 0.8394 - val_loss: 0.6180 - val_accuracy: 0.7360\n",
            "Epoch 353/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3619 - accuracy: 0.8429 - val_loss: 0.6153 - val_accuracy: 0.7472\n",
            "Epoch 354/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3737 - accuracy: 0.8372 - val_loss: 0.6110 - val_accuracy: 0.7584\n",
            "Epoch 355/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3589 - accuracy: 0.8534 - val_loss: 0.6052 - val_accuracy: 0.7697\n",
            "Epoch 356/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3649 - accuracy: 0.8490 - val_loss: 0.6288 - val_accuracy: 0.7584\n",
            "Epoch 357/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3732 - accuracy: 0.8283 - val_loss: 0.6229 - val_accuracy: 0.7640\n",
            "Epoch 358/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3398 - accuracy: 0.8715 - val_loss: 0.6317 - val_accuracy: 0.7472\n",
            "Epoch 359/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3716 - accuracy: 0.8439 - val_loss: 0.6682 - val_accuracy: 0.7584\n",
            "Epoch 360/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.3789 - accuracy: 0.8381 - val_loss: 0.5984 - val_accuracy: 0.7472\n",
            "Epoch 361/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3613 - accuracy: 0.8516 - val_loss: 0.6210 - val_accuracy: 0.7640\n",
            "Epoch 362/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3961 - accuracy: 0.8153 - val_loss: 0.6063 - val_accuracy: 0.7303\n",
            "Epoch 363/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3583 - accuracy: 0.8397 - val_loss: 0.5968 - val_accuracy: 0.7697\n",
            "Epoch 364/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3782 - accuracy: 0.8293 - val_loss: 0.8871 - val_accuracy: 0.7022\n",
            "Epoch 365/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4345 - accuracy: 0.8086 - val_loss: 0.7185 - val_accuracy: 0.7022\n",
            "Epoch 366/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3827 - accuracy: 0.8325 - val_loss: 0.6586 - val_accuracy: 0.7303\n",
            "Epoch 367/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3644 - accuracy: 0.8452 - val_loss: 0.8279 - val_accuracy: 0.6966\n",
            "Epoch 368/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4257 - accuracy: 0.8211 - val_loss: 0.5844 - val_accuracy: 0.7584\n",
            "Epoch 369/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3556 - accuracy: 0.8460 - val_loss: 0.6082 - val_accuracy: 0.7640\n",
            "Epoch 370/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3447 - accuracy: 0.8439 - val_loss: 0.6232 - val_accuracy: 0.7360\n",
            "Epoch 371/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.3506 - accuracy: 0.8462 - val_loss: 0.5997 - val_accuracy: 0.7472\n",
            "Epoch 372/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3690 - accuracy: 0.8386 - val_loss: 0.5858 - val_accuracy: 0.7753\n",
            "Epoch 373/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3526 - accuracy: 0.8497 - val_loss: 0.6729 - val_accuracy: 0.7191\n",
            "Epoch 374/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3573 - accuracy: 0.8505 - val_loss: 0.6715 - val_accuracy: 0.7303\n",
            "Epoch 375/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3539 - accuracy: 0.8307 - val_loss: 0.5996 - val_accuracy: 0.7303\n",
            "Epoch 376/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3752 - accuracy: 0.8318 - val_loss: 0.6004 - val_accuracy: 0.7528\n",
            "Epoch 377/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3894 - accuracy: 0.8377 - val_loss: 0.5992 - val_accuracy: 0.7697\n",
            "Epoch 378/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3459 - accuracy: 0.8530 - val_loss: 0.6493 - val_accuracy: 0.7303\n",
            "Epoch 379/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3742 - accuracy: 0.8296 - val_loss: 0.5963 - val_accuracy: 0.7697\n",
            "Epoch 380/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3494 - accuracy: 0.8453 - val_loss: 0.6171 - val_accuracy: 0.7584\n",
            "Epoch 381/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3391 - accuracy: 0.8605 - val_loss: 0.6142 - val_accuracy: 0.7303\n",
            "Epoch 382/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3660 - accuracy: 0.8397 - val_loss: 0.6254 - val_accuracy: 0.7640\n",
            "Epoch 383/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3565 - accuracy: 0.8570 - val_loss: 0.6375 - val_accuracy: 0.7697\n",
            "Epoch 384/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3436 - accuracy: 0.8512 - val_loss: 0.6261 - val_accuracy: 0.7303\n",
            "Epoch 385/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3603 - accuracy: 0.8316 - val_loss: 0.6381 - val_accuracy: 0.7416\n",
            "Epoch 386/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3596 - accuracy: 0.8386 - val_loss: 0.6159 - val_accuracy: 0.7472\n",
            "Epoch 387/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3577 - accuracy: 0.8375 - val_loss: 0.7429 - val_accuracy: 0.7079\n",
            "Epoch 388/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3789 - accuracy: 0.8396 - val_loss: 0.6137 - val_accuracy: 0.7640\n",
            "Epoch 389/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3322 - accuracy: 0.8562 - val_loss: 0.6099 - val_accuracy: 0.7472\n",
            "Epoch 390/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3312 - accuracy: 0.8551 - val_loss: 0.6196 - val_accuracy: 0.7584\n",
            "Epoch 391/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3523 - accuracy: 0.8485 - val_loss: 0.6089 - val_accuracy: 0.7303\n",
            "Epoch 392/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3604 - accuracy: 0.8538 - val_loss: 0.6101 - val_accuracy: 0.7753\n",
            "Epoch 393/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3421 - accuracy: 0.8465 - val_loss: 0.6139 - val_accuracy: 0.7640\n",
            "Epoch 394/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3596 - accuracy: 0.8386 - val_loss: 0.7134 - val_accuracy: 0.6966\n",
            "Epoch 395/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3726 - accuracy: 0.8327 - val_loss: 0.6605 - val_accuracy: 0.6910\n",
            "Epoch 396/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3601 - accuracy: 0.8350 - val_loss: 0.5833 - val_accuracy: 0.7753\n",
            "Epoch 397/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3542 - accuracy: 0.8524 - val_loss: 0.5688 - val_accuracy: 0.7697\n",
            "Epoch 398/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3640 - accuracy: 0.8362 - val_loss: 0.6190 - val_accuracy: 0.7416\n",
            "Epoch 399/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3422 - accuracy: 0.8382 - val_loss: 0.5975 - val_accuracy: 0.7472\n",
            "Epoch 400/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3388 - accuracy: 0.8419 - val_loss: 0.5973 - val_accuracy: 0.7584\n",
            "Epoch 401/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3588 - accuracy: 0.8407 - val_loss: 0.5954 - val_accuracy: 0.7247\n",
            "Epoch 402/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3572 - accuracy: 0.8545 - val_loss: 0.6165 - val_accuracy: 0.7360\n",
            "Epoch 403/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.4085 - accuracy: 0.8155 - val_loss: 0.6326 - val_accuracy: 0.7416\n",
            "Epoch 404/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3335 - accuracy: 0.8573 - val_loss: 0.7364 - val_accuracy: 0.7079\n",
            "Epoch 405/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.4014 - accuracy: 0.8230 - val_loss: 0.5985 - val_accuracy: 0.7697\n",
            "Epoch 406/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3244 - accuracy: 0.8673 - val_loss: 0.6144 - val_accuracy: 0.7416\n",
            "Epoch 407/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3849 - accuracy: 0.8283 - val_loss: 0.6250 - val_accuracy: 0.7640\n",
            "Epoch 408/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3377 - accuracy: 0.8577 - val_loss: 0.6400 - val_accuracy: 0.7640\n",
            "Epoch 409/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3627 - accuracy: 0.8424 - val_loss: 0.6712 - val_accuracy: 0.7135\n",
            "Epoch 410/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3536 - accuracy: 0.8493 - val_loss: 0.8591 - val_accuracy: 0.6573\n",
            "Epoch 411/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4935 - accuracy: 0.7981 - val_loss: 0.6558 - val_accuracy: 0.7303\n",
            "Epoch 412/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3454 - accuracy: 0.8495 - val_loss: 0.5948 - val_accuracy: 0.7584\n",
            "Epoch 413/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3575 - accuracy: 0.8340 - val_loss: 0.6510 - val_accuracy: 0.7303\n",
            "Epoch 414/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3659 - accuracy: 0.8402 - val_loss: 0.6416 - val_accuracy: 0.7416\n",
            "Epoch 415/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3715 - accuracy: 0.8406 - val_loss: 0.6093 - val_accuracy: 0.7697\n",
            "Epoch 416/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3561 - accuracy: 0.8449 - val_loss: 0.5944 - val_accuracy: 0.7640\n",
            "Epoch 417/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3559 - accuracy: 0.8473 - val_loss: 0.6199 - val_accuracy: 0.7416\n",
            "Epoch 418/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3476 - accuracy: 0.8426 - val_loss: 0.6020 - val_accuracy: 0.7640\n",
            "Epoch 419/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3484 - accuracy: 0.8397 - val_loss: 0.6103 - val_accuracy: 0.7416\n",
            "Epoch 420/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3528 - accuracy: 0.8366 - val_loss: 0.7279 - val_accuracy: 0.6910\n",
            "Epoch 421/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3896 - accuracy: 0.8061 - val_loss: 0.6091 - val_accuracy: 0.7697\n",
            "Epoch 422/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3500 - accuracy: 0.8549 - val_loss: 0.6301 - val_accuracy: 0.7528\n",
            "Epoch 423/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3688 - accuracy: 0.8307 - val_loss: 0.6463 - val_accuracy: 0.7360\n",
            "Epoch 424/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3618 - accuracy: 0.8422 - val_loss: 0.6172 - val_accuracy: 0.7472\n",
            "Epoch 425/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3554 - accuracy: 0.8440 - val_loss: 0.6063 - val_accuracy: 0.7472\n",
            "Epoch 426/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3703 - accuracy: 0.8388 - val_loss: 0.6437 - val_accuracy: 0.7247\n",
            "Epoch 427/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3571 - accuracy: 0.8313 - val_loss: 0.6209 - val_accuracy: 0.7528\n",
            "Epoch 428/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3616 - accuracy: 0.8445 - val_loss: 0.6954 - val_accuracy: 0.7247\n",
            "Epoch 429/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3776 - accuracy: 0.8270 - val_loss: 0.6668 - val_accuracy: 0.7303\n",
            "Epoch 430/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3710 - accuracy: 0.8375 - val_loss: 0.6433 - val_accuracy: 0.7528\n",
            "Epoch 431/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3734 - accuracy: 0.8406 - val_loss: 0.6262 - val_accuracy: 0.7640\n",
            "Epoch 432/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3500 - accuracy: 0.8467 - val_loss: 0.6203 - val_accuracy: 0.7472\n",
            "Epoch 433/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3960 - accuracy: 0.8181 - val_loss: 0.6146 - val_accuracy: 0.7640\n",
            "Epoch 434/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3565 - accuracy: 0.8500 - val_loss: 0.6251 - val_accuracy: 0.7753\n",
            "Epoch 435/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3389 - accuracy: 0.8561 - val_loss: 0.6156 - val_accuracy: 0.7697\n",
            "Epoch 436/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3738 - accuracy: 0.8461 - val_loss: 0.6018 - val_accuracy: 0.7753\n",
            "Epoch 437/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3727 - accuracy: 0.8354 - val_loss: 0.5960 - val_accuracy: 0.7640\n",
            "Epoch 438/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3626 - accuracy: 0.8439 - val_loss: 0.6079 - val_accuracy: 0.7697\n",
            "Epoch 439/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3958 - accuracy: 0.8250 - val_loss: 0.6214 - val_accuracy: 0.7472\n",
            "Epoch 440/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3746 - accuracy: 0.8341 - val_loss: 0.6173 - val_accuracy: 0.7472\n",
            "Epoch 441/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3655 - accuracy: 0.8448 - val_loss: 0.6150 - val_accuracy: 0.7809\n",
            "Epoch 442/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3714 - accuracy: 0.8257 - val_loss: 0.6217 - val_accuracy: 0.7697\n",
            "Epoch 443/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3492 - accuracy: 0.8482 - val_loss: 0.6142 - val_accuracy: 0.7697\n",
            "Epoch 444/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3619 - accuracy: 0.8350 - val_loss: 0.6359 - val_accuracy: 0.7697\n",
            "Epoch 445/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3501 - accuracy: 0.8388 - val_loss: 0.6162 - val_accuracy: 0.7697\n",
            "Epoch 446/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3241 - accuracy: 0.8545 - val_loss: 0.7288 - val_accuracy: 0.6910\n",
            "Epoch 447/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3774 - accuracy: 0.8220 - val_loss: 0.6032 - val_accuracy: 0.7640\n",
            "Epoch 448/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3621 - accuracy: 0.8397 - val_loss: 0.6237 - val_accuracy: 0.7303\n",
            "Epoch 449/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3539 - accuracy: 0.8548 - val_loss: 0.6340 - val_accuracy: 0.7472\n",
            "Epoch 450/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3558 - accuracy: 0.8456 - val_loss: 0.6051 - val_accuracy: 0.7584\n",
            "Epoch 451/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3826 - accuracy: 0.8338 - val_loss: 0.6213 - val_accuracy: 0.7528\n",
            "Epoch 452/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3721 - accuracy: 0.8453 - val_loss: 0.6290 - val_accuracy: 0.7416\n",
            "Epoch 453/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3677 - accuracy: 0.8339 - val_loss: 0.6764 - val_accuracy: 0.7247\n",
            "Epoch 454/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3677 - accuracy: 0.8355 - val_loss: 0.6219 - val_accuracy: 0.7528\n",
            "Epoch 455/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3429 - accuracy: 0.8431 - val_loss: 0.6305 - val_accuracy: 0.7472\n",
            "Epoch 456/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3625 - accuracy: 0.8379 - val_loss: 0.6582 - val_accuracy: 0.7360\n",
            "Epoch 457/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3371 - accuracy: 0.8508 - val_loss: 0.6325 - val_accuracy: 0.7697\n",
            "Epoch 458/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3320 - accuracy: 0.8560 - val_loss: 0.6525 - val_accuracy: 0.7528\n",
            "Epoch 459/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3541 - accuracy: 0.8477 - val_loss: 0.6112 - val_accuracy: 0.7472\n",
            "Epoch 460/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3349 - accuracy: 0.8681 - val_loss: 0.6422 - val_accuracy: 0.7472\n",
            "Epoch 461/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.3591 - accuracy: 0.8465 - val_loss: 0.6457 - val_accuracy: 0.7416\n",
            "Epoch 462/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3527 - accuracy: 0.8487 - val_loss: 0.6547 - val_accuracy: 0.7472\n",
            "Epoch 463/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3531 - accuracy: 0.8377 - val_loss: 0.6709 - val_accuracy: 0.7191\n",
            "Epoch 464/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3468 - accuracy: 0.8486 - val_loss: 0.6259 - val_accuracy: 0.7416\n",
            "Epoch 465/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3843 - accuracy: 0.8327 - val_loss: 0.6027 - val_accuracy: 0.7697\n",
            "Epoch 466/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3719 - accuracy: 0.8401 - val_loss: 0.6345 - val_accuracy: 0.7472\n",
            "Epoch 467/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3513 - accuracy: 0.8476 - val_loss: 0.6472 - val_accuracy: 0.7528\n",
            "Epoch 468/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3647 - accuracy: 0.8268 - val_loss: 0.6257 - val_accuracy: 0.7697\n",
            "Epoch 469/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3701 - accuracy: 0.8371 - val_loss: 0.6212 - val_accuracy: 0.7697\n",
            "Epoch 470/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3568 - accuracy: 0.8382 - val_loss: 0.6579 - val_accuracy: 0.7528\n",
            "Epoch 471/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3292 - accuracy: 0.8574 - val_loss: 0.6393 - val_accuracy: 0.7697\n",
            "Epoch 472/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3397 - accuracy: 0.8552 - val_loss: 0.7251 - val_accuracy: 0.7022\n",
            "Epoch 473/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3626 - accuracy: 0.8428 - val_loss: 0.6148 - val_accuracy: 0.7472\n",
            "Epoch 474/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3477 - accuracy: 0.8395 - val_loss: 0.6809 - val_accuracy: 0.7303\n",
            "Epoch 475/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3675 - accuracy: 0.8394 - val_loss: 0.6257 - val_accuracy: 0.7360\n",
            "Epoch 476/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3596 - accuracy: 0.8329 - val_loss: 0.7262 - val_accuracy: 0.7191\n",
            "Epoch 477/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3906 - accuracy: 0.8192 - val_loss: 0.6210 - val_accuracy: 0.7528\n",
            "Epoch 478/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3820 - accuracy: 0.8250 - val_loss: 0.6971 - val_accuracy: 0.7247\n",
            "Epoch 479/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3766 - accuracy: 0.8369 - val_loss: 0.6195 - val_accuracy: 0.7697\n",
            "Epoch 480/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3790 - accuracy: 0.8268 - val_loss: 0.6350 - val_accuracy: 0.7584\n",
            "Epoch 481/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3597 - accuracy: 0.8327 - val_loss: 0.6362 - val_accuracy: 0.7584\n",
            "Epoch 482/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3436 - accuracy: 0.8428 - val_loss: 0.6422 - val_accuracy: 0.7584\n",
            "Epoch 483/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3578 - accuracy: 0.8382 - val_loss: 0.6919 - val_accuracy: 0.7247\n",
            "Epoch 484/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3631 - accuracy: 0.8281 - val_loss: 0.6258 - val_accuracy: 0.7640\n",
            "Epoch 485/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3643 - accuracy: 0.8417 - val_loss: 0.6521 - val_accuracy: 0.7640\n",
            "Epoch 486/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4217 - accuracy: 0.8169 - val_loss: 0.6353 - val_accuracy: 0.7640\n",
            "Epoch 487/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3724 - accuracy: 0.8378 - val_loss: 0.7495 - val_accuracy: 0.7135\n",
            "Epoch 488/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3689 - accuracy: 0.8503 - val_loss: 0.6254 - val_accuracy: 0.7416\n",
            "Epoch 489/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4223 - accuracy: 0.8122 - val_loss: 0.6055 - val_accuracy: 0.7753\n",
            "Epoch 490/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3625 - accuracy: 0.8350 - val_loss: 0.6215 - val_accuracy: 0.7472\n",
            "Epoch 491/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3390 - accuracy: 0.8595 - val_loss: 0.6764 - val_accuracy: 0.7022\n",
            "Epoch 492/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3568 - accuracy: 0.8426 - val_loss: 0.6438 - val_accuracy: 0.7416\n",
            "Epoch 493/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3441 - accuracy: 0.8495 - val_loss: 0.6222 - val_accuracy: 0.7360\n",
            "Epoch 494/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3481 - accuracy: 0.8479 - val_loss: 0.6172 - val_accuracy: 0.7697\n",
            "Epoch 495/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3420 - accuracy: 0.8475 - val_loss: 0.6276 - val_accuracy: 0.7528\n",
            "Epoch 496/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3830 - accuracy: 0.8254 - val_loss: 0.6266 - val_accuracy: 0.7416\n",
            "Epoch 497/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3460 - accuracy: 0.8527 - val_loss: 0.6061 - val_accuracy: 0.7753\n",
            "Epoch 498/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3455 - accuracy: 0.8604 - val_loss: 0.6198 - val_accuracy: 0.7697\n",
            "Epoch 499/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3590 - accuracy: 0.8442 - val_loss: 0.6050 - val_accuracy: 0.7697\n",
            "Epoch 500/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3845 - accuracy: 0.8394 - val_loss: 0.7086 - val_accuracy: 0.6854\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5JjQMl9btuL",
        "outputId": "7cc5d2c7-3f1f-47fe-f42f-2b46a84a4947"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 0s 2ms/step - loss: 0.7086 - accuracy: 0.6854\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7086278796195984, 0.6853932738304138]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBBI1uSrgEsu"
      },
      "source": [
        "Now use a batch size of 200 and 200 epochs. Have you observed a significant difference in performance?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0n0qLX_gEsv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3adc16ad-34fc-4920-8a5c-4131ad026899"
      },
      "source": [
        "# Answer below:\n",
        "model.compile(optimizer=sgd, loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, batch_size=200, epochs=200,\n",
        "                    validation_data = (X_test, y_test), verbose=1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "4/4 [==============================] - 1s 102ms/step - loss: 0.3691 - accuracy: 0.8412 - val_loss: 0.6165 - val_accuracy: 0.7697\n",
            "Epoch 2/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3441 - accuracy: 0.8481 - val_loss: 0.6257 - val_accuracy: 0.7697\n",
            "Epoch 3/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3386 - accuracy: 0.8537 - val_loss: 0.6196 - val_accuracy: 0.7697\n",
            "Epoch 4/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3596 - accuracy: 0.8411 - val_loss: 0.6285 - val_accuracy: 0.7697\n",
            "Epoch 5/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3546 - accuracy: 0.8374 - val_loss: 0.6199 - val_accuracy: 0.7697\n",
            "Epoch 6/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3542 - accuracy: 0.8383 - val_loss: 0.6149 - val_accuracy: 0.7753\n",
            "Epoch 7/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3461 - accuracy: 0.8458 - val_loss: 0.6112 - val_accuracy: 0.7640\n",
            "Epoch 8/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3508 - accuracy: 0.8466 - val_loss: 0.6216 - val_accuracy: 0.7697\n",
            "Epoch 9/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3514 - accuracy: 0.8476 - val_loss: 0.6244 - val_accuracy: 0.7697\n",
            "Epoch 10/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3425 - accuracy: 0.8544 - val_loss: 0.6483 - val_accuracy: 0.7416\n",
            "Epoch 11/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3442 - accuracy: 0.8538 - val_loss: 0.6303 - val_accuracy: 0.7640\n",
            "Epoch 12/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3308 - accuracy: 0.8585 - val_loss: 0.6243 - val_accuracy: 0.7697\n",
            "Epoch 13/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3444 - accuracy: 0.8468 - val_loss: 0.6323 - val_accuracy: 0.7640\n",
            "Epoch 14/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3573 - accuracy: 0.8441 - val_loss: 0.6205 - val_accuracy: 0.7753\n",
            "Epoch 15/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3473 - accuracy: 0.8496 - val_loss: 0.6194 - val_accuracy: 0.7697\n",
            "Epoch 16/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3443 - accuracy: 0.8442 - val_loss: 0.6315 - val_accuracy: 0.7584\n",
            "Epoch 17/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3541 - accuracy: 0.8412 - val_loss: 0.6393 - val_accuracy: 0.7584\n",
            "Epoch 18/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3580 - accuracy: 0.8391 - val_loss: 0.6330 - val_accuracy: 0.7697\n",
            "Epoch 19/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3270 - accuracy: 0.8584 - val_loss: 0.6331 - val_accuracy: 0.7697\n",
            "Epoch 20/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3471 - accuracy: 0.8473 - val_loss: 0.6412 - val_accuracy: 0.7697\n",
            "Epoch 21/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3499 - accuracy: 0.8349 - val_loss: 0.6384 - val_accuracy: 0.7697\n",
            "Epoch 22/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3540 - accuracy: 0.8349 - val_loss: 0.6277 - val_accuracy: 0.7640\n",
            "Epoch 23/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3575 - accuracy: 0.8354 - val_loss: 0.6416 - val_accuracy: 0.7640\n",
            "Epoch 24/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3542 - accuracy: 0.8442 - val_loss: 0.6266 - val_accuracy: 0.7697\n",
            "Epoch 25/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3347 - accuracy: 0.8562 - val_loss: 0.6468 - val_accuracy: 0.7640\n",
            "Epoch 26/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3449 - accuracy: 0.8488 - val_loss: 0.6635 - val_accuracy: 0.7416\n",
            "Epoch 27/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3444 - accuracy: 0.8477 - val_loss: 0.6379 - val_accuracy: 0.7640\n",
            "Epoch 28/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3456 - accuracy: 0.8526 - val_loss: 0.6373 - val_accuracy: 0.7697\n",
            "Epoch 29/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3488 - accuracy: 0.8386 - val_loss: 0.6260 - val_accuracy: 0.7697\n",
            "Epoch 30/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3438 - accuracy: 0.8456 - val_loss: 0.6314 - val_accuracy: 0.7753\n",
            "Epoch 31/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3515 - accuracy: 0.8437 - val_loss: 0.6338 - val_accuracy: 0.7640\n",
            "Epoch 32/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3594 - accuracy: 0.8362 - val_loss: 0.6370 - val_accuracy: 0.7640\n",
            "Epoch 33/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3627 - accuracy: 0.8408 - val_loss: 0.6468 - val_accuracy: 0.7640\n",
            "Epoch 34/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3437 - accuracy: 0.8566 - val_loss: 0.6505 - val_accuracy: 0.7640\n",
            "Epoch 35/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3477 - accuracy: 0.8541 - val_loss: 0.6346 - val_accuracy: 0.7697\n",
            "Epoch 36/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3432 - accuracy: 0.8488 - val_loss: 0.6363 - val_accuracy: 0.7697\n",
            "Epoch 37/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3442 - accuracy: 0.8500 - val_loss: 0.6563 - val_accuracy: 0.7416\n",
            "Epoch 38/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3560 - accuracy: 0.8328 - val_loss: 0.6392 - val_accuracy: 0.7640\n",
            "Epoch 39/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3521 - accuracy: 0.8401 - val_loss: 0.6275 - val_accuracy: 0.7697\n",
            "Epoch 40/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3507 - accuracy: 0.8520 - val_loss: 0.6354 - val_accuracy: 0.7753\n",
            "Epoch 41/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3314 - accuracy: 0.8514 - val_loss: 0.6371 - val_accuracy: 0.7697\n",
            "Epoch 42/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3335 - accuracy: 0.8561 - val_loss: 0.6471 - val_accuracy: 0.7528\n",
            "Epoch 43/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3582 - accuracy: 0.8399 - val_loss: 0.6276 - val_accuracy: 0.7697\n",
            "Epoch 44/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3622 - accuracy: 0.8365 - val_loss: 0.6339 - val_accuracy: 0.7697\n",
            "Epoch 45/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3457 - accuracy: 0.8428 - val_loss: 0.6384 - val_accuracy: 0.7697\n",
            "Epoch 46/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3276 - accuracy: 0.8576 - val_loss: 0.6339 - val_accuracy: 0.7697\n",
            "Epoch 47/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3296 - accuracy: 0.8638 - val_loss: 0.6387 - val_accuracy: 0.7697\n",
            "Epoch 48/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3550 - accuracy: 0.8353 - val_loss: 0.6318 - val_accuracy: 0.7753\n",
            "Epoch 49/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3577 - accuracy: 0.8482 - val_loss: 0.6325 - val_accuracy: 0.7753\n",
            "Epoch 50/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3323 - accuracy: 0.8547 - val_loss: 0.6397 - val_accuracy: 0.7697\n",
            "Epoch 51/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3455 - accuracy: 0.8444 - val_loss: 0.6550 - val_accuracy: 0.7472\n",
            "Epoch 52/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3367 - accuracy: 0.8396 - val_loss: 0.6587 - val_accuracy: 0.7416\n",
            "Epoch 53/200\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.3585 - accuracy: 0.8349 - val_loss: 0.6462 - val_accuracy: 0.7640\n",
            "Epoch 54/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3434 - accuracy: 0.8448 - val_loss: 0.6417 - val_accuracy: 0.7697\n",
            "Epoch 55/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3634 - accuracy: 0.8335 - val_loss: 0.6418 - val_accuracy: 0.7697\n",
            "Epoch 56/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3463 - accuracy: 0.8478 - val_loss: 0.6405 - val_accuracy: 0.7697\n",
            "Epoch 57/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3444 - accuracy: 0.8496 - val_loss: 0.6406 - val_accuracy: 0.7697\n",
            "Epoch 58/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3547 - accuracy: 0.8368 - val_loss: 0.6286 - val_accuracy: 0.7697\n",
            "Epoch 59/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3593 - accuracy: 0.8308 - val_loss: 0.6443 - val_accuracy: 0.7697\n",
            "Epoch 60/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3409 - accuracy: 0.8567 - val_loss: 0.6455 - val_accuracy: 0.7697\n",
            "Epoch 61/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3428 - accuracy: 0.8382 - val_loss: 0.6385 - val_accuracy: 0.7697\n",
            "Epoch 62/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3568 - accuracy: 0.8419 - val_loss: 0.6346 - val_accuracy: 0.7753\n",
            "Epoch 63/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3489 - accuracy: 0.8472 - val_loss: 0.6607 - val_accuracy: 0.7416\n",
            "Epoch 64/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3422 - accuracy: 0.8509 - val_loss: 0.6437 - val_accuracy: 0.7697\n",
            "Epoch 65/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3357 - accuracy: 0.8542 - val_loss: 0.6718 - val_accuracy: 0.7416\n",
            "Epoch 66/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3538 - accuracy: 0.8401 - val_loss: 0.6443 - val_accuracy: 0.7640\n",
            "Epoch 67/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3524 - accuracy: 0.8407 - val_loss: 0.6273 - val_accuracy: 0.7753\n",
            "Epoch 68/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3518 - accuracy: 0.8433 - val_loss: 0.6348 - val_accuracy: 0.7753\n",
            "Epoch 69/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3306 - accuracy: 0.8497 - val_loss: 0.6413 - val_accuracy: 0.7697\n",
            "Epoch 70/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3397 - accuracy: 0.8472 - val_loss: 0.6504 - val_accuracy: 0.7584\n",
            "Epoch 71/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3497 - accuracy: 0.8494 - val_loss: 0.6377 - val_accuracy: 0.7697\n",
            "Epoch 72/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3534 - accuracy: 0.8422 - val_loss: 0.6419 - val_accuracy: 0.7753\n",
            "Epoch 73/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3308 - accuracy: 0.8507 - val_loss: 0.6826 - val_accuracy: 0.7303\n",
            "Epoch 74/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3569 - accuracy: 0.8403 - val_loss: 0.6413 - val_accuracy: 0.7640\n",
            "Epoch 75/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3334 - accuracy: 0.8511 - val_loss: 0.6435 - val_accuracy: 0.7697\n",
            "Epoch 76/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3324 - accuracy: 0.8556 - val_loss: 0.6307 - val_accuracy: 0.7753\n",
            "Epoch 77/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3381 - accuracy: 0.8492 - val_loss: 0.6391 - val_accuracy: 0.7753\n",
            "Epoch 78/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3582 - accuracy: 0.8337 - val_loss: 0.6307 - val_accuracy: 0.7697\n",
            "Epoch 79/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3454 - accuracy: 0.8531 - val_loss: 0.6465 - val_accuracy: 0.7697\n",
            "Epoch 80/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3382 - accuracy: 0.8563 - val_loss: 0.6415 - val_accuracy: 0.7697\n",
            "Epoch 81/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3409 - accuracy: 0.8482 - val_loss: 0.6427 - val_accuracy: 0.7640\n",
            "Epoch 82/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3612 - accuracy: 0.8420 - val_loss: 0.6435 - val_accuracy: 0.7697\n",
            "Epoch 83/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3449 - accuracy: 0.8491 - val_loss: 0.6486 - val_accuracy: 0.7697\n",
            "Epoch 84/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3342 - accuracy: 0.8506 - val_loss: 0.6501 - val_accuracy: 0.7640\n",
            "Epoch 85/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3338 - accuracy: 0.8601 - val_loss: 0.6488 - val_accuracy: 0.7697\n",
            "Epoch 86/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3497 - accuracy: 0.8448 - val_loss: 0.6472 - val_accuracy: 0.7697\n",
            "Epoch 87/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3270 - accuracy: 0.8617 - val_loss: 0.6438 - val_accuracy: 0.7697\n",
            "Epoch 88/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3432 - accuracy: 0.8485 - val_loss: 0.6531 - val_accuracy: 0.7640\n",
            "Epoch 89/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3409 - accuracy: 0.8482 - val_loss: 0.6368 - val_accuracy: 0.7640\n",
            "Epoch 90/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3522 - accuracy: 0.8469 - val_loss: 0.6482 - val_accuracy: 0.7640\n",
            "Epoch 91/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3494 - accuracy: 0.8426 - val_loss: 0.6491 - val_accuracy: 0.7640\n",
            "Epoch 92/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3545 - accuracy: 0.8452 - val_loss: 0.6533 - val_accuracy: 0.7640\n",
            "Epoch 93/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3378 - accuracy: 0.8518 - val_loss: 0.6437 - val_accuracy: 0.7753\n",
            "Epoch 94/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3691 - accuracy: 0.8371 - val_loss: 0.6620 - val_accuracy: 0.7472\n",
            "Epoch 95/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3453 - accuracy: 0.8507 - val_loss: 0.6474 - val_accuracy: 0.7753\n",
            "Epoch 96/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3454 - accuracy: 0.8473 - val_loss: 0.6802 - val_accuracy: 0.7360\n",
            "Epoch 97/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3526 - accuracy: 0.8429 - val_loss: 0.6447 - val_accuracy: 0.7753\n",
            "Epoch 98/200\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.3365 - accuracy: 0.8483 - val_loss: 0.6374 - val_accuracy: 0.7697\n",
            "Epoch 99/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3509 - accuracy: 0.8452 - val_loss: 0.6480 - val_accuracy: 0.7697\n",
            "Epoch 100/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3476 - accuracy: 0.8434 - val_loss: 0.6383 - val_accuracy: 0.7697\n",
            "Epoch 101/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3565 - accuracy: 0.8408 - val_loss: 0.6407 - val_accuracy: 0.7697\n",
            "Epoch 102/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3405 - accuracy: 0.8501 - val_loss: 0.6446 - val_accuracy: 0.7697\n",
            "Epoch 103/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3590 - accuracy: 0.8287 - val_loss: 0.6281 - val_accuracy: 0.7697\n",
            "Epoch 104/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3657 - accuracy: 0.8353 - val_loss: 0.6580 - val_accuracy: 0.7584\n",
            "Epoch 105/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3391 - accuracy: 0.8548 - val_loss: 0.6432 - val_accuracy: 0.7697\n",
            "Epoch 106/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3653 - accuracy: 0.8361 - val_loss: 0.6472 - val_accuracy: 0.7697\n",
            "Epoch 107/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3408 - accuracy: 0.8435 - val_loss: 0.6623 - val_accuracy: 0.7528\n",
            "Epoch 108/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3464 - accuracy: 0.8383 - val_loss: 0.6480 - val_accuracy: 0.7697\n",
            "Epoch 109/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3333 - accuracy: 0.8516 - val_loss: 0.6353 - val_accuracy: 0.7753\n",
            "Epoch 110/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3329 - accuracy: 0.8491 - val_loss: 0.6626 - val_accuracy: 0.7472\n",
            "Epoch 111/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3576 - accuracy: 0.8402 - val_loss: 0.6365 - val_accuracy: 0.7697\n",
            "Epoch 112/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3451 - accuracy: 0.8344 - val_loss: 0.6542 - val_accuracy: 0.7640\n",
            "Epoch 113/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3238 - accuracy: 0.8593 - val_loss: 0.6742 - val_accuracy: 0.7416\n",
            "Epoch 114/200\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3407 - accuracy: 0.8422 - val_loss: 0.6370 - val_accuracy: 0.7697\n",
            "Epoch 115/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3550 - accuracy: 0.8424 - val_loss: 0.6529 - val_accuracy: 0.7640\n",
            "Epoch 116/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3399 - accuracy: 0.8432 - val_loss: 0.6530 - val_accuracy: 0.7697\n",
            "Epoch 117/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3489 - accuracy: 0.8432 - val_loss: 0.6676 - val_accuracy: 0.7472\n",
            "Epoch 118/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3443 - accuracy: 0.8438 - val_loss: 0.6550 - val_accuracy: 0.7640\n",
            "Epoch 119/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3281 - accuracy: 0.8639 - val_loss: 0.6552 - val_accuracy: 0.7640\n",
            "Epoch 120/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3360 - accuracy: 0.8511 - val_loss: 0.6427 - val_accuracy: 0.7697\n",
            "Epoch 121/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3541 - accuracy: 0.8423 - val_loss: 0.6540 - val_accuracy: 0.7697\n",
            "Epoch 122/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3454 - accuracy: 0.8555 - val_loss: 0.6396 - val_accuracy: 0.7697\n",
            "Epoch 123/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3629 - accuracy: 0.8429 - val_loss: 0.6465 - val_accuracy: 0.7697\n",
            "Epoch 124/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3453 - accuracy: 0.8508 - val_loss: 0.6541 - val_accuracy: 0.7697\n",
            "Epoch 125/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3487 - accuracy: 0.8487 - val_loss: 0.6518 - val_accuracy: 0.7697\n",
            "Epoch 126/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3444 - accuracy: 0.8506 - val_loss: 0.6422 - val_accuracy: 0.7753\n",
            "Epoch 127/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3418 - accuracy: 0.8445 - val_loss: 0.6372 - val_accuracy: 0.7697\n",
            "Epoch 128/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3390 - accuracy: 0.8573 - val_loss: 0.6528 - val_accuracy: 0.7640\n",
            "Epoch 129/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3386 - accuracy: 0.8443 - val_loss: 0.6632 - val_accuracy: 0.7528\n",
            "Epoch 130/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3354 - accuracy: 0.8493 - val_loss: 0.6496 - val_accuracy: 0.7697\n",
            "Epoch 131/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3658 - accuracy: 0.8425 - val_loss: 0.6550 - val_accuracy: 0.7640\n",
            "Epoch 132/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3428 - accuracy: 0.8437 - val_loss: 0.6442 - val_accuracy: 0.7753\n",
            "Epoch 133/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3631 - accuracy: 0.8353 - val_loss: 0.6447 - val_accuracy: 0.7697\n",
            "Epoch 134/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3482 - accuracy: 0.8439 - val_loss: 0.6766 - val_accuracy: 0.7360\n",
            "Epoch 135/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3383 - accuracy: 0.8563 - val_loss: 0.6403 - val_accuracy: 0.7472\n",
            "Epoch 136/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3677 - accuracy: 0.8329 - val_loss: 0.6790 - val_accuracy: 0.7416\n",
            "Epoch 137/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3536 - accuracy: 0.8410 - val_loss: 0.6508 - val_accuracy: 0.7697\n",
            "Epoch 138/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3357 - accuracy: 0.8478 - val_loss: 0.6752 - val_accuracy: 0.7472\n",
            "Epoch 139/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3425 - accuracy: 0.8542 - val_loss: 0.7172 - val_accuracy: 0.7303\n",
            "Epoch 140/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3913 - accuracy: 0.8261 - val_loss: 0.6457 - val_accuracy: 0.7753\n",
            "Epoch 141/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3518 - accuracy: 0.8480 - val_loss: 0.6561 - val_accuracy: 0.7640\n",
            "Epoch 142/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3495 - accuracy: 0.8378 - val_loss: 0.6452 - val_accuracy: 0.7753\n",
            "Epoch 143/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3484 - accuracy: 0.8492 - val_loss: 0.6470 - val_accuracy: 0.7697\n",
            "Epoch 144/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3631 - accuracy: 0.8337 - val_loss: 0.6541 - val_accuracy: 0.7753\n",
            "Epoch 145/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3308 - accuracy: 0.8488 - val_loss: 0.6394 - val_accuracy: 0.7472\n",
            "Epoch 146/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3468 - accuracy: 0.8457 - val_loss: 0.6392 - val_accuracy: 0.7472\n",
            "Epoch 147/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3519 - accuracy: 0.8567 - val_loss: 0.6381 - val_accuracy: 0.7472\n",
            "Epoch 148/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3496 - accuracy: 0.8420 - val_loss: 0.6363 - val_accuracy: 0.7697\n",
            "Epoch 149/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3434 - accuracy: 0.8517 - val_loss: 0.6424 - val_accuracy: 0.7697\n",
            "Epoch 150/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3167 - accuracy: 0.8608 - val_loss: 0.6488 - val_accuracy: 0.7753\n",
            "Epoch 151/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3512 - accuracy: 0.8357 - val_loss: 0.6402 - val_accuracy: 0.7753\n",
            "Epoch 152/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3723 - accuracy: 0.8291 - val_loss: 0.6430 - val_accuracy: 0.7753\n",
            "Epoch 153/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3596 - accuracy: 0.8363 - val_loss: 0.6455 - val_accuracy: 0.7697\n",
            "Epoch 154/200\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 0.3503 - accuracy: 0.8455 - val_loss: 0.6375 - val_accuracy: 0.7697\n",
            "Epoch 155/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3475 - accuracy: 0.8511 - val_loss: 0.6590 - val_accuracy: 0.7640\n",
            "Epoch 156/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3528 - accuracy: 0.8442 - val_loss: 0.6479 - val_accuracy: 0.7697\n",
            "Epoch 157/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3482 - accuracy: 0.8395 - val_loss: 0.6392 - val_accuracy: 0.7697\n",
            "Epoch 158/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3464 - accuracy: 0.8429 - val_loss: 0.6578 - val_accuracy: 0.7640\n",
            "Epoch 159/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3261 - accuracy: 0.8632 - val_loss: 0.6470 - val_accuracy: 0.7640\n",
            "Epoch 160/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3383 - accuracy: 0.8473 - val_loss: 0.6494 - val_accuracy: 0.7753\n",
            "Epoch 161/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3384 - accuracy: 0.8449 - val_loss: 0.6911 - val_accuracy: 0.7303\n",
            "Epoch 162/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3481 - accuracy: 0.8485 - val_loss: 0.6646 - val_accuracy: 0.7640\n",
            "Epoch 163/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3400 - accuracy: 0.8510 - val_loss: 0.6357 - val_accuracy: 0.7472\n",
            "Epoch 164/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3769 - accuracy: 0.8235 - val_loss: 0.6542 - val_accuracy: 0.7753\n",
            "Epoch 165/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3372 - accuracy: 0.8454 - val_loss: 0.6628 - val_accuracy: 0.7472\n",
            "Epoch 166/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3339 - accuracy: 0.8579 - val_loss: 0.6561 - val_accuracy: 0.7640\n",
            "Epoch 167/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3359 - accuracy: 0.8514 - val_loss: 0.6803 - val_accuracy: 0.7360\n",
            "Epoch 168/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3468 - accuracy: 0.8498 - val_loss: 0.6540 - val_accuracy: 0.7697\n",
            "Epoch 169/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3493 - accuracy: 0.8422 - val_loss: 0.6593 - val_accuracy: 0.7640\n",
            "Epoch 170/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3397 - accuracy: 0.8380 - val_loss: 0.6516 - val_accuracy: 0.7697\n",
            "Epoch 171/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3493 - accuracy: 0.8349 - val_loss: 0.6479 - val_accuracy: 0.7753\n",
            "Epoch 172/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3606 - accuracy: 0.8399 - val_loss: 0.6546 - val_accuracy: 0.7753\n",
            "Epoch 173/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3436 - accuracy: 0.8523 - val_loss: 0.6724 - val_accuracy: 0.7584\n",
            "Epoch 174/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3570 - accuracy: 0.8342 - val_loss: 0.6399 - val_accuracy: 0.7697\n",
            "Epoch 175/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3656 - accuracy: 0.8463 - val_loss: 0.6656 - val_accuracy: 0.7640\n",
            "Epoch 176/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3355 - accuracy: 0.8496 - val_loss: 0.6567 - val_accuracy: 0.7753\n",
            "Epoch 177/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3365 - accuracy: 0.8502 - val_loss: 0.6430 - val_accuracy: 0.7697\n",
            "Epoch 178/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3311 - accuracy: 0.8489 - val_loss: 0.6535 - val_accuracy: 0.7697\n",
            "Epoch 179/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3344 - accuracy: 0.8507 - val_loss: 0.6623 - val_accuracy: 0.7697\n",
            "Epoch 180/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3461 - accuracy: 0.8484 - val_loss: 0.6761 - val_accuracy: 0.7472\n",
            "Epoch 181/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3389 - accuracy: 0.8488 - val_loss: 0.6552 - val_accuracy: 0.7697\n",
            "Epoch 182/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3344 - accuracy: 0.8531 - val_loss: 0.6542 - val_accuracy: 0.7753\n",
            "Epoch 183/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3510 - accuracy: 0.8489 - val_loss: 0.6751 - val_accuracy: 0.7584\n",
            "Epoch 184/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3410 - accuracy: 0.8471 - val_loss: 0.6580 - val_accuracy: 0.7640\n",
            "Epoch 185/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3520 - accuracy: 0.8457 - val_loss: 0.6643 - val_accuracy: 0.7528\n",
            "Epoch 186/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3466 - accuracy: 0.8440 - val_loss: 0.6546 - val_accuracy: 0.7753\n",
            "Epoch 187/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3571 - accuracy: 0.8421 - val_loss: 0.6531 - val_accuracy: 0.7753\n",
            "Epoch 188/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3329 - accuracy: 0.8565 - val_loss: 0.6517 - val_accuracy: 0.7753\n",
            "Epoch 189/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3368 - accuracy: 0.8540 - val_loss: 0.6487 - val_accuracy: 0.7697\n",
            "Epoch 190/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3473 - accuracy: 0.8364 - val_loss: 0.6639 - val_accuracy: 0.7640\n",
            "Epoch 191/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3458 - accuracy: 0.8432 - val_loss: 0.6630 - val_accuracy: 0.7584\n",
            "Epoch 192/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3495 - accuracy: 0.8455 - val_loss: 0.6527 - val_accuracy: 0.7753\n",
            "Epoch 193/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3502 - accuracy: 0.8481 - val_loss: 0.6776 - val_accuracy: 0.7416\n",
            "Epoch 194/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3490 - accuracy: 0.8496 - val_loss: 0.6665 - val_accuracy: 0.7472\n",
            "Epoch 195/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3587 - accuracy: 0.8365 - val_loss: 0.6476 - val_accuracy: 0.7528\n",
            "Epoch 196/200\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.3590 - accuracy: 0.8319 - val_loss: 0.6567 - val_accuracy: 0.7753\n",
            "Epoch 197/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3340 - accuracy: 0.8465 - val_loss: 0.6822 - val_accuracy: 0.7360\n",
            "Epoch 198/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3378 - accuracy: 0.8532 - val_loss: 0.6515 - val_accuracy: 0.7697\n",
            "Epoch 199/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3579 - accuracy: 0.8381 - val_loss: 0.6549 - val_accuracy: 0.7640\n",
            "Epoch 200/200\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.3585 - accuracy: 0.8422 - val_loss: 0.6588 - val_accuracy: 0.7697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvdcZGbvcKz8",
        "outputId": "f45601c9-b690-4c79-fea2-ef2b52723e47"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6588 - accuracy: 0.7697\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6587988138198853, 0.7696629166603088]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGUXhgE8cPdA"
      },
      "source": [
        "The performance for each is more or less the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyY8ex2MgEsw"
      },
      "source": [
        "Now create a model with 7 layers. The model should have an input layer with unit size 128, then hidden layers of size 128, 64, 64, 32, 32, and an output layer of size 1. Use a sigmoid activation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0Nv70YugEsx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b03d4822-010d-4e46-c6d8-8c2e1e95af3f"
      },
      "source": [
        "# Answer below\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 128)               1408      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 33,505\n",
            "Trainable params: 33,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJbIQ5AgEsy"
      },
      "source": [
        "Fit and compile the model using the SGD optimizer you previously defined, batch size = 80 and epochs = 200"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9B2GhuLgEsz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48ccd7fe-adee-478c-c7a7-2b698f7954df"
      },
      "source": [
        "# Answer below:\n",
        "model.compile(optimizer=sgd, loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, batch_size=80, epochs=200,\n",
        "                    validation_data = (X_test, y_test), verbose=1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "9/9 [==============================] - 1s 26ms/step - loss: 0.6917 - accuracy: 0.4818 - val_loss: 0.6695 - val_accuracy: 0.6573\n",
            "Epoch 2/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6735 - accuracy: 0.6072 - val_loss: 0.6540 - val_accuracy: 0.6629\n",
            "Epoch 3/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6633 - accuracy: 0.6015 - val_loss: 0.6412 - val_accuracy: 0.6629\n",
            "Epoch 4/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6494 - accuracy: 0.6044 - val_loss: 0.6285 - val_accuracy: 0.6629\n",
            "Epoch 5/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6407 - accuracy: 0.5969 - val_loss: 0.6156 - val_accuracy: 0.6629\n",
            "Epoch 6/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6317 - accuracy: 0.5902 - val_loss: 0.6023 - val_accuracy: 0.6629\n",
            "Epoch 7/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6069 - accuracy: 0.6185 - val_loss: 0.5891 - val_accuracy: 0.7135\n",
            "Epoch 8/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5906 - accuracy: 0.6921 - val_loss: 0.5709 - val_accuracy: 0.7697\n",
            "Epoch 9/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5596 - accuracy: 0.7997 - val_loss: 0.5572 - val_accuracy: 0.7921\n",
            "Epoch 10/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5520 - accuracy: 0.7862 - val_loss: 0.5346 - val_accuracy: 0.7921\n",
            "Epoch 11/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5165 - accuracy: 0.8248 - val_loss: 0.5175 - val_accuracy: 0.7921\n",
            "Epoch 12/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.5066 - accuracy: 0.8057 - val_loss: 0.5044 - val_accuracy: 0.7865\n",
            "Epoch 13/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4925 - accuracy: 0.8041 - val_loss: 0.4942 - val_accuracy: 0.7865\n",
            "Epoch 14/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4690 - accuracy: 0.8118 - val_loss: 0.4890 - val_accuracy: 0.7697\n",
            "Epoch 15/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4733 - accuracy: 0.8071 - val_loss: 0.4815 - val_accuracy: 0.8034\n",
            "Epoch 16/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4510 - accuracy: 0.8090 - val_loss: 0.4793 - val_accuracy: 0.7697\n",
            "Epoch 17/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.8059 - val_loss: 0.4713 - val_accuracy: 0.7809\n",
            "Epoch 18/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4455 - accuracy: 0.8185 - val_loss: 0.4855 - val_accuracy: 0.7472\n",
            "Epoch 19/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4254 - accuracy: 0.8301 - val_loss: 0.4683 - val_accuracy: 0.7809\n",
            "Epoch 20/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4161 - accuracy: 0.8189 - val_loss: 0.4660 - val_accuracy: 0.7809\n",
            "Epoch 21/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4058 - accuracy: 0.8352 - val_loss: 0.4688 - val_accuracy: 0.7753\n",
            "Epoch 22/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4240 - accuracy: 0.8090 - val_loss: 0.4705 - val_accuracy: 0.7753\n",
            "Epoch 23/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4182 - accuracy: 0.8196 - val_loss: 0.4743 - val_accuracy: 0.7753\n",
            "Epoch 24/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4296 - accuracy: 0.8149 - val_loss: 0.4683 - val_accuracy: 0.7809\n",
            "Epoch 25/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3919 - accuracy: 0.8395 - val_loss: 0.4790 - val_accuracy: 0.7753\n",
            "Epoch 26/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8212 - val_loss: 0.4747 - val_accuracy: 0.7921\n",
            "Epoch 27/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4394 - accuracy: 0.8115 - val_loss: 0.4743 - val_accuracy: 0.7865\n",
            "Epoch 28/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4046 - accuracy: 0.8238 - val_loss: 0.4757 - val_accuracy: 0.7921\n",
            "Epoch 29/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4190 - accuracy: 0.8109 - val_loss: 0.4802 - val_accuracy: 0.7809\n",
            "Epoch 30/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4013 - accuracy: 0.8172 - val_loss: 0.4849 - val_accuracy: 0.7753\n",
            "Epoch 31/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4073 - accuracy: 0.8232 - val_loss: 0.4863 - val_accuracy: 0.7753\n",
            "Epoch 32/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4044 - accuracy: 0.8059 - val_loss: 0.4792 - val_accuracy: 0.7921\n",
            "Epoch 33/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4080 - accuracy: 0.8192 - val_loss: 0.4855 - val_accuracy: 0.7921\n",
            "Epoch 34/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4059 - accuracy: 0.8277 - val_loss: 0.4990 - val_accuracy: 0.7697\n",
            "Epoch 35/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3970 - accuracy: 0.8306 - val_loss: 0.5017 - val_accuracy: 0.7809\n",
            "Epoch 36/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4020 - accuracy: 0.8308 - val_loss: 0.5136 - val_accuracy: 0.7753\n",
            "Epoch 37/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4152 - accuracy: 0.8082 - val_loss: 0.5053 - val_accuracy: 0.7697\n",
            "Epoch 38/200\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 0.4115 - accuracy: 0.8177 - val_loss: 0.4939 - val_accuracy: 0.7865\n",
            "Epoch 39/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4164 - accuracy: 0.8192 - val_loss: 0.4993 - val_accuracy: 0.7753\n",
            "Epoch 40/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4333 - accuracy: 0.8114 - val_loss: 0.5339 - val_accuracy: 0.7584\n",
            "Epoch 41/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3974 - accuracy: 0.8156 - val_loss: 0.4962 - val_accuracy: 0.7865\n",
            "Epoch 42/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4093 - accuracy: 0.8181 - val_loss: 0.5025 - val_accuracy: 0.7753\n",
            "Epoch 43/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4187 - accuracy: 0.8041 - val_loss: 0.5145 - val_accuracy: 0.7753\n",
            "Epoch 44/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3912 - accuracy: 0.8375 - val_loss: 0.5025 - val_accuracy: 0.7865\n",
            "Epoch 45/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4119 - accuracy: 0.8148 - val_loss: 0.5069 - val_accuracy: 0.7865\n",
            "Epoch 46/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4094 - accuracy: 0.8114 - val_loss: 0.5271 - val_accuracy: 0.7697\n",
            "Epoch 47/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3952 - accuracy: 0.8281 - val_loss: 0.5073 - val_accuracy: 0.7809\n",
            "Epoch 48/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3859 - accuracy: 0.8192 - val_loss: 0.5520 - val_accuracy: 0.7528\n",
            "Epoch 49/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4235 - accuracy: 0.8168 - val_loss: 0.5237 - val_accuracy: 0.7753\n",
            "Epoch 50/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3902 - accuracy: 0.8230 - val_loss: 0.5148 - val_accuracy: 0.7809\n",
            "Epoch 51/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3706 - accuracy: 0.8292 - val_loss: 0.5436 - val_accuracy: 0.7472\n",
            "Epoch 52/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3833 - accuracy: 0.8391 - val_loss: 0.5478 - val_accuracy: 0.7528\n",
            "Epoch 53/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3741 - accuracy: 0.8353 - val_loss: 0.5144 - val_accuracy: 0.7697\n",
            "Epoch 54/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3853 - accuracy: 0.8207 - val_loss: 0.5140 - val_accuracy: 0.7753\n",
            "Epoch 55/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4202 - accuracy: 0.8181 - val_loss: 0.5275 - val_accuracy: 0.7753\n",
            "Epoch 56/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3934 - accuracy: 0.8413 - val_loss: 0.5192 - val_accuracy: 0.7697\n",
            "Epoch 57/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3562 - accuracy: 0.8375 - val_loss: 0.5380 - val_accuracy: 0.7528\n",
            "Epoch 58/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3909 - accuracy: 0.8233 - val_loss: 0.5686 - val_accuracy: 0.7360\n",
            "Epoch 59/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3878 - accuracy: 0.8016 - val_loss: 0.5298 - val_accuracy: 0.7697\n",
            "Epoch 60/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3964 - accuracy: 0.8321 - val_loss: 0.5317 - val_accuracy: 0.7753\n",
            "Epoch 61/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4001 - accuracy: 0.8378 - val_loss: 0.5285 - val_accuracy: 0.7640\n",
            "Epoch 62/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3791 - accuracy: 0.8405 - val_loss: 0.5259 - val_accuracy: 0.7697\n",
            "Epoch 63/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3969 - accuracy: 0.8238 - val_loss: 0.5404 - val_accuracy: 0.7584\n",
            "Epoch 64/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4036 - accuracy: 0.8083 - val_loss: 0.5472 - val_accuracy: 0.7528\n",
            "Epoch 65/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4323 - accuracy: 0.8070 - val_loss: 0.5265 - val_accuracy: 0.7753\n",
            "Epoch 66/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3875 - accuracy: 0.8431 - val_loss: 0.5308 - val_accuracy: 0.7753\n",
            "Epoch 67/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3502 - accuracy: 0.8637 - val_loss: 0.5562 - val_accuracy: 0.7584\n",
            "Epoch 68/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3862 - accuracy: 0.8430 - val_loss: 0.5562 - val_accuracy: 0.7528\n",
            "Epoch 69/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3627 - accuracy: 0.8410 - val_loss: 0.5564 - val_accuracy: 0.7416\n",
            "Epoch 70/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3911 - accuracy: 0.8376 - val_loss: 0.6036 - val_accuracy: 0.7191\n",
            "Epoch 71/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3919 - accuracy: 0.8365 - val_loss: 0.5295 - val_accuracy: 0.7697\n",
            "Epoch 72/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3980 - accuracy: 0.8151 - val_loss: 0.5410 - val_accuracy: 0.7753\n",
            "Epoch 73/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3644 - accuracy: 0.8409 - val_loss: 0.5375 - val_accuracy: 0.7640\n",
            "Epoch 74/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3703 - accuracy: 0.8425 - val_loss: 0.5811 - val_accuracy: 0.7303\n",
            "Epoch 75/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4187 - accuracy: 0.8106 - val_loss: 0.5702 - val_accuracy: 0.7360\n",
            "Epoch 76/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3734 - accuracy: 0.8342 - val_loss: 0.5433 - val_accuracy: 0.7528\n",
            "Epoch 77/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3820 - accuracy: 0.8360 - val_loss: 0.5442 - val_accuracy: 0.7528\n",
            "Epoch 78/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3887 - accuracy: 0.8308 - val_loss: 0.5630 - val_accuracy: 0.7472\n",
            "Epoch 79/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3924 - accuracy: 0.8234 - val_loss: 0.5531 - val_accuracy: 0.7640\n",
            "Epoch 80/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3845 - accuracy: 0.8292 - val_loss: 0.5514 - val_accuracy: 0.7584\n",
            "Epoch 81/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3775 - accuracy: 0.8277 - val_loss: 0.5511 - val_accuracy: 0.7697\n",
            "Epoch 82/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3678 - accuracy: 0.8480 - val_loss: 0.5455 - val_accuracy: 0.7697\n",
            "Epoch 83/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3804 - accuracy: 0.8349 - val_loss: 0.5429 - val_accuracy: 0.7528\n",
            "Epoch 84/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4003 - accuracy: 0.8240 - val_loss: 0.5541 - val_accuracy: 0.7640\n",
            "Epoch 85/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3952 - accuracy: 0.8314 - val_loss: 0.5487 - val_accuracy: 0.7528\n",
            "Epoch 86/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3342 - accuracy: 0.8539 - val_loss: 0.5681 - val_accuracy: 0.7472\n",
            "Epoch 87/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3680 - accuracy: 0.8383 - val_loss: 0.5728 - val_accuracy: 0.7528\n",
            "Epoch 88/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.4007 - accuracy: 0.8338 - val_loss: 0.5696 - val_accuracy: 0.7528\n",
            "Epoch 89/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3728 - accuracy: 0.8477 - val_loss: 0.5885 - val_accuracy: 0.7472\n",
            "Epoch 90/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3873 - accuracy: 0.8294 - val_loss: 0.5581 - val_accuracy: 0.7584\n",
            "Epoch 91/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3933 - accuracy: 0.8182 - val_loss: 0.5493 - val_accuracy: 0.7640\n",
            "Epoch 92/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3571 - accuracy: 0.8516 - val_loss: 0.5838 - val_accuracy: 0.7472\n",
            "Epoch 93/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3749 - accuracy: 0.8364 - val_loss: 0.5498 - val_accuracy: 0.7528\n",
            "Epoch 94/200\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.3933 - accuracy: 0.8193 - val_loss: 0.5619 - val_accuracy: 0.7640\n",
            "Epoch 95/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3797 - accuracy: 0.8208 - val_loss: 0.5530 - val_accuracy: 0.7528\n",
            "Epoch 96/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3635 - accuracy: 0.8353 - val_loss: 0.5529 - val_accuracy: 0.7697\n",
            "Epoch 97/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3609 - accuracy: 0.8577 - val_loss: 0.5747 - val_accuracy: 0.7640\n",
            "Epoch 98/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3587 - accuracy: 0.8484 - val_loss: 0.5804 - val_accuracy: 0.7697\n",
            "Epoch 99/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3558 - accuracy: 0.8389 - val_loss: 0.5565 - val_accuracy: 0.7528\n",
            "Epoch 100/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3983 - accuracy: 0.8322 - val_loss: 0.5565 - val_accuracy: 0.7528\n",
            "Epoch 101/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3988 - accuracy: 0.8267 - val_loss: 0.5528 - val_accuracy: 0.7528\n",
            "Epoch 102/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3830 - accuracy: 0.8381 - val_loss: 0.6213 - val_accuracy: 0.7303\n",
            "Epoch 103/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3755 - accuracy: 0.8321 - val_loss: 0.5777 - val_accuracy: 0.7697\n",
            "Epoch 104/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3814 - accuracy: 0.8225 - val_loss: 0.5525 - val_accuracy: 0.7697\n",
            "Epoch 105/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3728 - accuracy: 0.8250 - val_loss: 0.5549 - val_accuracy: 0.7584\n",
            "Epoch 106/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3298 - accuracy: 0.8616 - val_loss: 0.5578 - val_accuracy: 0.7584\n",
            "Epoch 107/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3746 - accuracy: 0.8363 - val_loss: 0.5581 - val_accuracy: 0.7528\n",
            "Epoch 108/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3931 - accuracy: 0.8261 - val_loss: 0.5622 - val_accuracy: 0.7528\n",
            "Epoch 109/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3815 - accuracy: 0.8261 - val_loss: 0.5604 - val_accuracy: 0.7528\n",
            "Epoch 110/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4025 - accuracy: 0.8297 - val_loss: 0.5611 - val_accuracy: 0.7528\n",
            "Epoch 111/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3909 - accuracy: 0.8459 - val_loss: 0.5730 - val_accuracy: 0.7584\n",
            "Epoch 112/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4119 - accuracy: 0.7969 - val_loss: 0.5936 - val_accuracy: 0.7528\n",
            "Epoch 113/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3770 - accuracy: 0.8283 - val_loss: 0.5620 - val_accuracy: 0.7528\n",
            "Epoch 114/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3734 - accuracy: 0.8387 - val_loss: 0.6361 - val_accuracy: 0.7303\n",
            "Epoch 115/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3818 - accuracy: 0.8231 - val_loss: 0.5798 - val_accuracy: 0.7697\n",
            "Epoch 116/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3786 - accuracy: 0.8519 - val_loss: 0.5661 - val_accuracy: 0.7528\n",
            "Epoch 117/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3855 - accuracy: 0.8294 - val_loss: 0.5728 - val_accuracy: 0.7584\n",
            "Epoch 118/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3927 - accuracy: 0.8194 - val_loss: 0.5787 - val_accuracy: 0.7472\n",
            "Epoch 119/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3667 - accuracy: 0.8453 - val_loss: 0.5967 - val_accuracy: 0.7528\n",
            "Epoch 120/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3718 - accuracy: 0.8521 - val_loss: 0.5679 - val_accuracy: 0.7528\n",
            "Epoch 121/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3936 - accuracy: 0.8041 - val_loss: 0.5751 - val_accuracy: 0.7528\n",
            "Epoch 122/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3752 - accuracy: 0.8322 - val_loss: 0.6008 - val_accuracy: 0.7416\n",
            "Epoch 123/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3340 - accuracy: 0.8657 - val_loss: 0.5701 - val_accuracy: 0.7247\n",
            "Epoch 124/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4069 - accuracy: 0.8229 - val_loss: 0.5737 - val_accuracy: 0.7584\n",
            "Epoch 125/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4228 - accuracy: 0.8152 - val_loss: 0.6184 - val_accuracy: 0.7360\n",
            "Epoch 126/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3757 - accuracy: 0.8281 - val_loss: 0.5740 - val_accuracy: 0.7303\n",
            "Epoch 127/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3723 - accuracy: 0.8371 - val_loss: 0.6098 - val_accuracy: 0.7472\n",
            "Epoch 128/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.3623 - accuracy: 0.8418 - val_loss: 0.5969 - val_accuracy: 0.7472\n",
            "Epoch 129/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3614 - accuracy: 0.8459 - val_loss: 0.5931 - val_accuracy: 0.7528\n",
            "Epoch 130/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3628 - accuracy: 0.8393 - val_loss: 0.5611 - val_accuracy: 0.7584\n",
            "Epoch 131/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3710 - accuracy: 0.8387 - val_loss: 0.5671 - val_accuracy: 0.7528\n",
            "Epoch 132/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3400 - accuracy: 0.8581 - val_loss: 0.6283 - val_accuracy: 0.7360\n",
            "Epoch 133/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3980 - accuracy: 0.8198 - val_loss: 0.5873 - val_accuracy: 0.7697\n",
            "Epoch 134/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3726 - accuracy: 0.8447 - val_loss: 0.5816 - val_accuracy: 0.7528\n",
            "Epoch 135/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3879 - accuracy: 0.8310 - val_loss: 0.5738 - val_accuracy: 0.7360\n",
            "Epoch 136/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3367 - accuracy: 0.8541 - val_loss: 0.5729 - val_accuracy: 0.7247\n",
            "Epoch 137/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3797 - accuracy: 0.8340 - val_loss: 0.5741 - val_accuracy: 0.7528\n",
            "Epoch 138/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3705 - accuracy: 0.8285 - val_loss: 0.5697 - val_accuracy: 0.7584\n",
            "Epoch 139/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3718 - accuracy: 0.8397 - val_loss: 0.5685 - val_accuracy: 0.7640\n",
            "Epoch 140/200\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.4021 - accuracy: 0.8198 - val_loss: 0.5744 - val_accuracy: 0.7640\n",
            "Epoch 141/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3378 - accuracy: 0.8678 - val_loss: 0.6090 - val_accuracy: 0.7528\n",
            "Epoch 142/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3823 - accuracy: 0.8325 - val_loss: 0.5802 - val_accuracy: 0.7584\n",
            "Epoch 143/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3739 - accuracy: 0.8420 - val_loss: 0.5821 - val_accuracy: 0.7640\n",
            "Epoch 144/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3573 - accuracy: 0.8414 - val_loss: 0.5989 - val_accuracy: 0.7584\n",
            "Epoch 145/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3860 - accuracy: 0.8239 - val_loss: 0.6080 - val_accuracy: 0.7528\n",
            "Epoch 146/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3721 - accuracy: 0.8405 - val_loss: 0.5949 - val_accuracy: 0.7697\n",
            "Epoch 147/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3340 - accuracy: 0.8542 - val_loss: 0.6107 - val_accuracy: 0.7416\n",
            "Epoch 148/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3921 - accuracy: 0.8199 - val_loss: 0.5780 - val_accuracy: 0.7584\n",
            "Epoch 149/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3922 - accuracy: 0.8299 - val_loss: 0.5849 - val_accuracy: 0.7472\n",
            "Epoch 150/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3864 - accuracy: 0.8304 - val_loss: 0.5862 - val_accuracy: 0.7640\n",
            "Epoch 151/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3500 - accuracy: 0.8464 - val_loss: 0.5820 - val_accuracy: 0.7472\n",
            "Epoch 152/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3309 - accuracy: 0.8619 - val_loss: 0.5787 - val_accuracy: 0.7640\n",
            "Epoch 153/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3683 - accuracy: 0.8434 - val_loss: 0.5951 - val_accuracy: 0.7640\n",
            "Epoch 154/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3920 - accuracy: 0.8207 - val_loss: 0.5804 - val_accuracy: 0.7640\n",
            "Epoch 155/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3643 - accuracy: 0.8381 - val_loss: 0.5822 - val_accuracy: 0.7472\n",
            "Epoch 156/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3628 - accuracy: 0.8338 - val_loss: 0.5801 - val_accuracy: 0.7360\n",
            "Epoch 157/200\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3722 - accuracy: 0.8444 - val_loss: 0.5902 - val_accuracy: 0.7640\n",
            "Epoch 158/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3656 - accuracy: 0.8342 - val_loss: 0.5969 - val_accuracy: 0.7584\n",
            "Epoch 159/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3647 - accuracy: 0.8420 - val_loss: 0.5947 - val_accuracy: 0.7584\n",
            "Epoch 160/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3730 - accuracy: 0.8308 - val_loss: 0.5815 - val_accuracy: 0.7360\n",
            "Epoch 161/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3680 - accuracy: 0.8383 - val_loss: 0.5693 - val_accuracy: 0.7753\n",
            "Epoch 162/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3559 - accuracy: 0.8431 - val_loss: 0.5744 - val_accuracy: 0.7584\n",
            "Epoch 163/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3903 - accuracy: 0.8247 - val_loss: 0.5760 - val_accuracy: 0.7360\n",
            "Epoch 164/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3658 - accuracy: 0.8313 - val_loss: 0.6185 - val_accuracy: 0.7472\n",
            "Epoch 165/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3592 - accuracy: 0.8488 - val_loss: 0.6388 - val_accuracy: 0.7360\n",
            "Epoch 166/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3825 - accuracy: 0.8292 - val_loss: 0.5809 - val_accuracy: 0.7528\n",
            "Epoch 167/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3487 - accuracy: 0.8413 - val_loss: 0.5992 - val_accuracy: 0.7640\n",
            "Epoch 168/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3804 - accuracy: 0.8444 - val_loss: 0.6396 - val_accuracy: 0.7472\n",
            "Epoch 169/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3854 - accuracy: 0.8242 - val_loss: 0.5760 - val_accuracy: 0.7360\n",
            "Epoch 170/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3584 - accuracy: 0.8465 - val_loss: 0.5909 - val_accuracy: 0.7584\n",
            "Epoch 171/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3637 - accuracy: 0.8420 - val_loss: 0.5847 - val_accuracy: 0.7640\n",
            "Epoch 172/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3435 - accuracy: 0.8492 - val_loss: 0.6317 - val_accuracy: 0.7416\n",
            "Epoch 173/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3788 - accuracy: 0.8383 - val_loss: 0.5783 - val_accuracy: 0.7584\n",
            "Epoch 174/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3582 - accuracy: 0.8330 - val_loss: 0.5878 - val_accuracy: 0.7303\n",
            "Epoch 175/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3708 - accuracy: 0.8305 - val_loss: 0.5864 - val_accuracy: 0.7416\n",
            "Epoch 176/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3863 - accuracy: 0.8380 - val_loss: 0.5827 - val_accuracy: 0.7360\n",
            "Epoch 177/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3606 - accuracy: 0.8465 - val_loss: 0.5916 - val_accuracy: 0.7416\n",
            "Epoch 178/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3607 - accuracy: 0.8367 - val_loss: 0.5904 - val_accuracy: 0.7640\n",
            "Epoch 179/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3621 - accuracy: 0.8408 - val_loss: 0.6311 - val_accuracy: 0.7528\n",
            "Epoch 180/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3310 - accuracy: 0.8693 - val_loss: 0.6140 - val_accuracy: 0.7584\n",
            "Epoch 181/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3510 - accuracy: 0.8567 - val_loss: 0.5955 - val_accuracy: 0.7360\n",
            "Epoch 182/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3440 - accuracy: 0.8535 - val_loss: 0.5858 - val_accuracy: 0.7697\n",
            "Epoch 183/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3627 - accuracy: 0.8402 - val_loss: 0.5833 - val_accuracy: 0.7360\n",
            "Epoch 184/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3752 - accuracy: 0.8355 - val_loss: 0.6274 - val_accuracy: 0.7528\n",
            "Epoch 185/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.4218 - accuracy: 0.8223 - val_loss: 0.5973 - val_accuracy: 0.7640\n",
            "Epoch 186/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3584 - accuracy: 0.8374 - val_loss: 0.5940 - val_accuracy: 0.7584\n",
            "Epoch 187/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3311 - accuracy: 0.8571 - val_loss: 0.5880 - val_accuracy: 0.7640\n",
            "Epoch 188/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3603 - accuracy: 0.8361 - val_loss: 0.5877 - val_accuracy: 0.7360\n",
            "Epoch 189/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3656 - accuracy: 0.8491 - val_loss: 0.5920 - val_accuracy: 0.7640\n",
            "Epoch 190/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3752 - accuracy: 0.8293 - val_loss: 0.6397 - val_accuracy: 0.7360\n",
            "Epoch 191/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3553 - accuracy: 0.8309 - val_loss: 0.6063 - val_accuracy: 0.7640\n",
            "Epoch 192/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3492 - accuracy: 0.8475 - val_loss: 0.5958 - val_accuracy: 0.7640\n",
            "Epoch 193/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3446 - accuracy: 0.8621 - val_loss: 0.6056 - val_accuracy: 0.7697\n",
            "Epoch 194/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3611 - accuracy: 0.8327 - val_loss: 0.6037 - val_accuracy: 0.7528\n",
            "Epoch 195/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3533 - accuracy: 0.8582 - val_loss: 0.5949 - val_accuracy: 0.7697\n",
            "Epoch 196/200\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 0.3587 - accuracy: 0.8476 - val_loss: 0.5878 - val_accuracy: 0.7360\n",
            "Epoch 197/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3597 - accuracy: 0.8473 - val_loss: 0.5919 - val_accuracy: 0.7303\n",
            "Epoch 198/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3838 - accuracy: 0.8317 - val_loss: 0.5972 - val_accuracy: 0.7697\n",
            "Epoch 199/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3568 - accuracy: 0.8486 - val_loss: 0.6135 - val_accuracy: 0.7697\n",
            "Epoch 200/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3597 - accuracy: 0.8339 - val_loss: 0.5939 - val_accuracy: 0.7753\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8ZsoXgtcev5",
        "outputId": "b88cc186-0640-4985-8abe-006a6a375c19"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 0s 3ms/step - loss: 0.5939 - accuracy: 0.7753\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5939145088195801, 0.7752808928489685]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clQxRuz8gEs0"
      },
      "source": [
        "Define a new SGD optimizer with a learning rate of 0.001"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWdxpU9hgEs1"
      },
      "source": [
        "# Answer below:\n",
        "sgd = SGD(lr=0.001)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dGgoNlrgEs2"
      },
      "source": [
        "Fit and compile the model using this SGD optimizer, batch size = 80 and epochs = 200. Compare to previous results. What do you think went wrong and why?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uRr-yCvgEs3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65c9ffa8-1780-4233-eb92-e0b29081671d"
      },
      "source": [
        "# Answer below:\n",
        "model.compile(optimizer=sgd, loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, batch_size=80, epochs=200,\n",
        "                    validation_data = (X_test, y_test), verbose=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "9/9 [==============================] - 1s 28ms/step - loss: 0.3386 - accuracy: 0.8619 - val_loss: 0.5943 - val_accuracy: 0.7753\n",
            "Epoch 2/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3488 - accuracy: 0.8550 - val_loss: 0.5947 - val_accuracy: 0.7753\n",
            "Epoch 3/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3707 - accuracy: 0.8404 - val_loss: 0.5949 - val_accuracy: 0.7753\n",
            "Epoch 4/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3877 - accuracy: 0.8333 - val_loss: 0.5953 - val_accuracy: 0.7753\n",
            "Epoch 5/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3544 - accuracy: 0.8502 - val_loss: 0.5954 - val_accuracy: 0.7753\n",
            "Epoch 6/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3483 - accuracy: 0.8523 - val_loss: 0.5956 - val_accuracy: 0.7753\n",
            "Epoch 7/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3534 - accuracy: 0.8595 - val_loss: 0.5959 - val_accuracy: 0.7753\n",
            "Epoch 8/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3563 - accuracy: 0.8315 - val_loss: 0.5961 - val_accuracy: 0.7753\n",
            "Epoch 9/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3545 - accuracy: 0.8466 - val_loss: 0.5964 - val_accuracy: 0.7697\n",
            "Epoch 10/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3666 - accuracy: 0.8326 - val_loss: 0.5966 - val_accuracy: 0.7697\n",
            "Epoch 11/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3732 - accuracy: 0.8339 - val_loss: 0.5965 - val_accuracy: 0.7697\n",
            "Epoch 12/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3551 - accuracy: 0.8404 - val_loss: 0.5968 - val_accuracy: 0.7697\n",
            "Epoch 13/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3497 - accuracy: 0.8443 - val_loss: 0.5969 - val_accuracy: 0.7697\n",
            "Epoch 14/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3286 - accuracy: 0.8635 - val_loss: 0.5969 - val_accuracy: 0.7697\n",
            "Epoch 15/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3529 - accuracy: 0.8569 - val_loss: 0.5973 - val_accuracy: 0.7697\n",
            "Epoch 16/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3384 - accuracy: 0.8552 - val_loss: 0.5974 - val_accuracy: 0.7697\n",
            "Epoch 17/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3602 - accuracy: 0.8462 - val_loss: 0.5975 - val_accuracy: 0.7697\n",
            "Epoch 18/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3404 - accuracy: 0.8551 - val_loss: 0.5976 - val_accuracy: 0.7697\n",
            "Epoch 19/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3496 - accuracy: 0.8506 - val_loss: 0.5977 - val_accuracy: 0.7697\n",
            "Epoch 20/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3480 - accuracy: 0.8445 - val_loss: 0.5978 - val_accuracy: 0.7697\n",
            "Epoch 21/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3386 - accuracy: 0.8520 - val_loss: 0.5979 - val_accuracy: 0.7697\n",
            "Epoch 22/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3485 - accuracy: 0.8491 - val_loss: 0.5982 - val_accuracy: 0.7697\n",
            "Epoch 23/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3541 - accuracy: 0.8462 - val_loss: 0.5983 - val_accuracy: 0.7697\n",
            "Epoch 24/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3395 - accuracy: 0.8532 - val_loss: 0.5985 - val_accuracy: 0.7697\n",
            "Epoch 25/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3534 - accuracy: 0.8438 - val_loss: 0.5987 - val_accuracy: 0.7697\n",
            "Epoch 26/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3723 - accuracy: 0.8271 - val_loss: 0.5986 - val_accuracy: 0.7697\n",
            "Epoch 27/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3208 - accuracy: 0.8683 - val_loss: 0.5989 - val_accuracy: 0.7697\n",
            "Epoch 28/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3486 - accuracy: 0.8459 - val_loss: 0.5990 - val_accuracy: 0.7697\n",
            "Epoch 29/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3429 - accuracy: 0.8489 - val_loss: 0.5991 - val_accuracy: 0.7697\n",
            "Epoch 30/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3637 - accuracy: 0.8366 - val_loss: 0.5991 - val_accuracy: 0.7697\n",
            "Epoch 31/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3596 - accuracy: 0.8427 - val_loss: 0.5992 - val_accuracy: 0.7697\n",
            "Epoch 32/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3242 - accuracy: 0.8715 - val_loss: 0.5993 - val_accuracy: 0.7697\n",
            "Epoch 33/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3504 - accuracy: 0.8498 - val_loss: 0.5994 - val_accuracy: 0.7697\n",
            "Epoch 34/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3508 - accuracy: 0.8504 - val_loss: 0.5994 - val_accuracy: 0.7697\n",
            "Epoch 35/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3654 - accuracy: 0.8352 - val_loss: 0.5995 - val_accuracy: 0.7697\n",
            "Epoch 36/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3390 - accuracy: 0.8540 - val_loss: 0.5997 - val_accuracy: 0.7697\n",
            "Epoch 37/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3517 - accuracy: 0.8467 - val_loss: 0.5997 - val_accuracy: 0.7697\n",
            "Epoch 38/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3442 - accuracy: 0.8468 - val_loss: 0.5998 - val_accuracy: 0.7697\n",
            "Epoch 39/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3759 - accuracy: 0.8333 - val_loss: 0.5998 - val_accuracy: 0.7697\n",
            "Epoch 40/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3443 - accuracy: 0.8572 - val_loss: 0.6000 - val_accuracy: 0.7697\n",
            "Epoch 41/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3298 - accuracy: 0.8537 - val_loss: 0.5999 - val_accuracy: 0.7697\n",
            "Epoch 42/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3454 - accuracy: 0.8550 - val_loss: 0.6000 - val_accuracy: 0.7697\n",
            "Epoch 43/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3352 - accuracy: 0.8530 - val_loss: 0.6000 - val_accuracy: 0.7697\n",
            "Epoch 44/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3838 - accuracy: 0.8263 - val_loss: 0.6001 - val_accuracy: 0.7697\n",
            "Epoch 45/200\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 0.3438 - accuracy: 0.8479 - val_loss: 0.6003 - val_accuracy: 0.7697\n",
            "Epoch 46/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3603 - accuracy: 0.8481 - val_loss: 0.6003 - val_accuracy: 0.7697\n",
            "Epoch 47/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3505 - accuracy: 0.8464 - val_loss: 0.6003 - val_accuracy: 0.7697\n",
            "Epoch 48/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3518 - accuracy: 0.8470 - val_loss: 0.6003 - val_accuracy: 0.7697\n",
            "Epoch 49/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3582 - accuracy: 0.8520 - val_loss: 0.6004 - val_accuracy: 0.7697\n",
            "Epoch 50/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3468 - accuracy: 0.8387 - val_loss: 0.6004 - val_accuracy: 0.7697\n",
            "Epoch 51/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3164 - accuracy: 0.8656 - val_loss: 0.6005 - val_accuracy: 0.7697\n",
            "Epoch 52/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3633 - accuracy: 0.8424 - val_loss: 0.6005 - val_accuracy: 0.7697\n",
            "Epoch 53/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3512 - accuracy: 0.8501 - val_loss: 0.6007 - val_accuracy: 0.7697\n",
            "Epoch 54/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3682 - accuracy: 0.8370 - val_loss: 0.6007 - val_accuracy: 0.7697\n",
            "Epoch 55/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3583 - accuracy: 0.8330 - val_loss: 0.6010 - val_accuracy: 0.7697\n",
            "Epoch 56/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3277 - accuracy: 0.8499 - val_loss: 0.6009 - val_accuracy: 0.7697\n",
            "Epoch 57/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3525 - accuracy: 0.8546 - val_loss: 0.6011 - val_accuracy: 0.7697\n",
            "Epoch 58/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3610 - accuracy: 0.8492 - val_loss: 0.6011 - val_accuracy: 0.7697\n",
            "Epoch 59/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3359 - accuracy: 0.8480 - val_loss: 0.6012 - val_accuracy: 0.7697\n",
            "Epoch 60/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3444 - accuracy: 0.8479 - val_loss: 0.6011 - val_accuracy: 0.7697\n",
            "Epoch 61/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3679 - accuracy: 0.8392 - val_loss: 0.6010 - val_accuracy: 0.7697\n",
            "Epoch 62/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3494 - accuracy: 0.8517 - val_loss: 0.6012 - val_accuracy: 0.7697\n",
            "Epoch 63/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3661 - accuracy: 0.8344 - val_loss: 0.6014 - val_accuracy: 0.7697\n",
            "Epoch 64/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3535 - accuracy: 0.8524 - val_loss: 0.6015 - val_accuracy: 0.7697\n",
            "Epoch 65/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3618 - accuracy: 0.8466 - val_loss: 0.6016 - val_accuracy: 0.7697\n",
            "Epoch 66/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3358 - accuracy: 0.8654 - val_loss: 0.6017 - val_accuracy: 0.7697\n",
            "Epoch 67/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3415 - accuracy: 0.8437 - val_loss: 0.6017 - val_accuracy: 0.7697\n",
            "Epoch 68/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3540 - accuracy: 0.8503 - val_loss: 0.6018 - val_accuracy: 0.7697\n",
            "Epoch 69/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3635 - accuracy: 0.8299 - val_loss: 0.6018 - val_accuracy: 0.7697\n",
            "Epoch 70/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3718 - accuracy: 0.8334 - val_loss: 0.6017 - val_accuracy: 0.7697\n",
            "Epoch 71/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3571 - accuracy: 0.8518 - val_loss: 0.6019 - val_accuracy: 0.7697\n",
            "Epoch 72/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3348 - accuracy: 0.8574 - val_loss: 0.6019 - val_accuracy: 0.7697\n",
            "Epoch 73/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3298 - accuracy: 0.8641 - val_loss: 0.6020 - val_accuracy: 0.7697\n",
            "Epoch 74/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3697 - accuracy: 0.8410 - val_loss: 0.6019 - val_accuracy: 0.7697\n",
            "Epoch 75/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3740 - accuracy: 0.8319 - val_loss: 0.6021 - val_accuracy: 0.7697\n",
            "Epoch 76/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3246 - accuracy: 0.8672 - val_loss: 0.6021 - val_accuracy: 0.7697\n",
            "Epoch 77/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3550 - accuracy: 0.8458 - val_loss: 0.6022 - val_accuracy: 0.7697\n",
            "Epoch 78/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3517 - accuracy: 0.8429 - val_loss: 0.6023 - val_accuracy: 0.7697\n",
            "Epoch 79/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3417 - accuracy: 0.8512 - val_loss: 0.6023 - val_accuracy: 0.7697\n",
            "Epoch 80/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3371 - accuracy: 0.8514 - val_loss: 0.6024 - val_accuracy: 0.7697\n",
            "Epoch 81/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3635 - accuracy: 0.8400 - val_loss: 0.6025 - val_accuracy: 0.7697\n",
            "Epoch 82/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3521 - accuracy: 0.8468 - val_loss: 0.6025 - val_accuracy: 0.7697\n",
            "Epoch 83/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3665 - accuracy: 0.8359 - val_loss: 0.6027 - val_accuracy: 0.7697\n",
            "Epoch 84/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3232 - accuracy: 0.8609 - val_loss: 0.6028 - val_accuracy: 0.7697\n",
            "Epoch 85/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3498 - accuracy: 0.8507 - val_loss: 0.6029 - val_accuracy: 0.7697\n",
            "Epoch 86/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3581 - accuracy: 0.8443 - val_loss: 0.6028 - val_accuracy: 0.7697\n",
            "Epoch 87/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3475 - accuracy: 0.8463 - val_loss: 0.6028 - val_accuracy: 0.7697\n",
            "Epoch 88/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3592 - accuracy: 0.8424 - val_loss: 0.6029 - val_accuracy: 0.7697\n",
            "Epoch 89/200\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 0.3524 - accuracy: 0.8461 - val_loss: 0.6030 - val_accuracy: 0.7697\n",
            "Epoch 90/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3525 - accuracy: 0.8442 - val_loss: 0.6029 - val_accuracy: 0.7697\n",
            "Epoch 91/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3426 - accuracy: 0.8501 - val_loss: 0.6029 - val_accuracy: 0.7697\n",
            "Epoch 92/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3343 - accuracy: 0.8472 - val_loss: 0.6029 - val_accuracy: 0.7697\n",
            "Epoch 93/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3822 - accuracy: 0.8268 - val_loss: 0.6030 - val_accuracy: 0.7697\n",
            "Epoch 94/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3354 - accuracy: 0.8642 - val_loss: 0.6031 - val_accuracy: 0.7697\n",
            "Epoch 95/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3492 - accuracy: 0.8440 - val_loss: 0.6032 - val_accuracy: 0.7697\n",
            "Epoch 96/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3680 - accuracy: 0.8328 - val_loss: 0.6030 - val_accuracy: 0.7697\n",
            "Epoch 97/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3214 - accuracy: 0.8671 - val_loss: 0.6030 - val_accuracy: 0.7697\n",
            "Epoch 98/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3641 - accuracy: 0.8377 - val_loss: 0.6031 - val_accuracy: 0.7697\n",
            "Epoch 99/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3417 - accuracy: 0.8553 - val_loss: 0.6030 - val_accuracy: 0.7697\n",
            "Epoch 100/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3393 - accuracy: 0.8599 - val_loss: 0.6031 - val_accuracy: 0.7697\n",
            "Epoch 101/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3794 - accuracy: 0.8350 - val_loss: 0.6031 - val_accuracy: 0.7697\n",
            "Epoch 102/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3484 - accuracy: 0.8643 - val_loss: 0.6032 - val_accuracy: 0.7697\n",
            "Epoch 103/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3484 - accuracy: 0.8605 - val_loss: 0.6034 - val_accuracy: 0.7697\n",
            "Epoch 104/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3628 - accuracy: 0.8524 - val_loss: 0.6035 - val_accuracy: 0.7697\n",
            "Epoch 105/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3491 - accuracy: 0.8375 - val_loss: 0.6035 - val_accuracy: 0.7697\n",
            "Epoch 106/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3702 - accuracy: 0.8265 - val_loss: 0.6034 - val_accuracy: 0.7697\n",
            "Epoch 107/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3666 - accuracy: 0.8369 - val_loss: 0.6035 - val_accuracy: 0.7697\n",
            "Epoch 108/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3424 - accuracy: 0.8516 - val_loss: 0.6038 - val_accuracy: 0.7697\n",
            "Epoch 109/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3750 - accuracy: 0.8383 - val_loss: 0.6038 - val_accuracy: 0.7697\n",
            "Epoch 110/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3639 - accuracy: 0.8432 - val_loss: 0.6038 - val_accuracy: 0.7697\n",
            "Epoch 111/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3639 - accuracy: 0.8428 - val_loss: 0.6038 - val_accuracy: 0.7697\n",
            "Epoch 112/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3396 - accuracy: 0.8457 - val_loss: 0.6040 - val_accuracy: 0.7697\n",
            "Epoch 113/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3398 - accuracy: 0.8479 - val_loss: 0.6040 - val_accuracy: 0.7697\n",
            "Epoch 114/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3394 - accuracy: 0.8519 - val_loss: 0.6039 - val_accuracy: 0.7697\n",
            "Epoch 115/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3331 - accuracy: 0.8616 - val_loss: 0.6040 - val_accuracy: 0.7697\n",
            "Epoch 116/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3263 - accuracy: 0.8522 - val_loss: 0.6040 - val_accuracy: 0.7697\n",
            "Epoch 117/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3540 - accuracy: 0.8531 - val_loss: 0.6043 - val_accuracy: 0.7697\n",
            "Epoch 118/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3331 - accuracy: 0.8590 - val_loss: 0.6042 - val_accuracy: 0.7697\n",
            "Epoch 119/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3376 - accuracy: 0.8523 - val_loss: 0.6041 - val_accuracy: 0.7697\n",
            "Epoch 120/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3486 - accuracy: 0.8541 - val_loss: 0.6043 - val_accuracy: 0.7697\n",
            "Epoch 121/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3351 - accuracy: 0.8502 - val_loss: 0.6042 - val_accuracy: 0.7697\n",
            "Epoch 122/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3526 - accuracy: 0.8472 - val_loss: 0.6044 - val_accuracy: 0.7697\n",
            "Epoch 123/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3680 - accuracy: 0.8333 - val_loss: 0.6044 - val_accuracy: 0.7697\n",
            "Epoch 124/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3395 - accuracy: 0.8529 - val_loss: 0.6044 - val_accuracy: 0.7697\n",
            "Epoch 125/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3463 - accuracy: 0.8482 - val_loss: 0.6045 - val_accuracy: 0.7697\n",
            "Epoch 126/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3374 - accuracy: 0.8611 - val_loss: 0.6045 - val_accuracy: 0.7697\n",
            "Epoch 127/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3530 - accuracy: 0.8462 - val_loss: 0.6047 - val_accuracy: 0.7697\n",
            "Epoch 128/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3255 - accuracy: 0.8611 - val_loss: 0.6049 - val_accuracy: 0.7697\n",
            "Epoch 129/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3743 - accuracy: 0.8261 - val_loss: 0.6049 - val_accuracy: 0.7697\n",
            "Epoch 130/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3893 - accuracy: 0.8233 - val_loss: 0.6049 - val_accuracy: 0.7697\n",
            "Epoch 131/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3265 - accuracy: 0.8569 - val_loss: 0.6048 - val_accuracy: 0.7697\n",
            "Epoch 132/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3748 - accuracy: 0.8442 - val_loss: 0.6049 - val_accuracy: 0.7697\n",
            "Epoch 133/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3704 - accuracy: 0.8368 - val_loss: 0.6049 - val_accuracy: 0.7697\n",
            "Epoch 134/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3627 - accuracy: 0.8331 - val_loss: 0.6050 - val_accuracy: 0.7697\n",
            "Epoch 135/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3236 - accuracy: 0.8601 - val_loss: 0.6052 - val_accuracy: 0.7697\n",
            "Epoch 136/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3319 - accuracy: 0.8545 - val_loss: 0.6050 - val_accuracy: 0.7697\n",
            "Epoch 137/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3573 - accuracy: 0.8479 - val_loss: 0.6049 - val_accuracy: 0.7697\n",
            "Epoch 138/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3404 - accuracy: 0.8548 - val_loss: 0.6049 - val_accuracy: 0.7697\n",
            "Epoch 139/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3423 - accuracy: 0.8639 - val_loss: 0.6049 - val_accuracy: 0.7697\n",
            "Epoch 140/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3452 - accuracy: 0.8485 - val_loss: 0.6049 - val_accuracy: 0.7697\n",
            "Epoch 141/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3810 - accuracy: 0.8200 - val_loss: 0.6050 - val_accuracy: 0.7697\n",
            "Epoch 142/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3444 - accuracy: 0.8549 - val_loss: 0.6052 - val_accuracy: 0.7697\n",
            "Epoch 143/200\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 0.3451 - accuracy: 0.8454 - val_loss: 0.6052 - val_accuracy: 0.7697\n",
            "Epoch 144/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3662 - accuracy: 0.8360 - val_loss: 0.6053 - val_accuracy: 0.7697\n",
            "Epoch 145/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3471 - accuracy: 0.8551 - val_loss: 0.6054 - val_accuracy: 0.7697\n",
            "Epoch 146/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3480 - accuracy: 0.8356 - val_loss: 0.6053 - val_accuracy: 0.7697\n",
            "Epoch 147/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3503 - accuracy: 0.8468 - val_loss: 0.6054 - val_accuracy: 0.7697\n",
            "Epoch 148/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3523 - accuracy: 0.8466 - val_loss: 0.6057 - val_accuracy: 0.7697\n",
            "Epoch 149/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3665 - accuracy: 0.8443 - val_loss: 0.6058 - val_accuracy: 0.7697\n",
            "Epoch 150/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3742 - accuracy: 0.8299 - val_loss: 0.6056 - val_accuracy: 0.7697\n",
            "Epoch 151/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3391 - accuracy: 0.8538 - val_loss: 0.6058 - val_accuracy: 0.7697\n",
            "Epoch 152/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3390 - accuracy: 0.8572 - val_loss: 0.6060 - val_accuracy: 0.7697\n",
            "Epoch 153/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3469 - accuracy: 0.8405 - val_loss: 0.6060 - val_accuracy: 0.7697\n",
            "Epoch 154/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3476 - accuracy: 0.8552 - val_loss: 0.6058 - val_accuracy: 0.7697\n",
            "Epoch 155/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3401 - accuracy: 0.8521 - val_loss: 0.6060 - val_accuracy: 0.7697\n",
            "Epoch 156/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3642 - accuracy: 0.8389 - val_loss: 0.6059 - val_accuracy: 0.7697\n",
            "Epoch 157/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3465 - accuracy: 0.8560 - val_loss: 0.6060 - val_accuracy: 0.7697\n",
            "Epoch 158/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3439 - accuracy: 0.8456 - val_loss: 0.6060 - val_accuracy: 0.7697\n",
            "Epoch 159/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3356 - accuracy: 0.8613 - val_loss: 0.6060 - val_accuracy: 0.7697\n",
            "Epoch 160/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3542 - accuracy: 0.8587 - val_loss: 0.6060 - val_accuracy: 0.7697\n",
            "Epoch 161/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3527 - accuracy: 0.8533 - val_loss: 0.6060 - val_accuracy: 0.7697\n",
            "Epoch 162/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3684 - accuracy: 0.8413 - val_loss: 0.6059 - val_accuracy: 0.7697\n",
            "Epoch 163/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3732 - accuracy: 0.8285 - val_loss: 0.6060 - val_accuracy: 0.7697\n",
            "Epoch 164/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3479 - accuracy: 0.8432 - val_loss: 0.6060 - val_accuracy: 0.7697\n",
            "Epoch 165/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3228 - accuracy: 0.8648 - val_loss: 0.6061 - val_accuracy: 0.7697\n",
            "Epoch 166/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3570 - accuracy: 0.8409 - val_loss: 0.6062 - val_accuracy: 0.7697\n",
            "Epoch 167/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3690 - accuracy: 0.8350 - val_loss: 0.6062 - val_accuracy: 0.7697\n",
            "Epoch 168/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3549 - accuracy: 0.8419 - val_loss: 0.6061 - val_accuracy: 0.7697\n",
            "Epoch 169/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3493 - accuracy: 0.8510 - val_loss: 0.6062 - val_accuracy: 0.7697\n",
            "Epoch 170/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3482 - accuracy: 0.8470 - val_loss: 0.6062 - val_accuracy: 0.7697\n",
            "Epoch 171/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3463 - accuracy: 0.8505 - val_loss: 0.6062 - val_accuracy: 0.7697\n",
            "Epoch 172/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3367 - accuracy: 0.8593 - val_loss: 0.6064 - val_accuracy: 0.7697\n",
            "Epoch 173/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3484 - accuracy: 0.8508 - val_loss: 0.6063 - val_accuracy: 0.7697\n",
            "Epoch 174/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3638 - accuracy: 0.8376 - val_loss: 0.6062 - val_accuracy: 0.7697\n",
            "Epoch 175/200\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3764 - accuracy: 0.8295 - val_loss: 0.6064 - val_accuracy: 0.7697\n",
            "Epoch 176/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3617 - accuracy: 0.8503 - val_loss: 0.6066 - val_accuracy: 0.7697\n",
            "Epoch 177/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3451 - accuracy: 0.8379 - val_loss: 0.6065 - val_accuracy: 0.7697\n",
            "Epoch 178/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3696 - accuracy: 0.8403 - val_loss: 0.6064 - val_accuracy: 0.7697\n",
            "Epoch 179/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3608 - accuracy: 0.8418 - val_loss: 0.6066 - val_accuracy: 0.7697\n",
            "Epoch 180/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3293 - accuracy: 0.8615 - val_loss: 0.6067 - val_accuracy: 0.7697\n",
            "Epoch 181/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3576 - accuracy: 0.8518 - val_loss: 0.6066 - val_accuracy: 0.7697\n",
            "Epoch 182/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3357 - accuracy: 0.8536 - val_loss: 0.6067 - val_accuracy: 0.7697\n",
            "Epoch 183/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3821 - accuracy: 0.8420 - val_loss: 0.6068 - val_accuracy: 0.7697\n",
            "Epoch 184/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3551 - accuracy: 0.8375 - val_loss: 0.6066 - val_accuracy: 0.7697\n",
            "Epoch 185/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3431 - accuracy: 0.8562 - val_loss: 0.6067 - val_accuracy: 0.7697\n",
            "Epoch 186/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3410 - accuracy: 0.8545 - val_loss: 0.6066 - val_accuracy: 0.7697\n",
            "Epoch 187/200\n",
            "9/9 [==============================] - 0s 25ms/step - loss: 0.3512 - accuracy: 0.8433 - val_loss: 0.6066 - val_accuracy: 0.7697\n",
            "Epoch 188/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3339 - accuracy: 0.8512 - val_loss: 0.6067 - val_accuracy: 0.7697\n",
            "Epoch 189/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3711 - accuracy: 0.8399 - val_loss: 0.6067 - val_accuracy: 0.7697\n",
            "Epoch 190/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3432 - accuracy: 0.8590 - val_loss: 0.6070 - val_accuracy: 0.7697\n",
            "Epoch 191/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3709 - accuracy: 0.8350 - val_loss: 0.6069 - val_accuracy: 0.7697\n",
            "Epoch 192/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3385 - accuracy: 0.8537 - val_loss: 0.6070 - val_accuracy: 0.7697\n",
            "Epoch 193/200\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.3584 - accuracy: 0.8432 - val_loss: 0.6071 - val_accuracy: 0.7697\n",
            "Epoch 194/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3397 - accuracy: 0.8521 - val_loss: 0.6070 - val_accuracy: 0.7697\n",
            "Epoch 195/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.3575 - accuracy: 0.8404 - val_loss: 0.6071 - val_accuracy: 0.7697\n",
            "Epoch 196/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3537 - accuracy: 0.8474 - val_loss: 0.6073 - val_accuracy: 0.7697\n",
            "Epoch 197/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3573 - accuracy: 0.8499 - val_loss: 0.6072 - val_accuracy: 0.7697\n",
            "Epoch 198/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3652 - accuracy: 0.8438 - val_loss: 0.6073 - val_accuracy: 0.7697\n",
            "Epoch 199/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3452 - accuracy: 0.8482 - val_loss: 0.6072 - val_accuracy: 0.7697\n",
            "Epoch 200/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.3469 - accuracy: 0.8487 - val_loss: 0.6074 - val_accuracy: 0.7697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0xqljN1cp6e",
        "outputId": "a76e1439-f110-492b-b1a1-003cde2710c7"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 0s 2ms/step - loss: 0.6074 - accuracy: 0.7697\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6074440479278564, 0.7696629166603088]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBk_SyQ0gEs4"
      },
      "source": [
        "Look at the prediction for the training and test data. Print the confusion matrix for the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdSFP3e0dO8t"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kc8UU8q31ATw",
        "outputId": "76e01dbc-7b84-463d-d94b-951d13342d5c"
      },
      "source": [
        "# model.predict(X_test).flatten()\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.4388497e-01, 4.3972093e-01, 1.2865044e-01, 4.0278032e-02,\n",
              "       9.7239733e-01, 4.6241185e-01, 7.5176269e-02, 9.9428034e-01,\n",
              "       1.4287920e-01, 3.5167030e-01, 1.2865044e-01, 5.5044424e-02,\n",
              "       2.1992479e-01, 4.6241185e-01, 3.5167030e-01, 7.6714277e-02,\n",
              "       9.7928762e-01, 4.0278032e-02, 1.4287920e-01, 5.5044424e-02,\n",
              "       9.6114045e-03, 1.4287920e-01, 5.5362934e-01, 1.4287920e-01,\n",
              "       7.0019597e-01, 3.5167030e-01, 3.1406957e-01, 1.4287920e-01,\n",
              "       1.4287920e-01, 9.7239733e-01, 3.7345842e-01, 8.6091733e-01,\n",
              "       8.4491438e-01, 1.4287920e-01, 4.6241185e-01, 3.5167030e-01,\n",
              "       1.4287920e-01, 7.6714277e-02, 7.6123524e-01, 5.9713628e-02,\n",
              "       9.2180479e-01, 7.6123524e-01, 8.9462027e-03, 2.5781515e-01,\n",
              "       1.4287920e-01, 7.0627874e-01, 9.2180479e-01, 9.9548608e-01,\n",
              "       9.6284270e-01, 3.7345842e-01, 8.7807357e-01, 5.4369181e-01,\n",
              "       1.4287920e-01, 4.0278032e-02, 1.4287920e-01, 4.4212216e-03,\n",
              "       9.2180479e-01, 8.6091733e-01, 3.3373538e-01, 7.6714277e-02,\n",
              "       9.9516618e-01, 9.4009304e-01, 5.9827298e-01, 4.0278032e-02,\n",
              "       1.4287920e-01, 4.0278032e-02, 3.5167030e-01, 4.3972093e-01,\n",
              "       4.0278032e-02, 3.5167030e-01, 3.5167030e-01, 6.3450098e-01,\n",
              "       1.4287920e-01, 9.8474681e-01, 1.4287920e-01, 3.5167030e-01,\n",
              "       3.5167030e-01, 5.2919561e-01, 1.4287920e-01, 9.8269433e-01,\n",
              "       6.3450098e-01, 5.7510685e-02, 3.3373538e-01, 3.5167030e-01,\n",
              "       4.0795305e-01, 1.4287920e-01, 8.4491438e-01, 5.5362934e-01,\n",
              "       6.3450098e-01, 9.9398041e-01, 5.5362934e-01, 9.8474681e-01,\n",
              "       7.5176269e-02, 1.4287920e-01, 1.9058204e-01, 9.9445087e-01,\n",
              "       3.7345842e-01, 1.4287920e-01, 2.5781515e-01, 5.7510685e-02,\n",
              "       9.2180479e-01, 4.6241185e-01, 8.6995184e-01, 3.5167030e-01,\n",
              "       1.2865044e-01, 9.2180479e-01, 8.1451513e-02, 3.5167030e-01,\n",
              "       1.4287920e-01, 7.6714277e-02, 1.4287920e-01, 1.2865044e-01,\n",
              "       1.4287920e-01, 7.5176269e-02, 5.9827298e-01, 8.4491438e-01,\n",
              "       1.4287920e-01, 1.4287920e-01, 1.2994000e-01, 8.4491438e-01,\n",
              "       1.4287920e-01, 4.0278032e-02, 3.5167030e-01, 1.4287920e-01,\n",
              "       8.4491438e-01, 3.7345842e-01, 1.2865044e-01, 1.4287920e-01,\n",
              "       1.5593772e-01, 1.4287920e-01, 2.5781515e-01, 7.9402477e-01,\n",
              "       3.5167030e-01, 9.8276192e-01, 9.2595554e-04, 6.3450098e-01,\n",
              "       1.2865044e-01, 4.6241185e-01, 1.4287920e-01, 1.2865044e-01,\n",
              "       8.4491438e-01, 9.8792505e-01, 3.7345842e-01, 8.3390903e-01,\n",
              "       9.6114045e-03, 9.9445087e-01, 3.6448470e-01, 5.5877388e-01,\n",
              "       1.4287920e-01, 4.0278032e-02, 8.3390903e-01, 7.6714277e-02,\n",
              "       9.9548608e-01, 1.4287920e-01, 7.5176269e-02, 9.9398041e-01,\n",
              "       2.3660861e-01, 1.4287920e-01, 1.4287920e-01, 1.4287920e-01,\n",
              "       3.5167030e-01, 4.6241185e-01, 4.0278032e-02, 1.4287920e-01,\n",
              "       9.8276192e-01, 1.4287920e-01, 4.0278032e-02, 9.9398041e-01,\n",
              "       1.4287920e-01, 1.2865044e-01, 9.1178060e-02, 1.4287920e-01,\n",
              "       1.4287920e-01, 1.4287920e-01, 1.4287920e-01, 3.7345842e-01,\n",
              "       3.7345842e-01, 9.8269433e-01], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAVgCFGQ0Ops",
        "outputId": "6e1cd067-1f0f-4780-d5d8-f8b83ead8782"
      },
      "source": [
        "y_pred = pd.Series((model.predict(X_test) > 0.5).flatten().astype(\"int32\"))\n",
        "y_pred"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0\n",
              "1      0\n",
              "2      0\n",
              "3      0\n",
              "4      1\n",
              "      ..\n",
              "173    0\n",
              "174    0\n",
              "175    0\n",
              "176    0\n",
              "177    1\n",
              "Length: 178, dtype: int32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_UZ_QIsdjz8"
      },
      "source": [
        "cm = confusion_matrix(y_true=y_test, y_pred=y_pred)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfKxxtoygEs4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "667985e0-8901-4179-ba8c-bb425c813354"
      },
      "source": [
        "plot_confusion_matrix(cm, classes=[0,1])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[100  18]\n",
            " [ 23  37]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgkF5e2UgEs6"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P9SzACofNf6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECkGP4wUS9m5"
      },
      "source": [
        "#Lecture Notes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNvRbkrVS9ZR",
        "outputId": "f13dc7d2-e8bc-4254-8282-6fd1d72bd87c"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "input_dim = 784 #28x28\n",
        "output_dim = num_classes = 10 #number of classes 0-9\n",
        "batch_size = 128\n",
        "num_epochs = 20\n",
        "\n",
        "X_train = X_train.reshape(60000,784).astype('float32')\n",
        "X_test = X_test.reshape(10000, input_dim).astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test= to_categorical(y_test, num_classes)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "GnlGbn6bT0go"
      },
      "source": [
        "#@title Hyperparameters\n",
        "\n",
        "learning_rate = 0.1 #@param {type: 'number'}\n",
        "optimizer = 'adam' #@param {type:'string'}"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jMR_xw8T0XX",
        "outputId": "ac6b542e-4c21-4ca7-9156-97907498ac3c"
      },
      "source": [
        "print(learning_rate)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SSB8ndIBVD9a",
        "outputId": "ba44585e-0b13-4021-8323-6e0689051577"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eK05tVxKWFeV",
        "outputId": "0362c457-14dd-43d1-8a31-77914df0ee17"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 16320183497064767656, name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 14638920512\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 14504208164543365665\n",
              " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOeqCZZrWT4O",
        "outputId": "6afdec9e-60d7-41b3-828e-cf33a9166e77"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(1028, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(1028, activation='relu'))\n",
        "model.add(Dense(output_dim, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_21 (Dense)             (None, 1028)              806980    \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 1028)              1057812   \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 10)                10290     \n",
            "=================================================================\n",
            "Total params: 1,875,082\n",
            "Trainable params: 1,875,082\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3guPJ0wWj5i"
      },
      "source": [
        "sgd = SGD(lr=0.5)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rC5ThILoWsdJ"
      },
      "source": [
        "model.compile(optimizer=sgd, loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBHNuMujXD2P",
        "outputId": "6b56f523-4ef8-49ed-a9b6-b9f9cad8af7b"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=batch_size,\n",
        "          validation_data = (X_test, y_test),\n",
        "          epochs=num_epochs, verbose=1)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4886 - accuracy: 0.8411 - val_loss: 0.1121 - val_accuracy: 0.9654\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0924 - accuracy: 0.9722 - val_loss: 0.0835 - val_accuracy: 0.9740\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0540 - accuracy: 0.9833 - val_loss: 0.0723 - val_accuracy: 0.9774\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0364 - accuracy: 0.9891 - val_loss: 0.0650 - val_accuracy: 0.9803\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0235 - accuracy: 0.9928 - val_loss: 0.0641 - val_accuracy: 0.9787\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0178 - accuracy: 0.9954 - val_loss: 0.0670 - val_accuracy: 0.9797\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0110 - accuracy: 0.9975 - val_loss: 0.0566 - val_accuracy: 0.9826\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0064 - accuracy: 0.9989 - val_loss: 0.0642 - val_accuracy: 0.9818\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0034 - accuracy: 0.9996 - val_loss: 0.0541 - val_accuracy: 0.9850\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.0559 - val_accuracy: 0.9844\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0561 - val_accuracy: 0.9849\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 8.8984e-04 - accuracy: 1.0000 - val_loss: 0.0581 - val_accuracy: 0.9854\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 9.0363e-04 - accuracy: 1.0000 - val_loss: 0.0586 - val_accuracy: 0.9853\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 6.3683e-04 - accuracy: 1.0000 - val_loss: 0.0591 - val_accuracy: 0.9853\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 5.1182e-04 - accuracy: 1.0000 - val_loss: 0.0598 - val_accuracy: 0.9855\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 4.6598e-04 - accuracy: 1.0000 - val_loss: 0.0609 - val_accuracy: 0.9853\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 4.0491e-04 - accuracy: 1.0000 - val_loss: 0.0616 - val_accuracy: 0.9853\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 3.7438e-04 - accuracy: 1.0000 - val_loss: 0.0617 - val_accuracy: 0.9854\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 3.4737e-04 - accuracy: 1.0000 - val_loss: 0.0620 - val_accuracy: 0.9852\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 3.0718e-04 - accuracy: 1.0000 - val_loss: 0.0624 - val_accuracy: 0.9851\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "D7_8psYDXQg1",
        "outputId": "9382396d-2e11-4203-9548-3c4e90374915"
      },
      "source": [
        "df = pd.DataFrame(history.history)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.257476</td>\n",
              "      <td>0.918900</td>\n",
              "      <td>0.112066</td>\n",
              "      <td>0.9654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.087674</td>\n",
              "      <td>0.973267</td>\n",
              "      <td>0.083464</td>\n",
              "      <td>0.9740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.054704</td>\n",
              "      <td>0.982617</td>\n",
              "      <td>0.072288</td>\n",
              "      <td>0.9774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.037319</td>\n",
              "      <td>0.988883</td>\n",
              "      <td>0.064952</td>\n",
              "      <td>0.9803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.025745</td>\n",
              "      <td>0.991867</td>\n",
              "      <td>0.064067</td>\n",
              "      <td>0.9787</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       loss  accuracy  val_loss  val_accuracy\n",
              "0  0.257476  0.918900  0.112066        0.9654\n",
              "1  0.087674  0.973267  0.083464        0.9740\n",
              "2  0.054704  0.982617  0.072288        0.9774\n",
              "3  0.037319  0.988883  0.064952        0.9803\n",
              "4  0.025745  0.991867  0.064067        0.9787"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "6UbrDWF1YLgp",
        "outputId": "3ff03f8a-6ddd-4751-a049-b9066274be9b"
      },
      "source": [
        "df[['accuracy', 'val_accuracy']].plot(figsize=(14,7))\n",
        "\n",
        "#elbow of accuracy shows where it peaks out"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6bd5beec88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "401lyrstYOQZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}