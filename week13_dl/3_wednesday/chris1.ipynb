{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "Day 78 Lecture 1 Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqtxiRasgEsb"
      },
      "source": [
        "## Gradient Descent and Backpropagation\n",
        "\n",
        "In this assignment, we will learn about gradient descent and backpropagation algorithms. We will create a neural network and tweak some of the parameters in SGD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOd2GWD5gEsd"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "661suxNdgEsg"
      },
      "source": [
        "Let's use the data we processed in the titanic assigment and load it below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvmZdYdEgEsg"
      },
      "source": [
        "titanic = pd.read_csv('https://tf-assets-prod.s3.amazonaws.com/tf-curric/data-science/titanic_processed.csv')"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSpXsYXpgEsi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "57808168-20b8-477c-e66a-a5f764d5fe4e"
      },
      "source": [
        "titanic.head()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Pclass_1</th>\n",
              "      <th>Pclass_2</th>\n",
              "      <th>Pclass_3</th>\n",
              "      <th>Sex_female</th>\n",
              "      <th>Sex_male</th>\n",
              "      <th>Embarked_C</th>\n",
              "      <th>Embarked_Q</th>\n",
              "      <th>Embarked_S</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Survived  SibSp  Parch  ...  Embarked_C  Embarked_Q  Embarked_S\n",
              "0         0      1      0  ...           0           0           1\n",
              "1         1      1      0  ...           1           0           0\n",
              "2         1      0      0  ...           0           0           1\n",
              "3         1      1      0  ...           0           0           1\n",
              "4         0      0      0  ...           0           0           1\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc_uypIkgEsk"
      },
      "source": [
        "Split the data into train and test with 20% of data in test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RP9pCPlNgEsl"
      },
      "source": [
        "# Answer below\n",
        "y = titanic.Survived\n",
        "X = titanic.drop('Survived',axis=1)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QBmGKEpgEsm"
      },
      "source": [
        "Create a model with 5 layers - The first layer should be of unit size 128 and input shape with the shape of the input and the last layer should be of size 1. The hidden layers should be of size 64, 32, and 32, respectively. Use a sigmoid activation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVefZBONgEsn"
      },
      "source": [
        "# Answer below\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IADHujAgEso"
      },
      "source": [
        "Initialize an SGD optimizer with learning rate 0.05. Note that in older versions of keras, we use `lr` instead of `learning_rate`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhM1nLP1gEsp"
      },
      "source": [
        "# Answer below:\n",
        "sgd = SGD(lr=0.05)\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6cVa2JHgEsq"
      },
      "source": [
        "compile and fit the model using the optimizer you initialized above. Use a batch size of 100 and 50 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AbyqTAigEsr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3653b03-0fb9-4611-993f-7feef46d4726"
      },
      "source": [
        "# Answer below:\n",
        "model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=100, epochs=50, verbose=1)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "8/8 [==============================] - 1s 30ms/step - loss: 0.6648 - accuracy: 0.6394 - val_loss: 0.6724 - val_accuracy: 0.5225\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6316 - accuracy: 0.6369 - val_loss: 0.6652 - val_accuracy: 0.5225\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6120 - accuracy: 0.6316 - val_loss: 0.6558 - val_accuracy: 0.5225\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.5812 - accuracy: 0.6581 - val_loss: 0.6410 - val_accuracy: 0.5225\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5724 - accuracy: 0.6425 - val_loss: 0.6330 - val_accuracy: 0.5225\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5531 - accuracy: 0.6450 - val_loss: 0.6298 - val_accuracy: 0.5281\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5183 - accuracy: 0.6975 - val_loss: 0.6066 - val_accuracy: 0.7697\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5228 - accuracy: 0.8078 - val_loss: 0.5975 - val_accuracy: 0.7697\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5061 - accuracy: 0.8229 - val_loss: 0.5890 - val_accuracy: 0.7809\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4984 - accuracy: 0.8220 - val_loss: 0.5943 - val_accuracy: 0.7809\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5000 - accuracy: 0.8133 - val_loss: 0.6136 - val_accuracy: 0.7584\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5023 - accuracy: 0.8048 - val_loss: 0.6048 - val_accuracy: 0.7809\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4818 - accuracy: 0.8106 - val_loss: 0.5945 - val_accuracy: 0.7809\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.4883 - accuracy: 0.8035 - val_loss: 0.5743 - val_accuracy: 0.7584\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4848 - accuracy: 0.8139 - val_loss: 0.5662 - val_accuracy: 0.7528\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4442 - accuracy: 0.8315 - val_loss: 0.5775 - val_accuracy: 0.7528\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4772 - accuracy: 0.8088 - val_loss: 0.5845 - val_accuracy: 0.7809\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4623 - accuracy: 0.8153 - val_loss: 0.5605 - val_accuracy: 0.7528\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4676 - accuracy: 0.8148 - val_loss: 0.5335 - val_accuracy: 0.7472\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4684 - accuracy: 0.8016 - val_loss: 0.5722 - val_accuracy: 0.7528\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4551 - accuracy: 0.8289 - val_loss: 0.5465 - val_accuracy: 0.7528\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4438 - accuracy: 0.8182 - val_loss: 0.5493 - val_accuracy: 0.7528\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4407 - accuracy: 0.8331 - val_loss: 0.5890 - val_accuracy: 0.7809\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4484 - accuracy: 0.8178 - val_loss: 0.5885 - val_accuracy: 0.7809\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5038 - accuracy: 0.7818 - val_loss: 0.5234 - val_accuracy: 0.7584\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4631 - accuracy: 0.8092 - val_loss: 0.5230 - val_accuracy: 0.7472\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4719 - accuracy: 0.7874 - val_loss: 0.5265 - val_accuracy: 0.7584\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4196 - accuracy: 0.8287 - val_loss: 0.5152 - val_accuracy: 0.7472\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4281 - accuracy: 0.8218 - val_loss: 0.5270 - val_accuracy: 0.7584\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4127 - accuracy: 0.8428 - val_loss: 0.5290 - val_accuracy: 0.7528\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4268 - accuracy: 0.8351 - val_loss: 0.5761 - val_accuracy: 0.7528\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4624 - accuracy: 0.7994 - val_loss: 0.5198 - val_accuracy: 0.7472\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4272 - accuracy: 0.8293 - val_loss: 0.5488 - val_accuracy: 0.7528\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4232 - accuracy: 0.8369 - val_loss: 0.5006 - val_accuracy: 0.7528\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4490 - accuracy: 0.7886 - val_loss: 0.5059 - val_accuracy: 0.7472\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4236 - accuracy: 0.8180 - val_loss: 0.4962 - val_accuracy: 0.7584\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4452 - accuracy: 0.8055 - val_loss: 0.6007 - val_accuracy: 0.7584\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4490 - accuracy: 0.8084 - val_loss: 0.4988 - val_accuracy: 0.7528\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4284 - accuracy: 0.8066 - val_loss: 0.5448 - val_accuracy: 0.7528\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4220 - accuracy: 0.8302 - val_loss: 0.5645 - val_accuracy: 0.7697\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4254 - accuracy: 0.8321 - val_loss: 0.5095 - val_accuracy: 0.7416\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4355 - accuracy: 0.8104 - val_loss: 0.5995 - val_accuracy: 0.7697\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4526 - accuracy: 0.7910 - val_loss: 0.5292 - val_accuracy: 0.7697\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4185 - accuracy: 0.8199 - val_loss: 0.5147 - val_accuracy: 0.7472\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4566 - accuracy: 0.8008 - val_loss: 0.4767 - val_accuracy: 0.7753\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4196 - accuracy: 0.8267 - val_loss: 0.5183 - val_accuracy: 0.7416\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4062 - accuracy: 0.8316 - val_loss: 0.5885 - val_accuracy: 0.7584\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4147 - accuracy: 0.8296 - val_loss: 0.6010 - val_accuracy: 0.7584\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4445 - accuracy: 0.8094 - val_loss: 0.5120 - val_accuracy: 0.7416\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4206 - accuracy: 0.8181 - val_loss: 0.4810 - val_accuracy: 0.7528\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRoBkaAkgEss"
      },
      "source": [
        "Now use the same batch size, but fit your model using 500 epochs. Is there a difference in performance?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp9JQJDTgEst",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8297096-4d25-4733-9839-72b15ec7be12"
      },
      "source": [
        "# Answer below:\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history1 = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=100, epochs=500, verbose=1)\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "8/8 [==============================] - 1s 32ms/step - loss: 0.6746 - accuracy: 0.6511 - val_loss: 0.6777 - val_accuracy: 0.5225\n",
            "Epoch 2/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6492 - accuracy: 0.6329 - val_loss: 0.6719 - val_accuracy: 0.5225\n",
            "Epoch 3/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.6305 - accuracy: 0.6368 - val_loss: 0.6681 - val_accuracy: 0.5225\n",
            "Epoch 4/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.6052 - accuracy: 0.6574 - val_loss: 0.6649 - val_accuracy: 0.5225\n",
            "Epoch 5/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5972 - accuracy: 0.6443 - val_loss: 0.6573 - val_accuracy: 0.5225\n",
            "Epoch 6/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5821 - accuracy: 0.6352 - val_loss: 0.6486 - val_accuracy: 0.5225\n",
            "Epoch 7/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5595 - accuracy: 0.6598 - val_loss: 0.6298 - val_accuracy: 0.6067\n",
            "Epoch 8/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.5488 - accuracy: 0.7167 - val_loss: 0.6098 - val_accuracy: 0.7247\n",
            "Epoch 9/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5340 - accuracy: 0.8016 - val_loss: 0.6020 - val_accuracy: 0.7360\n",
            "Epoch 10/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5205 - accuracy: 0.7912 - val_loss: 0.6046 - val_accuracy: 0.7247\n",
            "Epoch 11/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.5222 - accuracy: 0.7855 - val_loss: 0.6012 - val_accuracy: 0.7247\n",
            "Epoch 12/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4968 - accuracy: 0.8018 - val_loss: 0.5789 - val_accuracy: 0.7697\n",
            "Epoch 13/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4694 - accuracy: 0.8049 - val_loss: 0.5655 - val_accuracy: 0.7640\n",
            "Epoch 14/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4785 - accuracy: 0.8132 - val_loss: 0.5500 - val_accuracy: 0.7416\n",
            "Epoch 15/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4600 - accuracy: 0.8230 - val_loss: 0.5683 - val_accuracy: 0.7416\n",
            "Epoch 16/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4793 - accuracy: 0.8105 - val_loss: 0.5617 - val_accuracy: 0.7584\n",
            "Epoch 17/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4588 - accuracy: 0.8007 - val_loss: 0.5763 - val_accuracy: 0.7416\n",
            "Epoch 18/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4389 - accuracy: 0.8211 - val_loss: 0.5387 - val_accuracy: 0.7472\n",
            "Epoch 19/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4231 - accuracy: 0.8288 - val_loss: 0.5484 - val_accuracy: 0.7528\n",
            "Epoch 20/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4416 - accuracy: 0.8269 - val_loss: 0.5598 - val_accuracy: 0.7528\n",
            "Epoch 21/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.4320 - accuracy: 0.8289 - val_loss: 0.5768 - val_accuracy: 0.7528\n",
            "Epoch 22/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4548 - accuracy: 0.8249 - val_loss: 0.5373 - val_accuracy: 0.7528\n",
            "Epoch 23/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4322 - accuracy: 0.8318 - val_loss: 0.5294 - val_accuracy: 0.7472\n",
            "Epoch 24/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4397 - accuracy: 0.8063 - val_loss: 0.5458 - val_accuracy: 0.7528\n",
            "Epoch 25/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4374 - accuracy: 0.8167 - val_loss: 0.5459 - val_accuracy: 0.7528\n",
            "Epoch 26/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4309 - accuracy: 0.8223 - val_loss: 0.5333 - val_accuracy: 0.7640\n",
            "Epoch 27/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4305 - accuracy: 0.8239 - val_loss: 0.5475 - val_accuracy: 0.7528\n",
            "Epoch 28/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4116 - accuracy: 0.8442 - val_loss: 0.5445 - val_accuracy: 0.7528\n",
            "Epoch 29/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4447 - accuracy: 0.8181 - val_loss: 0.5241 - val_accuracy: 0.7697\n",
            "Epoch 30/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4128 - accuracy: 0.8276 - val_loss: 0.5278 - val_accuracy: 0.7640\n",
            "Epoch 31/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4397 - accuracy: 0.8149 - val_loss: 0.5242 - val_accuracy: 0.7584\n",
            "Epoch 32/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4307 - accuracy: 0.8293 - val_loss: 0.5059 - val_accuracy: 0.7528\n",
            "Epoch 33/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4440 - accuracy: 0.7941 - val_loss: 0.5271 - val_accuracy: 0.7640\n",
            "Epoch 34/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4163 - accuracy: 0.8310 - val_loss: 0.5058 - val_accuracy: 0.7528\n",
            "Epoch 35/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4276 - accuracy: 0.8142 - val_loss: 0.5105 - val_accuracy: 0.7528\n",
            "Epoch 36/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4049 - accuracy: 0.8244 - val_loss: 0.5282 - val_accuracy: 0.7640\n",
            "Epoch 37/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4301 - accuracy: 0.8336 - val_loss: 0.5618 - val_accuracy: 0.7809\n",
            "Epoch 38/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4219 - accuracy: 0.8298 - val_loss: 0.4952 - val_accuracy: 0.7528\n",
            "Epoch 39/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4152 - accuracy: 0.8137 - val_loss: 0.5224 - val_accuracy: 0.7640\n",
            "Epoch 40/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4031 - accuracy: 0.8412 - val_loss: 0.5345 - val_accuracy: 0.7640\n",
            "Epoch 41/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4151 - accuracy: 0.8270 - val_loss: 0.5114 - val_accuracy: 0.7472\n",
            "Epoch 42/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4279 - accuracy: 0.8134 - val_loss: 0.4981 - val_accuracy: 0.7640\n",
            "Epoch 43/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4452 - accuracy: 0.7927 - val_loss: 0.5272 - val_accuracy: 0.7528\n",
            "Epoch 44/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3817 - accuracy: 0.8385 - val_loss: 0.5072 - val_accuracy: 0.7528\n",
            "Epoch 45/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4227 - accuracy: 0.8185 - val_loss: 0.5054 - val_accuracy: 0.7528\n",
            "Epoch 46/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4041 - accuracy: 0.8335 - val_loss: 0.5204 - val_accuracy: 0.7528\n",
            "Epoch 47/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4114 - accuracy: 0.8306 - val_loss: 0.5155 - val_accuracy: 0.7528\n",
            "Epoch 48/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4194 - accuracy: 0.8210 - val_loss: 0.5603 - val_accuracy: 0.7809\n",
            "Epoch 49/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4093 - accuracy: 0.8225 - val_loss: 0.4941 - val_accuracy: 0.7528\n",
            "Epoch 50/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4214 - accuracy: 0.8147 - val_loss: 0.5283 - val_accuracy: 0.7528\n",
            "Epoch 51/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4136 - accuracy: 0.8320 - val_loss: 0.4952 - val_accuracy: 0.7528\n",
            "Epoch 52/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4183 - accuracy: 0.8201 - val_loss: 0.4869 - val_accuracy: 0.7528\n",
            "Epoch 53/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4116 - accuracy: 0.8173 - val_loss: 0.5278 - val_accuracy: 0.7809\n",
            "Epoch 54/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3993 - accuracy: 0.8317 - val_loss: 0.4824 - val_accuracy: 0.7528\n",
            "Epoch 55/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4270 - accuracy: 0.8077 - val_loss: 0.5710 - val_accuracy: 0.7809\n",
            "Epoch 56/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4028 - accuracy: 0.8282 - val_loss: 0.4927 - val_accuracy: 0.7697\n",
            "Epoch 57/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3959 - accuracy: 0.8398 - val_loss: 0.4860 - val_accuracy: 0.7640\n",
            "Epoch 58/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4119 - accuracy: 0.8342 - val_loss: 0.5036 - val_accuracy: 0.7528\n",
            "Epoch 59/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4057 - accuracy: 0.8319 - val_loss: 0.5136 - val_accuracy: 0.7303\n",
            "Epoch 60/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4578 - accuracy: 0.7715 - val_loss: 0.5474 - val_accuracy: 0.7809\n",
            "Epoch 61/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.4228 - accuracy: 0.8247 - val_loss: 0.4870 - val_accuracy: 0.7584\n",
            "Epoch 62/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4158 - accuracy: 0.8234 - val_loss: 0.4945 - val_accuracy: 0.7584\n",
            "Epoch 63/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8260 - val_loss: 0.5509 - val_accuracy: 0.7809\n",
            "Epoch 64/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4312 - accuracy: 0.8156 - val_loss: 0.5021 - val_accuracy: 0.7416\n",
            "Epoch 65/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4101 - accuracy: 0.8302 - val_loss: 0.5362 - val_accuracy: 0.7809\n",
            "Epoch 66/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3797 - accuracy: 0.8503 - val_loss: 0.4935 - val_accuracy: 0.7584\n",
            "Epoch 67/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4181 - accuracy: 0.8224 - val_loss: 0.5928 - val_accuracy: 0.7528\n",
            "Epoch 68/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3847 - accuracy: 0.8355 - val_loss: 0.4901 - val_accuracy: 0.7584\n",
            "Epoch 69/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3921 - accuracy: 0.8420 - val_loss: 0.4838 - val_accuracy: 0.7584\n",
            "Epoch 70/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4123 - accuracy: 0.8250 - val_loss: 0.4819 - val_accuracy: 0.7640\n",
            "Epoch 71/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4008 - accuracy: 0.8354 - val_loss: 0.5173 - val_accuracy: 0.7809\n",
            "Epoch 72/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3968 - accuracy: 0.8307 - val_loss: 0.5202 - val_accuracy: 0.7809\n",
            "Epoch 73/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3852 - accuracy: 0.8406 - val_loss: 0.4871 - val_accuracy: 0.7584\n",
            "Epoch 74/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4116 - accuracy: 0.8181 - val_loss: 0.4882 - val_accuracy: 0.7640\n",
            "Epoch 75/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4275 - accuracy: 0.8218 - val_loss: 0.5332 - val_accuracy: 0.7528\n",
            "Epoch 76/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4359 - accuracy: 0.8098 - val_loss: 0.4992 - val_accuracy: 0.7528\n",
            "Epoch 77/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3851 - accuracy: 0.8377 - val_loss: 0.5234 - val_accuracy: 0.7528\n",
            "Epoch 78/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3789 - accuracy: 0.8332 - val_loss: 0.4849 - val_accuracy: 0.7472\n",
            "Epoch 79/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4185 - accuracy: 0.8174 - val_loss: 0.4999 - val_accuracy: 0.7528\n",
            "Epoch 80/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4018 - accuracy: 0.8187 - val_loss: 0.5324 - val_accuracy: 0.7809\n",
            "Epoch 81/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3890 - accuracy: 0.8332 - val_loss: 0.4747 - val_accuracy: 0.7697\n",
            "Epoch 82/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4010 - accuracy: 0.8347 - val_loss: 0.5019 - val_accuracy: 0.7528\n",
            "Epoch 83/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4420 - accuracy: 0.8095 - val_loss: 0.5209 - val_accuracy: 0.7528\n",
            "Epoch 84/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3850 - accuracy: 0.8339 - val_loss: 0.5095 - val_accuracy: 0.7528\n",
            "Epoch 85/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3960 - accuracy: 0.8282 - val_loss: 0.4918 - val_accuracy: 0.7584\n",
            "Epoch 86/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3961 - accuracy: 0.8279 - val_loss: 0.4990 - val_accuracy: 0.7640\n",
            "Epoch 87/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4011 - accuracy: 0.8282 - val_loss: 0.5818 - val_accuracy: 0.7697\n",
            "Epoch 88/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3999 - accuracy: 0.8309 - val_loss: 0.5177 - val_accuracy: 0.7809\n",
            "Epoch 89/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3876 - accuracy: 0.8273 - val_loss: 0.5258 - val_accuracy: 0.7809\n",
            "Epoch 90/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4021 - accuracy: 0.8261 - val_loss: 0.4984 - val_accuracy: 0.7584\n",
            "Epoch 91/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4076 - accuracy: 0.8274 - val_loss: 0.4995 - val_accuracy: 0.7584\n",
            "Epoch 92/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8267 - val_loss: 0.5344 - val_accuracy: 0.7528\n",
            "Epoch 93/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4112 - accuracy: 0.8196 - val_loss: 0.5014 - val_accuracy: 0.7584\n",
            "Epoch 94/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4139 - accuracy: 0.8132 - val_loss: 0.6159 - val_accuracy: 0.7753\n",
            "Epoch 95/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3873 - accuracy: 0.8374 - val_loss: 0.5833 - val_accuracy: 0.7809\n",
            "Epoch 96/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4189 - accuracy: 0.8144 - val_loss: 0.5617 - val_accuracy: 0.7809\n",
            "Epoch 97/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3999 - accuracy: 0.8295 - val_loss: 0.5101 - val_accuracy: 0.7472\n",
            "Epoch 98/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4080 - accuracy: 0.8206 - val_loss: 0.4825 - val_accuracy: 0.7640\n",
            "Epoch 99/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4171 - accuracy: 0.8105 - val_loss: 0.4837 - val_accuracy: 0.7640\n",
            "Epoch 100/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4083 - accuracy: 0.8249 - val_loss: 0.5024 - val_accuracy: 0.7528\n",
            "Epoch 101/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3927 - accuracy: 0.8282 - val_loss: 0.4790 - val_accuracy: 0.7640\n",
            "Epoch 102/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3958 - accuracy: 0.8329 - val_loss: 0.5935 - val_accuracy: 0.7472\n",
            "Epoch 103/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4245 - accuracy: 0.8094 - val_loss: 0.5137 - val_accuracy: 0.7809\n",
            "Epoch 104/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4118 - accuracy: 0.8183 - val_loss: 0.5165 - val_accuracy: 0.7809\n",
            "Epoch 105/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4020 - accuracy: 0.8196 - val_loss: 0.4716 - val_accuracy: 0.7753\n",
            "Epoch 106/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4100 - accuracy: 0.8175 - val_loss: 0.5581 - val_accuracy: 0.7472\n",
            "Epoch 107/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3880 - accuracy: 0.8277 - val_loss: 0.4964 - val_accuracy: 0.7697\n",
            "Epoch 108/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4229 - accuracy: 0.8083 - val_loss: 0.5280 - val_accuracy: 0.7809\n",
            "Epoch 109/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.3977 - accuracy: 0.8303 - val_loss: 0.4876 - val_accuracy: 0.7584\n",
            "Epoch 110/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4073 - accuracy: 0.8199 - val_loss: 0.4903 - val_accuracy: 0.7584\n",
            "Epoch 111/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4066 - accuracy: 0.8265 - val_loss: 0.5314 - val_accuracy: 0.7809\n",
            "Epoch 112/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4076 - accuracy: 0.8202 - val_loss: 0.4748 - val_accuracy: 0.7528\n",
            "Epoch 113/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4130 - accuracy: 0.8263 - val_loss: 0.4832 - val_accuracy: 0.7584\n",
            "Epoch 114/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3889 - accuracy: 0.8345 - val_loss: 0.4943 - val_accuracy: 0.7528\n",
            "Epoch 115/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3863 - accuracy: 0.8344 - val_loss: 0.5489 - val_accuracy: 0.7809\n",
            "Epoch 116/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4020 - accuracy: 0.8231 - val_loss: 0.6120 - val_accuracy: 0.7753\n",
            "Epoch 117/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4223 - accuracy: 0.8113 - val_loss: 0.4780 - val_accuracy: 0.7640\n",
            "Epoch 118/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3978 - accuracy: 0.8226 - val_loss: 0.4757 - val_accuracy: 0.7697\n",
            "Epoch 119/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4149 - accuracy: 0.8268 - val_loss: 0.4835 - val_accuracy: 0.7528\n",
            "Epoch 120/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3830 - accuracy: 0.8180 - val_loss: 0.4971 - val_accuracy: 0.7528\n",
            "Epoch 121/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4008 - accuracy: 0.8161 - val_loss: 0.4811 - val_accuracy: 0.7528\n",
            "Epoch 122/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3802 - accuracy: 0.8216 - val_loss: 0.4937 - val_accuracy: 0.7584\n",
            "Epoch 123/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4125 - accuracy: 0.8067 - val_loss: 0.5418 - val_accuracy: 0.7809\n",
            "Epoch 124/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3937 - accuracy: 0.8261 - val_loss: 0.4991 - val_accuracy: 0.7528\n",
            "Epoch 125/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3699 - accuracy: 0.8471 - val_loss: 0.4804 - val_accuracy: 0.7753\n",
            "Epoch 126/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4167 - accuracy: 0.8244 - val_loss: 0.4830 - val_accuracy: 0.7584\n",
            "Epoch 127/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3730 - accuracy: 0.8377 - val_loss: 0.5634 - val_accuracy: 0.7809\n",
            "Epoch 128/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4302 - accuracy: 0.8052 - val_loss: 0.4933 - val_accuracy: 0.7640\n",
            "Epoch 129/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4133 - accuracy: 0.8096 - val_loss: 0.5219 - val_accuracy: 0.7809\n",
            "Epoch 130/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4004 - accuracy: 0.8284 - val_loss: 0.4885 - val_accuracy: 0.7528\n",
            "Epoch 131/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3808 - accuracy: 0.8293 - val_loss: 0.4807 - val_accuracy: 0.7697\n",
            "Epoch 132/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.4048 - accuracy: 0.8268 - val_loss: 0.5263 - val_accuracy: 0.7528\n",
            "Epoch 133/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3924 - accuracy: 0.8223 - val_loss: 0.5484 - val_accuracy: 0.7809\n",
            "Epoch 134/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3879 - accuracy: 0.8318 - val_loss: 0.5226 - val_accuracy: 0.7528\n",
            "Epoch 135/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3831 - accuracy: 0.8377 - val_loss: 0.5226 - val_accuracy: 0.7809\n",
            "Epoch 136/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4035 - accuracy: 0.8052 - val_loss: 0.5127 - val_accuracy: 0.7528\n",
            "Epoch 137/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3932 - accuracy: 0.8315 - val_loss: 0.5005 - val_accuracy: 0.7697\n",
            "Epoch 138/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3895 - accuracy: 0.8209 - val_loss: 0.5160 - val_accuracy: 0.7528\n",
            "Epoch 139/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4038 - accuracy: 0.8109 - val_loss: 0.4953 - val_accuracy: 0.7584\n",
            "Epoch 140/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3911 - accuracy: 0.8262 - val_loss: 0.4976 - val_accuracy: 0.7584\n",
            "Epoch 141/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3923 - accuracy: 0.8264 - val_loss: 0.5217 - val_accuracy: 0.7921\n",
            "Epoch 142/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3912 - accuracy: 0.8275 - val_loss: 0.4830 - val_accuracy: 0.7584\n",
            "Epoch 143/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4096 - accuracy: 0.8107 - val_loss: 0.5323 - val_accuracy: 0.7809\n",
            "Epoch 144/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3890 - accuracy: 0.8283 - val_loss: 0.5320 - val_accuracy: 0.7528\n",
            "Epoch 145/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4158 - accuracy: 0.8202 - val_loss: 0.6718 - val_accuracy: 0.7191\n",
            "Epoch 146/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4206 - accuracy: 0.8146 - val_loss: 0.4840 - val_accuracy: 0.7528\n",
            "Epoch 147/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3698 - accuracy: 0.8340 - val_loss: 0.5043 - val_accuracy: 0.7528\n",
            "Epoch 148/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4225 - accuracy: 0.8029 - val_loss: 0.4776 - val_accuracy: 0.7640\n",
            "Epoch 149/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3790 - accuracy: 0.8352 - val_loss: 0.4755 - val_accuracy: 0.7809\n",
            "Epoch 150/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3870 - accuracy: 0.8256 - val_loss: 0.5266 - val_accuracy: 0.7809\n",
            "Epoch 151/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3907 - accuracy: 0.8277 - val_loss: 0.4796 - val_accuracy: 0.7584\n",
            "Epoch 152/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4080 - accuracy: 0.8221 - val_loss: 0.5030 - val_accuracy: 0.7640\n",
            "Epoch 153/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3878 - accuracy: 0.8304 - val_loss: 0.4962 - val_accuracy: 0.7584\n",
            "Epoch 154/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3672 - accuracy: 0.8460 - val_loss: 0.4862 - val_accuracy: 0.7697\n",
            "Epoch 155/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3758 - accuracy: 0.8358 - val_loss: 0.4936 - val_accuracy: 0.7640\n",
            "Epoch 156/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3738 - accuracy: 0.8320 - val_loss: 0.4881 - val_accuracy: 0.7697\n",
            "Epoch 157/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.3813 - accuracy: 0.8425 - val_loss: 0.5827 - val_accuracy: 0.7809\n",
            "Epoch 158/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4148 - accuracy: 0.8205 - val_loss: 0.4775 - val_accuracy: 0.7697\n",
            "Epoch 159/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4073 - accuracy: 0.8208 - val_loss: 0.5174 - val_accuracy: 0.7640\n",
            "Epoch 160/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3802 - accuracy: 0.8381 - val_loss: 0.5474 - val_accuracy: 0.7809\n",
            "Epoch 161/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3773 - accuracy: 0.8288 - val_loss: 0.5516 - val_accuracy: 0.7809\n",
            "Epoch 162/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3891 - accuracy: 0.8426 - val_loss: 0.4696 - val_accuracy: 0.7753\n",
            "Epoch 163/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3955 - accuracy: 0.8262 - val_loss: 0.5346 - val_accuracy: 0.7809\n",
            "Epoch 164/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3955 - accuracy: 0.8289 - val_loss: 0.4947 - val_accuracy: 0.7640\n",
            "Epoch 165/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.4131 - accuracy: 0.8267 - val_loss: 0.4995 - val_accuracy: 0.7584\n",
            "Epoch 166/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3633 - accuracy: 0.8309 - val_loss: 0.4969 - val_accuracy: 0.7809\n",
            "Epoch 167/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4039 - accuracy: 0.8153 - val_loss: 0.4996 - val_accuracy: 0.7528\n",
            "Epoch 168/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4050 - accuracy: 0.8245 - val_loss: 0.5037 - val_accuracy: 0.7528\n",
            "Epoch 169/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3909 - accuracy: 0.8294 - val_loss: 0.5388 - val_accuracy: 0.7809\n",
            "Epoch 170/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4043 - accuracy: 0.8245 - val_loss: 0.4762 - val_accuracy: 0.7753\n",
            "Epoch 171/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4170 - accuracy: 0.8182 - val_loss: 0.5367 - val_accuracy: 0.7528\n",
            "Epoch 172/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4030 - accuracy: 0.8119 - val_loss: 0.4761 - val_accuracy: 0.7584\n",
            "Epoch 173/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3913 - accuracy: 0.8297 - val_loss: 0.5273 - val_accuracy: 0.7809\n",
            "Epoch 174/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3980 - accuracy: 0.8220 - val_loss: 0.5597 - val_accuracy: 0.7809\n",
            "Epoch 175/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4065 - accuracy: 0.8231 - val_loss: 0.4729 - val_accuracy: 0.7753\n",
            "Epoch 176/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3916 - accuracy: 0.8246 - val_loss: 0.4968 - val_accuracy: 0.7809\n",
            "Epoch 177/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3964 - accuracy: 0.8288 - val_loss: 0.4685 - val_accuracy: 0.7809\n",
            "Epoch 178/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3917 - accuracy: 0.8329 - val_loss: 0.5031 - val_accuracy: 0.7528\n",
            "Epoch 179/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3844 - accuracy: 0.8300 - val_loss: 0.5061 - val_accuracy: 0.7528\n",
            "Epoch 180/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3884 - accuracy: 0.8345 - val_loss: 0.5037 - val_accuracy: 0.7640\n",
            "Epoch 181/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3657 - accuracy: 0.8419 - val_loss: 0.4780 - val_accuracy: 0.7809\n",
            "Epoch 182/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3777 - accuracy: 0.8450 - val_loss: 0.4769 - val_accuracy: 0.7697\n",
            "Epoch 183/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4113 - accuracy: 0.8263 - val_loss: 0.5230 - val_accuracy: 0.7528\n",
            "Epoch 184/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3778 - accuracy: 0.8403 - val_loss: 0.4904 - val_accuracy: 0.7697\n",
            "Epoch 185/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3957 - accuracy: 0.8264 - val_loss: 0.4855 - val_accuracy: 0.7584\n",
            "Epoch 186/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4182 - accuracy: 0.8063 - val_loss: 0.5022 - val_accuracy: 0.7640\n",
            "Epoch 187/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4059 - accuracy: 0.8155 - val_loss: 0.5217 - val_accuracy: 0.7640\n",
            "Epoch 188/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3828 - accuracy: 0.8367 - val_loss: 0.4894 - val_accuracy: 0.7584\n",
            "Epoch 189/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3913 - accuracy: 0.8303 - val_loss: 0.4816 - val_accuracy: 0.7809\n",
            "Epoch 190/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3944 - accuracy: 0.8369 - val_loss: 0.5210 - val_accuracy: 0.7809\n",
            "Epoch 191/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3905 - accuracy: 0.8297 - val_loss: 0.5146 - val_accuracy: 0.7809\n",
            "Epoch 192/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3876 - accuracy: 0.8244 - val_loss: 0.4839 - val_accuracy: 0.7640\n",
            "Epoch 193/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3567 - accuracy: 0.8551 - val_loss: 0.5131 - val_accuracy: 0.7865\n",
            "Epoch 194/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3943 - accuracy: 0.8260 - val_loss: 0.4824 - val_accuracy: 0.7697\n",
            "Epoch 195/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4166 - accuracy: 0.8053 - val_loss: 0.4914 - val_accuracy: 0.7528\n",
            "Epoch 196/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3635 - accuracy: 0.8373 - val_loss: 0.5269 - val_accuracy: 0.7809\n",
            "Epoch 197/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3876 - accuracy: 0.8269 - val_loss: 0.7489 - val_accuracy: 0.6966\n",
            "Epoch 198/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4248 - accuracy: 0.8118 - val_loss: 0.5080 - val_accuracy: 0.7528\n",
            "Epoch 199/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3931 - accuracy: 0.8132 - val_loss: 0.4667 - val_accuracy: 0.7809\n",
            "Epoch 200/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4138 - accuracy: 0.8141 - val_loss: 0.4826 - val_accuracy: 0.7528\n",
            "Epoch 201/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3924 - accuracy: 0.8284 - val_loss: 0.5795 - val_accuracy: 0.7809\n",
            "Epoch 202/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3793 - accuracy: 0.8300 - val_loss: 0.4944 - val_accuracy: 0.7809\n",
            "Epoch 203/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3984 - accuracy: 0.8166 - val_loss: 0.4818 - val_accuracy: 0.7697\n",
            "Epoch 204/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3942 - accuracy: 0.8353 - val_loss: 0.5481 - val_accuracy: 0.7865\n",
            "Epoch 205/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.3905 - accuracy: 0.8215 - val_loss: 0.4674 - val_accuracy: 0.7865\n",
            "Epoch 206/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3621 - accuracy: 0.8475 - val_loss: 0.4759 - val_accuracy: 0.7809\n",
            "Epoch 207/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3779 - accuracy: 0.8453 - val_loss: 0.5062 - val_accuracy: 0.7809\n",
            "Epoch 208/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3763 - accuracy: 0.8375 - val_loss: 0.5451 - val_accuracy: 0.7865\n",
            "Epoch 209/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3931 - accuracy: 0.8386 - val_loss: 0.5404 - val_accuracy: 0.7865\n",
            "Epoch 210/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3838 - accuracy: 0.8267 - val_loss: 0.4893 - val_accuracy: 0.7753\n",
            "Epoch 211/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3875 - accuracy: 0.8232 - val_loss: 0.5008 - val_accuracy: 0.7640\n",
            "Epoch 212/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3883 - accuracy: 0.8317 - val_loss: 0.5043 - val_accuracy: 0.7528\n",
            "Epoch 213/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3748 - accuracy: 0.8390 - val_loss: 0.4925 - val_accuracy: 0.7640\n",
            "Epoch 214/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3746 - accuracy: 0.8409 - val_loss: 0.5209 - val_accuracy: 0.7584\n",
            "Epoch 215/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3852 - accuracy: 0.8227 - val_loss: 0.4989 - val_accuracy: 0.7640\n",
            "Epoch 216/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3870 - accuracy: 0.8279 - val_loss: 0.5255 - val_accuracy: 0.7584\n",
            "Epoch 217/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3891 - accuracy: 0.8204 - val_loss: 0.4950 - val_accuracy: 0.7640\n",
            "Epoch 218/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3857 - accuracy: 0.8267 - val_loss: 0.4961 - val_accuracy: 0.7528\n",
            "Epoch 219/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3711 - accuracy: 0.8389 - val_loss: 0.4971 - val_accuracy: 0.7640\n",
            "Epoch 220/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3747 - accuracy: 0.8276 - val_loss: 0.4836 - val_accuracy: 0.7753\n",
            "Epoch 221/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3797 - accuracy: 0.8324 - val_loss: 0.4817 - val_accuracy: 0.7809\n",
            "Epoch 222/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4026 - accuracy: 0.8107 - val_loss: 0.4829 - val_accuracy: 0.7640\n",
            "Epoch 223/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4007 - accuracy: 0.8181 - val_loss: 0.4811 - val_accuracy: 0.7809\n",
            "Epoch 224/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3693 - accuracy: 0.8469 - val_loss: 0.5184 - val_accuracy: 0.7921\n",
            "Epoch 225/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3860 - accuracy: 0.8253 - val_loss: 0.5003 - val_accuracy: 0.7921\n",
            "Epoch 226/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3878 - accuracy: 0.8216 - val_loss: 0.5133 - val_accuracy: 0.7809\n",
            "Epoch 227/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3971 - accuracy: 0.8128 - val_loss: 0.5519 - val_accuracy: 0.7865\n",
            "Epoch 228/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3499 - accuracy: 0.8537 - val_loss: 0.4730 - val_accuracy: 0.7865\n",
            "Epoch 229/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4114 - accuracy: 0.8061 - val_loss: 0.4967 - val_accuracy: 0.7528\n",
            "Epoch 230/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3932 - accuracy: 0.8282 - val_loss: 0.5214 - val_accuracy: 0.7978\n",
            "Epoch 231/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3985 - accuracy: 0.8287 - val_loss: 0.5192 - val_accuracy: 0.7921\n",
            "Epoch 232/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4043 - accuracy: 0.8282 - val_loss: 0.4789 - val_accuracy: 0.7865\n",
            "Epoch 233/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3752 - accuracy: 0.8293 - val_loss: 0.4793 - val_accuracy: 0.7753\n",
            "Epoch 234/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3979 - accuracy: 0.8179 - val_loss: 0.5157 - val_accuracy: 0.7640\n",
            "Epoch 235/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3648 - accuracy: 0.8484 - val_loss: 0.4834 - val_accuracy: 0.7697\n",
            "Epoch 236/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3948 - accuracy: 0.8260 - val_loss: 0.5067 - val_accuracy: 0.7640\n",
            "Epoch 237/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3692 - accuracy: 0.8405 - val_loss: 0.4896 - val_accuracy: 0.7753\n",
            "Epoch 238/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4146 - accuracy: 0.8156 - val_loss: 0.4968 - val_accuracy: 0.7528\n",
            "Epoch 239/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3844 - accuracy: 0.8298 - val_loss: 0.4935 - val_accuracy: 0.7809\n",
            "Epoch 240/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3992 - accuracy: 0.8219 - val_loss: 0.5553 - val_accuracy: 0.7809\n",
            "Epoch 241/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3899 - accuracy: 0.8206 - val_loss: 0.5072 - val_accuracy: 0.7528\n",
            "Epoch 242/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3497 - accuracy: 0.8491 - val_loss: 0.5495 - val_accuracy: 0.7809\n",
            "Epoch 243/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3593 - accuracy: 0.8410 - val_loss: 0.4927 - val_accuracy: 0.7584\n",
            "Epoch 244/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3830 - accuracy: 0.8338 - val_loss: 0.5304 - val_accuracy: 0.7809\n",
            "Epoch 245/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4021 - accuracy: 0.8184 - val_loss: 0.5315 - val_accuracy: 0.7809\n",
            "Epoch 246/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3543 - accuracy: 0.8403 - val_loss: 0.5179 - val_accuracy: 0.7640\n",
            "Epoch 247/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3998 - accuracy: 0.8146 - val_loss: 0.5156 - val_accuracy: 0.7753\n",
            "Epoch 248/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3698 - accuracy: 0.8461 - val_loss: 0.5956 - val_accuracy: 0.7528\n",
            "Epoch 249/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3932 - accuracy: 0.8310 - val_loss: 0.4980 - val_accuracy: 0.7753\n",
            "Epoch 250/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3905 - accuracy: 0.8311 - val_loss: 0.5069 - val_accuracy: 0.7640\n",
            "Epoch 251/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3796 - accuracy: 0.8460 - val_loss: 0.4982 - val_accuracy: 0.7753\n",
            "Epoch 252/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4005 - accuracy: 0.8110 - val_loss: 0.4929 - val_accuracy: 0.7697\n",
            "Epoch 253/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.3849 - accuracy: 0.8403 - val_loss: 0.5733 - val_accuracy: 0.7528\n",
            "Epoch 254/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3896 - accuracy: 0.8250 - val_loss: 0.5229 - val_accuracy: 0.7528\n",
            "Epoch 255/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3782 - accuracy: 0.8315 - val_loss: 0.4959 - val_accuracy: 0.7978\n",
            "Epoch 256/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3849 - accuracy: 0.8283 - val_loss: 0.5206 - val_accuracy: 0.7809\n",
            "Epoch 257/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.3664 - accuracy: 0.8364 - val_loss: 0.5119 - val_accuracy: 0.7921\n",
            "Epoch 258/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3994 - accuracy: 0.8188 - val_loss: 0.5543 - val_accuracy: 0.7809\n",
            "Epoch 259/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3985 - accuracy: 0.8155 - val_loss: 0.5127 - val_accuracy: 0.7640\n",
            "Epoch 260/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4030 - accuracy: 0.8215 - val_loss: 0.4983 - val_accuracy: 0.7528\n",
            "Epoch 261/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3812 - accuracy: 0.8343 - val_loss: 0.5013 - val_accuracy: 0.7584\n",
            "Epoch 262/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4032 - accuracy: 0.8218 - val_loss: 0.4962 - val_accuracy: 0.7584\n",
            "Epoch 263/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3621 - accuracy: 0.8471 - val_loss: 0.6043 - val_accuracy: 0.7640\n",
            "Epoch 264/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4129 - accuracy: 0.8206 - val_loss: 0.5215 - val_accuracy: 0.7640\n",
            "Epoch 265/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8196 - val_loss: 0.5746 - val_accuracy: 0.7921\n",
            "Epoch 266/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3805 - accuracy: 0.8265 - val_loss: 0.5037 - val_accuracy: 0.7416\n",
            "Epoch 267/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3776 - accuracy: 0.8299 - val_loss: 0.4882 - val_accuracy: 0.7640\n",
            "Epoch 268/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3958 - accuracy: 0.8038 - val_loss: 0.4934 - val_accuracy: 0.7528\n",
            "Epoch 269/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3876 - accuracy: 0.8343 - val_loss: 0.5106 - val_accuracy: 0.7584\n",
            "Epoch 270/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3893 - accuracy: 0.8294 - val_loss: 0.5200 - val_accuracy: 0.7640\n",
            "Epoch 271/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3670 - accuracy: 0.8398 - val_loss: 0.6284 - val_accuracy: 0.7191\n",
            "Epoch 272/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.4001 - accuracy: 0.8031 - val_loss: 0.5506 - val_accuracy: 0.7865\n",
            "Epoch 273/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3859 - accuracy: 0.8290 - val_loss: 0.5154 - val_accuracy: 0.7640\n",
            "Epoch 274/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3804 - accuracy: 0.8411 - val_loss: 0.5650 - val_accuracy: 0.7809\n",
            "Epoch 275/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3955 - accuracy: 0.8324 - val_loss: 0.5889 - val_accuracy: 0.7809\n",
            "Epoch 276/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3797 - accuracy: 0.8301 - val_loss: 0.4888 - val_accuracy: 0.7809\n",
            "Epoch 277/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3865 - accuracy: 0.8202 - val_loss: 0.6929 - val_accuracy: 0.7191\n",
            "Epoch 278/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4103 - accuracy: 0.8175 - val_loss: 0.5010 - val_accuracy: 0.7640\n",
            "Epoch 279/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3627 - accuracy: 0.8500 - val_loss: 0.4984 - val_accuracy: 0.7753\n",
            "Epoch 280/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3891 - accuracy: 0.8359 - val_loss: 0.5032 - val_accuracy: 0.7697\n",
            "Epoch 281/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4002 - accuracy: 0.8204 - val_loss: 0.5038 - val_accuracy: 0.7584\n",
            "Epoch 282/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4047 - accuracy: 0.8195 - val_loss: 0.5153 - val_accuracy: 0.7528\n",
            "Epoch 283/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3763 - accuracy: 0.8362 - val_loss: 0.5478 - val_accuracy: 0.7809\n",
            "Epoch 284/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3489 - accuracy: 0.8444 - val_loss: 0.5589 - val_accuracy: 0.7753\n",
            "Epoch 285/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3822 - accuracy: 0.8188 - val_loss: 0.5329 - val_accuracy: 0.7472\n",
            "Epoch 286/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3648 - accuracy: 0.8278 - val_loss: 0.4841 - val_accuracy: 0.7865\n",
            "Epoch 287/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3809 - accuracy: 0.8330 - val_loss: 0.5454 - val_accuracy: 0.7809\n",
            "Epoch 288/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3872 - accuracy: 0.8258 - val_loss: 0.5288 - val_accuracy: 0.7528\n",
            "Epoch 289/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3450 - accuracy: 0.8387 - val_loss: 0.5659 - val_accuracy: 0.7753\n",
            "Epoch 290/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4061 - accuracy: 0.7924 - val_loss: 0.5021 - val_accuracy: 0.7640\n",
            "Epoch 291/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3577 - accuracy: 0.8531 - val_loss: 0.4959 - val_accuracy: 0.7753\n",
            "Epoch 292/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3901 - accuracy: 0.8284 - val_loss: 0.5225 - val_accuracy: 0.7640\n",
            "Epoch 293/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3699 - accuracy: 0.8452 - val_loss: 0.4982 - val_accuracy: 0.7584\n",
            "Epoch 294/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3778 - accuracy: 0.8256 - val_loss: 0.5168 - val_accuracy: 0.7640\n",
            "Epoch 295/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3866 - accuracy: 0.8357 - val_loss: 0.4908 - val_accuracy: 0.7865\n",
            "Epoch 296/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4035 - accuracy: 0.8210 - val_loss: 0.5215 - val_accuracy: 0.7640\n",
            "Epoch 297/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3754 - accuracy: 0.8290 - val_loss: 0.4958 - val_accuracy: 0.7865\n",
            "Epoch 298/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3678 - accuracy: 0.8468 - val_loss: 0.4981 - val_accuracy: 0.7753\n",
            "Epoch 299/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3883 - accuracy: 0.8286 - val_loss: 0.6039 - val_accuracy: 0.7753\n",
            "Epoch 300/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3696 - accuracy: 0.8411 - val_loss: 0.5937 - val_accuracy: 0.7472\n",
            "Epoch 301/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.3684 - accuracy: 0.8301 - val_loss: 0.5212 - val_accuracy: 0.7640\n",
            "Epoch 302/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3773 - accuracy: 0.8246 - val_loss: 0.7174 - val_accuracy: 0.7079\n",
            "Epoch 303/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4070 - accuracy: 0.8120 - val_loss: 0.4901 - val_accuracy: 0.7640\n",
            "Epoch 304/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3885 - accuracy: 0.8186 - val_loss: 0.6090 - val_accuracy: 0.7753\n",
            "Epoch 305/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3885 - accuracy: 0.8309 - val_loss: 0.5448 - val_accuracy: 0.7753\n",
            "Epoch 306/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3612 - accuracy: 0.8370 - val_loss: 0.4996 - val_accuracy: 0.7697\n",
            "Epoch 307/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3881 - accuracy: 0.8385 - val_loss: 0.5857 - val_accuracy: 0.7472\n",
            "Epoch 308/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3756 - accuracy: 0.8343 - val_loss: 0.4961 - val_accuracy: 0.7753\n",
            "Epoch 309/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3951 - accuracy: 0.8214 - val_loss: 0.4860 - val_accuracy: 0.7697\n",
            "Epoch 310/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3806 - accuracy: 0.8299 - val_loss: 0.5902 - val_accuracy: 0.7416\n",
            "Epoch 311/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3869 - accuracy: 0.8191 - val_loss: 0.4780 - val_accuracy: 0.7753\n",
            "Epoch 312/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3766 - accuracy: 0.8365 - val_loss: 0.5312 - val_accuracy: 0.7978\n",
            "Epoch 313/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4006 - accuracy: 0.8098 - val_loss: 0.6240 - val_accuracy: 0.7584\n",
            "Epoch 314/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3795 - accuracy: 0.8272 - val_loss: 0.6190 - val_accuracy: 0.7360\n",
            "Epoch 315/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4251 - accuracy: 0.8120 - val_loss: 0.4960 - val_accuracy: 0.7640\n",
            "Epoch 316/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.3831 - accuracy: 0.8448 - val_loss: 0.5016 - val_accuracy: 0.7584\n",
            "Epoch 317/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3809 - accuracy: 0.8408 - val_loss: 0.5209 - val_accuracy: 0.7809\n",
            "Epoch 318/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3793 - accuracy: 0.8252 - val_loss: 0.5089 - val_accuracy: 0.7640\n",
            "Epoch 319/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3911 - accuracy: 0.8200 - val_loss: 0.5534 - val_accuracy: 0.7753\n",
            "Epoch 320/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4054 - accuracy: 0.8065 - val_loss: 0.4990 - val_accuracy: 0.7584\n",
            "Epoch 321/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3878 - accuracy: 0.8349 - val_loss: 0.4952 - val_accuracy: 0.7528\n",
            "Epoch 322/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3679 - accuracy: 0.8396 - val_loss: 0.5226 - val_accuracy: 0.7809\n",
            "Epoch 323/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3762 - accuracy: 0.8301 - val_loss: 0.5223 - val_accuracy: 0.7528\n",
            "Epoch 324/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3692 - accuracy: 0.8341 - val_loss: 0.4847 - val_accuracy: 0.7865\n",
            "Epoch 325/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3918 - accuracy: 0.8291 - val_loss: 0.5432 - val_accuracy: 0.7809\n",
            "Epoch 326/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3590 - accuracy: 0.8359 - val_loss: 0.5579 - val_accuracy: 0.7809\n",
            "Epoch 327/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3714 - accuracy: 0.8173 - val_loss: 0.5135 - val_accuracy: 0.7697\n",
            "Epoch 328/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3649 - accuracy: 0.8384 - val_loss: 0.5642 - val_accuracy: 0.7472\n",
            "Epoch 329/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3732 - accuracy: 0.8364 - val_loss: 0.5229 - val_accuracy: 0.7472\n",
            "Epoch 330/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.3691 - accuracy: 0.8425 - val_loss: 0.4938 - val_accuracy: 0.7753\n",
            "Epoch 331/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4024 - accuracy: 0.8173 - val_loss: 0.5331 - val_accuracy: 0.7528\n",
            "Epoch 332/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.3709 - accuracy: 0.8325 - val_loss: 0.5066 - val_accuracy: 0.7697\n",
            "Epoch 333/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3794 - accuracy: 0.8412 - val_loss: 0.5525 - val_accuracy: 0.7472\n",
            "Epoch 334/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3620 - accuracy: 0.8430 - val_loss: 0.5442 - val_accuracy: 0.7360\n",
            "Epoch 335/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4036 - accuracy: 0.8165 - val_loss: 0.5181 - val_accuracy: 0.7697\n",
            "Epoch 336/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4047 - accuracy: 0.8145 - val_loss: 0.5099 - val_accuracy: 0.7697\n",
            "Epoch 337/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3898 - accuracy: 0.8279 - val_loss: 0.5060 - val_accuracy: 0.7640\n",
            "Epoch 338/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3922 - accuracy: 0.8199 - val_loss: 0.5425 - val_accuracy: 0.7472\n",
            "Epoch 339/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3809 - accuracy: 0.8321 - val_loss: 0.4897 - val_accuracy: 0.7921\n",
            "Epoch 340/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4037 - accuracy: 0.8111 - val_loss: 0.5594 - val_accuracy: 0.7472\n",
            "Epoch 341/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3755 - accuracy: 0.8340 - val_loss: 0.5339 - val_accuracy: 0.7584\n",
            "Epoch 342/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3703 - accuracy: 0.8264 - val_loss: 0.5346 - val_accuracy: 0.7921\n",
            "Epoch 343/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3708 - accuracy: 0.8316 - val_loss: 0.5025 - val_accuracy: 0.7753\n",
            "Epoch 344/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3615 - accuracy: 0.8501 - val_loss: 0.6163 - val_accuracy: 0.7809\n",
            "Epoch 345/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3785 - accuracy: 0.8368 - val_loss: 0.6691 - val_accuracy: 0.7247\n",
            "Epoch 346/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4046 - accuracy: 0.8122 - val_loss: 0.5589 - val_accuracy: 0.7416\n",
            "Epoch 347/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3845 - accuracy: 0.8313 - val_loss: 0.5712 - val_accuracy: 0.7753\n",
            "Epoch 348/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3680 - accuracy: 0.8425 - val_loss: 0.5094 - val_accuracy: 0.7753\n",
            "Epoch 349/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.3731 - accuracy: 0.8454 - val_loss: 0.5297 - val_accuracy: 0.7640\n",
            "Epoch 350/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3761 - accuracy: 0.8208 - val_loss: 0.4831 - val_accuracy: 0.7697\n",
            "Epoch 351/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3943 - accuracy: 0.8301 - val_loss: 0.4871 - val_accuracy: 0.7697\n",
            "Epoch 352/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3579 - accuracy: 0.8429 - val_loss: 0.4987 - val_accuracy: 0.7640\n",
            "Epoch 353/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3927 - accuracy: 0.8226 - val_loss: 0.6114 - val_accuracy: 0.7640\n",
            "Epoch 354/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.3381 - accuracy: 0.8498 - val_loss: 0.5051 - val_accuracy: 0.7697\n",
            "Epoch 355/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3558 - accuracy: 0.8380 - val_loss: 0.5737 - val_accuracy: 0.7809\n",
            "Epoch 356/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3548 - accuracy: 0.8423 - val_loss: 0.5826 - val_accuracy: 0.7528\n",
            "Epoch 357/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3822 - accuracy: 0.8306 - val_loss: 0.6143 - val_accuracy: 0.7416\n",
            "Epoch 358/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3858 - accuracy: 0.8307 - val_loss: 0.5183 - val_accuracy: 0.7753\n",
            "Epoch 359/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3769 - accuracy: 0.8375 - val_loss: 0.5682 - val_accuracy: 0.7809\n",
            "Epoch 360/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3881 - accuracy: 0.8305 - val_loss: 0.5397 - val_accuracy: 0.7697\n",
            "Epoch 361/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3602 - accuracy: 0.8417 - val_loss: 0.5297 - val_accuracy: 0.7753\n",
            "Epoch 362/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3666 - accuracy: 0.8493 - val_loss: 0.5443 - val_accuracy: 0.7472\n",
            "Epoch 363/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3941 - accuracy: 0.8231 - val_loss: 0.5366 - val_accuracy: 0.7584\n",
            "Epoch 364/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3888 - accuracy: 0.8206 - val_loss: 0.8195 - val_accuracy: 0.6798\n",
            "Epoch 365/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4415 - accuracy: 0.7965 - val_loss: 0.5163 - val_accuracy: 0.7528\n",
            "Epoch 366/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4053 - accuracy: 0.8161 - val_loss: 0.5047 - val_accuracy: 0.7697\n",
            "Epoch 367/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3693 - accuracy: 0.8464 - val_loss: 0.5394 - val_accuracy: 0.7528\n",
            "Epoch 368/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3719 - accuracy: 0.8374 - val_loss: 0.5205 - val_accuracy: 0.7584\n",
            "Epoch 369/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3694 - accuracy: 0.8448 - val_loss: 0.5417 - val_accuracy: 0.7584\n",
            "Epoch 370/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3741 - accuracy: 0.8434 - val_loss: 0.5806 - val_accuracy: 0.7809\n",
            "Epoch 371/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3969 - accuracy: 0.8338 - val_loss: 0.5302 - val_accuracy: 0.7697\n",
            "Epoch 372/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3886 - accuracy: 0.8211 - val_loss: 0.5938 - val_accuracy: 0.7528\n",
            "Epoch 373/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3946 - accuracy: 0.8278 - val_loss: 0.6043 - val_accuracy: 0.7753\n",
            "Epoch 374/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3923 - accuracy: 0.8156 - val_loss: 0.5340 - val_accuracy: 0.7528\n",
            "Epoch 375/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3748 - accuracy: 0.8470 - val_loss: 0.4983 - val_accuracy: 0.7584\n",
            "Epoch 376/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3966 - accuracy: 0.8266 - val_loss: 0.5605 - val_accuracy: 0.7753\n",
            "Epoch 377/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3746 - accuracy: 0.8284 - val_loss: 0.5206 - val_accuracy: 0.7528\n",
            "Epoch 378/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3608 - accuracy: 0.8478 - val_loss: 0.4928 - val_accuracy: 0.7697\n",
            "Epoch 379/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3687 - accuracy: 0.8438 - val_loss: 0.5210 - val_accuracy: 0.7584\n",
            "Epoch 380/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3859 - accuracy: 0.8336 - val_loss: 0.5008 - val_accuracy: 0.7697\n",
            "Epoch 381/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3978 - accuracy: 0.8274 - val_loss: 0.5076 - val_accuracy: 0.7753\n",
            "Epoch 382/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3942 - accuracy: 0.8166 - val_loss: 0.5089 - val_accuracy: 0.7697\n",
            "Epoch 383/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4035 - accuracy: 0.8218 - val_loss: 0.5398 - val_accuracy: 0.7584\n",
            "Epoch 384/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3502 - accuracy: 0.8500 - val_loss: 0.5534 - val_accuracy: 0.7472\n",
            "Epoch 385/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3879 - accuracy: 0.8278 - val_loss: 0.5814 - val_accuracy: 0.7640\n",
            "Epoch 386/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3651 - accuracy: 0.8324 - val_loss: 0.6071 - val_accuracy: 0.7640\n",
            "Epoch 387/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3735 - accuracy: 0.8348 - val_loss: 0.5222 - val_accuracy: 0.7640\n",
            "Epoch 388/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3618 - accuracy: 0.8451 - val_loss: 0.5561 - val_accuracy: 0.7472\n",
            "Epoch 389/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3609 - accuracy: 0.8471 - val_loss: 0.5831 - val_accuracy: 0.7472\n",
            "Epoch 390/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3736 - accuracy: 0.8237 - val_loss: 0.6783 - val_accuracy: 0.7191\n",
            "Epoch 391/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3964 - accuracy: 0.8189 - val_loss: 0.5241 - val_accuracy: 0.7697\n",
            "Epoch 392/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3832 - accuracy: 0.8308 - val_loss: 0.6000 - val_accuracy: 0.7753\n",
            "Epoch 393/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4121 - accuracy: 0.8086 - val_loss: 0.5072 - val_accuracy: 0.7753\n",
            "Epoch 394/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3895 - accuracy: 0.8061 - val_loss: 0.5099 - val_accuracy: 0.7809\n",
            "Epoch 395/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3590 - accuracy: 0.8403 - val_loss: 0.6671 - val_accuracy: 0.7247\n",
            "Epoch 396/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.4181 - accuracy: 0.8254 - val_loss: 0.5063 - val_accuracy: 0.7697\n",
            "Epoch 397/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.3796 - accuracy: 0.8350 - val_loss: 0.4964 - val_accuracy: 0.7640\n",
            "Epoch 398/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3902 - accuracy: 0.8323 - val_loss: 0.5259 - val_accuracy: 0.7472\n",
            "Epoch 399/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3793 - accuracy: 0.8319 - val_loss: 0.5197 - val_accuracy: 0.7697\n",
            "Epoch 400/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4020 - accuracy: 0.8164 - val_loss: 0.5434 - val_accuracy: 0.7472\n",
            "Epoch 401/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3612 - accuracy: 0.8363 - val_loss: 0.5109 - val_accuracy: 0.7640\n",
            "Epoch 402/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3623 - accuracy: 0.8493 - val_loss: 0.5307 - val_accuracy: 0.7865\n",
            "Epoch 403/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3554 - accuracy: 0.8543 - val_loss: 0.6239 - val_accuracy: 0.7640\n",
            "Epoch 404/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3840 - accuracy: 0.8266 - val_loss: 0.5712 - val_accuracy: 0.7809\n",
            "Epoch 405/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3918 - accuracy: 0.8237 - val_loss: 0.5210 - val_accuracy: 0.7640\n",
            "Epoch 406/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3644 - accuracy: 0.8406 - val_loss: 0.5591 - val_accuracy: 0.7809\n",
            "Epoch 407/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3877 - accuracy: 0.8282 - val_loss: 0.4952 - val_accuracy: 0.7697\n",
            "Epoch 408/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3688 - accuracy: 0.8525 - val_loss: 0.5110 - val_accuracy: 0.7753\n",
            "Epoch 409/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3786 - accuracy: 0.8374 - val_loss: 0.5248 - val_accuracy: 0.7753\n",
            "Epoch 410/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3688 - accuracy: 0.8426 - val_loss: 0.5050 - val_accuracy: 0.7584\n",
            "Epoch 411/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.4042 - accuracy: 0.8111 - val_loss: 0.5557 - val_accuracy: 0.7809\n",
            "Epoch 412/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3929 - accuracy: 0.8222 - val_loss: 0.5266 - val_accuracy: 0.7921\n",
            "Epoch 413/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3629 - accuracy: 0.8365 - val_loss: 0.4965 - val_accuracy: 0.7697\n",
            "Epoch 414/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3744 - accuracy: 0.8346 - val_loss: 0.5852 - val_accuracy: 0.7809\n",
            "Epoch 415/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3752 - accuracy: 0.8365 - val_loss: 0.5214 - val_accuracy: 0.7528\n",
            "Epoch 416/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3784 - accuracy: 0.8407 - val_loss: 0.5228 - val_accuracy: 0.7978\n",
            "Epoch 417/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3573 - accuracy: 0.8457 - val_loss: 0.5240 - val_accuracy: 0.7640\n",
            "Epoch 418/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3737 - accuracy: 0.8419 - val_loss: 0.5705 - val_accuracy: 0.7528\n",
            "Epoch 419/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3879 - accuracy: 0.8324 - val_loss: 0.5135 - val_accuracy: 0.7697\n",
            "Epoch 420/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3785 - accuracy: 0.8372 - val_loss: 0.5554 - val_accuracy: 0.7640\n",
            "Epoch 421/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3787 - accuracy: 0.8337 - val_loss: 0.5186 - val_accuracy: 0.7472\n",
            "Epoch 422/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4060 - accuracy: 0.8108 - val_loss: 0.5248 - val_accuracy: 0.7640\n",
            "Epoch 423/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3665 - accuracy: 0.8430 - val_loss: 0.5884 - val_accuracy: 0.7697\n",
            "Epoch 424/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3795 - accuracy: 0.8333 - val_loss: 0.5597 - val_accuracy: 0.7753\n",
            "Epoch 425/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3578 - accuracy: 0.8433 - val_loss: 0.5626 - val_accuracy: 0.7809\n",
            "Epoch 426/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3784 - accuracy: 0.8277 - val_loss: 0.5169 - val_accuracy: 0.7640\n",
            "Epoch 427/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3507 - accuracy: 0.8540 - val_loss: 0.6133 - val_accuracy: 0.7472\n",
            "Epoch 428/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3727 - accuracy: 0.8298 - val_loss: 0.5221 - val_accuracy: 0.7809\n",
            "Epoch 429/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3884 - accuracy: 0.8370 - val_loss: 0.5102 - val_accuracy: 0.7809\n",
            "Epoch 430/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3697 - accuracy: 0.8271 - val_loss: 0.5698 - val_accuracy: 0.7809\n",
            "Epoch 431/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3926 - accuracy: 0.8348 - val_loss: 0.5380 - val_accuracy: 0.7640\n",
            "Epoch 432/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3636 - accuracy: 0.8302 - val_loss: 0.5611 - val_accuracy: 0.7978\n",
            "Epoch 433/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3871 - accuracy: 0.8297 - val_loss: 0.5944 - val_accuracy: 0.7528\n",
            "Epoch 434/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3723 - accuracy: 0.8287 - val_loss: 0.6216 - val_accuracy: 0.7247\n",
            "Epoch 435/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3809 - accuracy: 0.8278 - val_loss: 0.4957 - val_accuracy: 0.7809\n",
            "Epoch 436/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3657 - accuracy: 0.8383 - val_loss: 0.5535 - val_accuracy: 0.7584\n",
            "Epoch 437/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3768 - accuracy: 0.8379 - val_loss: 0.5455 - val_accuracy: 0.7584\n",
            "Epoch 438/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3746 - accuracy: 0.8305 - val_loss: 0.6507 - val_accuracy: 0.7247\n",
            "Epoch 439/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4066 - accuracy: 0.8119 - val_loss: 0.5636 - val_accuracy: 0.7584\n",
            "Epoch 440/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3697 - accuracy: 0.8335 - val_loss: 0.5203 - val_accuracy: 0.7809\n",
            "Epoch 441/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3883 - accuracy: 0.8358 - val_loss: 0.5098 - val_accuracy: 0.7753\n",
            "Epoch 442/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3809 - accuracy: 0.8346 - val_loss: 0.5067 - val_accuracy: 0.7753\n",
            "Epoch 443/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3685 - accuracy: 0.8368 - val_loss: 0.5174 - val_accuracy: 0.7753\n",
            "Epoch 444/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3505 - accuracy: 0.8446 - val_loss: 0.5271 - val_accuracy: 0.7584\n",
            "Epoch 445/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.3521 - accuracy: 0.8496 - val_loss: 0.5221 - val_accuracy: 0.7809\n",
            "Epoch 446/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3538 - accuracy: 0.8486 - val_loss: 0.5119 - val_accuracy: 0.7865\n",
            "Epoch 447/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3509 - accuracy: 0.8550 - val_loss: 0.5626 - val_accuracy: 0.7472\n",
            "Epoch 448/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3643 - accuracy: 0.8465 - val_loss: 0.6398 - val_accuracy: 0.7247\n",
            "Epoch 449/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3872 - accuracy: 0.8307 - val_loss: 0.5192 - val_accuracy: 0.7921\n",
            "Epoch 450/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3885 - accuracy: 0.8187 - val_loss: 0.4996 - val_accuracy: 0.7697\n",
            "Epoch 451/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4025 - accuracy: 0.8243 - val_loss: 0.5157 - val_accuracy: 0.7753\n",
            "Epoch 452/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3889 - accuracy: 0.8350 - val_loss: 0.5784 - val_accuracy: 0.7865\n",
            "Epoch 453/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3841 - accuracy: 0.8227 - val_loss: 0.5334 - val_accuracy: 0.7809\n",
            "Epoch 454/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3654 - accuracy: 0.8390 - val_loss: 0.5645 - val_accuracy: 0.7528\n",
            "Epoch 455/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3576 - accuracy: 0.8429 - val_loss: 0.5560 - val_accuracy: 0.7640\n",
            "Epoch 456/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3634 - accuracy: 0.8447 - val_loss: 0.5200 - val_accuracy: 0.7697\n",
            "Epoch 457/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3627 - accuracy: 0.8336 - val_loss: 0.5760 - val_accuracy: 0.7528\n",
            "Epoch 458/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3694 - accuracy: 0.8277 - val_loss: 0.6089 - val_accuracy: 0.7472\n",
            "Epoch 459/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3616 - accuracy: 0.8394 - val_loss: 0.6131 - val_accuracy: 0.7472\n",
            "Epoch 460/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3819 - accuracy: 0.8324 - val_loss: 0.5713 - val_accuracy: 0.7584\n",
            "Epoch 461/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3727 - accuracy: 0.8243 - val_loss: 0.5371 - val_accuracy: 0.7753\n",
            "Epoch 462/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3548 - accuracy: 0.8530 - val_loss: 0.6586 - val_accuracy: 0.7135\n",
            "Epoch 463/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3897 - accuracy: 0.8182 - val_loss: 0.5555 - val_accuracy: 0.7528\n",
            "Epoch 464/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3517 - accuracy: 0.8494 - val_loss: 0.5809 - val_accuracy: 0.7360\n",
            "Epoch 465/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3580 - accuracy: 0.8426 - val_loss: 0.5217 - val_accuracy: 0.7865\n",
            "Epoch 466/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3846 - accuracy: 0.8336 - val_loss: 0.6924 - val_accuracy: 0.7416\n",
            "Epoch 467/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.4200 - accuracy: 0.8071 - val_loss: 0.5829 - val_accuracy: 0.7416\n",
            "Epoch 468/500\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.3850 - accuracy: 0.8340 - val_loss: 0.5802 - val_accuracy: 0.7472\n",
            "Epoch 469/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3579 - accuracy: 0.8376 - val_loss: 0.5404 - val_accuracy: 0.7528\n",
            "Epoch 470/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3542 - accuracy: 0.8551 - val_loss: 0.7497 - val_accuracy: 0.7135\n",
            "Epoch 471/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3974 - accuracy: 0.8285 - val_loss: 0.5203 - val_accuracy: 0.7584\n",
            "Epoch 472/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3603 - accuracy: 0.8427 - val_loss: 0.5613 - val_accuracy: 0.7753\n",
            "Epoch 473/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3444 - accuracy: 0.8424 - val_loss: 0.5338 - val_accuracy: 0.7584\n",
            "Epoch 474/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3904 - accuracy: 0.8271 - val_loss: 0.5081 - val_accuracy: 0.7697\n",
            "Epoch 475/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3605 - accuracy: 0.8421 - val_loss: 0.5096 - val_accuracy: 0.7809\n",
            "Epoch 476/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3774 - accuracy: 0.8256 - val_loss: 0.5060 - val_accuracy: 0.7697\n",
            "Epoch 477/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3521 - accuracy: 0.8376 - val_loss: 0.5182 - val_accuracy: 0.7753\n",
            "Epoch 478/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3811 - accuracy: 0.8305 - val_loss: 0.5696 - val_accuracy: 0.7809\n",
            "Epoch 479/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3701 - accuracy: 0.8412 - val_loss: 0.5412 - val_accuracy: 0.7584\n",
            "Epoch 480/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3891 - accuracy: 0.8281 - val_loss: 0.5267 - val_accuracy: 0.7865\n",
            "Epoch 481/500\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3706 - accuracy: 0.8449 - val_loss: 0.6853 - val_accuracy: 0.7191\n",
            "Epoch 482/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3742 - accuracy: 0.8271 - val_loss: 0.5669 - val_accuracy: 0.7472\n",
            "Epoch 483/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3383 - accuracy: 0.8527 - val_loss: 0.5318 - val_accuracy: 0.7753\n",
            "Epoch 484/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3594 - accuracy: 0.8475 - val_loss: 0.5480 - val_accuracy: 0.7528\n",
            "Epoch 485/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3504 - accuracy: 0.8509 - val_loss: 0.5225 - val_accuracy: 0.7640\n",
            "Epoch 486/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3614 - accuracy: 0.8546 - val_loss: 0.5038 - val_accuracy: 0.7809\n",
            "Epoch 487/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3834 - accuracy: 0.8320 - val_loss: 0.5449 - val_accuracy: 0.7865\n",
            "Epoch 488/500\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3820 - accuracy: 0.8411 - val_loss: 0.5209 - val_accuracy: 0.7697\n",
            "Epoch 489/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3548 - accuracy: 0.8460 - val_loss: 0.5054 - val_accuracy: 0.7809\n",
            "Epoch 490/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3611 - accuracy: 0.8515 - val_loss: 0.5503 - val_accuracy: 0.7584\n",
            "Epoch 491/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3700 - accuracy: 0.8395 - val_loss: 0.6051 - val_accuracy: 0.7753\n",
            "Epoch 492/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.4002 - accuracy: 0.8233 - val_loss: 0.6204 - val_accuracy: 0.7360\n",
            "Epoch 493/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.3876 - accuracy: 0.8164 - val_loss: 0.5269 - val_accuracy: 0.7697\n",
            "Epoch 494/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3683 - accuracy: 0.8470 - val_loss: 0.6007 - val_accuracy: 0.7472\n",
            "Epoch 495/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3511 - accuracy: 0.8303 - val_loss: 0.6645 - val_accuracy: 0.7360\n",
            "Epoch 496/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3563 - accuracy: 0.8385 - val_loss: 0.5335 - val_accuracy: 0.7416\n",
            "Epoch 497/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3480 - accuracy: 0.8543 - val_loss: 0.5279 - val_accuracy: 0.7753\n",
            "Epoch 498/500\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.3500 - accuracy: 0.8564 - val_loss: 0.5178 - val_accuracy: 0.7865\n",
            "Epoch 499/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3714 - accuracy: 0.8411 - val_loss: 0.5210 - val_accuracy: 0.7753\n",
            "Epoch 500/500\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3831 - accuracy: 0.8215 - val_loss: 0.5556 - val_accuracy: 0.7809\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBBI1uSrgEsu"
      },
      "source": [
        "Now use a batch size of 200 and 200 epochs. Have you observed a significant difference in performance?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0n0qLX_gEsv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b04da97f-2fec-4111-c166-19253d4edb01"
      },
      "source": [
        "# Answer below:\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history2 = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=200, epochs=200, verbose=1)\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "4/4 [==============================] - 1s 64ms/step - loss: 0.6680 - accuracy: 0.6387 - val_loss: 0.7113 - val_accuracy: 0.5225\n",
            "Epoch 2/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6661 - accuracy: 0.6437 - val_loss: 0.7111 - val_accuracy: 0.5225\n",
            "Epoch 3/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6657 - accuracy: 0.6392 - val_loss: 0.7109 - val_accuracy: 0.5225\n",
            "Epoch 4/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6599 - accuracy: 0.6542 - val_loss: 0.7107 - val_accuracy: 0.5225\n",
            "Epoch 5/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6625 - accuracy: 0.6485 - val_loss: 0.7105 - val_accuracy: 0.5225\n",
            "Epoch 6/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6643 - accuracy: 0.6425 - val_loss: 0.7104 - val_accuracy: 0.5225\n",
            "Epoch 7/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6675 - accuracy: 0.6360 - val_loss: 0.7102 - val_accuracy: 0.5225\n",
            "Epoch 8/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6633 - accuracy: 0.6457 - val_loss: 0.7100 - val_accuracy: 0.5225\n",
            "Epoch 9/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6609 - accuracy: 0.6427 - val_loss: 0.7099 - val_accuracy: 0.5225\n",
            "Epoch 10/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6614 - accuracy: 0.6439 - val_loss: 0.7097 - val_accuracy: 0.5225\n",
            "Epoch 11/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6632 - accuracy: 0.6350 - val_loss: 0.7095 - val_accuracy: 0.5225\n",
            "Epoch 12/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6647 - accuracy: 0.6392 - val_loss: 0.7094 - val_accuracy: 0.5225\n",
            "Epoch 13/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6578 - accuracy: 0.6562 - val_loss: 0.7092 - val_accuracy: 0.5225\n",
            "Epoch 14/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6610 - accuracy: 0.6432 - val_loss: 0.7090 - val_accuracy: 0.5225\n",
            "Epoch 15/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6592 - accuracy: 0.6435 - val_loss: 0.7089 - val_accuracy: 0.5225\n",
            "Epoch 16/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6622 - accuracy: 0.6369 - val_loss: 0.7087 - val_accuracy: 0.5225\n",
            "Epoch 17/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6650 - accuracy: 0.6312 - val_loss: 0.7086 - val_accuracy: 0.5225\n",
            "Epoch 18/200\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.6664 - accuracy: 0.6279 - val_loss: 0.7084 - val_accuracy: 0.5225\n",
            "Epoch 19/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6625 - accuracy: 0.6332 - val_loss: 0.7083 - val_accuracy: 0.5225\n",
            "Epoch 20/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6601 - accuracy: 0.6364 - val_loss: 0.7081 - val_accuracy: 0.5225\n",
            "Epoch 21/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6553 - accuracy: 0.6555 - val_loss: 0.7080 - val_accuracy: 0.5225\n",
            "Epoch 22/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6582 - accuracy: 0.6529 - val_loss: 0.7078 - val_accuracy: 0.5225\n",
            "Epoch 23/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6551 - accuracy: 0.6567 - val_loss: 0.7077 - val_accuracy: 0.5225\n",
            "Epoch 24/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6570 - accuracy: 0.6450 - val_loss: 0.7075 - val_accuracy: 0.5225\n",
            "Epoch 25/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6576 - accuracy: 0.6417 - val_loss: 0.7074 - val_accuracy: 0.5225\n",
            "Epoch 26/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6584 - accuracy: 0.6350 - val_loss: 0.7072 - val_accuracy: 0.5225\n",
            "Epoch 27/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6540 - accuracy: 0.6480 - val_loss: 0.7071 - val_accuracy: 0.5225\n",
            "Epoch 28/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6603 - accuracy: 0.6305 - val_loss: 0.7069 - val_accuracy: 0.5225\n",
            "Epoch 29/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6581 - accuracy: 0.6405 - val_loss: 0.7068 - val_accuracy: 0.5225\n",
            "Epoch 30/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6569 - accuracy: 0.6504 - val_loss: 0.7066 - val_accuracy: 0.5225\n",
            "Epoch 31/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6567 - accuracy: 0.6402 - val_loss: 0.7065 - val_accuracy: 0.5225\n",
            "Epoch 32/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6573 - accuracy: 0.6400 - val_loss: 0.7064 - val_accuracy: 0.5225\n",
            "Epoch 33/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6538 - accuracy: 0.6444 - val_loss: 0.7062 - val_accuracy: 0.5225\n",
            "Epoch 34/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6563 - accuracy: 0.6345 - val_loss: 0.7061 - val_accuracy: 0.5225\n",
            "Epoch 35/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6521 - accuracy: 0.6485 - val_loss: 0.7059 - val_accuracy: 0.5225\n",
            "Epoch 36/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6548 - accuracy: 0.6465 - val_loss: 0.7058 - val_accuracy: 0.5225\n",
            "Epoch 37/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6518 - accuracy: 0.6500 - val_loss: 0.7057 - val_accuracy: 0.5225\n",
            "Epoch 38/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6540 - accuracy: 0.6410 - val_loss: 0.7055 - val_accuracy: 0.5225\n",
            "Epoch 39/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6557 - accuracy: 0.6325 - val_loss: 0.7054 - val_accuracy: 0.5225\n",
            "Epoch 40/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6470 - accuracy: 0.6610 - val_loss: 0.7052 - val_accuracy: 0.5225\n",
            "Epoch 41/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6546 - accuracy: 0.6382 - val_loss: 0.7051 - val_accuracy: 0.5225\n",
            "Epoch 42/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6544 - accuracy: 0.6324 - val_loss: 0.7050 - val_accuracy: 0.5225\n",
            "Epoch 43/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6477 - accuracy: 0.6519 - val_loss: 0.7048 - val_accuracy: 0.5225\n",
            "Epoch 44/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6501 - accuracy: 0.6474 - val_loss: 0.7047 - val_accuracy: 0.5225\n",
            "Epoch 45/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6492 - accuracy: 0.6495 - val_loss: 0.7045 - val_accuracy: 0.5225\n",
            "Epoch 46/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6482 - accuracy: 0.6485 - val_loss: 0.7044 - val_accuracy: 0.5225\n",
            "Epoch 47/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6513 - accuracy: 0.6385 - val_loss: 0.7043 - val_accuracy: 0.5225\n",
            "Epoch 48/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6490 - accuracy: 0.6485 - val_loss: 0.7041 - val_accuracy: 0.5225\n",
            "Epoch 49/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6520 - accuracy: 0.6439 - val_loss: 0.7040 - val_accuracy: 0.5225\n",
            "Epoch 50/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6517 - accuracy: 0.6410 - val_loss: 0.7038 - val_accuracy: 0.5225\n",
            "Epoch 51/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6515 - accuracy: 0.6384 - val_loss: 0.7036 - val_accuracy: 0.5225\n",
            "Epoch 52/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6467 - accuracy: 0.6500 - val_loss: 0.7035 - val_accuracy: 0.5225\n",
            "Epoch 53/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6513 - accuracy: 0.6404 - val_loss: 0.7033 - val_accuracy: 0.5225\n",
            "Epoch 54/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6514 - accuracy: 0.6324 - val_loss: 0.7031 - val_accuracy: 0.5225\n",
            "Epoch 55/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6454 - accuracy: 0.6507 - val_loss: 0.7030 - val_accuracy: 0.5225\n",
            "Epoch 56/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6473 - accuracy: 0.6479 - val_loss: 0.7028 - val_accuracy: 0.5225\n",
            "Epoch 57/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6534 - accuracy: 0.6234 - val_loss: 0.7027 - val_accuracy: 0.5225\n",
            "Epoch 58/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6463 - accuracy: 0.6442 - val_loss: 0.7026 - val_accuracy: 0.5225\n",
            "Epoch 59/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6466 - accuracy: 0.6450 - val_loss: 0.7024 - val_accuracy: 0.5225\n",
            "Epoch 60/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6501 - accuracy: 0.6339 - val_loss: 0.7023 - val_accuracy: 0.5225\n",
            "Epoch 61/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6487 - accuracy: 0.6349 - val_loss: 0.7022 - val_accuracy: 0.5225\n",
            "Epoch 62/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6454 - accuracy: 0.6427 - val_loss: 0.7020 - val_accuracy: 0.5225\n",
            "Epoch 63/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6429 - accuracy: 0.6509 - val_loss: 0.7019 - val_accuracy: 0.5225\n",
            "Epoch 64/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6427 - accuracy: 0.6489 - val_loss: 0.7018 - val_accuracy: 0.5225\n",
            "Epoch 65/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6468 - accuracy: 0.6444 - val_loss: 0.7016 - val_accuracy: 0.5225\n",
            "Epoch 66/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6464 - accuracy: 0.6414 - val_loss: 0.7015 - val_accuracy: 0.5225\n",
            "Epoch 67/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6486 - accuracy: 0.6337 - val_loss: 0.7014 - val_accuracy: 0.5225\n",
            "Epoch 68/200\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.6426 - accuracy: 0.6487 - val_loss: 0.7012 - val_accuracy: 0.5225\n",
            "Epoch 69/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6482 - accuracy: 0.6309 - val_loss: 0.7011 - val_accuracy: 0.5225\n",
            "Epoch 70/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6521 - accuracy: 0.6247 - val_loss: 0.7010 - val_accuracy: 0.5225\n",
            "Epoch 71/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6429 - accuracy: 0.6415 - val_loss: 0.7008 - val_accuracy: 0.5225\n",
            "Epoch 72/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6411 - accuracy: 0.6580 - val_loss: 0.7007 - val_accuracy: 0.5225\n",
            "Epoch 73/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6481 - accuracy: 0.6294 - val_loss: 0.7006 - val_accuracy: 0.5225\n",
            "Epoch 74/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6344 - accuracy: 0.6607 - val_loss: 0.7004 - val_accuracy: 0.5225\n",
            "Epoch 75/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6421 - accuracy: 0.6445 - val_loss: 0.7003 - val_accuracy: 0.5225\n",
            "Epoch 76/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6472 - accuracy: 0.6320 - val_loss: 0.7002 - val_accuracy: 0.5225\n",
            "Epoch 77/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6383 - accuracy: 0.6560 - val_loss: 0.7000 - val_accuracy: 0.5225\n",
            "Epoch 78/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6425 - accuracy: 0.6369 - val_loss: 0.6999 - val_accuracy: 0.5225\n",
            "Epoch 79/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6433 - accuracy: 0.6439 - val_loss: 0.6997 - val_accuracy: 0.5225\n",
            "Epoch 80/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6382 - accuracy: 0.6542 - val_loss: 0.6996 - val_accuracy: 0.5225\n",
            "Epoch 81/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6477 - accuracy: 0.6277 - val_loss: 0.6995 - val_accuracy: 0.5225\n",
            "Epoch 82/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6405 - accuracy: 0.6449 - val_loss: 0.6993 - val_accuracy: 0.5225\n",
            "Epoch 83/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6457 - accuracy: 0.6274 - val_loss: 0.6992 - val_accuracy: 0.5225\n",
            "Epoch 84/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6463 - accuracy: 0.6329 - val_loss: 0.6991 - val_accuracy: 0.5225\n",
            "Epoch 85/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6347 - accuracy: 0.6539 - val_loss: 0.6990 - val_accuracy: 0.5225\n",
            "Epoch 86/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6383 - accuracy: 0.6487 - val_loss: 0.6988 - val_accuracy: 0.5225\n",
            "Epoch 87/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6375 - accuracy: 0.6539 - val_loss: 0.6987 - val_accuracy: 0.5225\n",
            "Epoch 88/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6443 - accuracy: 0.6319 - val_loss: 0.6986 - val_accuracy: 0.5225\n",
            "Epoch 89/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6386 - accuracy: 0.6395 - val_loss: 0.6985 - val_accuracy: 0.5225\n",
            "Epoch 90/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6410 - accuracy: 0.6400 - val_loss: 0.6984 - val_accuracy: 0.5225\n",
            "Epoch 91/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6428 - accuracy: 0.6332 - val_loss: 0.6982 - val_accuracy: 0.5225\n",
            "Epoch 92/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6488 - accuracy: 0.6187 - val_loss: 0.6981 - val_accuracy: 0.5225\n",
            "Epoch 93/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6431 - accuracy: 0.6315 - val_loss: 0.6980 - val_accuracy: 0.5225\n",
            "Epoch 94/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6386 - accuracy: 0.6364 - val_loss: 0.6979 - val_accuracy: 0.5225\n",
            "Epoch 95/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6444 - accuracy: 0.6234 - val_loss: 0.6978 - val_accuracy: 0.5225\n",
            "Epoch 96/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6364 - accuracy: 0.6457 - val_loss: 0.6977 - val_accuracy: 0.5225\n",
            "Epoch 97/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6391 - accuracy: 0.6444 - val_loss: 0.6976 - val_accuracy: 0.5225\n",
            "Epoch 98/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6437 - accuracy: 0.6274 - val_loss: 0.6975 - val_accuracy: 0.5225\n",
            "Epoch 99/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6396 - accuracy: 0.6372 - val_loss: 0.6974 - val_accuracy: 0.5225\n",
            "Epoch 100/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6374 - accuracy: 0.6430 - val_loss: 0.6972 - val_accuracy: 0.5225\n",
            "Epoch 101/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6394 - accuracy: 0.6399 - val_loss: 0.6971 - val_accuracy: 0.5225\n",
            "Epoch 102/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6411 - accuracy: 0.6284 - val_loss: 0.6970 - val_accuracy: 0.5225\n",
            "Epoch 103/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6330 - accuracy: 0.6489 - val_loss: 0.6969 - val_accuracy: 0.5225\n",
            "Epoch 104/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6423 - accuracy: 0.6267 - val_loss: 0.6968 - val_accuracy: 0.5225\n",
            "Epoch 105/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6337 - accuracy: 0.6450 - val_loss: 0.6967 - val_accuracy: 0.5225\n",
            "Epoch 106/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6412 - accuracy: 0.6379 - val_loss: 0.6966 - val_accuracy: 0.5225\n",
            "Epoch 107/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6430 - accuracy: 0.6244 - val_loss: 0.6965 - val_accuracy: 0.5225\n",
            "Epoch 108/200\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6277 - accuracy: 0.6635 - val_loss: 0.6964 - val_accuracy: 0.5225\n",
            "Epoch 109/200\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6366 - accuracy: 0.6424 - val_loss: 0.6963 - val_accuracy: 0.5225\n",
            "Epoch 110/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6343 - accuracy: 0.6389 - val_loss: 0.6961 - val_accuracy: 0.5225\n",
            "Epoch 111/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6399 - accuracy: 0.6334 - val_loss: 0.6960 - val_accuracy: 0.5225\n",
            "Epoch 112/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6371 - accuracy: 0.6375 - val_loss: 0.6959 - val_accuracy: 0.5225\n",
            "Epoch 113/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6400 - accuracy: 0.6310 - val_loss: 0.6958 - val_accuracy: 0.5225\n",
            "Epoch 114/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6357 - accuracy: 0.6389 - val_loss: 0.6957 - val_accuracy: 0.5225\n",
            "Epoch 115/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6342 - accuracy: 0.6455 - val_loss: 0.6956 - val_accuracy: 0.5225\n",
            "Epoch 116/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6373 - accuracy: 0.6320 - val_loss: 0.6955 - val_accuracy: 0.5225\n",
            "Epoch 117/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6399 - accuracy: 0.6340 - val_loss: 0.6954 - val_accuracy: 0.5225\n",
            "Epoch 118/200\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.6313 - accuracy: 0.6512 - val_loss: 0.6953 - val_accuracy: 0.5225\n",
            "Epoch 119/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6345 - accuracy: 0.6370 - val_loss: 0.6952 - val_accuracy: 0.5225\n",
            "Epoch 120/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6366 - accuracy: 0.6310 - val_loss: 0.6951 - val_accuracy: 0.5225\n",
            "Epoch 121/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6401 - accuracy: 0.6259 - val_loss: 0.6950 - val_accuracy: 0.5225\n",
            "Epoch 122/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6289 - accuracy: 0.6459 - val_loss: 0.6949 - val_accuracy: 0.5225\n",
            "Epoch 123/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6299 - accuracy: 0.6482 - val_loss: 0.6947 - val_accuracy: 0.5225\n",
            "Epoch 124/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6292 - accuracy: 0.6455 - val_loss: 0.6946 - val_accuracy: 0.5225\n",
            "Epoch 125/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6192 - accuracy: 0.6692 - val_loss: 0.6945 - val_accuracy: 0.5225\n",
            "Epoch 126/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6304 - accuracy: 0.6405 - val_loss: 0.6944 - val_accuracy: 0.5225\n",
            "Epoch 127/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6237 - accuracy: 0.6584 - val_loss: 0.6942 - val_accuracy: 0.5225\n",
            "Epoch 128/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6271 - accuracy: 0.6469 - val_loss: 0.6941 - val_accuracy: 0.5225\n",
            "Epoch 129/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6267 - accuracy: 0.6442 - val_loss: 0.6940 - val_accuracy: 0.5225\n",
            "Epoch 130/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6318 - accuracy: 0.6367 - val_loss: 0.6939 - val_accuracy: 0.5225\n",
            "Epoch 131/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6291 - accuracy: 0.6459 - val_loss: 0.6938 - val_accuracy: 0.5225\n",
            "Epoch 132/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6265 - accuracy: 0.6464 - val_loss: 0.6937 - val_accuracy: 0.5225\n",
            "Epoch 133/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6311 - accuracy: 0.6387 - val_loss: 0.6936 - val_accuracy: 0.5225\n",
            "Epoch 134/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6299 - accuracy: 0.6425 - val_loss: 0.6934 - val_accuracy: 0.5225\n",
            "Epoch 135/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6276 - accuracy: 0.6414 - val_loss: 0.6933 - val_accuracy: 0.5225\n",
            "Epoch 136/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6311 - accuracy: 0.6407 - val_loss: 0.6932 - val_accuracy: 0.5225\n",
            "Epoch 137/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6322 - accuracy: 0.6312 - val_loss: 0.6931 - val_accuracy: 0.5225\n",
            "Epoch 138/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6380 - accuracy: 0.6204 - val_loss: 0.6930 - val_accuracy: 0.5225\n",
            "Epoch 139/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6273 - accuracy: 0.6517 - val_loss: 0.6929 - val_accuracy: 0.5225\n",
            "Epoch 140/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6312 - accuracy: 0.6410 - val_loss: 0.6928 - val_accuracy: 0.5225\n",
            "Epoch 141/200\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6269 - accuracy: 0.6442 - val_loss: 0.6927 - val_accuracy: 0.5225\n",
            "Epoch 142/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6322 - accuracy: 0.6347 - val_loss: 0.6926 - val_accuracy: 0.5225\n",
            "Epoch 143/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6349 - accuracy: 0.6279 - val_loss: 0.6925 - val_accuracy: 0.5225\n",
            "Epoch 144/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6253 - accuracy: 0.6442 - val_loss: 0.6923 - val_accuracy: 0.5225\n",
            "Epoch 145/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6284 - accuracy: 0.6435 - val_loss: 0.6922 - val_accuracy: 0.5225\n",
            "Epoch 146/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6223 - accuracy: 0.6504 - val_loss: 0.6921 - val_accuracy: 0.5225\n",
            "Epoch 147/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6315 - accuracy: 0.6322 - val_loss: 0.6920 - val_accuracy: 0.5225\n",
            "Epoch 148/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6327 - accuracy: 0.6327 - val_loss: 0.6919 - val_accuracy: 0.5225\n",
            "Epoch 149/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6226 - accuracy: 0.6530 - val_loss: 0.6918 - val_accuracy: 0.5225\n",
            "Epoch 150/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6308 - accuracy: 0.6337 - val_loss: 0.6917 - val_accuracy: 0.5225\n",
            "Epoch 151/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6297 - accuracy: 0.6340 - val_loss: 0.6916 - val_accuracy: 0.5225\n",
            "Epoch 152/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6241 - accuracy: 0.6460 - val_loss: 0.6915 - val_accuracy: 0.5225\n",
            "Epoch 153/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6273 - accuracy: 0.6357 - val_loss: 0.6913 - val_accuracy: 0.5225\n",
            "Epoch 154/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6271 - accuracy: 0.6392 - val_loss: 0.6912 - val_accuracy: 0.5225\n",
            "Epoch 155/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6275 - accuracy: 0.6389 - val_loss: 0.6911 - val_accuracy: 0.5225\n",
            "Epoch 156/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6314 - accuracy: 0.6277 - val_loss: 0.6910 - val_accuracy: 0.5225\n",
            "Epoch 157/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6219 - accuracy: 0.6520 - val_loss: 0.6909 - val_accuracy: 0.5225\n",
            "Epoch 158/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6234 - accuracy: 0.6450 - val_loss: 0.6908 - val_accuracy: 0.5225\n",
            "Epoch 159/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6191 - accuracy: 0.6522 - val_loss: 0.6907 - val_accuracy: 0.5225\n",
            "Epoch 160/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6259 - accuracy: 0.6392 - val_loss: 0.6906 - val_accuracy: 0.5225\n",
            "Epoch 161/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6227 - accuracy: 0.6430 - val_loss: 0.6905 - val_accuracy: 0.5225\n",
            "Epoch 162/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6265 - accuracy: 0.6420 - val_loss: 0.6903 - val_accuracy: 0.5225\n",
            "Epoch 163/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6173 - accuracy: 0.6529 - val_loss: 0.6902 - val_accuracy: 0.5225\n",
            "Epoch 164/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6309 - accuracy: 0.6239 - val_loss: 0.6901 - val_accuracy: 0.5225\n",
            "Epoch 165/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6236 - accuracy: 0.6405 - val_loss: 0.6900 - val_accuracy: 0.5225\n",
            "Epoch 166/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6189 - accuracy: 0.6522 - val_loss: 0.6898 - val_accuracy: 0.5225\n",
            "Epoch 167/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6215 - accuracy: 0.6460 - val_loss: 0.6897 - val_accuracy: 0.5225\n",
            "Epoch 168/200\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.6170 - accuracy: 0.6515 - val_loss: 0.6896 - val_accuracy: 0.5225\n",
            "Epoch 169/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6258 - accuracy: 0.6369 - val_loss: 0.6895 - val_accuracy: 0.5225\n",
            "Epoch 170/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6267 - accuracy: 0.6305 - val_loss: 0.6894 - val_accuracy: 0.5225\n",
            "Epoch 171/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6144 - accuracy: 0.6529 - val_loss: 0.6893 - val_accuracy: 0.5225\n",
            "Epoch 172/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6190 - accuracy: 0.6485 - val_loss: 0.6892 - val_accuracy: 0.5225\n",
            "Epoch 173/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6214 - accuracy: 0.6407 - val_loss: 0.6890 - val_accuracy: 0.5225\n",
            "Epoch 174/200\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6248 - accuracy: 0.6362 - val_loss: 0.6889 - val_accuracy: 0.5225\n",
            "Epoch 175/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6237 - accuracy: 0.6370 - val_loss: 0.6888 - val_accuracy: 0.5225\n",
            "Epoch 176/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6248 - accuracy: 0.6374 - val_loss: 0.6887 - val_accuracy: 0.5225\n",
            "Epoch 177/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6209 - accuracy: 0.6424 - val_loss: 0.6886 - val_accuracy: 0.5225\n",
            "Epoch 178/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6200 - accuracy: 0.6489 - val_loss: 0.6885 - val_accuracy: 0.5225\n",
            "Epoch 179/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6212 - accuracy: 0.6434 - val_loss: 0.6884 - val_accuracy: 0.5225\n",
            "Epoch 180/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6255 - accuracy: 0.6319 - val_loss: 0.6883 - val_accuracy: 0.5225\n",
            "Epoch 181/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6210 - accuracy: 0.6414 - val_loss: 0.6882 - val_accuracy: 0.5225\n",
            "Epoch 182/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6279 - accuracy: 0.6289 - val_loss: 0.6880 - val_accuracy: 0.5225\n",
            "Epoch 183/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6231 - accuracy: 0.6294 - val_loss: 0.6879 - val_accuracy: 0.5225\n",
            "Epoch 184/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6157 - accuracy: 0.6474 - val_loss: 0.6878 - val_accuracy: 0.5225\n",
            "Epoch 185/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6139 - accuracy: 0.6502 - val_loss: 0.6877 - val_accuracy: 0.5225\n",
            "Epoch 186/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6190 - accuracy: 0.6449 - val_loss: 0.6876 - val_accuracy: 0.5225\n",
            "Epoch 187/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6136 - accuracy: 0.6520 - val_loss: 0.6874 - val_accuracy: 0.5225\n",
            "Epoch 188/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6199 - accuracy: 0.6432 - val_loss: 0.6873 - val_accuracy: 0.5225\n",
            "Epoch 189/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6233 - accuracy: 0.6324 - val_loss: 0.6872 - val_accuracy: 0.5225\n",
            "Epoch 190/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6208 - accuracy: 0.6437 - val_loss: 0.6871 - val_accuracy: 0.5225\n",
            "Epoch 191/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6223 - accuracy: 0.6374 - val_loss: 0.6870 - val_accuracy: 0.5225\n",
            "Epoch 192/200\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6173 - accuracy: 0.6465 - val_loss: 0.6868 - val_accuracy: 0.5225\n",
            "Epoch 193/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6181 - accuracy: 0.6410 - val_loss: 0.6867 - val_accuracy: 0.5225\n",
            "Epoch 194/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6186 - accuracy: 0.6414 - val_loss: 0.6866 - val_accuracy: 0.5225\n",
            "Epoch 195/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6325 - accuracy: 0.6170 - val_loss: 0.6865 - val_accuracy: 0.5225\n",
            "Epoch 196/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6108 - accuracy: 0.6545 - val_loss: 0.6864 - val_accuracy: 0.5225\n",
            "Epoch 197/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6156 - accuracy: 0.6485 - val_loss: 0.6863 - val_accuracy: 0.5225\n",
            "Epoch 198/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.6214 - accuracy: 0.6314 - val_loss: 0.6861 - val_accuracy: 0.5225\n",
            "Epoch 199/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6206 - accuracy: 0.6354 - val_loss: 0.6860 - val_accuracy: 0.5225\n",
            "Epoch 200/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6180 - accuracy: 0.6372 - val_loss: 0.6859 - val_accuracy: 0.5225\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyY8ex2MgEsw"
      },
      "source": [
        "Now create a model with 7 layers. The model should have an input layer with unit size 128, then hidden layers of size 128, 64, 64, 32, 32, and an output layer of size 1. Use a sigmoid activation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0Nv70YugEsx"
      },
      "source": [
        "# Answer below\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJbIQ5AgEsy"
      },
      "source": [
        "Fit and compile the model using the SGD optimizer you previously defined, batch size = 80 and epochs = 200"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9B2GhuLgEsz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b05da44d-3979-40dd-ad90-b97e357609f7"
      },
      "source": [
        "# Answer below:\n",
        "model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history3 = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=80, epochs=200, verbose=1)\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "9/9 [==============================] - 1s 29ms/step - loss: 0.6969 - accuracy: 0.3012 - val_loss: 0.6956 - val_accuracy: 0.3764\n",
            "Epoch 2/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6956 - accuracy: 0.3528 - val_loss: 0.6953 - val_accuracy: 0.4270\n",
            "Epoch 3/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6946 - accuracy: 0.3983 - val_loss: 0.6950 - val_accuracy: 0.4101\n",
            "Epoch 4/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6943 - accuracy: 0.3826 - val_loss: 0.6948 - val_accuracy: 0.4213\n",
            "Epoch 5/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6930 - accuracy: 0.4546 - val_loss: 0.6945 - val_accuracy: 0.5562\n",
            "Epoch 6/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6925 - accuracy: 0.6512 - val_loss: 0.6942 - val_accuracy: 0.5169\n",
            "Epoch 7/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6913 - accuracy: 0.6696 - val_loss: 0.6940 - val_accuracy: 0.4888\n",
            "Epoch 8/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6906 - accuracy: 0.6497 - val_loss: 0.6938 - val_accuracy: 0.4944\n",
            "Epoch 9/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6907 - accuracy: 0.6407 - val_loss: 0.6935 - val_accuracy: 0.5225\n",
            "Epoch 10/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6898 - accuracy: 0.6367 - val_loss: 0.6933 - val_accuracy: 0.5225\n",
            "Epoch 11/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6894 - accuracy: 0.6300 - val_loss: 0.6931 - val_accuracy: 0.5225\n",
            "Epoch 12/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6874 - accuracy: 0.6649 - val_loss: 0.6929 - val_accuracy: 0.5225\n",
            "Epoch 13/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6879 - accuracy: 0.6328 - val_loss: 0.6928 - val_accuracy: 0.5225\n",
            "Epoch 14/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6863 - accuracy: 0.6456 - val_loss: 0.6926 - val_accuracy: 0.5225\n",
            "Epoch 15/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6862 - accuracy: 0.6368 - val_loss: 0.6925 - val_accuracy: 0.5225\n",
            "Epoch 16/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6843 - accuracy: 0.6656 - val_loss: 0.6923 - val_accuracy: 0.5225\n",
            "Epoch 17/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6858 - accuracy: 0.6216 - val_loss: 0.6922 - val_accuracy: 0.5225\n",
            "Epoch 18/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6835 - accuracy: 0.6578 - val_loss: 0.6921 - val_accuracy: 0.5225\n",
            "Epoch 19/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6853 - accuracy: 0.6226 - val_loss: 0.6919 - val_accuracy: 0.5225\n",
            "Epoch 20/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6836 - accuracy: 0.6358 - val_loss: 0.6918 - val_accuracy: 0.5225\n",
            "Epoch 21/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6819 - accuracy: 0.6458 - val_loss: 0.6916 - val_accuracy: 0.5225\n",
            "Epoch 22/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6823 - accuracy: 0.6381 - val_loss: 0.6915 - val_accuracy: 0.5225\n",
            "Epoch 23/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6825 - accuracy: 0.6299 - val_loss: 0.6913 - val_accuracy: 0.5225\n",
            "Epoch 24/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6802 - accuracy: 0.6467 - val_loss: 0.6912 - val_accuracy: 0.5225\n",
            "Epoch 25/200\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.6796 - accuracy: 0.6553 - val_loss: 0.6911 - val_accuracy: 0.5225\n",
            "Epoch 26/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6801 - accuracy: 0.6415 - val_loss: 0.6909 - val_accuracy: 0.5225\n",
            "Epoch 27/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6790 - accuracy: 0.6461 - val_loss: 0.6908 - val_accuracy: 0.5225\n",
            "Epoch 28/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6772 - accuracy: 0.6572 - val_loss: 0.6906 - val_accuracy: 0.5225\n",
            "Epoch 29/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6782 - accuracy: 0.6461 - val_loss: 0.6904 - val_accuracy: 0.5225\n",
            "Epoch 30/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6782 - accuracy: 0.6282 - val_loss: 0.6903 - val_accuracy: 0.5225\n",
            "Epoch 31/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6758 - accuracy: 0.6509 - val_loss: 0.6901 - val_accuracy: 0.5225\n",
            "Epoch 32/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6755 - accuracy: 0.6483 - val_loss: 0.6900 - val_accuracy: 0.5225\n",
            "Epoch 33/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6737 - accuracy: 0.6604 - val_loss: 0.6899 - val_accuracy: 0.5225\n",
            "Epoch 34/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6755 - accuracy: 0.6383 - val_loss: 0.6897 - val_accuracy: 0.5225\n",
            "Epoch 35/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6737 - accuracy: 0.6518 - val_loss: 0.6895 - val_accuracy: 0.5225\n",
            "Epoch 36/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6721 - accuracy: 0.6600 - val_loss: 0.6894 - val_accuracy: 0.5225\n",
            "Epoch 37/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6728 - accuracy: 0.6438 - val_loss: 0.6893 - val_accuracy: 0.5225\n",
            "Epoch 38/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6751 - accuracy: 0.6287 - val_loss: 0.6891 - val_accuracy: 0.5225\n",
            "Epoch 39/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6727 - accuracy: 0.6376 - val_loss: 0.6890 - val_accuracy: 0.5225\n",
            "Epoch 40/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6729 - accuracy: 0.6355 - val_loss: 0.6888 - val_accuracy: 0.5225\n",
            "Epoch 41/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6728 - accuracy: 0.6303 - val_loss: 0.6887 - val_accuracy: 0.5225\n",
            "Epoch 42/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6709 - accuracy: 0.6420 - val_loss: 0.6885 - val_accuracy: 0.5225\n",
            "Epoch 43/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6719 - accuracy: 0.6317 - val_loss: 0.6884 - val_accuracy: 0.5225\n",
            "Epoch 44/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6710 - accuracy: 0.6295 - val_loss: 0.6882 - val_accuracy: 0.5225\n",
            "Epoch 45/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6675 - accuracy: 0.6478 - val_loss: 0.6881 - val_accuracy: 0.5225\n",
            "Epoch 46/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6683 - accuracy: 0.6451 - val_loss: 0.6879 - val_accuracy: 0.5225\n",
            "Epoch 47/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6691 - accuracy: 0.6329 - val_loss: 0.6878 - val_accuracy: 0.5225\n",
            "Epoch 48/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6645 - accuracy: 0.6585 - val_loss: 0.6876 - val_accuracy: 0.5225\n",
            "Epoch 49/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6666 - accuracy: 0.6414 - val_loss: 0.6875 - val_accuracy: 0.5225\n",
            "Epoch 50/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6648 - accuracy: 0.6493 - val_loss: 0.6874 - val_accuracy: 0.5225\n",
            "Epoch 51/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6672 - accuracy: 0.6300 - val_loss: 0.6873 - val_accuracy: 0.5225\n",
            "Epoch 52/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6673 - accuracy: 0.6291 - val_loss: 0.6871 - val_accuracy: 0.5225\n",
            "Epoch 53/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6649 - accuracy: 0.6395 - val_loss: 0.6870 - val_accuracy: 0.5225\n",
            "Epoch 54/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6689 - accuracy: 0.6158 - val_loss: 0.6869 - val_accuracy: 0.5225\n",
            "Epoch 55/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6630 - accuracy: 0.6453 - val_loss: 0.6868 - val_accuracy: 0.5225\n",
            "Epoch 56/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6651 - accuracy: 0.6311 - val_loss: 0.6867 - val_accuracy: 0.5225\n",
            "Epoch 57/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6619 - accuracy: 0.6438 - val_loss: 0.6866 - val_accuracy: 0.5225\n",
            "Epoch 58/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6596 - accuracy: 0.6524 - val_loss: 0.6865 - val_accuracy: 0.5225\n",
            "Epoch 59/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6609 - accuracy: 0.6431 - val_loss: 0.6864 - val_accuracy: 0.5225\n",
            "Epoch 60/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6581 - accuracy: 0.6574 - val_loss: 0.6863 - val_accuracy: 0.5225\n",
            "Epoch 61/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6598 - accuracy: 0.6498 - val_loss: 0.6862 - val_accuracy: 0.5225\n",
            "Epoch 62/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6597 - accuracy: 0.6392 - val_loss: 0.6861 - val_accuracy: 0.5225\n",
            "Epoch 63/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6595 - accuracy: 0.6441 - val_loss: 0.6860 - val_accuracy: 0.5225\n",
            "Epoch 64/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6585 - accuracy: 0.6457 - val_loss: 0.6860 - val_accuracy: 0.5225\n",
            "Epoch 65/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6591 - accuracy: 0.6413 - val_loss: 0.6859 - val_accuracy: 0.5225\n",
            "Epoch 66/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6586 - accuracy: 0.6394 - val_loss: 0.6858 - val_accuracy: 0.5225\n",
            "Epoch 67/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6591 - accuracy: 0.6395 - val_loss: 0.6857 - val_accuracy: 0.5225\n",
            "Epoch 68/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6600 - accuracy: 0.6320 - val_loss: 0.6856 - val_accuracy: 0.5225\n",
            "Epoch 69/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6534 - accuracy: 0.6597 - val_loss: 0.6856 - val_accuracy: 0.5225\n",
            "Epoch 70/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6573 - accuracy: 0.6411 - val_loss: 0.6855 - val_accuracy: 0.5225\n",
            "Epoch 71/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6549 - accuracy: 0.6486 - val_loss: 0.6854 - val_accuracy: 0.5225\n",
            "Epoch 72/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6582 - accuracy: 0.6335 - val_loss: 0.6854 - val_accuracy: 0.5225\n",
            "Epoch 73/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6587 - accuracy: 0.6251 - val_loss: 0.6853 - val_accuracy: 0.5225\n",
            "Epoch 74/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6527 - accuracy: 0.6523 - val_loss: 0.6852 - val_accuracy: 0.5225\n",
            "Epoch 75/200\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.6578 - accuracy: 0.6280 - val_loss: 0.6852 - val_accuracy: 0.5225\n",
            "Epoch 76/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6518 - accuracy: 0.6546 - val_loss: 0.6851 - val_accuracy: 0.5225\n",
            "Epoch 77/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6558 - accuracy: 0.6395 - val_loss: 0.6850 - val_accuracy: 0.5225\n",
            "Epoch 78/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6583 - accuracy: 0.6241 - val_loss: 0.6850 - val_accuracy: 0.5225\n",
            "Epoch 79/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6500 - accuracy: 0.6556 - val_loss: 0.6849 - val_accuracy: 0.5225\n",
            "Epoch 80/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6593 - accuracy: 0.6172 - val_loss: 0.6848 - val_accuracy: 0.5225\n",
            "Epoch 81/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6572 - accuracy: 0.6236 - val_loss: 0.6847 - val_accuracy: 0.5225\n",
            "Epoch 82/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6548 - accuracy: 0.6364 - val_loss: 0.6847 - val_accuracy: 0.5225\n",
            "Epoch 83/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6541 - accuracy: 0.6347 - val_loss: 0.6846 - val_accuracy: 0.5225\n",
            "Epoch 84/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6522 - accuracy: 0.6365 - val_loss: 0.6845 - val_accuracy: 0.5225\n",
            "Epoch 85/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6611 - accuracy: 0.6059 - val_loss: 0.6845 - val_accuracy: 0.5225\n",
            "Epoch 86/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6493 - accuracy: 0.6523 - val_loss: 0.6844 - val_accuracy: 0.5225\n",
            "Epoch 87/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6490 - accuracy: 0.6466 - val_loss: 0.6843 - val_accuracy: 0.5225\n",
            "Epoch 88/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6494 - accuracy: 0.6446 - val_loss: 0.6842 - val_accuracy: 0.5225\n",
            "Epoch 89/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6533 - accuracy: 0.6274 - val_loss: 0.6842 - val_accuracy: 0.5225\n",
            "Epoch 90/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6523 - accuracy: 0.6344 - val_loss: 0.6841 - val_accuracy: 0.5225\n",
            "Epoch 91/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6466 - accuracy: 0.6503 - val_loss: 0.6840 - val_accuracy: 0.5225\n",
            "Epoch 92/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6476 - accuracy: 0.6472 - val_loss: 0.6840 - val_accuracy: 0.5225\n",
            "Epoch 93/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6579 - accuracy: 0.6130 - val_loss: 0.6839 - val_accuracy: 0.5225\n",
            "Epoch 94/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6455 - accuracy: 0.6514 - val_loss: 0.6838 - val_accuracy: 0.5225\n",
            "Epoch 95/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6452 - accuracy: 0.6510 - val_loss: 0.6837 - val_accuracy: 0.5225\n",
            "Epoch 96/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6541 - accuracy: 0.6173 - val_loss: 0.6837 - val_accuracy: 0.5225\n",
            "Epoch 97/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6461 - accuracy: 0.6482 - val_loss: 0.6836 - val_accuracy: 0.5225\n",
            "Epoch 98/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6458 - accuracy: 0.6475 - val_loss: 0.6835 - val_accuracy: 0.5225\n",
            "Epoch 99/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6493 - accuracy: 0.6300 - val_loss: 0.6834 - val_accuracy: 0.5225\n",
            "Epoch 100/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6520 - accuracy: 0.6251 - val_loss: 0.6833 - val_accuracy: 0.5225\n",
            "Epoch 101/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6385 - accuracy: 0.6704 - val_loss: 0.6832 - val_accuracy: 0.5225\n",
            "Epoch 102/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6447 - accuracy: 0.6441 - val_loss: 0.6831 - val_accuracy: 0.5225\n",
            "Epoch 103/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6447 - accuracy: 0.6465 - val_loss: 0.6830 - val_accuracy: 0.5225\n",
            "Epoch 104/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6412 - accuracy: 0.6544 - val_loss: 0.6829 - val_accuracy: 0.5225\n",
            "Epoch 105/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6482 - accuracy: 0.6259 - val_loss: 0.6828 - val_accuracy: 0.5225\n",
            "Epoch 106/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6455 - accuracy: 0.6405 - val_loss: 0.6827 - val_accuracy: 0.5225\n",
            "Epoch 107/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6389 - accuracy: 0.6595 - val_loss: 0.6826 - val_accuracy: 0.5225\n",
            "Epoch 108/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6374 - accuracy: 0.6584 - val_loss: 0.6825 - val_accuracy: 0.5225\n",
            "Epoch 109/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6436 - accuracy: 0.6425 - val_loss: 0.6824 - val_accuracy: 0.5225\n",
            "Epoch 110/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6357 - accuracy: 0.6624 - val_loss: 0.6822 - val_accuracy: 0.5225\n",
            "Epoch 111/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6396 - accuracy: 0.6499 - val_loss: 0.6821 - val_accuracy: 0.5225\n",
            "Epoch 112/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6396 - accuracy: 0.6467 - val_loss: 0.6820 - val_accuracy: 0.5225\n",
            "Epoch 113/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.6361 - accuracy: 0.6629 - val_loss: 0.6819 - val_accuracy: 0.5225\n",
            "Epoch 114/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.6377 - accuracy: 0.6511 - val_loss: 0.6817 - val_accuracy: 0.5225\n",
            "Epoch 115/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6407 - accuracy: 0.6423 - val_loss: 0.6816 - val_accuracy: 0.5225\n",
            "Epoch 116/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6374 - accuracy: 0.6539 - val_loss: 0.6815 - val_accuracy: 0.5225\n",
            "Epoch 117/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6389 - accuracy: 0.6412 - val_loss: 0.6813 - val_accuracy: 0.5225\n",
            "Epoch 118/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6337 - accuracy: 0.6624 - val_loss: 0.6812 - val_accuracy: 0.5225\n",
            "Epoch 119/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6351 - accuracy: 0.6525 - val_loss: 0.6811 - val_accuracy: 0.5225\n",
            "Epoch 120/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6406 - accuracy: 0.6378 - val_loss: 0.6809 - val_accuracy: 0.5225\n",
            "Epoch 121/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6466 - accuracy: 0.6181 - val_loss: 0.6808 - val_accuracy: 0.5225\n",
            "Epoch 122/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6355 - accuracy: 0.6545 - val_loss: 0.6806 - val_accuracy: 0.5225\n",
            "Epoch 123/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6335 - accuracy: 0.6543 - val_loss: 0.6805 - val_accuracy: 0.5225\n",
            "Epoch 124/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6288 - accuracy: 0.6701 - val_loss: 0.6803 - val_accuracy: 0.5225\n",
            "Epoch 125/200\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.6425 - accuracy: 0.6285 - val_loss: 0.6801 - val_accuracy: 0.5225\n",
            "Epoch 126/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6324 - accuracy: 0.6580 - val_loss: 0.6799 - val_accuracy: 0.5225\n",
            "Epoch 127/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6421 - accuracy: 0.6311 - val_loss: 0.6798 - val_accuracy: 0.5225\n",
            "Epoch 128/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6418 - accuracy: 0.6244 - val_loss: 0.6796 - val_accuracy: 0.5225\n",
            "Epoch 129/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6358 - accuracy: 0.6417 - val_loss: 0.6794 - val_accuracy: 0.5225\n",
            "Epoch 130/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6446 - accuracy: 0.6108 - val_loss: 0.6792 - val_accuracy: 0.5225\n",
            "Epoch 131/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6361 - accuracy: 0.6415 - val_loss: 0.6790 - val_accuracy: 0.5225\n",
            "Epoch 132/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6364 - accuracy: 0.6366 - val_loss: 0.6789 - val_accuracy: 0.5225\n",
            "Epoch 133/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6301 - accuracy: 0.6544 - val_loss: 0.6787 - val_accuracy: 0.5225\n",
            "Epoch 134/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6335 - accuracy: 0.6446 - val_loss: 0.6785 - val_accuracy: 0.5225\n",
            "Epoch 135/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6244 - accuracy: 0.6727 - val_loss: 0.6783 - val_accuracy: 0.5225\n",
            "Epoch 136/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6325 - accuracy: 0.6449 - val_loss: 0.6781 - val_accuracy: 0.5225\n",
            "Epoch 137/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6362 - accuracy: 0.6323 - val_loss: 0.6779 - val_accuracy: 0.5225\n",
            "Epoch 138/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6344 - accuracy: 0.6381 - val_loss: 0.6777 - val_accuracy: 0.5225\n",
            "Epoch 139/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6243 - accuracy: 0.6682 - val_loss: 0.6775 - val_accuracy: 0.5225\n",
            "Epoch 140/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6419 - accuracy: 0.6136 - val_loss: 0.6773 - val_accuracy: 0.5225\n",
            "Epoch 141/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6324 - accuracy: 0.6439 - val_loss: 0.6770 - val_accuracy: 0.5225\n",
            "Epoch 142/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6243 - accuracy: 0.6606 - val_loss: 0.6768 - val_accuracy: 0.5225\n",
            "Epoch 143/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6250 - accuracy: 0.6573 - val_loss: 0.6766 - val_accuracy: 0.5225\n",
            "Epoch 144/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6342 - accuracy: 0.6297 - val_loss: 0.6764 - val_accuracy: 0.5225\n",
            "Epoch 145/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6334 - accuracy: 0.6360 - val_loss: 0.6762 - val_accuracy: 0.5225\n",
            "Epoch 146/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6214 - accuracy: 0.6614 - val_loss: 0.6760 - val_accuracy: 0.5225\n",
            "Epoch 147/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6320 - accuracy: 0.6381 - val_loss: 0.6758 - val_accuracy: 0.5225\n",
            "Epoch 148/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6326 - accuracy: 0.6335 - val_loss: 0.6755 - val_accuracy: 0.5225\n",
            "Epoch 149/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6327 - accuracy: 0.6273 - val_loss: 0.6753 - val_accuracy: 0.5225\n",
            "Epoch 150/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6210 - accuracy: 0.6549 - val_loss: 0.6751 - val_accuracy: 0.5225\n",
            "Epoch 151/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6325 - accuracy: 0.6352 - val_loss: 0.6748 - val_accuracy: 0.5225\n",
            "Epoch 152/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6293 - accuracy: 0.6404 - val_loss: 0.6746 - val_accuracy: 0.5225\n",
            "Epoch 153/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6199 - accuracy: 0.6568 - val_loss: 0.6743 - val_accuracy: 0.5225\n",
            "Epoch 154/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6264 - accuracy: 0.6394 - val_loss: 0.6741 - val_accuracy: 0.5225\n",
            "Epoch 155/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6226 - accuracy: 0.6489 - val_loss: 0.6738 - val_accuracy: 0.5225\n",
            "Epoch 156/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6292 - accuracy: 0.6310 - val_loss: 0.6736 - val_accuracy: 0.5225\n",
            "Epoch 157/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6324 - accuracy: 0.6206 - val_loss: 0.6733 - val_accuracy: 0.5225\n",
            "Epoch 158/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6291 - accuracy: 0.6293 - val_loss: 0.6731 - val_accuracy: 0.5225\n",
            "Epoch 159/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6216 - accuracy: 0.6515 - val_loss: 0.6728 - val_accuracy: 0.5225\n",
            "Epoch 160/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6304 - accuracy: 0.6214 - val_loss: 0.6725 - val_accuracy: 0.5225\n",
            "Epoch 161/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6240 - accuracy: 0.6360 - val_loss: 0.6723 - val_accuracy: 0.5225\n",
            "Epoch 162/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6174 - accuracy: 0.6563 - val_loss: 0.6720 - val_accuracy: 0.5225\n",
            "Epoch 163/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6108 - accuracy: 0.6768 - val_loss: 0.6717 - val_accuracy: 0.5225\n",
            "Epoch 164/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6166 - accuracy: 0.6527 - val_loss: 0.6714 - val_accuracy: 0.5225\n",
            "Epoch 165/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6279 - accuracy: 0.6210 - val_loss: 0.6712 - val_accuracy: 0.5225\n",
            "Epoch 166/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6257 - accuracy: 0.6278 - val_loss: 0.6709 - val_accuracy: 0.5225\n",
            "Epoch 167/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6230 - accuracy: 0.6387 - val_loss: 0.6706 - val_accuracy: 0.5225\n",
            "Epoch 168/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6259 - accuracy: 0.6264 - val_loss: 0.6703 - val_accuracy: 0.5225\n",
            "Epoch 169/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6263 - accuracy: 0.6268 - val_loss: 0.6700 - val_accuracy: 0.5225\n",
            "Epoch 170/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6161 - accuracy: 0.6516 - val_loss: 0.6698 - val_accuracy: 0.5225\n",
            "Epoch 171/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6254 - accuracy: 0.6289 - val_loss: 0.6695 - val_accuracy: 0.5225\n",
            "Epoch 172/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6128 - accuracy: 0.6492 - val_loss: 0.6692 - val_accuracy: 0.5225\n",
            "Epoch 173/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6215 - accuracy: 0.6358 - val_loss: 0.6690 - val_accuracy: 0.5225\n",
            "Epoch 174/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6147 - accuracy: 0.6437 - val_loss: 0.6687 - val_accuracy: 0.5225\n",
            "Epoch 175/200\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 0.6094 - accuracy: 0.6576 - val_loss: 0.6684 - val_accuracy: 0.5225\n",
            "Epoch 176/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6166 - accuracy: 0.6434 - val_loss: 0.6681 - val_accuracy: 0.5225\n",
            "Epoch 177/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6195 - accuracy: 0.6308 - val_loss: 0.6679 - val_accuracy: 0.5225\n",
            "Epoch 178/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6277 - accuracy: 0.6090 - val_loss: 0.6676 - val_accuracy: 0.5225\n",
            "Epoch 179/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6185 - accuracy: 0.6372 - val_loss: 0.6673 - val_accuracy: 0.5225\n",
            "Epoch 180/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6170 - accuracy: 0.6331 - val_loss: 0.6670 - val_accuracy: 0.5225\n",
            "Epoch 181/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6078 - accuracy: 0.6521 - val_loss: 0.6667 - val_accuracy: 0.5225\n",
            "Epoch 182/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6077 - accuracy: 0.6596 - val_loss: 0.6665 - val_accuracy: 0.5225\n",
            "Epoch 183/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6226 - accuracy: 0.6261 - val_loss: 0.6662 - val_accuracy: 0.5225\n",
            "Epoch 184/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6070 - accuracy: 0.6555 - val_loss: 0.6659 - val_accuracy: 0.5225\n",
            "Epoch 185/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6162 - accuracy: 0.6359 - val_loss: 0.6656 - val_accuracy: 0.5225\n",
            "Epoch 186/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6243 - accuracy: 0.6180 - val_loss: 0.6653 - val_accuracy: 0.5225\n",
            "Epoch 187/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6118 - accuracy: 0.6472 - val_loss: 0.6650 - val_accuracy: 0.5225\n",
            "Epoch 188/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6135 - accuracy: 0.6371 - val_loss: 0.6647 - val_accuracy: 0.5225\n",
            "Epoch 189/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6186 - accuracy: 0.6250 - val_loss: 0.6644 - val_accuracy: 0.5225\n",
            "Epoch 190/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6088 - accuracy: 0.6474 - val_loss: 0.6641 - val_accuracy: 0.5225\n",
            "Epoch 191/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6042 - accuracy: 0.6573 - val_loss: 0.6638 - val_accuracy: 0.5225\n",
            "Epoch 192/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6131 - accuracy: 0.6327 - val_loss: 0.6635 - val_accuracy: 0.5225\n",
            "Epoch 193/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6087 - accuracy: 0.6423 - val_loss: 0.6632 - val_accuracy: 0.5225\n",
            "Epoch 194/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6068 - accuracy: 0.6461 - val_loss: 0.6629 - val_accuracy: 0.5225\n",
            "Epoch 195/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6081 - accuracy: 0.6417 - val_loss: 0.6626 - val_accuracy: 0.5225\n",
            "Epoch 196/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6069 - accuracy: 0.6469 - val_loss: 0.6623 - val_accuracy: 0.5225\n",
            "Epoch 197/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6119 - accuracy: 0.6290 - val_loss: 0.6620 - val_accuracy: 0.5225\n",
            "Epoch 198/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6002 - accuracy: 0.6589 - val_loss: 0.6617 - val_accuracy: 0.5225\n",
            "Epoch 199/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6039 - accuracy: 0.6464 - val_loss: 0.6614 - val_accuracy: 0.5225\n",
            "Epoch 200/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5979 - accuracy: 0.6521 - val_loss: 0.6611 - val_accuracy: 0.5225\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clQxRuz8gEs0"
      },
      "source": [
        "Define a new SGD optimizer with a learning rate of 0.001"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWdxpU9hgEs1"
      },
      "source": [
        "# Answer below:\n",
        "sgd = SGD(lr=0.001)\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dGgoNlrgEs2"
      },
      "source": [
        "Fit and compile the model using this SGD optimizer, batch size = 80 and epochs = 200. Compare to previous results. What do you think went wrong and why?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uRr-yCvgEs3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "615f3fd5-a505-472b-e36a-05d9c6ad3ef0"
      },
      "source": [
        "# Answer below:\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history4 = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=80, epochs=200, verbose=1)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "9/9 [==============================] - 1s 48ms/step - loss: 0.6989 - accuracy: 0.3455 - val_loss: 0.6906 - val_accuracy: 0.4775\n",
            "Epoch 2/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6963 - accuracy: 0.3682 - val_loss: 0.6900 - val_accuracy: 0.4719\n",
            "Epoch 3/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6960 - accuracy: 0.3668 - val_loss: 0.6894 - val_accuracy: 0.4663\n",
            "Epoch 4/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.3668 - val_loss: 0.6887 - val_accuracy: 0.4551\n",
            "Epoch 5/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6911 - accuracy: 0.4718 - val_loss: 0.6881 - val_accuracy: 0.6573\n",
            "Epoch 6/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6907 - accuracy: 0.6237 - val_loss: 0.6876 - val_accuracy: 0.6629\n",
            "Epoch 7/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6892 - accuracy: 0.6582 - val_loss: 0.6872 - val_accuracy: 0.6573\n",
            "Epoch 8/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6882 - accuracy: 0.6891 - val_loss: 0.6868 - val_accuracy: 0.7022\n",
            "Epoch 9/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6872 - accuracy: 0.7417 - val_loss: 0.6865 - val_accuracy: 0.7079\n",
            "Epoch 10/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6859 - accuracy: 0.7499 - val_loss: 0.6861 - val_accuracy: 0.6966\n",
            "Epoch 11/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6846 - accuracy: 0.7219 - val_loss: 0.6858 - val_accuracy: 0.6910\n",
            "Epoch 12/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6845 - accuracy: 0.6890 - val_loss: 0.6855 - val_accuracy: 0.6966\n",
            "Epoch 13/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6832 - accuracy: 0.7144 - val_loss: 0.6853 - val_accuracy: 0.6629\n",
            "Epoch 14/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6819 - accuracy: 0.7287 - val_loss: 0.6851 - val_accuracy: 0.6629\n",
            "Epoch 15/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6807 - accuracy: 0.7248 - val_loss: 0.6848 - val_accuracy: 0.6517\n",
            "Epoch 16/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6804 - accuracy: 0.6998 - val_loss: 0.6846 - val_accuracy: 0.6067\n",
            "Epoch 17/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6800 - accuracy: 0.6833 - val_loss: 0.6844 - val_accuracy: 0.6067\n",
            "Epoch 18/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6794 - accuracy: 0.6706 - val_loss: 0.6842 - val_accuracy: 0.6011\n",
            "Epoch 19/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6792 - accuracy: 0.6620 - val_loss: 0.6840 - val_accuracy: 0.5955\n",
            "Epoch 20/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6777 - accuracy: 0.6737 - val_loss: 0.6838 - val_accuracy: 0.5843\n",
            "Epoch 21/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6770 - accuracy: 0.6847 - val_loss: 0.6836 - val_accuracy: 0.5843\n",
            "Epoch 22/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6762 - accuracy: 0.6789 - val_loss: 0.6834 - val_accuracy: 0.5899\n",
            "Epoch 23/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6751 - accuracy: 0.6774 - val_loss: 0.6832 - val_accuracy: 0.5899\n",
            "Epoch 24/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6745 - accuracy: 0.6771 - val_loss: 0.6830 - val_accuracy: 0.5843\n",
            "Epoch 25/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6735 - accuracy: 0.6801 - val_loss: 0.6828 - val_accuracy: 0.5843\n",
            "Epoch 26/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6729 - accuracy: 0.6839 - val_loss: 0.6827 - val_accuracy: 0.5843\n",
            "Epoch 27/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6716 - accuracy: 0.6841 - val_loss: 0.6825 - val_accuracy: 0.5843\n",
            "Epoch 28/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6753 - accuracy: 0.6392 - val_loss: 0.6823 - val_accuracy: 0.5843\n",
            "Epoch 29/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6728 - accuracy: 0.6594 - val_loss: 0.6822 - val_accuracy: 0.5843\n",
            "Epoch 30/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6688 - accuracy: 0.6931 - val_loss: 0.6820 - val_accuracy: 0.5843\n",
            "Epoch 31/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6724 - accuracy: 0.6513 - val_loss: 0.6818 - val_accuracy: 0.5843\n",
            "Epoch 32/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6721 - accuracy: 0.6449 - val_loss: 0.6817 - val_accuracy: 0.5843\n",
            "Epoch 33/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6699 - accuracy: 0.6560 - val_loss: 0.6815 - val_accuracy: 0.5843\n",
            "Epoch 34/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6676 - accuracy: 0.6814 - val_loss: 0.6814 - val_accuracy: 0.5843\n",
            "Epoch 35/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6676 - accuracy: 0.6725 - val_loss: 0.6813 - val_accuracy: 0.5843\n",
            "Epoch 36/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6656 - accuracy: 0.6773 - val_loss: 0.6811 - val_accuracy: 0.5449\n",
            "Epoch 37/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6678 - accuracy: 0.6497 - val_loss: 0.6810 - val_accuracy: 0.5449\n",
            "Epoch 38/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6666 - accuracy: 0.6603 - val_loss: 0.6808 - val_accuracy: 0.5449\n",
            "Epoch 39/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6653 - accuracy: 0.6639 - val_loss: 0.6807 - val_accuracy: 0.5449\n",
            "Epoch 40/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6650 - accuracy: 0.6635 - val_loss: 0.6805 - val_accuracy: 0.5449\n",
            "Epoch 41/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6621 - accuracy: 0.6630 - val_loss: 0.6804 - val_accuracy: 0.5225\n",
            "Epoch 42/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6654 - accuracy: 0.6383 - val_loss: 0.6803 - val_accuracy: 0.5225\n",
            "Epoch 43/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6646 - accuracy: 0.6388 - val_loss: 0.6802 - val_accuracy: 0.5225\n",
            "Epoch 44/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6613 - accuracy: 0.6553 - val_loss: 0.6801 - val_accuracy: 0.5225\n",
            "Epoch 45/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6608 - accuracy: 0.6591 - val_loss: 0.6799 - val_accuracy: 0.5225\n",
            "Epoch 46/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6598 - accuracy: 0.6611 - val_loss: 0.6798 - val_accuracy: 0.5225\n",
            "Epoch 47/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6637 - accuracy: 0.6337 - val_loss: 0.6797 - val_accuracy: 0.5225\n",
            "Epoch 48/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6617 - accuracy: 0.6410 - val_loss: 0.6796 - val_accuracy: 0.5225\n",
            "Epoch 49/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6592 - accuracy: 0.6474 - val_loss: 0.6795 - val_accuracy: 0.5225\n",
            "Epoch 50/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6619 - accuracy: 0.6340 - val_loss: 0.6794 - val_accuracy: 0.5225\n",
            "Epoch 51/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6606 - accuracy: 0.6354 - val_loss: 0.6793 - val_accuracy: 0.5225\n",
            "Epoch 52/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6596 - accuracy: 0.6349 - val_loss: 0.6791 - val_accuracy: 0.5225\n",
            "Epoch 53/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6595 - accuracy: 0.6387 - val_loss: 0.6790 - val_accuracy: 0.5225\n",
            "Epoch 54/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6601 - accuracy: 0.6283 - val_loss: 0.6789 - val_accuracy: 0.5225\n",
            "Epoch 55/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6575 - accuracy: 0.6428 - val_loss: 0.6788 - val_accuracy: 0.5225\n",
            "Epoch 56/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6570 - accuracy: 0.6406 - val_loss: 0.6787 - val_accuracy: 0.5225\n",
            "Epoch 57/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6558 - accuracy: 0.6512 - val_loss: 0.6786 - val_accuracy: 0.5225\n",
            "Epoch 58/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6560 - accuracy: 0.6438 - val_loss: 0.6785 - val_accuracy: 0.5225\n",
            "Epoch 59/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6527 - accuracy: 0.6600 - val_loss: 0.6784 - val_accuracy: 0.5225\n",
            "Epoch 60/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6577 - accuracy: 0.6368 - val_loss: 0.6783 - val_accuracy: 0.5225\n",
            "Epoch 61/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6576 - accuracy: 0.6291 - val_loss: 0.6783 - val_accuracy: 0.5225\n",
            "Epoch 62/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6562 - accuracy: 0.6372 - val_loss: 0.6782 - val_accuracy: 0.5225\n",
            "Epoch 63/200\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.6526 - accuracy: 0.6467 - val_loss: 0.6781 - val_accuracy: 0.5225\n",
            "Epoch 64/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6538 - accuracy: 0.6447 - val_loss: 0.6780 - val_accuracy: 0.5225\n",
            "Epoch 65/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6502 - accuracy: 0.6603 - val_loss: 0.6779 - val_accuracy: 0.5225\n",
            "Epoch 66/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6557 - accuracy: 0.6345 - val_loss: 0.6778 - val_accuracy: 0.5225\n",
            "Epoch 67/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6557 - accuracy: 0.6335 - val_loss: 0.6777 - val_accuracy: 0.5225\n",
            "Epoch 68/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6497 - accuracy: 0.6495 - val_loss: 0.6777 - val_accuracy: 0.5225\n",
            "Epoch 69/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6541 - accuracy: 0.6370 - val_loss: 0.6776 - val_accuracy: 0.5225\n",
            "Epoch 70/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6477 - accuracy: 0.6571 - val_loss: 0.6775 - val_accuracy: 0.5225\n",
            "Epoch 71/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6528 - accuracy: 0.6350 - val_loss: 0.6774 - val_accuracy: 0.5225\n",
            "Epoch 72/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6528 - accuracy: 0.6380 - val_loss: 0.6773 - val_accuracy: 0.5225\n",
            "Epoch 73/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6500 - accuracy: 0.6419 - val_loss: 0.6773 - val_accuracy: 0.5225\n",
            "Epoch 74/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6513 - accuracy: 0.6302 - val_loss: 0.6772 - val_accuracy: 0.5225\n",
            "Epoch 75/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6513 - accuracy: 0.6359 - val_loss: 0.6771 - val_accuracy: 0.5225\n",
            "Epoch 76/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6465 - accuracy: 0.6536 - val_loss: 0.6770 - val_accuracy: 0.5225\n",
            "Epoch 77/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6516 - accuracy: 0.6346 - val_loss: 0.6769 - val_accuracy: 0.5225\n",
            "Epoch 78/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6478 - accuracy: 0.6371 - val_loss: 0.6769 - val_accuracy: 0.5225\n",
            "Epoch 79/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6429 - accuracy: 0.6672 - val_loss: 0.6768 - val_accuracy: 0.5225\n",
            "Epoch 80/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6509 - accuracy: 0.6282 - val_loss: 0.6767 - val_accuracy: 0.5225\n",
            "Epoch 81/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6441 - accuracy: 0.6551 - val_loss: 0.6767 - val_accuracy: 0.5225\n",
            "Epoch 82/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6465 - accuracy: 0.6540 - val_loss: 0.6766 - val_accuracy: 0.5225\n",
            "Epoch 83/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6484 - accuracy: 0.6424 - val_loss: 0.6765 - val_accuracy: 0.5225\n",
            "Epoch 84/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6500 - accuracy: 0.6242 - val_loss: 0.6764 - val_accuracy: 0.5225\n",
            "Epoch 85/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6469 - accuracy: 0.6462 - val_loss: 0.6764 - val_accuracy: 0.5225\n",
            "Epoch 86/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6421 - accuracy: 0.6593 - val_loss: 0.6763 - val_accuracy: 0.5225\n",
            "Epoch 87/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6485 - accuracy: 0.6295 - val_loss: 0.6762 - val_accuracy: 0.5225\n",
            "Epoch 88/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6450 - accuracy: 0.6405 - val_loss: 0.6761 - val_accuracy: 0.5225\n",
            "Epoch 89/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6424 - accuracy: 0.6560 - val_loss: 0.6761 - val_accuracy: 0.5225\n",
            "Epoch 90/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6387 - accuracy: 0.6651 - val_loss: 0.6760 - val_accuracy: 0.5225\n",
            "Epoch 91/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6382 - accuracy: 0.6703 - val_loss: 0.6759 - val_accuracy: 0.5225\n",
            "Epoch 92/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6433 - accuracy: 0.6380 - val_loss: 0.6758 - val_accuracy: 0.5225\n",
            "Epoch 93/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6452 - accuracy: 0.6368 - val_loss: 0.6757 - val_accuracy: 0.5225\n",
            "Epoch 94/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6459 - accuracy: 0.6347 - val_loss: 0.6756 - val_accuracy: 0.5225\n",
            "Epoch 95/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6494 - accuracy: 0.6125 - val_loss: 0.6756 - val_accuracy: 0.5225\n",
            "Epoch 96/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6450 - accuracy: 0.6373 - val_loss: 0.6755 - val_accuracy: 0.5225\n",
            "Epoch 97/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6412 - accuracy: 0.6469 - val_loss: 0.6754 - val_accuracy: 0.5225\n",
            "Epoch 98/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6400 - accuracy: 0.6485 - val_loss: 0.6753 - val_accuracy: 0.5225\n",
            "Epoch 99/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6344 - accuracy: 0.6693 - val_loss: 0.6752 - val_accuracy: 0.5225\n",
            "Epoch 100/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6533 - accuracy: 0.6025 - val_loss: 0.6752 - val_accuracy: 0.5225\n",
            "Epoch 101/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6440 - accuracy: 0.6354 - val_loss: 0.6751 - val_accuracy: 0.5225\n",
            "Epoch 102/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6321 - accuracy: 0.6760 - val_loss: 0.6750 - val_accuracy: 0.5225\n",
            "Epoch 103/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6354 - accuracy: 0.6551 - val_loss: 0.6749 - val_accuracy: 0.5225\n",
            "Epoch 104/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6429 - accuracy: 0.6312 - val_loss: 0.6748 - val_accuracy: 0.5225\n",
            "Epoch 105/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6443 - accuracy: 0.6273 - val_loss: 0.6747 - val_accuracy: 0.5225\n",
            "Epoch 106/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6419 - accuracy: 0.6318 - val_loss: 0.6746 - val_accuracy: 0.5225\n",
            "Epoch 107/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6451 - accuracy: 0.6234 - val_loss: 0.6745 - val_accuracy: 0.5225\n",
            "Epoch 108/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6392 - accuracy: 0.6412 - val_loss: 0.6745 - val_accuracy: 0.5225\n",
            "Epoch 109/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.6347 - accuracy: 0.6506 - val_loss: 0.6744 - val_accuracy: 0.5225\n",
            "Epoch 110/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6408 - accuracy: 0.6302 - val_loss: 0.6743 - val_accuracy: 0.5225\n",
            "Epoch 111/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6394 - accuracy: 0.6411 - val_loss: 0.6742 - val_accuracy: 0.5225\n",
            "Epoch 112/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6305 - accuracy: 0.6683 - val_loss: 0.6741 - val_accuracy: 0.5225\n",
            "Epoch 113/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6394 - accuracy: 0.6396 - val_loss: 0.6740 - val_accuracy: 0.5225\n",
            "Epoch 114/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6339 - accuracy: 0.6534 - val_loss: 0.6739 - val_accuracy: 0.5225\n",
            "Epoch 115/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6417 - accuracy: 0.6288 - val_loss: 0.6738 - val_accuracy: 0.5225\n",
            "Epoch 116/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6407 - accuracy: 0.6316 - val_loss: 0.6737 - val_accuracy: 0.5225\n",
            "Epoch 117/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6378 - accuracy: 0.6403 - val_loss: 0.6735 - val_accuracy: 0.5225\n",
            "Epoch 118/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6417 - accuracy: 0.6210 - val_loss: 0.6734 - val_accuracy: 0.5225\n",
            "Epoch 119/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6400 - accuracy: 0.6249 - val_loss: 0.6733 - val_accuracy: 0.5225\n",
            "Epoch 120/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6410 - accuracy: 0.6231 - val_loss: 0.6732 - val_accuracy: 0.5225\n",
            "Epoch 121/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6307 - accuracy: 0.6536 - val_loss: 0.6731 - val_accuracy: 0.5225\n",
            "Epoch 122/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6374 - accuracy: 0.6324 - val_loss: 0.6730 - val_accuracy: 0.5225\n",
            "Epoch 123/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6361 - accuracy: 0.6386 - val_loss: 0.6729 - val_accuracy: 0.5225\n",
            "Epoch 124/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6426 - accuracy: 0.6084 - val_loss: 0.6728 - val_accuracy: 0.5225\n",
            "Epoch 125/200\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.6325 - accuracy: 0.6537 - val_loss: 0.6726 - val_accuracy: 0.5225\n",
            "Epoch 126/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6303 - accuracy: 0.6495 - val_loss: 0.6725 - val_accuracy: 0.5225\n",
            "Epoch 127/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6337 - accuracy: 0.6406 - val_loss: 0.6724 - val_accuracy: 0.5225\n",
            "Epoch 128/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6339 - accuracy: 0.6395 - val_loss: 0.6723 - val_accuracy: 0.5225\n",
            "Epoch 129/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6295 - accuracy: 0.6512 - val_loss: 0.6722 - val_accuracy: 0.5225\n",
            "Epoch 130/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6318 - accuracy: 0.6438 - val_loss: 0.6720 - val_accuracy: 0.5225\n",
            "Epoch 131/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6281 - accuracy: 0.6499 - val_loss: 0.6719 - val_accuracy: 0.5225\n",
            "Epoch 132/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6380 - accuracy: 0.6220 - val_loss: 0.6718 - val_accuracy: 0.5225\n",
            "Epoch 133/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6304 - accuracy: 0.6490 - val_loss: 0.6717 - val_accuracy: 0.5225\n",
            "Epoch 134/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6283 - accuracy: 0.6502 - val_loss: 0.6716 - val_accuracy: 0.5225\n",
            "Epoch 135/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6336 - accuracy: 0.6325 - val_loss: 0.6715 - val_accuracy: 0.5225\n",
            "Epoch 136/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6299 - accuracy: 0.6411 - val_loss: 0.6714 - val_accuracy: 0.5225\n",
            "Epoch 137/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6304 - accuracy: 0.6409 - val_loss: 0.6712 - val_accuracy: 0.5225\n",
            "Epoch 138/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6221 - accuracy: 0.6640 - val_loss: 0.6711 - val_accuracy: 0.5225\n",
            "Epoch 139/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6278 - accuracy: 0.6520 - val_loss: 0.6710 - val_accuracy: 0.5225\n",
            "Epoch 140/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6241 - accuracy: 0.6567 - val_loss: 0.6709 - val_accuracy: 0.5225\n",
            "Epoch 141/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6243 - accuracy: 0.6541 - val_loss: 0.6708 - val_accuracy: 0.5225\n",
            "Epoch 142/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6315 - accuracy: 0.6350 - val_loss: 0.6707 - val_accuracy: 0.5225\n",
            "Epoch 143/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6291 - accuracy: 0.6459 - val_loss: 0.6706 - val_accuracy: 0.5225\n",
            "Epoch 144/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6259 - accuracy: 0.6491 - val_loss: 0.6704 - val_accuracy: 0.5225\n",
            "Epoch 145/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6311 - accuracy: 0.6457 - val_loss: 0.6703 - val_accuracy: 0.5225\n",
            "Epoch 146/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6277 - accuracy: 0.6416 - val_loss: 0.6702 - val_accuracy: 0.5225\n",
            "Epoch 147/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.6205 - accuracy: 0.6648 - val_loss: 0.6701 - val_accuracy: 0.5225\n",
            "Epoch 148/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6265 - accuracy: 0.6426 - val_loss: 0.6699 - val_accuracy: 0.5225\n",
            "Epoch 149/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6255 - accuracy: 0.6478 - val_loss: 0.6698 - val_accuracy: 0.5225\n",
            "Epoch 150/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6190 - accuracy: 0.6591 - val_loss: 0.6696 - val_accuracy: 0.5225\n",
            "Epoch 151/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6266 - accuracy: 0.6428 - val_loss: 0.6695 - val_accuracy: 0.5225\n",
            "Epoch 152/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6296 - accuracy: 0.6277 - val_loss: 0.6694 - val_accuracy: 0.5225\n",
            "Epoch 153/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6197 - accuracy: 0.6642 - val_loss: 0.6692 - val_accuracy: 0.5225\n",
            "Epoch 154/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6372 - accuracy: 0.6106 - val_loss: 0.6690 - val_accuracy: 0.5225\n",
            "Epoch 155/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6250 - accuracy: 0.6396 - val_loss: 0.6689 - val_accuracy: 0.5225\n",
            "Epoch 156/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6289 - accuracy: 0.6289 - val_loss: 0.6687 - val_accuracy: 0.5225\n",
            "Epoch 157/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6193 - accuracy: 0.6529 - val_loss: 0.6686 - val_accuracy: 0.5225\n",
            "Epoch 158/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6323 - accuracy: 0.6207 - val_loss: 0.6684 - val_accuracy: 0.5225\n",
            "Epoch 159/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6218 - accuracy: 0.6450 - val_loss: 0.6683 - val_accuracy: 0.5225\n",
            "Epoch 160/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6293 - accuracy: 0.6322 - val_loss: 0.6681 - val_accuracy: 0.5225\n",
            "Epoch 161/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6326 - accuracy: 0.6215 - val_loss: 0.6679 - val_accuracy: 0.5225\n",
            "Epoch 162/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6173 - accuracy: 0.6474 - val_loss: 0.6678 - val_accuracy: 0.5225\n",
            "Epoch 163/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6193 - accuracy: 0.6345 - val_loss: 0.6676 - val_accuracy: 0.5225\n",
            "Epoch 164/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6260 - accuracy: 0.6298 - val_loss: 0.6674 - val_accuracy: 0.5225\n",
            "Epoch 165/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6234 - accuracy: 0.6413 - val_loss: 0.6673 - val_accuracy: 0.5225\n",
            "Epoch 166/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6154 - accuracy: 0.6535 - val_loss: 0.6671 - val_accuracy: 0.5225\n",
            "Epoch 167/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6244 - accuracy: 0.6427 - val_loss: 0.6669 - val_accuracy: 0.5225\n",
            "Epoch 168/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6149 - accuracy: 0.6597 - val_loss: 0.6667 - val_accuracy: 0.5225\n",
            "Epoch 169/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6226 - accuracy: 0.6420 - val_loss: 0.6665 - val_accuracy: 0.5225\n",
            "Epoch 170/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6238 - accuracy: 0.6316 - val_loss: 0.6664 - val_accuracy: 0.5225\n",
            "Epoch 171/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6270 - accuracy: 0.6292 - val_loss: 0.6662 - val_accuracy: 0.5225\n",
            "Epoch 172/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6161 - accuracy: 0.6449 - val_loss: 0.6660 - val_accuracy: 0.5225\n",
            "Epoch 173/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6209 - accuracy: 0.6344 - val_loss: 0.6659 - val_accuracy: 0.5225\n",
            "Epoch 174/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6086 - accuracy: 0.6651 - val_loss: 0.6657 - val_accuracy: 0.5225\n",
            "Epoch 175/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6141 - accuracy: 0.6516 - val_loss: 0.6655 - val_accuracy: 0.5225\n",
            "Epoch 176/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.6066 - accuracy: 0.6662 - val_loss: 0.6653 - val_accuracy: 0.5225\n",
            "Epoch 177/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6177 - accuracy: 0.6423 - val_loss: 0.6651 - val_accuracy: 0.5225\n",
            "Epoch 178/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6206 - accuracy: 0.6358 - val_loss: 0.6649 - val_accuracy: 0.5225\n",
            "Epoch 179/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6161 - accuracy: 0.6418 - val_loss: 0.6648 - val_accuracy: 0.5225\n",
            "Epoch 180/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6123 - accuracy: 0.6460 - val_loss: 0.6646 - val_accuracy: 0.5225\n",
            "Epoch 181/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6082 - accuracy: 0.6671 - val_loss: 0.6644 - val_accuracy: 0.5225\n",
            "Epoch 182/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6105 - accuracy: 0.6533 - val_loss: 0.6642 - val_accuracy: 0.5225\n",
            "Epoch 183/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6223 - accuracy: 0.6238 - val_loss: 0.6640 - val_accuracy: 0.5225\n",
            "Epoch 184/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6131 - accuracy: 0.6403 - val_loss: 0.6638 - val_accuracy: 0.5225\n",
            "Epoch 185/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6130 - accuracy: 0.6401 - val_loss: 0.6636 - val_accuracy: 0.5225\n",
            "Epoch 186/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6181 - accuracy: 0.6324 - val_loss: 0.6634 - val_accuracy: 0.5225\n",
            "Epoch 187/200\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.6018 - accuracy: 0.6684 - val_loss: 0.6632 - val_accuracy: 0.5225\n",
            "Epoch 188/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6059 - accuracy: 0.6542 - val_loss: 0.6630 - val_accuracy: 0.5225\n",
            "Epoch 189/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6223 - accuracy: 0.6161 - val_loss: 0.6629 - val_accuracy: 0.5225\n",
            "Epoch 190/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6002 - accuracy: 0.6751 - val_loss: 0.6626 - val_accuracy: 0.5225\n",
            "Epoch 191/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6166 - accuracy: 0.6308 - val_loss: 0.6624 - val_accuracy: 0.5225\n",
            "Epoch 192/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6136 - accuracy: 0.6331 - val_loss: 0.6622 - val_accuracy: 0.5225\n",
            "Epoch 193/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6094 - accuracy: 0.6423 - val_loss: 0.6620 - val_accuracy: 0.5225\n",
            "Epoch 194/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6184 - accuracy: 0.6169 - val_loss: 0.6618 - val_accuracy: 0.5225\n",
            "Epoch 195/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6102 - accuracy: 0.6445 - val_loss: 0.6616 - val_accuracy: 0.5225\n",
            "Epoch 196/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6151 - accuracy: 0.6313 - val_loss: 0.6614 - val_accuracy: 0.5225\n",
            "Epoch 197/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6117 - accuracy: 0.6369 - val_loss: 0.6612 - val_accuracy: 0.5225\n",
            "Epoch 198/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6069 - accuracy: 0.6426 - val_loss: 0.6610 - val_accuracy: 0.5225\n",
            "Epoch 199/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6128 - accuracy: 0.6387 - val_loss: 0.6608 - val_accuracy: 0.5225\n",
            "Epoch 200/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6170 - accuracy: 0.6358 - val_loss: 0.6606 - val_accuracy: 0.5225\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYYDOgV6mElT",
        "outputId": "fe3f89d9-9ed7-4632-b25f-af6711ad1498",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "df1 = pd.DataFrame(history3.history)\n",
        "df1[['loss','val_loss']].plot()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f24cda1bb00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mDawPgemoBq",
        "outputId": "9528fe82-57e8-41aa-c473-0993ec9f08c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "df2 = pd.DataFrame(history4.history)\n",
        "df2[['loss','val_loss']].plot()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f24cd973ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBk_SyQ0gEs4"
      },
      "source": [
        "Look at the prediction for the training and test data. Print the confusion matrix for the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfKxxtoygEs4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3b6745c-8631-47b3-abe2-0c7f9e492bb8"
      },
      "source": [
        "# a horrible model\n",
        "pred = model.predict(X_test)\n",
        "y_pred = np.where(pred > 0.5, 1, 0).flatten()\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(pred)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.39939553]\n",
            " [0.43902984]\n",
            " [0.33709824]\n",
            " [0.35029444]\n",
            " [0.39777696]\n",
            " [0.37087655]\n",
            " [0.22676045]\n",
            " [0.19414908]\n",
            " [0.4093485 ]\n",
            " [0.35333097]\n",
            " [0.37602973]\n",
            " [0.4149902 ]\n",
            " [0.34463355]\n",
            " [0.35333097]\n",
            " [0.35333097]\n",
            " [0.43792757]\n",
            " [0.39777696]\n",
            " [0.35681784]\n",
            " [0.4104059 ]\n",
            " [0.4093485 ]\n",
            " [0.35029444]\n",
            " [0.37602973]\n",
            " [0.35333097]\n",
            " [0.35029444]\n",
            " [0.35333097]\n",
            " [0.35029444]\n",
            " [0.39939553]\n",
            " [0.39407706]\n",
            " [0.19414908]\n",
            " [0.35333097]\n",
            " [0.43766615]\n",
            " [0.4725978 ]\n",
            " [0.4144572 ]\n",
            " [0.44031858]\n",
            " [0.40814006]\n",
            " [0.43766615]\n",
            " [0.34578192]\n",
            " [0.43766615]\n",
            " [0.35333097]\n",
            " [0.46602845]\n",
            " [0.35333097]\n",
            " [0.46602845]\n",
            " [0.4149902 ]\n",
            " [0.35333097]\n",
            " [0.4093485 ]\n",
            " [0.4144572 ]\n",
            " [0.35029444]\n",
            " [0.40333226]\n",
            " [0.35029444]\n",
            " [0.43766615]\n",
            " [0.4725978 ]\n",
            " [0.37087655]\n",
            " [0.43902984]\n",
            " [0.40814006]\n",
            " [0.35333097]\n",
            " [0.44031858]\n",
            " [0.35333097]\n",
            " [0.37944552]\n",
            " [0.37087655]\n",
            " [0.35333097]\n",
            " [0.35681784]\n",
            " [0.4219591 ]\n",
            " [0.4403186 ]\n",
            " [0.35333097]\n",
            " [0.41246063]\n",
            " [0.43766615]\n",
            " [0.36755973]\n",
            " [0.35029444]\n",
            " [0.35029444]\n",
            " [0.43639645]\n",
            " [0.43902984]\n",
            " [0.3033926 ]\n",
            " [0.4104059 ]\n",
            " [0.4144572 ]\n",
            " [0.37087655]\n",
            " [0.36755973]\n",
            " [0.3555653 ]\n",
            " [0.43902984]\n",
            " [0.35029444]\n",
            " [0.35333097]\n",
            " [0.40333226]\n",
            " [0.35333097]\n",
            " [0.43766615]\n",
            " [0.32819533]\n",
            " [0.35333097]\n",
            " [0.35333097]\n",
            " [0.3385393 ]\n",
            " [0.35333097]\n",
            " [0.44031858]\n",
            " [0.4149902 ]\n",
            " [0.2922367 ]\n",
            " [0.44031858]\n",
            " [0.255323  ]\n",
            " [0.4725978 ]\n",
            " [0.4342282 ]\n",
            " [0.43792754]\n",
            " [0.37087655]\n",
            " [0.29221043]\n",
            " [0.37664276]\n",
            " [0.32181787]\n",
            " [0.37087655]\n",
            " [0.2602117 ]\n",
            " [0.43902984]\n",
            " [0.4725978 ]\n",
            " [0.4219591 ]\n",
            " [0.36755973]\n",
            " [0.23032206]\n",
            " [0.39626372]\n",
            " [0.35333097]\n",
            " [0.35333097]\n",
            " [0.35333097]\n",
            " [0.37087655]\n",
            " [0.4093485 ]\n",
            " [0.35333097]\n",
            " [0.35333097]\n",
            " [0.35333097]\n",
            " [0.37087655]\n",
            " [0.35333097]\n",
            " [0.35333097]\n",
            " [0.4093485 ]\n",
            " [0.4093485 ]\n",
            " [0.35333097]\n",
            " [0.44031858]\n",
            " [0.37087655]\n",
            " [0.35333097]\n",
            " [0.35333097]\n",
            " [0.35333097]\n",
            " [0.43902984]\n",
            " [0.37087655]\n",
            " [0.29838687]\n",
            " [0.4144572 ]\n",
            " [0.37602973]\n",
            " [0.35333097]\n",
            " [0.35333097]\n",
            " [0.4144572 ]\n",
            " [0.35333097]\n",
            " [0.344478  ]\n",
            " [0.43902984]\n",
            " [0.33039957]\n",
            " [0.37087655]\n",
            " [0.35333097]\n",
            " [0.4104059 ]\n",
            " [0.35333097]\n",
            " [0.35029444]\n",
            " [0.4104059 ]\n",
            " [0.42569143]\n",
            " [0.37602973]\n",
            " [0.34077427]\n",
            " [0.44571775]\n",
            " [0.36755973]\n",
            " [0.32644796]\n",
            " [0.4725978 ]\n",
            " [0.40333226]\n",
            " [0.37087655]\n",
            " [0.39407706]\n",
            " [0.35029444]\n",
            " [0.3854125 ]\n",
            " [0.43766615]\n",
            " [0.4149902 ]\n",
            " [0.3397168 ]\n",
            " [0.35333097]\n",
            " [0.37087655]\n",
            " [0.41246063]\n",
            " [0.35333097]\n",
            " [0.4031696 ]\n",
            " [0.35333097]\n",
            " [0.39777696]\n",
            " [0.4144572 ]\n",
            " [0.35333097]\n",
            " [0.43766615]\n",
            " [0.39777696]\n",
            " [0.4093485 ]\n",
            " [0.37087655]\n",
            " [0.37087655]\n",
            " [0.39626372]\n",
            " [0.35333097]\n",
            " [0.35333097]\n",
            " [0.35029444]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGTn7cJtrv-l",
        "outputId": "20e7c3f5-83fe-4a5c-81c7-98199952ea8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "confusion_matrix(y_test,y_pred)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[93,  0],\n",
              "       [85,  0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    }
  ]
}