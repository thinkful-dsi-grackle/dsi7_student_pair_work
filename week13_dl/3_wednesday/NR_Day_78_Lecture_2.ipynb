{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "NR Day 78 Lecture 2",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vEszfzSgGvb"
      },
      "source": [
        "## Day 83 Lecture 2 Assignment\n",
        "\n",
        "In this assignment, we will learn about other optimization algorithms. We will create a neural network and try out the different optimization algorithms and compare their performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grVMFvpMgGvd"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJfwGXExgGvf"
      },
      "source": [
        "In this assignment, we will be using the cancer data that we have worked with in previous lessons. The pre-processed data is loaded below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itA0U381gGvg"
      },
      "source": [
        "cancer = pd.read_csv('https://tf-assets-prod.s3.amazonaws.com/tf-curric/data-science/cancer_processed.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocNzndc-gGvi",
        "outputId": "247913e1-774f-4e7c-8bdf-5f4bd201edfe"
      },
      "source": [
        "cancer.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>diagnosis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
              "0        17.99         10.38          122.80     1001.0          0.11840   \n",
              "1        20.57         17.77          132.90     1326.0          0.08474   \n",
              "2        19.69         21.25          130.00     1203.0          0.10960   \n",
              "3        11.42         20.38           77.58      386.1          0.14250   \n",
              "4        20.29         14.34          135.10     1297.0          0.10030   \n",
              "\n",
              "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
              "0           0.27760          0.3001              0.14710         0.2419   \n",
              "1           0.07864          0.0869              0.07017         0.1812   \n",
              "2           0.15990          0.1974              0.12790         0.2069   \n",
              "3           0.28390          0.2414              0.10520         0.2597   \n",
              "4           0.13280          0.1980              0.10430         0.1809   \n",
              "\n",
              "   fractal_dimension_mean diagnosis  \n",
              "0                 0.07871         M  \n",
              "1                 0.05667         M  \n",
              "2                 0.05999         M  \n",
              "3                 0.09744         M  \n",
              "4                 0.05883         M  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMyeFkQTgGvm"
      },
      "source": [
        "As you may recall, diagnosis is the target variable. One hot encode the diagnosis column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tCQR6LjgGvn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "outputId": "a3aa8e3d-3734-4114-de77-f82f5575fd32"
      },
      "source": [
        "# Answer below:\n",
        "\n",
        "cancer_oh = pd.get_dummies(cancer, columns=['diagnosis'], drop_first=True)\n",
        "cancer_oh"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>diagnosis_M</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     radius_mean  texture_mean  ...  fractal_dimension_mean  diagnosis_M\n",
              "0          17.99         10.38  ...                 0.07871            1\n",
              "1          20.57         17.77  ...                 0.05667            1\n",
              "2          19.69         21.25  ...                 0.05999            1\n",
              "3          11.42         20.38  ...                 0.09744            1\n",
              "4          20.29         14.34  ...                 0.05883            1\n",
              "..           ...           ...  ...                     ...          ...\n",
              "564        21.56         22.39  ...                 0.05623            1\n",
              "565        20.13         28.25  ...                 0.05533            1\n",
              "566        16.60         28.08  ...                 0.05648            1\n",
              "567        20.60         29.33  ...                 0.07016            1\n",
              "568         7.76         24.54  ...                 0.05884            0\n",
              "\n",
              "[569 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcJDxAb7gGvp"
      },
      "source": [
        "Split the data into train and test with 20% of the data in test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9DgU09lgGvq"
      },
      "source": [
        "# Answer below\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = cancer_oh.drop(['diagnosis_M'], axis=1)\n",
        "y = cancer_oh.diagnosis_M\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eghtF43gGvk"
      },
      "source": [
        "Scale all other variables using the standard scaler."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7cjZatEgGvk"
      },
      "source": [
        "# Answer below:\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scale = StandardScaler()\n",
        "X_train_scale = scale.fit_transform(X_train)\n",
        "X_test_scale = scale.transform(X_test)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTOKHMqrgGvr"
      },
      "source": [
        "Generate a sequential model consisting of 5 layers. The layers should be of size 128, 64, 32, 32, 1. Use the appropriate activation for the output layer based on the type of prediction algorithm we are producing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuLbt7X2gGvs"
      },
      "source": [
        "# Answer below\n",
        "\n",
        "def build_model(opt='Adam'):\n",
        "  model = Sequential()\n",
        "  #first\n",
        "  model.add(Dense(128, input_dim=X_train_scale.shape[1], activation='relu'))\n",
        "  model.add(Dense(64, activation='relu'))\n",
        "  model.add(Dense(32, activation='relu'))\n",
        "  model.add(Dense(32, activation='relu'))\n",
        "  #last layer/output\n",
        "  model.add(Dense(1, activation='sigmoid')) #binary\n",
        "\n",
        "  model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLyq5KXtgGvt"
      },
      "source": [
        "Initialize a SGD optimizer with learning rate 0.05 and momentum 0.9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlNXLxoUgGvu"
      },
      "source": [
        "# Answer below:\n",
        "\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "sgd = SGD(learning_rate=0.5, momentum=0.9)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-O0YHk_gGvv"
      },
      "source": [
        "Compile and fit the model using the appropriate loss function and metric and use the optimizers defined above.\n",
        "\n",
        "batch size = 100, epochs = 200"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD9IZdHMgGvw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eb584a9-4f01-4fa8-f6bb-4cef88f478ee"
      },
      "source": [
        "# Answer below:\n",
        "\n",
        "m_sgd = build_model(opt=sgd)\n",
        "\n",
        "\n",
        "h_sgd = m_sgd.fit(X_train_scale, y_train, \n",
        "                            validation_data=(X_test_scale, y_test), batch_size=100, epochs=200)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "5/5 [==============================] - 1s 109ms/step - loss: 0.6643 - accuracy: 0.7580 - val_loss: 0.1245 - val_accuracy: 0.9386\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2514 - accuracy: 0.9227 - val_loss: 0.1033 - val_accuracy: 0.9737\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.7093 - accuracy: 0.8326 - val_loss: 0.1877 - val_accuracy: 0.9298\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4639 - accuracy: 0.8505 - val_loss: 0.5105 - val_accuracy: 0.8421\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6300 - accuracy: 0.8279 - val_loss: 0.2223 - val_accuracy: 0.9386\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 90.3407 - accuracy: 0.8621 - val_loss: 100693744.0000 - val_accuracy: 0.6228\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.5513 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6313 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.6442 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6194 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6161 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6259 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6305 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6519 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6105 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - 0s 38ms/step - loss: nan - accuracy: 0.6481 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6390 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6198 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6027 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6355 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6372 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 22/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6163 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 23/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6372 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 24/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6413 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 25/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6398 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 26/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6488 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 27/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6059 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 28/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6167 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 29/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6361 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 30/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6440 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 31/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6302 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 32/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.6273 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 33/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6331 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 34/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6456 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 35/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6180 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 36/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6237 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 37/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6354 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6409 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6241 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 40/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6541 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6404 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 42/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6220 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6113 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6291 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 45/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6223 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 46/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6394 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 47/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6280 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 48/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6342 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 49/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6156 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 50/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6115 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 51/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6251 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 52/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6384 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 53/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6192 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 54/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.5949 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 55/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6288 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 56/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6608 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 57/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6261 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 58/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6229 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 59/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6502 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 60/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6341 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 61/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6341 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 62/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6274 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 63/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6098 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 64/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6305 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 65/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6238 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 66/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6359 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 67/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.5967 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 68/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6356 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 69/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6266 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 70/200\n",
            "5/5 [==============================] - 0s 38ms/step - loss: nan - accuracy: 0.6351 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 71/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6180 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 72/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6076 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 73/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6401 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 74/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6466 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 75/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: nan - accuracy: 0.6365 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 76/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.6408 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 77/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6220 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 78/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.6276 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 79/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6487 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 80/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6394 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 81/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6141 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 82/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6220 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 83/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6366 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 84/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6308 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 85/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6254 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 86/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6352 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 87/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.6158 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.6365 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 89/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6363 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6349 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 91/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6158 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 92/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6234 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 93/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6180 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 94/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.6437 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 95/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6233 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 96/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.6465 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 97/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6272 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 98/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6361 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 99/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6242 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 100/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6076 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 101/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6179 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 102/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.6340 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 103/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6345 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 104/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.6327 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 105/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.6509 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 106/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6195 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 107/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6349 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 108/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6217 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 109/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6512 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 110/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6191 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 111/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6466 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 112/200\n",
            "5/5 [==============================] - 0s 39ms/step - loss: nan - accuracy: 0.6233 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 113/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.6345 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 114/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6222 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 115/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.5930 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 116/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6344 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 117/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6240 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 118/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6180 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 119/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6079 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 120/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.6183 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 121/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.6165 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 122/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6231 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 123/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6130 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 124/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6266 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 125/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.6317 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 126/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6252 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 127/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.6287 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 128/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6341 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 129/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6213 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 130/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6309 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 131/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6340 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 132/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6387 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 133/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.6227 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 134/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6259 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 135/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6424 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 136/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6254 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 137/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6131 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 138/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.6342 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 139/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6298 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 140/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6151 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 141/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6313 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 142/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6142 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 143/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6108 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 144/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.6276 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 145/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.6376 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 146/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6148 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 147/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6261 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 148/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6201 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 149/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.6167 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 150/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.6379 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 151/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6206 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 152/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6194 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 153/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6290 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 154/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.6234 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 155/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6361 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 156/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6242 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 157/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6352 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 158/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6405 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 159/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.6190 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 160/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6256 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 161/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6181 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 162/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6362 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 163/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.6430 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 164/200\n",
            "5/5 [==============================] - 0s 40ms/step - loss: nan - accuracy: 0.6280 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 165/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6423 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 166/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6341 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 167/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6334 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 168/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6251 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 169/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6236 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 170/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6351 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 171/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6299 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 172/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6236 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 173/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.6338 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 174/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: nan - accuracy: 0.6204 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 175/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6333 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 176/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.6458 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 177/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.6486 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 178/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6336 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 179/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6242 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 180/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6195 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 181/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: nan - accuracy: 0.6347 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 182/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.5917 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 183/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6494 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 184/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.6247 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 185/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6136 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 186/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.6195 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 187/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.6481 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 188/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6562 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 189/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6305 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 190/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6269 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 191/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6187 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 192/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.6119 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 193/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.6184 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 194/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.6280 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 195/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6269 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 196/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6031 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 197/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6229 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 198/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6324 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 199/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6320 - val_loss: nan - val_accuracy: 0.6228\n",
            "Epoch 200/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: nan - accuracy: 0.6167 - val_loss: nan - val_accuracy: 0.6228\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sRBwGzsgGvx"
      },
      "source": [
        "Define the RMSprop optimizer with a learning rate of 0.05."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odyJo-kugGvy"
      },
      "source": [
        "# Answer below:\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "rmsprop = RMSprop(learning_rate=0.05)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7GaEJGugGvz"
      },
      "source": [
        "Compile and fit the model using the optimizer defined above. What do you notice about the accuracy?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "477zsxjvgGv0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88038773-aa6c-4679-cf06-9dd3a98b67d1"
      },
      "source": [
        "# Answer below:\n",
        "\n",
        "model_rmsprop = build_model(opt=rmsprop)\n",
        "\n",
        "\n",
        "histroy_rmsprop = model_rmsprop.fit(X_train_scale, y_train, \n",
        "                                    validation_data=(X_test_scale, y_test), batch_size=100, epochs=200)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "5/5 [==============================] - 1s 77ms/step - loss: 10.1221 - accuracy: 0.5109 - val_loss: 0.4347 - val_accuracy: 0.8947\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3286 - accuracy: 0.8975 - val_loss: 0.1248 - val_accuracy: 0.9561\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1742 - accuracy: 0.9367 - val_loss: 0.0883 - val_accuracy: 0.9649\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1620 - accuracy: 0.9400 - val_loss: 0.0996 - val_accuracy: 0.9649\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1427 - accuracy: 0.9476 - val_loss: 0.1081 - val_accuracy: 0.9649\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1881 - accuracy: 0.9344 - val_loss: 0.1127 - val_accuracy: 0.9737\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1209 - accuracy: 0.9610 - val_loss: 0.1082 - val_accuracy: 0.9474\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1816 - accuracy: 0.9335 - val_loss: 0.1700 - val_accuracy: 0.9211\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1442 - accuracy: 0.9494 - val_loss: 0.1637 - val_accuracy: 0.9298\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1697 - accuracy: 0.9386 - val_loss: 0.0713 - val_accuracy: 0.9737\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0937 - accuracy: 0.9622 - val_loss: 0.0796 - val_accuracy: 0.9825\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0847 - accuracy: 0.9728 - val_loss: 0.1641 - val_accuracy: 0.9737\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1341 - accuracy: 0.9654 - val_loss: 0.0668 - val_accuracy: 0.9825\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1341 - accuracy: 0.9559 - val_loss: 0.0668 - val_accuracy: 0.9825\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0995 - accuracy: 0.9578 - val_loss: 0.0957 - val_accuracy: 0.9649\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0991 - accuracy: 0.9605 - val_loss: 0.3352 - val_accuracy: 0.8596\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2314 - accuracy: 0.9166 - val_loss: 0.0797 - val_accuracy: 0.9825\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0678 - accuracy: 0.9773 - val_loss: 0.1033 - val_accuracy: 0.9561\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0958 - accuracy: 0.9664 - val_loss: 0.0988 - val_accuracy: 0.9649\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1384 - accuracy: 0.9662 - val_loss: 0.0932 - val_accuracy: 0.9737\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0682 - accuracy: 0.9779 - val_loss: 0.1338 - val_accuracy: 0.9649\n",
            "Epoch 22/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0923 - accuracy: 0.9715 - val_loss: 0.1246 - val_accuracy: 0.9649\n",
            "Epoch 23/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1449 - accuracy: 0.9722 - val_loss: 0.3516 - val_accuracy: 0.9386\n",
            "Epoch 24/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3378 - accuracy: 0.9461 - val_loss: 0.1311 - val_accuracy: 0.9474\n",
            "Epoch 25/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0941 - accuracy: 0.9531 - val_loss: 0.1369 - val_accuracy: 0.9737\n",
            "Epoch 26/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0759 - accuracy: 0.9664 - val_loss: 0.0980 - val_accuracy: 0.9649\n",
            "Epoch 27/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0677 - accuracy: 0.9728 - val_loss: 0.2013 - val_accuracy: 0.9123\n",
            "Epoch 28/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1442 - accuracy: 0.9798 - val_loss: 0.1352 - val_accuracy: 0.9474\n",
            "Epoch 29/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0958 - accuracy: 0.9654 - val_loss: 0.0867 - val_accuracy: 0.9825\n",
            "Epoch 30/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0726 - accuracy: 0.9746 - val_loss: 0.2287 - val_accuracy: 0.9561\n",
            "Epoch 31/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3337 - accuracy: 0.9319 - val_loss: 0.1112 - val_accuracy: 0.9561\n",
            "Epoch 32/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0859 - accuracy: 0.9704 - val_loss: 0.0983 - val_accuracy: 0.9737\n",
            "Epoch 33/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0681 - accuracy: 0.9728 - val_loss: 0.0957 - val_accuracy: 0.9737\n",
            "Epoch 34/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0611 - accuracy: 0.9759 - val_loss: 0.2189 - val_accuracy: 0.9474\n",
            "Epoch 35/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1625 - accuracy: 0.9465 - val_loss: 0.0869 - val_accuracy: 0.9825\n",
            "Epoch 36/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0641 - accuracy: 0.9772 - val_loss: 0.2943 - val_accuracy: 0.9474\n",
            "Epoch 37/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0985 - accuracy: 0.9590 - val_loss: 0.1130 - val_accuracy: 0.9474\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0900 - accuracy: 0.9586 - val_loss: 0.0870 - val_accuracy: 0.9825\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0717 - accuracy: 0.9760 - val_loss: 0.0992 - val_accuracy: 0.9825\n",
            "Epoch 40/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0715 - accuracy: 0.9708 - val_loss: 0.1820 - val_accuracy: 0.9474\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0933 - accuracy: 0.9671 - val_loss: 0.1688 - val_accuracy: 0.9123\n",
            "Epoch 42/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1190 - accuracy: 0.9569 - val_loss: 0.1182 - val_accuracy: 0.9561\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0882 - accuracy: 0.9719 - val_loss: 0.1119 - val_accuracy: 0.9561\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0963 - accuracy: 0.9793 - val_loss: 0.1085 - val_accuracy: 0.9737\n",
            "Epoch 45/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0392 - accuracy: 0.9783 - val_loss: 0.2187 - val_accuracy: 0.9561\n",
            "Epoch 46/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1440 - accuracy: 0.9679 - val_loss: 0.0973 - val_accuracy: 0.9737\n",
            "Epoch 47/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0558 - accuracy: 0.9805 - val_loss: 0.0893 - val_accuracy: 0.9737\n",
            "Epoch 48/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0490 - accuracy: 0.9824 - val_loss: 0.0982 - val_accuracy: 0.9737\n",
            "Epoch 49/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0436 - accuracy: 0.9858 - val_loss: 0.1104 - val_accuracy: 0.9561\n",
            "Epoch 50/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0412 - accuracy: 0.9899 - val_loss: 0.2228 - val_accuracy: 0.9561\n",
            "Epoch 51/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4017 - accuracy: 0.9327 - val_loss: 0.1448 - val_accuracy: 0.9737\n",
            "Epoch 52/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2003 - accuracy: 0.9671 - val_loss: 0.2176 - val_accuracy: 0.9561\n",
            "Epoch 53/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0892 - accuracy: 0.9728 - val_loss: 0.1216 - val_accuracy: 0.9737\n",
            "Epoch 54/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0508 - accuracy: 0.9765 - val_loss: 0.1213 - val_accuracy: 0.9561\n",
            "Epoch 55/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0372 - accuracy: 0.9910 - val_loss: 0.1246 - val_accuracy: 0.9561\n",
            "Epoch 56/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0391 - accuracy: 0.9902 - val_loss: 0.1352 - val_accuracy: 0.9649\n",
            "Epoch 57/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0435 - accuracy: 0.9893 - val_loss: 0.2086 - val_accuracy: 0.9649\n",
            "Epoch 58/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0506 - accuracy: 0.9868 - val_loss: 0.1259 - val_accuracy: 0.9649\n",
            "Epoch 59/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0383 - accuracy: 0.9874 - val_loss: 0.1673 - val_accuracy: 0.9561\n",
            "Epoch 60/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0788 - accuracy: 0.9786 - val_loss: 0.1140 - val_accuracy: 0.9649\n",
            "Epoch 61/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0919 - accuracy: 0.9779 - val_loss: 0.0864 - val_accuracy: 0.9737\n",
            "Epoch 62/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0569 - accuracy: 0.9822 - val_loss: 0.1230 - val_accuracy: 0.9649\n",
            "Epoch 63/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0399 - accuracy: 0.9787 - val_loss: 0.1083 - val_accuracy: 0.9474\n",
            "Epoch 64/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0333 - accuracy: 0.9915 - val_loss: 0.1332 - val_accuracy: 0.9561\n",
            "Epoch 65/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0323 - accuracy: 0.9828 - val_loss: 0.2103 - val_accuracy: 0.9737\n",
            "Epoch 66/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0297 - accuracy: 0.9914 - val_loss: 0.3688 - val_accuracy: 0.9649\n",
            "Epoch 67/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1262 - accuracy: 0.9776 - val_loss: 0.3896 - val_accuracy: 0.9474\n",
            "Epoch 68/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1038 - accuracy: 0.9674 - val_loss: 0.0961 - val_accuracy: 0.9825\n",
            "Epoch 69/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0456 - accuracy: 0.9764 - val_loss: 0.1191 - val_accuracy: 0.9561\n",
            "Epoch 70/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0381 - accuracy: 0.9796 - val_loss: 0.2998 - val_accuracy: 0.9474\n",
            "Epoch 71/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0819 - accuracy: 0.9768 - val_loss: 0.1248 - val_accuracy: 0.9737\n",
            "Epoch 72/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0410 - accuracy: 0.9778 - val_loss: 0.1538 - val_accuracy: 0.9737\n",
            "Epoch 73/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0356 - accuracy: 0.9867 - val_loss: 0.1516 - val_accuracy: 0.9737\n",
            "Epoch 74/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0262 - accuracy: 0.9918 - val_loss: 0.1603 - val_accuracy: 0.9561\n",
            "Epoch 75/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0275 - accuracy: 0.9799 - val_loss: 0.2233 - val_accuracy: 0.9649\n",
            "Epoch 76/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1571 - accuracy: 0.9725 - val_loss: 4.0526 - val_accuracy: 0.5702\n",
            "Epoch 77/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.4703 - accuracy: 0.8168 - val_loss: 0.1642 - val_accuracy: 0.9649\n",
            "Epoch 78/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0468 - accuracy: 0.9870 - val_loss: 0.1329 - val_accuracy: 0.9561\n",
            "Epoch 79/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0261 - accuracy: 0.9921 - val_loss: 0.2555 - val_accuracy: 0.9737\n",
            "Epoch 80/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0902 - accuracy: 0.9834 - val_loss: 0.1414 - val_accuracy: 0.9386\n",
            "Epoch 81/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0413 - accuracy: 0.9856 - val_loss: 0.1505 - val_accuracy: 0.9474\n",
            "Epoch 82/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0244 - accuracy: 0.9926 - val_loss: 0.1481 - val_accuracy: 0.9649\n",
            "Epoch 83/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0566 - accuracy: 0.9823 - val_loss: 0.1695 - val_accuracy: 0.9737\n",
            "Epoch 84/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0852 - accuracy: 0.9797 - val_loss: 0.1509 - val_accuracy: 0.9737\n",
            "Epoch 85/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0556 - accuracy: 0.9842 - val_loss: 0.1216 - val_accuracy: 0.9649\n",
            "Epoch 86/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0525 - accuracy: 0.9819 - val_loss: 0.1194 - val_accuracy: 0.9649\n",
            "Epoch 87/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0408 - accuracy: 0.9873 - val_loss: 0.1797 - val_accuracy: 0.9737\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0444 - accuracy: 0.9847 - val_loss: 0.1799 - val_accuracy: 0.9737\n",
            "Epoch 89/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0367 - accuracy: 0.9853 - val_loss: 0.1717 - val_accuracy: 0.9737\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0298 - accuracy: 0.9914 - val_loss: 0.2185 - val_accuracy: 0.9737\n",
            "Epoch 91/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0344 - accuracy: 0.9862 - val_loss: 0.1783 - val_accuracy: 0.9649\n",
            "Epoch 92/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1193 - accuracy: 0.9661 - val_loss: 0.1362 - val_accuracy: 0.9649\n",
            "Epoch 93/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0211 - accuracy: 0.9945 - val_loss: 0.6808 - val_accuracy: 0.9474\n",
            "Epoch 94/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0457 - accuracy: 0.9768 - val_loss: 0.1084 - val_accuracy: 0.9649\n",
            "Epoch 95/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0665 - accuracy: 0.9735 - val_loss: 0.1596 - val_accuracy: 0.9737\n",
            "Epoch 96/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0254 - accuracy: 0.9912 - val_loss: 0.2044 - val_accuracy: 0.9561\n",
            "Epoch 97/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0396 - accuracy: 0.9820 - val_loss: 0.2812 - val_accuracy: 0.9649\n",
            "Epoch 98/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0320 - accuracy: 0.9948 - val_loss: 0.7217 - val_accuracy: 0.9035\n",
            "Epoch 99/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 6.2046 - accuracy: 0.8392 - val_loss: 0.3045 - val_accuracy: 0.9649\n",
            "Epoch 100/200\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.1181 - accuracy: 0.9674 - val_loss: 0.1889 - val_accuracy: 0.9737\n",
            "Epoch 101/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0729 - accuracy: 0.9821 - val_loss: 0.1429 - val_accuracy: 0.9386\n",
            "Epoch 102/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0678 - accuracy: 0.9712 - val_loss: 0.1775 - val_accuracy: 0.9737\n",
            "Epoch 103/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0399 - accuracy: 0.9897 - val_loss: 0.1693 - val_accuracy: 0.9737\n",
            "Epoch 104/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0576 - accuracy: 0.9841 - val_loss: 0.1840 - val_accuracy: 0.9737\n",
            "Epoch 105/200\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0313 - accuracy: 0.9892 - val_loss: 0.1712 - val_accuracy: 0.9474\n",
            "Epoch 106/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0568 - accuracy: 0.9795 - val_loss: 0.1895 - val_accuracy: 0.9737\n",
            "Epoch 107/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0268 - accuracy: 0.9888 - val_loss: 0.3119 - val_accuracy: 0.9649\n",
            "Epoch 108/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2157 - accuracy: 0.9349 - val_loss: 0.4131 - val_accuracy: 0.9474\n",
            "Epoch 109/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1868 - accuracy: 0.9794 - val_loss: 0.2955 - val_accuracy: 0.9649\n",
            "Epoch 110/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0410 - accuracy: 0.9870 - val_loss: 0.2687 - val_accuracy: 0.9474\n",
            "Epoch 111/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0233 - accuracy: 0.9895 - val_loss: 0.2700 - val_accuracy: 0.9561\n",
            "Epoch 112/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0237 - accuracy: 0.9870 - val_loss: 0.3037 - val_accuracy: 0.9474\n",
            "Epoch 113/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0242 - accuracy: 0.9923 - val_loss: 0.3214 - val_accuracy: 0.9649\n",
            "Epoch 114/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0244 - accuracy: 0.9892 - val_loss: 0.2345 - val_accuracy: 0.9474\n",
            "Epoch 115/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0278 - accuracy: 0.9886 - val_loss: 0.2292 - val_accuracy: 0.9386\n",
            "Epoch 116/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0244 - accuracy: 0.9890 - val_loss: 0.3058 - val_accuracy: 0.9561\n",
            "Epoch 117/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0217 - accuracy: 0.9930 - val_loss: 0.3028 - val_accuracy: 0.9474\n",
            "Epoch 118/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1314 - accuracy: 0.9794 - val_loss: 0.2693 - val_accuracy: 0.9649\n",
            "Epoch 119/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0744 - accuracy: 0.9777 - val_loss: 0.1351 - val_accuracy: 0.9474\n",
            "Epoch 120/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0333 - accuracy: 0.9918 - val_loss: 0.1893 - val_accuracy: 0.9737\n",
            "Epoch 121/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0212 - accuracy: 0.9904 - val_loss: 0.4394 - val_accuracy: 0.9737\n",
            "Epoch 122/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3576 - accuracy: 0.9615 - val_loss: 0.6987 - val_accuracy: 0.9123\n",
            "Epoch 123/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1984 - accuracy: 0.9516 - val_loss: 0.1794 - val_accuracy: 0.9474\n",
            "Epoch 124/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0473 - accuracy: 0.9906 - val_loss: 0.2690 - val_accuracy: 0.9561\n",
            "Epoch 125/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0275 - accuracy: 0.9935 - val_loss: 0.3075 - val_accuracy: 0.9474\n",
            "Epoch 126/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0170 - accuracy: 0.9967 - val_loss: 0.4206 - val_accuracy: 0.9561\n",
            "Epoch 127/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0137 - accuracy: 0.9946 - val_loss: 0.2876 - val_accuracy: 0.9298\n",
            "Epoch 128/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0171 - accuracy: 0.9958 - val_loss: 0.6522 - val_accuracy: 0.9386\n",
            "Epoch 129/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2853 - accuracy: 0.9620 - val_loss: 0.3995 - val_accuracy: 0.9737\n",
            "Epoch 130/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0454 - accuracy: 0.9936 - val_loss: 0.4443 - val_accuracy: 0.9649\n",
            "Epoch 131/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0353 - accuracy: 0.9855 - val_loss: 0.2947 - val_accuracy: 0.9386\n",
            "Epoch 132/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0177 - accuracy: 0.9880 - val_loss: 0.3119 - val_accuracy: 0.9561\n",
            "Epoch 133/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0129 - accuracy: 0.9976 - val_loss: 0.3910 - val_accuracy: 0.9649\n",
            "Epoch 134/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0419 - accuracy: 0.9914 - val_loss: 5.8761 - val_accuracy: 0.4474\n",
            "Epoch 135/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.7531 - accuracy: 0.8029 - val_loss: 0.1907 - val_accuracy: 0.9474\n",
            "Epoch 136/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0530 - accuracy: 0.9805 - val_loss: 0.2109 - val_accuracy: 0.9298\n",
            "Epoch 137/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0257 - accuracy: 0.9890 - val_loss: 0.1872 - val_accuracy: 0.9561\n",
            "Epoch 138/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0192 - accuracy: 0.9897 - val_loss: 0.1951 - val_accuracy: 0.9561\n",
            "Epoch 139/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0164 - accuracy: 0.9899 - val_loss: 0.2192 - val_accuracy: 0.9561\n",
            "Epoch 140/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0173 - accuracy: 0.9933 - val_loss: 0.2398 - val_accuracy: 0.9561\n",
            "Epoch 141/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 0.2792 - val_accuracy: 0.9561\n",
            "Epoch 142/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.3634 - val_accuracy: 0.9649\n",
            "Epoch 143/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1905 - accuracy: 0.9851 - val_loss: 0.5164 - val_accuracy: 0.9649\n",
            "Epoch 144/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1167 - accuracy: 0.9874 - val_loss: 0.4224 - val_accuracy: 0.9561\n",
            "Epoch 145/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0276 - accuracy: 0.9927 - val_loss: 0.3068 - val_accuracy: 0.9649\n",
            "Epoch 146/200\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.0234 - accuracy: 0.9894 - val_loss: 0.2053 - val_accuracy: 0.9561\n",
            "Epoch 147/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0184 - accuracy: 0.9963 - val_loss: 0.2938 - val_accuracy: 0.9737\n",
            "Epoch 148/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0203 - accuracy: 0.9921 - val_loss: 0.2954 - val_accuracy: 0.9561\n",
            "Epoch 149/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0132 - accuracy: 0.9967 - val_loss: 0.3395 - val_accuracy: 0.9561\n",
            "Epoch 150/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.3384 - val_accuracy: 0.9561\n",
            "Epoch 151/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0106 - accuracy: 0.9975 - val_loss: 0.3826 - val_accuracy: 0.9561\n",
            "Epoch 152/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0069 - accuracy: 0.9971 - val_loss: 0.4837 - val_accuracy: 0.9649\n",
            "Epoch 153/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0212 - accuracy: 0.9887 - val_loss: 0.4551 - val_accuracy: 0.9649\n",
            "Epoch 154/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0378 - accuracy: 0.9851 - val_loss: 0.3815 - val_accuracy: 0.9649\n",
            "Epoch 155/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0736 - accuracy: 0.9670 - val_loss: 0.4195 - val_accuracy: 0.9123\n",
            "Epoch 156/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1022 - accuracy: 0.9735 - val_loss: 0.4784 - val_accuracy: 0.9649\n",
            "Epoch 157/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0418 - accuracy: 0.9913 - val_loss: 0.7196 - val_accuracy: 0.9211\n",
            "Epoch 158/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 10.1229 - accuracy: 0.8792 - val_loss: 0.2161 - val_accuracy: 0.9474\n",
            "Epoch 159/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1612 - accuracy: 0.9599 - val_loss: 0.1743 - val_accuracy: 0.9386\n",
            "Epoch 160/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0684 - accuracy: 0.9843 - val_loss: 0.2120 - val_accuracy: 0.9474\n",
            "Epoch 161/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0522 - accuracy: 0.9807 - val_loss: 0.3255 - val_accuracy: 0.9386\n",
            "Epoch 162/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0247 - accuracy: 0.9922 - val_loss: 0.3568 - val_accuracy: 0.9561\n",
            "Epoch 163/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.3929 - val_accuracy: 0.9649\n",
            "Epoch 164/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0179 - accuracy: 0.9933 - val_loss: 0.3983 - val_accuracy: 0.9649\n",
            "Epoch 165/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 0.3192 - val_accuracy: 0.9123\n",
            "Epoch 166/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2427 - accuracy: 0.9277 - val_loss: 0.2051 - val_accuracy: 0.9561\n",
            "Epoch 167/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0249 - accuracy: 0.9876 - val_loss: 0.2626 - val_accuracy: 0.9561\n",
            "Epoch 168/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0432 - accuracy: 0.9825 - val_loss: 0.2536 - val_accuracy: 0.9561\n",
            "Epoch 169/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0121 - accuracy: 0.9967 - val_loss: 0.3070 - val_accuracy: 0.9737\n",
            "Epoch 170/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0075 - accuracy: 0.9993 - val_loss: 0.3466 - val_accuracy: 0.9649\n",
            "Epoch 171/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.3472 - val_accuracy: 0.9649\n",
            "Epoch 172/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0185 - accuracy: 0.9916 - val_loss: 0.3564 - val_accuracy: 0.9649\n",
            "Epoch 173/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0087 - accuracy: 0.9958 - val_loss: 0.3973 - val_accuracy: 0.9649\n",
            "Epoch 174/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0069 - accuracy: 0.9970 - val_loss: 0.3697 - val_accuracy: 0.9649\n",
            "Epoch 175/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0275 - accuracy: 0.9945 - val_loss: 0.1899 - val_accuracy: 0.9035\n",
            "Epoch 176/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2082 - accuracy: 0.9457 - val_loss: 0.2676 - val_accuracy: 0.9386\n",
            "Epoch 177/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0316 - accuracy: 0.9834 - val_loss: 0.3342 - val_accuracy: 0.9649\n",
            "Epoch 178/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0175 - accuracy: 0.9958 - val_loss: 0.4059 - val_accuracy: 0.9649\n",
            "Epoch 179/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0129 - accuracy: 0.9983 - val_loss: 0.4174 - val_accuracy: 0.9649\n",
            "Epoch 180/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.4499 - val_accuracy: 0.9649\n",
            "Epoch 181/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0043 - accuracy: 0.9993 - val_loss: 0.6425 - val_accuracy: 0.9649\n",
            "Epoch 182/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3572 - accuracy: 0.9855 - val_loss: 0.5574 - val_accuracy: 0.9561\n",
            "Epoch 183/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0093 - accuracy: 0.9985 - val_loss: 0.5898 - val_accuracy: 0.9649\n",
            "Epoch 184/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0116 - accuracy: 0.9958 - val_loss: 0.5662 - val_accuracy: 0.9561\n",
            "Epoch 185/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0116 - accuracy: 0.9941 - val_loss: 0.9320 - val_accuracy: 0.9561\n",
            "Epoch 186/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 1.3303 - val_accuracy: 0.9561\n",
            "Epoch 187/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 1.7540 - val_accuracy: 0.9649\n",
            "Epoch 188/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0059 - accuracy: 0.9975 - val_loss: 1.7542 - val_accuracy: 0.9649\n",
            "Epoch 189/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0099 - accuracy: 0.9958 - val_loss: 1.7543 - val_accuracy: 0.9649\n",
            "Epoch 190/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 1.7544 - val_accuracy: 0.9649\n",
            "Epoch 191/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0068 - accuracy: 0.9975 - val_loss: 1.7546 - val_accuracy: 0.9649\n",
            "Epoch 192/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 1.7553 - val_accuracy: 0.9649\n",
            "Epoch 193/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 1.7555 - val_accuracy: 0.9649\n",
            "Epoch 194/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 1.7556 - val_accuracy: 0.9649\n",
            "Epoch 195/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 1.7562 - val_accuracy: 0.9649\n",
            "Epoch 196/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0061 - accuracy: 0.9975 - val_loss: 1.7572 - val_accuracy: 0.9649\n",
            "Epoch 197/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 1.7598 - val_accuracy: 0.9649\n",
            "Epoch 198/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0063 - accuracy: 0.9975 - val_loss: 1.7618 - val_accuracy: 0.9649\n",
            "Epoch 199/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0105 - accuracy: 0.9958 - val_loss: 1.7641 - val_accuracy: 0.9649\n",
            "Epoch 200/200\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 1.7673 - val_accuracy: 0.9649\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3KhWb3igGv1"
      },
      "source": [
        "Define the Adam optimizer with learning rate 0.01"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewtmWJI3gGv1"
      },
      "source": [
        "# Answer below:\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "adam = Adam(learning_rate=0.01)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnxqbb7CgGv3"
      },
      "source": [
        "Compile and fit the model using the optimizer defined above. How does the peformance differ with this optimizer?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rG9-9Nk4gGv3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39f96671-00e3-4184-cf49-eb522b9175c0"
      },
      "source": [
        "# Answer below:\n",
        "\n",
        "model_adam = build_model(opt=adam)\n",
        "\n",
        "#fitting\n",
        "hist_adam = model_adam.fit(X_train_scale, y_train, \n",
        "                           validation_data=(X_test_scale, y_test), batch_size=100, epochs=200)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "5/5 [==============================] - 1s 45ms/step - loss: 0.5239 - accuracy: 0.8366 - val_loss: 0.0989 - val_accuracy: 0.9561\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1759 - accuracy: 0.9319 - val_loss: 0.0932 - val_accuracy: 0.9561\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1386 - accuracy: 0.9393 - val_loss: 0.0924 - val_accuracy: 0.9737\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1060 - accuracy: 0.9541 - val_loss: 0.0815 - val_accuracy: 0.9825\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1106 - accuracy: 0.9500 - val_loss: 0.0802 - val_accuracy: 0.9825\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0990 - accuracy: 0.9581 - val_loss: 0.0757 - val_accuracy: 0.9825\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0851 - accuracy: 0.9645 - val_loss: 0.0836 - val_accuracy: 0.9737\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0810 - accuracy: 0.9689 - val_loss: 0.0947 - val_accuracy: 0.9737\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0663 - accuracy: 0.9799 - val_loss: 0.0853 - val_accuracy: 0.9825\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0721 - accuracy: 0.9706 - val_loss: 0.0855 - val_accuracy: 0.9825\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0638 - accuracy: 0.9725 - val_loss: 0.0897 - val_accuracy: 0.9737\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0494 - accuracy: 0.9830 - val_loss: 0.1002 - val_accuracy: 0.9737\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0366 - accuracy: 0.9873 - val_loss: 0.1108 - val_accuracy: 0.9649\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0791 - accuracy: 0.9780 - val_loss: 0.1125 - val_accuracy: 0.9649\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0732 - accuracy: 0.9718 - val_loss: 0.1973 - val_accuracy: 0.9386\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1128 - accuracy: 0.9627 - val_loss: 0.0733 - val_accuracy: 0.9825\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0678 - accuracy: 0.9653 - val_loss: 0.0733 - val_accuracy: 0.9737\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0594 - accuracy: 0.9749 - val_loss: 0.0701 - val_accuracy: 0.9737\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0347 - accuracy: 0.9882 - val_loss: 0.0889 - val_accuracy: 0.9737\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0490 - accuracy: 0.9844 - val_loss: 0.1010 - val_accuracy: 0.9737\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0426 - accuracy: 0.9874 - val_loss: 0.1229 - val_accuracy: 0.9649\n",
            "Epoch 22/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0271 - accuracy: 0.9902 - val_loss: 0.1198 - val_accuracy: 0.9649\n",
            "Epoch 23/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0266 - accuracy: 0.9943 - val_loss: 0.1238 - val_accuracy: 0.9649\n",
            "Epoch 24/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0228 - accuracy: 0.9916 - val_loss: 0.1307 - val_accuracy: 0.9737\n",
            "Epoch 25/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0218 - accuracy: 0.9926 - val_loss: 0.1423 - val_accuracy: 0.9737\n",
            "Epoch 26/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0305 - accuracy: 0.9822 - val_loss: 0.1291 - val_accuracy: 0.9649\n",
            "Epoch 27/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0486 - accuracy: 0.9841 - val_loss: 0.0942 - val_accuracy: 0.9737\n",
            "Epoch 28/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0322 - accuracy: 0.9902 - val_loss: 0.1061 - val_accuracy: 0.9649\n",
            "Epoch 29/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0311 - accuracy: 0.9888 - val_loss: 0.1362 - val_accuracy: 0.9737\n",
            "Epoch 30/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0448 - accuracy: 0.9764 - val_loss: 0.1516 - val_accuracy: 0.9561\n",
            "Epoch 31/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0212 - accuracy: 0.9924 - val_loss: 0.1205 - val_accuracy: 0.9737\n",
            "Epoch 32/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0216 - accuracy: 0.9912 - val_loss: 0.1242 - val_accuracy: 0.9737\n",
            "Epoch 33/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0175 - accuracy: 0.9956 - val_loss: 0.1572 - val_accuracy: 0.9649\n",
            "Epoch 34/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0147 - accuracy: 0.9966 - val_loss: 0.1773 - val_accuracy: 0.9649\n",
            "Epoch 35/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0130 - accuracy: 0.9941 - val_loss: 0.2044 - val_accuracy: 0.9561\n",
            "Epoch 36/200\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0068 - accuracy: 0.9989 - val_loss: 0.2185 - val_accuracy: 0.9737\n",
            "Epoch 37/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.2410 - val_accuracy: 0.9561\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0089 - accuracy: 0.9957 - val_loss: 0.2707 - val_accuracy: 0.9737\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0264 - accuracy: 0.9925 - val_loss: 0.2567 - val_accuracy: 0.9737\n",
            "Epoch 40/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0218 - accuracy: 0.9941 - val_loss: 0.2600 - val_accuracy: 0.9649\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0356 - accuracy: 0.9870 - val_loss: 0.3543 - val_accuracy: 0.9298\n",
            "Epoch 42/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1686 - accuracy: 0.9650 - val_loss: 0.2103 - val_accuracy: 0.9386\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1233 - accuracy: 0.9756 - val_loss: 0.1614 - val_accuracy: 0.9737\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1701 - accuracy: 0.9582 - val_loss: 0.1301 - val_accuracy: 0.9561\n",
            "Epoch 45/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0797 - accuracy: 0.9789 - val_loss: 0.1113 - val_accuracy: 0.9649\n",
            "Epoch 46/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1135 - accuracy: 0.9635 - val_loss: 0.0904 - val_accuracy: 0.9737\n",
            "Epoch 47/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0733 - accuracy: 0.9793 - val_loss: 0.0785 - val_accuracy: 0.9825\n",
            "Epoch 48/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0551 - accuracy: 0.9748 - val_loss: 0.0893 - val_accuracy: 0.9649\n",
            "Epoch 49/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0465 - accuracy: 0.9806 - val_loss: 0.1121 - val_accuracy: 0.9561\n",
            "Epoch 50/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0391 - accuracy: 0.9856 - val_loss: 0.1248 - val_accuracy: 0.9737\n",
            "Epoch 51/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0262 - accuracy: 0.9920 - val_loss: 0.1409 - val_accuracy: 0.9649\n",
            "Epoch 52/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0299 - accuracy: 0.9921 - val_loss: 0.1405 - val_accuracy: 0.9649\n",
            "Epoch 53/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0218 - accuracy: 0.9885 - val_loss: 0.1400 - val_accuracy: 0.9649\n",
            "Epoch 54/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0258 - accuracy: 0.9916 - val_loss: 0.1498 - val_accuracy: 0.9561\n",
            "Epoch 55/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0142 - accuracy: 0.9971 - val_loss: 0.1722 - val_accuracy: 0.9649\n",
            "Epoch 56/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.1878 - val_accuracy: 0.9649\n",
            "Epoch 57/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0170 - accuracy: 0.9929 - val_loss: 0.1919 - val_accuracy: 0.9561\n",
            "Epoch 58/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 0.1984 - val_accuracy: 0.9649\n",
            "Epoch 59/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0155 - accuracy: 0.9939 - val_loss: 0.1778 - val_accuracy: 0.9649\n",
            "Epoch 60/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0138 - accuracy: 0.9975 - val_loss: 0.2152 - val_accuracy: 0.9649\n",
            "Epoch 61/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.2130 - val_accuracy: 0.9649\n",
            "Epoch 62/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0084 - accuracy: 0.9967 - val_loss: 0.2053 - val_accuracy: 0.9737\n",
            "Epoch 63/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0125 - accuracy: 0.9921 - val_loss: 0.1753 - val_accuracy: 0.9561\n",
            "Epoch 64/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0063 - accuracy: 0.9966 - val_loss: 0.1760 - val_accuracy: 0.9737\n",
            "Epoch 65/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0048 - accuracy: 0.9967 - val_loss: 0.1968 - val_accuracy: 0.9561\n",
            "Epoch 66/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0053 - accuracy: 0.9989 - val_loss: 0.2234 - val_accuracy: 0.9649\n",
            "Epoch 67/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.2363 - val_accuracy: 0.9649\n",
            "Epoch 68/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.2395 - val_accuracy: 0.9561\n",
            "Epoch 69/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.2490 - val_accuracy: 0.9561\n",
            "Epoch 70/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0081 - accuracy: 0.9971 - val_loss: 0.2423 - val_accuracy: 0.9561\n",
            "Epoch 71/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.2432 - val_accuracy: 0.9649\n",
            "Epoch 72/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0055 - accuracy: 0.9942 - val_loss: 0.2517 - val_accuracy: 0.9649\n",
            "Epoch 73/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0027 - accuracy: 0.9981 - val_loss: 0.2512 - val_accuracy: 0.9649\n",
            "Epoch 74/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.2720 - val_accuracy: 0.9474\n",
            "Epoch 75/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0085 - accuracy: 0.9956 - val_loss: 0.2435 - val_accuracy: 0.9649\n",
            "Epoch 76/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2550 - val_accuracy: 0.9649\n",
            "Epoch 77/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0076 - accuracy: 0.9967 - val_loss: 0.2519 - val_accuracy: 0.9649\n",
            "Epoch 78/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3065 - val_accuracy: 0.9386\n",
            "Epoch 79/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0118 - accuracy: 0.9924 - val_loss: 0.2802 - val_accuracy: 0.9649\n",
            "Epoch 80/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0312 - accuracy: 0.9915 - val_loss: 0.2039 - val_accuracy: 0.9561\n",
            "Epoch 81/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.2372 - val_accuracy: 0.9474\n",
            "Epoch 82/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0316 - accuracy: 0.9863 - val_loss: 0.1832 - val_accuracy: 0.9737\n",
            "Epoch 83/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0474 - accuracy: 0.9816 - val_loss: 0.2322 - val_accuracy: 0.9649\n",
            "Epoch 84/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0085 - accuracy: 0.9993 - val_loss: 0.2322 - val_accuracy: 0.9474\n",
            "Epoch 85/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0143 - accuracy: 0.9904 - val_loss: 0.2264 - val_accuracy: 0.9561\n",
            "Epoch 86/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 0.9649\n",
            "Epoch 87/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.2337 - val_accuracy: 0.9649\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2388 - val_accuracy: 0.9649\n",
            "Epoch 89/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2466 - val_accuracy: 0.9649\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2553 - val_accuracy: 0.9649\n",
            "Epoch 91/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2665 - val_accuracy: 0.9649\n",
            "Epoch 92/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0047 - accuracy: 0.9958 - val_loss: 0.2749 - val_accuracy: 0.9649\n",
            "Epoch 93/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2817 - val_accuracy: 0.9649\n",
            "Epoch 94/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2886 - val_accuracy: 0.9649\n",
            "Epoch 95/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2965 - val_accuracy: 0.9649\n",
            "Epoch 96/200\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.0015 - accuracy: 0.9989 - val_loss: 0.3014 - val_accuracy: 0.9649\n",
            "Epoch 97/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3119 - val_accuracy: 0.9649\n",
            "Epoch 98/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3184 - val_accuracy: 0.9649\n",
            "Epoch 99/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.3419e-04 - accuracy: 1.0000 - val_loss: 0.3230 - val_accuracy: 0.9649\n",
            "Epoch 100/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 8.5628e-04 - accuracy: 1.0000 - val_loss: 0.3295 - val_accuracy: 0.9649\n",
            "Epoch 101/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 4.6646e-04 - accuracy: 1.0000 - val_loss: 0.3345 - val_accuracy: 0.9649\n",
            "Epoch 102/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 4.5836e-04 - accuracy: 1.0000 - val_loss: 0.3392 - val_accuracy: 0.9649\n",
            "Epoch 103/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 3.4469e-04 - accuracy: 1.0000 - val_loss: 0.3444 - val_accuracy: 0.9649\n",
            "Epoch 104/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.4213e-04 - accuracy: 1.0000 - val_loss: 0.3487 - val_accuracy: 0.9649\n",
            "Epoch 105/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.4314e-04 - accuracy: 1.0000 - val_loss: 0.3527 - val_accuracy: 0.9649\n",
            "Epoch 106/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 3.2691e-04 - accuracy: 1.0000 - val_loss: 0.3556 - val_accuracy: 0.9649\n",
            "Epoch 107/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.9711e-04 - accuracy: 1.0000 - val_loss: 0.3587 - val_accuracy: 0.9649\n",
            "Epoch 108/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.7643e-04 - accuracy: 1.0000 - val_loss: 0.3614 - val_accuracy: 0.9649\n",
            "Epoch 109/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.0830e-04 - accuracy: 1.0000 - val_loss: 0.3654 - val_accuracy: 0.9649\n",
            "Epoch 110/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.8547e-04 - accuracy: 1.0000 - val_loss: 0.3669 - val_accuracy: 0.9649\n",
            "Epoch 111/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3210e-04 - accuracy: 1.0000 - val_loss: 0.3680 - val_accuracy: 0.9649\n",
            "Epoch 112/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.8555e-04 - accuracy: 1.0000 - val_loss: 0.3706 - val_accuracy: 0.9649\n",
            "Epoch 113/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 9.0131e-05 - accuracy: 1.0000 - val_loss: 0.3734 - val_accuracy: 0.9649\n",
            "Epoch 114/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.1574e-04 - accuracy: 1.0000 - val_loss: 0.3756 - val_accuracy: 0.9649\n",
            "Epoch 115/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.8203e-05 - accuracy: 1.0000 - val_loss: 0.3773 - val_accuracy: 0.9649\n",
            "Epoch 116/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.2988e-04 - accuracy: 1.0000 - val_loss: 0.3785 - val_accuracy: 0.9649\n",
            "Epoch 117/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.7002e-05 - accuracy: 1.0000 - val_loss: 0.3797 - val_accuracy: 0.9649\n",
            "Epoch 118/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.9135e-05 - accuracy: 1.0000 - val_loss: 0.3816 - val_accuracy: 0.9649\n",
            "Epoch 119/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 5.9358e-05 - accuracy: 1.0000 - val_loss: 0.3832 - val_accuracy: 0.9649\n",
            "Epoch 120/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 9.4854e-05 - accuracy: 1.0000 - val_loss: 0.3850 - val_accuracy: 0.9649\n",
            "Epoch 121/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 9.3030e-05 - accuracy: 1.0000 - val_loss: 0.3864 - val_accuracy: 0.9649\n",
            "Epoch 122/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 7.6666e-05 - accuracy: 1.0000 - val_loss: 0.3876 - val_accuracy: 0.9649\n",
            "Epoch 123/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.7667e-05 - accuracy: 1.0000 - val_loss: 0.3886 - val_accuracy: 0.9649\n",
            "Epoch 124/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 4.3510e-05 - accuracy: 1.0000 - val_loss: 0.3897 - val_accuracy: 0.9649\n",
            "Epoch 125/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.1803e-05 - accuracy: 1.0000 - val_loss: 0.3911 - val_accuracy: 0.9649\n",
            "Epoch 126/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 3.8361e-05 - accuracy: 1.0000 - val_loss: 0.3924 - val_accuracy: 0.9649\n",
            "Epoch 127/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 4.8813e-05 - accuracy: 1.0000 - val_loss: 0.3936 - val_accuracy: 0.9649\n",
            "Epoch 128/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 3.0964e-05 - accuracy: 1.0000 - val_loss: 0.3948 - val_accuracy: 0.9649\n",
            "Epoch 129/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 5.5533e-05 - accuracy: 1.0000 - val_loss: 0.3962 - val_accuracy: 0.9649\n",
            "Epoch 130/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 4.3518e-05 - accuracy: 1.0000 - val_loss: 0.3972 - val_accuracy: 0.9649\n",
            "Epoch 131/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 6.6914e-05 - accuracy: 1.0000 - val_loss: 0.3982 - val_accuracy: 0.9649\n",
            "Epoch 132/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 4.2035e-05 - accuracy: 1.0000 - val_loss: 0.3992 - val_accuracy: 0.9649\n",
            "Epoch 133/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 3.9907e-05 - accuracy: 1.0000 - val_loss: 0.4003 - val_accuracy: 0.9649\n",
            "Epoch 134/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 3.0520e-05 - accuracy: 1.0000 - val_loss: 0.4012 - val_accuracy: 0.9649\n",
            "Epoch 135/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 5.4955e-05 - accuracy: 1.0000 - val_loss: 0.4023 - val_accuracy: 0.9649\n",
            "Epoch 136/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.8622e-05 - accuracy: 1.0000 - val_loss: 0.4033 - val_accuracy: 0.9649\n",
            "Epoch 137/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 3.1984e-05 - accuracy: 1.0000 - val_loss: 0.4044 - val_accuracy: 0.9649\n",
            "Epoch 138/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 3.0924e-05 - accuracy: 1.0000 - val_loss: 0.4054 - val_accuracy: 0.9649\n",
            "Epoch 139/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 3.7602e-05 - accuracy: 1.0000 - val_loss: 0.4065 - val_accuracy: 0.9649\n",
            "Epoch 140/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.2371e-05 - accuracy: 1.0000 - val_loss: 0.4074 - val_accuracy: 0.9649\n",
            "Epoch 141/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 5.1463e-05 - accuracy: 1.0000 - val_loss: 0.4083 - val_accuracy: 0.9649\n",
            "Epoch 142/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 5.1250e-05 - accuracy: 1.0000 - val_loss: 0.4092 - val_accuracy: 0.9649\n",
            "Epoch 143/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.9452e-05 - accuracy: 1.0000 - val_loss: 0.4100 - val_accuracy: 0.9649\n",
            "Epoch 144/200\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 4.0748e-05 - accuracy: 1.0000 - val_loss: 0.4110 - val_accuracy: 0.9649\n",
            "Epoch 145/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.7650e-05 - accuracy: 1.0000 - val_loss: 0.4119 - val_accuracy: 0.9649\n",
            "Epoch 146/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.0104e-05 - accuracy: 1.0000 - val_loss: 0.4127 - val_accuracy: 0.9649\n",
            "Epoch 147/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.9064e-05 - accuracy: 1.0000 - val_loss: 0.4137 - val_accuracy: 0.9649\n",
            "Epoch 148/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.8359e-05 - accuracy: 1.0000 - val_loss: 0.4145 - val_accuracy: 0.9649\n",
            "Epoch 149/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.1582e-05 - accuracy: 1.0000 - val_loss: 0.4152 - val_accuracy: 0.9649\n",
            "Epoch 150/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.9339e-05 - accuracy: 1.0000 - val_loss: 0.4159 - val_accuracy: 0.9649\n",
            "Epoch 151/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.0559e-05 - accuracy: 1.0000 - val_loss: 0.4166 - val_accuracy: 0.9649\n",
            "Epoch 152/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.2224e-05 - accuracy: 1.0000 - val_loss: 0.4173 - val_accuracy: 0.9649\n",
            "Epoch 153/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 3.4654e-05 - accuracy: 1.0000 - val_loss: 0.4182 - val_accuracy: 0.9649\n",
            "Epoch 154/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.1341e-05 - accuracy: 1.0000 - val_loss: 0.4189 - val_accuracy: 0.9649\n",
            "Epoch 155/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.2647e-05 - accuracy: 1.0000 - val_loss: 0.4196 - val_accuracy: 0.9649\n",
            "Epoch 156/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.1067e-05 - accuracy: 1.0000 - val_loss: 0.4203 - val_accuracy: 0.9649\n",
            "Epoch 157/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.9947e-05 - accuracy: 1.0000 - val_loss: 0.4210 - val_accuracy: 0.9649\n",
            "Epoch 158/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 3.0314e-05 - accuracy: 1.0000 - val_loss: 0.4218 - val_accuracy: 0.9649\n",
            "Epoch 159/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.4074e-05 - accuracy: 1.0000 - val_loss: 0.4224 - val_accuracy: 0.9649\n",
            "Epoch 160/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.2594e-05 - accuracy: 1.0000 - val_loss: 0.4230 - val_accuracy: 0.9649\n",
            "Epoch 161/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.4667e-05 - accuracy: 1.0000 - val_loss: 0.4237 - val_accuracy: 0.9649\n",
            "Epoch 162/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.6363e-05 - accuracy: 1.0000 - val_loss: 0.4244 - val_accuracy: 0.9649\n",
            "Epoch 163/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.7119e-05 - accuracy: 1.0000 - val_loss: 0.4251 - val_accuracy: 0.9649\n",
            "Epoch 164/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.4730e-05 - accuracy: 1.0000 - val_loss: 0.4257 - val_accuracy: 0.9649\n",
            "Epoch 165/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.3864e-05 - accuracy: 1.0000 - val_loss: 0.4265 - val_accuracy: 0.9649\n",
            "Epoch 166/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.7490e-05 - accuracy: 1.0000 - val_loss: 0.4271 - val_accuracy: 0.9649\n",
            "Epoch 167/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.1549e-05 - accuracy: 1.0000 - val_loss: 0.4278 - val_accuracy: 0.9649\n",
            "Epoch 168/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.6290e-05 - accuracy: 1.0000 - val_loss: 0.4285 - val_accuracy: 0.9649\n",
            "Epoch 169/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 2.1991e-05 - accuracy: 1.0000 - val_loss: 0.4292 - val_accuracy: 0.9649\n",
            "Epoch 170/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.8676e-05 - accuracy: 1.0000 - val_loss: 0.4298 - val_accuracy: 0.9649\n",
            "Epoch 171/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.9826e-05 - accuracy: 1.0000 - val_loss: 0.4304 - val_accuracy: 0.9649\n",
            "Epoch 172/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.5410e-05 - accuracy: 1.0000 - val_loss: 0.4309 - val_accuracy: 0.9649\n",
            "Epoch 173/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.1944e-05 - accuracy: 1.0000 - val_loss: 0.4314 - val_accuracy: 0.9649\n",
            "Epoch 174/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.4052e-05 - accuracy: 1.0000 - val_loss: 0.4319 - val_accuracy: 0.9649\n",
            "Epoch 175/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.8189e-05 - accuracy: 1.0000 - val_loss: 0.4326 - val_accuracy: 0.9649\n",
            "Epoch 176/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.5272e-05 - accuracy: 1.0000 - val_loss: 0.4332 - val_accuracy: 0.9649\n",
            "Epoch 177/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.8144e-05 - accuracy: 1.0000 - val_loss: 0.4338 - val_accuracy: 0.9649\n",
            "Epoch 178/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.8772e-05 - accuracy: 1.0000 - val_loss: 0.4344 - val_accuracy: 0.9649\n",
            "Epoch 179/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.1586e-05 - accuracy: 1.0000 - val_loss: 0.4350 - val_accuracy: 0.9649\n",
            "Epoch 180/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.4573e-05 - accuracy: 1.0000 - val_loss: 0.4358 - val_accuracy: 0.9649\n",
            "Epoch 181/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2604e-05 - accuracy: 1.0000 - val_loss: 0.4363 - val_accuracy: 0.9649\n",
            "Epoch 182/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.3193e-06 - accuracy: 1.0000 - val_loss: 0.4368 - val_accuracy: 0.9649\n",
            "Epoch 183/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.9360e-05 - accuracy: 1.0000 - val_loss: 0.4375 - val_accuracy: 0.9649\n",
            "Epoch 184/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.1830e-05 - accuracy: 1.0000 - val_loss: 0.4381 - val_accuracy: 0.9649\n",
            "Epoch 185/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.3478e-05 - accuracy: 1.0000 - val_loss: 0.4386 - val_accuracy: 0.9649\n",
            "Epoch 186/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.6576e-05 - accuracy: 1.0000 - val_loss: 0.4391 - val_accuracy: 0.9649\n",
            "Epoch 187/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.2697e-05 - accuracy: 1.0000 - val_loss: 0.4396 - val_accuracy: 0.9649\n",
            "Epoch 188/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 9.4812e-06 - accuracy: 1.0000 - val_loss: 0.4403 - val_accuracy: 0.9649\n",
            "Epoch 189/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.0384e-05 - accuracy: 1.0000 - val_loss: 0.4408 - val_accuracy: 0.9649\n",
            "Epoch 190/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 9.6539e-06 - accuracy: 1.0000 - val_loss: 0.4413 - val_accuracy: 0.9649\n",
            "Epoch 191/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.5142e-05 - accuracy: 1.0000 - val_loss: 0.4420 - val_accuracy: 0.9649\n",
            "Epoch 192/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.2456e-05 - accuracy: 1.0000 - val_loss: 0.4425 - val_accuracy: 0.9649\n",
            "Epoch 193/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.1231e-05 - accuracy: 1.0000 - val_loss: 0.4430 - val_accuracy: 0.9649\n",
            "Epoch 194/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.1353e-05 - accuracy: 1.0000 - val_loss: 0.4435 - val_accuracy: 0.9649\n",
            "Epoch 195/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.0194e-05 - accuracy: 1.0000 - val_loss: 0.4440 - val_accuracy: 0.9649\n",
            "Epoch 196/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 8.8264e-06 - accuracy: 1.0000 - val_loss: 0.4446 - val_accuracy: 0.9649\n",
            "Epoch 197/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.2180e-05 - accuracy: 1.0000 - val_loss: 0.4452 - val_accuracy: 0.9649\n",
            "Epoch 198/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 9.3177e-06 - accuracy: 1.0000 - val_loss: 0.4456 - val_accuracy: 0.9649\n",
            "Epoch 199/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 8.9966e-06 - accuracy: 1.0000 - val_loss: 0.4461 - val_accuracy: 0.9649\n",
            "Epoch 200/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.1371e-05 - accuracy: 1.0000 - val_loss: 0.4466 - val_accuracy: 0.9649\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1opnI2qCgGv5"
      },
      "source": [
        "Now change the learning rate to 0.1 in your Adam optimizer and compare the results (both speed and accuracy)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIGTzU1DgGv6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43265d2b-c722-4665-8f87-2fac8fc1a21b"
      },
      "source": [
        "# Answer below:\n",
        "\n",
        "adam = Adam(learning_rate=0.1)\n",
        "\n",
        "adam_model = build_model(opt=adam)\n",
        "\n",
        "adam_hist = adam_model.fit(X_train_scale, y_train, validation_data=(X_test_scale, y_test), batch_size=100, epochs=200)\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "5/5 [==============================] - 1s 73ms/step - loss: 8.1595 - accuracy: 0.3970 - val_loss: 1.3998 - val_accuracy: 0.1842\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.9141 - accuracy: 0.4497 - val_loss: 0.4371 - val_accuracy: 0.6228\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4245 - accuracy: 0.6267 - val_loss: 0.2726 - val_accuracy: 0.9474\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2152 - accuracy: 0.9241 - val_loss: 0.1803 - val_accuracy: 0.9561\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4523 - accuracy: 0.8796 - val_loss: 0.5586 - val_accuracy: 0.9649\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6488 - accuracy: 0.9190 - val_loss: 0.1970 - val_accuracy: 0.9561\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2017 - accuracy: 0.9233 - val_loss: 0.1451 - val_accuracy: 0.9386\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1811 - accuracy: 0.9214 - val_loss: 0.1424 - val_accuracy: 0.9386\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1852 - accuracy: 0.9039 - val_loss: 0.1077 - val_accuracy: 0.9474\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1698 - accuracy: 0.9268 - val_loss: 0.1158 - val_accuracy: 0.9298\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1675 - accuracy: 0.9258 - val_loss: 0.1665 - val_accuracy: 0.9561\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1247 - accuracy: 0.9310 - val_loss: 0.2183 - val_accuracy: 0.9649\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1226 - accuracy: 0.9468 - val_loss: 0.1928 - val_accuracy: 0.9561\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1144 - accuracy: 0.9511 - val_loss: 0.1831 - val_accuracy: 0.9649\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1209 - accuracy: 0.9421 - val_loss: 0.2179 - val_accuracy: 0.9649\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1124 - accuracy: 0.9545 - val_loss: 0.2183 - val_accuracy: 0.9737\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0926 - accuracy: 0.9662 - val_loss: 0.2402 - val_accuracy: 0.9474\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1082 - accuracy: 0.9607 - val_loss: 0.2436 - val_accuracy: 0.9649\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0925 - accuracy: 0.9643 - val_loss: 0.3430 - val_accuracy: 0.9649\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0912 - accuracy: 0.9573 - val_loss: 0.4912 - val_accuracy: 0.9386\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1397 - accuracy: 0.9563 - val_loss: 0.2261 - val_accuracy: 0.9737\n",
            "Epoch 22/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0994 - accuracy: 0.9673 - val_loss: 0.1266 - val_accuracy: 0.9649\n",
            "Epoch 23/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1057 - accuracy: 0.9689 - val_loss: 0.0974 - val_accuracy: 0.9649\n",
            "Epoch 24/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1291 - accuracy: 0.9378 - val_loss: 0.0951 - val_accuracy: 0.9649\n",
            "Epoch 25/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0917 - accuracy: 0.9693 - val_loss: 0.1586 - val_accuracy: 0.9298\n",
            "Epoch 26/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1342 - accuracy: 0.9177 - val_loss: 0.1409 - val_accuracy: 0.9561\n",
            "Epoch 27/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1927 - accuracy: 0.9632 - val_loss: 0.0854 - val_accuracy: 0.9561\n",
            "Epoch 28/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1007 - accuracy: 0.9530 - val_loss: 0.1322 - val_accuracy: 0.9561\n",
            "Epoch 29/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1380 - accuracy: 0.9505 - val_loss: 0.2009 - val_accuracy: 0.9561\n",
            "Epoch 30/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1985 - accuracy: 0.9349 - val_loss: 0.1860 - val_accuracy: 0.9649\n",
            "Epoch 31/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0921 - accuracy: 0.9617 - val_loss: 0.2365 - val_accuracy: 0.9561\n",
            "Epoch 32/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0988 - accuracy: 0.9608 - val_loss: 0.3047 - val_accuracy: 0.9386\n",
            "Epoch 33/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1072 - accuracy: 0.9481 - val_loss: 0.2501 - val_accuracy: 0.9561\n",
            "Epoch 34/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0584 - accuracy: 0.9809 - val_loss: 0.1657 - val_accuracy: 0.9649\n",
            "Epoch 35/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0764 - accuracy: 0.9719 - val_loss: 0.1824 - val_accuracy: 0.9737\n",
            "Epoch 36/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0919 - accuracy: 0.9568 - val_loss: 0.1513 - val_accuracy: 0.9649\n",
            "Epoch 37/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1039 - accuracy: 0.9489 - val_loss: 0.1490 - val_accuracy: 0.9474\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0865 - accuracy: 0.9618 - val_loss: 0.2991 - val_accuracy: 0.9825\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1106 - accuracy: 0.9582 - val_loss: 0.3143 - val_accuracy: 0.9737\n",
            "Epoch 40/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0735 - accuracy: 0.9762 - val_loss: 0.3273 - val_accuracy: 0.9561\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0557 - accuracy: 0.9818 - val_loss: 0.3905 - val_accuracy: 0.9561\n",
            "Epoch 42/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0979 - accuracy: 0.9665 - val_loss: 0.2338 - val_accuracy: 0.9737\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0763 - accuracy: 0.9640 - val_loss: 0.1126 - val_accuracy: 0.9561\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0634 - accuracy: 0.9814 - val_loss: 0.1028 - val_accuracy: 0.9737\n",
            "Epoch 45/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0603 - accuracy: 0.9720 - val_loss: 0.0972 - val_accuracy: 0.9737\n",
            "Epoch 46/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0594 - accuracy: 0.9767 - val_loss: 0.1065 - val_accuracy: 0.9649\n",
            "Epoch 47/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0532 - accuracy: 0.9796 - val_loss: 0.1385 - val_accuracy: 0.9737\n",
            "Epoch 48/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0372 - accuracy: 0.9826 - val_loss: 0.2084 - val_accuracy: 0.9649\n",
            "Epoch 49/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0600 - accuracy: 0.9793 - val_loss: 0.2271 - val_accuracy: 0.9825\n",
            "Epoch 50/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0489 - accuracy: 0.9843 - val_loss: 0.2495 - val_accuracy: 0.9649\n",
            "Epoch 51/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0438 - accuracy: 0.9830 - val_loss: 0.2292 - val_accuracy: 0.9474\n",
            "Epoch 52/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0429 - accuracy: 0.9903 - val_loss: 0.1832 - val_accuracy: 0.9737\n",
            "Epoch 53/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0434 - accuracy: 0.9899 - val_loss: 0.1810 - val_accuracy: 0.9649\n",
            "Epoch 54/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0347 - accuracy: 0.9866 - val_loss: 0.2054 - val_accuracy: 0.9649\n",
            "Epoch 55/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0363 - accuracy: 0.9863 - val_loss: 0.2433 - val_accuracy: 0.9737\n",
            "Epoch 56/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0370 - accuracy: 0.9878 - val_loss: 0.2612 - val_accuracy: 0.9649\n",
            "Epoch 57/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0288 - accuracy: 0.9906 - val_loss: 0.3102 - val_accuracy: 0.9649\n",
            "Epoch 58/200\n",
            "5/5 [==============================] - 0s 42ms/step - loss: 0.0288 - accuracy: 0.9830 - val_loss: 0.3643 - val_accuracy: 0.9649\n",
            "Epoch 59/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0281 - accuracy: 0.9879 - val_loss: 0.4136 - val_accuracy: 0.9649\n",
            "Epoch 60/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0314 - accuracy: 0.9884 - val_loss: 0.3687 - val_accuracy: 0.9561\n",
            "Epoch 61/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0188 - accuracy: 0.9942 - val_loss: 0.3005 - val_accuracy: 0.9649\n",
            "Epoch 62/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0574 - accuracy: 0.9908 - val_loss: 0.3290 - val_accuracy: 0.9561\n",
            "Epoch 63/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1053 - accuracy: 0.9545 - val_loss: 0.1624 - val_accuracy: 0.9561\n",
            "Epoch 64/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.5402 - accuracy: 0.9551 - val_loss: 0.1353 - val_accuracy: 0.9825\n",
            "Epoch 65/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1073 - accuracy: 0.9516 - val_loss: 0.1032 - val_accuracy: 0.9649\n",
            "Epoch 66/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0924 - accuracy: 0.9530 - val_loss: 0.1296 - val_accuracy: 0.9825\n",
            "Epoch 67/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1057 - accuracy: 0.9587 - val_loss: 0.1085 - val_accuracy: 0.9737\n",
            "Epoch 68/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0833 - accuracy: 0.9587 - val_loss: 0.1496 - val_accuracy: 0.9825\n",
            "Epoch 69/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0520 - accuracy: 0.9774 - val_loss: 0.1686 - val_accuracy: 0.9737\n",
            "Epoch 70/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0618 - accuracy: 0.9715 - val_loss: 0.2101 - val_accuracy: 0.9561\n",
            "Epoch 71/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1179 - accuracy: 0.9858 - val_loss: 0.5808 - val_accuracy: 0.9211\n",
            "Epoch 72/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.5042 - accuracy: 0.8964 - val_loss: 0.1993 - val_accuracy: 0.9474\n",
            "Epoch 73/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2250 - accuracy: 0.9195 - val_loss: 0.4259 - val_accuracy: 0.7982\n",
            "Epoch 74/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5908 - accuracy: 0.8407 - val_loss: 0.1937 - val_accuracy: 0.9737\n",
            "Epoch 75/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2215 - accuracy: 0.9450 - val_loss: 0.2626 - val_accuracy: 0.9298\n",
            "Epoch 76/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2386 - accuracy: 0.9365 - val_loss: 0.1942 - val_accuracy: 0.9737\n",
            "Epoch 77/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1683 - accuracy: 0.9483 - val_loss: 0.2170 - val_accuracy: 0.9737\n",
            "Epoch 78/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2848 - accuracy: 0.9437 - val_loss: 1.3146 - val_accuracy: 0.4561\n",
            "Epoch 79/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 1.0050 - accuracy: 0.4163 - val_loss: 1.8462 - val_accuracy: 0.8947\n",
            "Epoch 80/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 1.7942 - accuracy: 0.7219 - val_loss: 0.5625 - val_accuracy: 0.8947\n",
            "Epoch 81/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4212 - accuracy: 0.9095 - val_loss: 0.8861 - val_accuracy: 0.9123\n",
            "Epoch 82/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2952 - accuracy: 0.9193 - val_loss: 0.2739 - val_accuracy: 0.9035\n",
            "Epoch 83/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2753 - accuracy: 0.9117 - val_loss: 0.3339 - val_accuracy: 0.8860\n",
            "Epoch 84/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3551 - accuracy: 0.8777 - val_loss: 0.2962 - val_accuracy: 0.9035\n",
            "Epoch 85/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5618 - accuracy: 0.8986 - val_loss: 0.2293 - val_accuracy: 0.9298\n",
            "Epoch 86/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3717 - accuracy: 0.8888 - val_loss: 0.2283 - val_accuracy: 0.9298\n",
            "Epoch 87/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4692 - accuracy: 0.9054 - val_loss: 0.2283 - val_accuracy: 0.9298\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3218 - accuracy: 0.8974 - val_loss: 0.3731 - val_accuracy: 0.8684\n",
            "Epoch 89/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4365 - accuracy: 0.8411 - val_loss: 0.3837 - val_accuracy: 0.8596\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4309 - accuracy: 0.8360 - val_loss: 0.4066 - val_accuracy: 0.8421\n",
            "Epoch 91/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3681 - accuracy: 0.8653 - val_loss: 0.3683 - val_accuracy: 0.8596\n",
            "Epoch 92/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3487 - accuracy: 0.8753 - val_loss: 0.3678 - val_accuracy: 0.8596\n",
            "Epoch 93/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3671 - accuracy: 0.8653 - val_loss: 0.3680 - val_accuracy: 0.8596\n",
            "Epoch 94/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3385 - accuracy: 0.8781 - val_loss: 0.3671 - val_accuracy: 0.8596\n",
            "Epoch 95/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3317 - accuracy: 0.8863 - val_loss: 0.3668 - val_accuracy: 0.8596\n",
            "Epoch 96/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3443 - accuracy: 0.8754 - val_loss: 0.3677 - val_accuracy: 0.8596\n",
            "Epoch 97/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3414 - accuracy: 0.8749 - val_loss: 0.3690 - val_accuracy: 0.8596\n",
            "Epoch 98/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3410 - accuracy: 0.8770 - val_loss: 0.3703 - val_accuracy: 0.8596\n",
            "Epoch 99/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3357 - accuracy: 0.8802 - val_loss: 0.3700 - val_accuracy: 0.8596\n",
            "Epoch 100/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3472 - accuracy: 0.8743 - val_loss: 0.3699 - val_accuracy: 0.8596\n",
            "Epoch 101/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3404 - accuracy: 0.8768 - val_loss: 0.3694 - val_accuracy: 0.8596\n",
            "Epoch 102/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3150 - accuracy: 0.8904 - val_loss: 0.3691 - val_accuracy: 0.8596\n",
            "Epoch 103/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3145 - accuracy: 0.8904 - val_loss: 0.3693 - val_accuracy: 0.8596\n",
            "Epoch 104/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3096 - accuracy: 0.8914 - val_loss: 0.3698 - val_accuracy: 0.8596\n",
            "Epoch 105/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3376 - accuracy: 0.8792 - val_loss: 0.3699 - val_accuracy: 0.8596\n",
            "Epoch 106/200\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.3282 - accuracy: 0.8838 - val_loss: 0.3695 - val_accuracy: 0.8596\n",
            "Epoch 107/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3521 - accuracy: 0.8714 - val_loss: 0.3693 - val_accuracy: 0.8596\n",
            "Epoch 108/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3380 - accuracy: 0.8782 - val_loss: 0.3689 - val_accuracy: 0.8596\n",
            "Epoch 109/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3113 - accuracy: 0.8909 - val_loss: 0.3692 - val_accuracy: 0.8596\n",
            "Epoch 110/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3483 - accuracy: 0.8722 - val_loss: 0.3682 - val_accuracy: 0.8596\n",
            "Epoch 111/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3466 - accuracy: 0.8731 - val_loss: 0.3678 - val_accuracy: 0.8596\n",
            "Epoch 112/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3326 - accuracy: 0.8841 - val_loss: 0.3678 - val_accuracy: 0.8596\n",
            "Epoch 113/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3356 - accuracy: 0.8763 - val_loss: 0.3674 - val_accuracy: 0.8596\n",
            "Epoch 114/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3308 - accuracy: 0.8841 - val_loss: 0.3679 - val_accuracy: 0.8596\n",
            "Epoch 115/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3094 - accuracy: 0.8943 - val_loss: 0.3685 - val_accuracy: 0.8596\n",
            "Epoch 116/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3365 - accuracy: 0.8822 - val_loss: 0.3684 - val_accuracy: 0.8596\n",
            "Epoch 117/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3039 - accuracy: 0.8981 - val_loss: 0.3683 - val_accuracy: 0.8596\n",
            "Epoch 118/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3460 - accuracy: 0.8739 - val_loss: 0.3675 - val_accuracy: 0.8596\n",
            "Epoch 119/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3154 - accuracy: 0.8889 - val_loss: 0.3677 - val_accuracy: 0.8596\n",
            "Epoch 120/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3388 - accuracy: 0.8775 - val_loss: 0.3677 - val_accuracy: 0.8596\n",
            "Epoch 121/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2880 - accuracy: 0.9066 - val_loss: 0.3681 - val_accuracy: 0.8596\n",
            "Epoch 122/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3271 - accuracy: 0.8827 - val_loss: 0.3677 - val_accuracy: 0.8596\n",
            "Epoch 123/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3364 - accuracy: 0.8800 - val_loss: 0.3685 - val_accuracy: 0.8596\n",
            "Epoch 124/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3242 - accuracy: 0.8875 - val_loss: 0.3692 - val_accuracy: 0.8596\n",
            "Epoch 125/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3374 - accuracy: 0.8791 - val_loss: 0.3690 - val_accuracy: 0.8596\n",
            "Epoch 126/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3328 - accuracy: 0.8804 - val_loss: 0.3683 - val_accuracy: 0.8596\n",
            "Epoch 127/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3354 - accuracy: 0.8781 - val_loss: 0.3677 - val_accuracy: 0.8596\n",
            "Epoch 128/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3046 - accuracy: 0.8972 - val_loss: 0.3682 - val_accuracy: 0.8596\n",
            "Epoch 129/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3396 - accuracy: 0.8795 - val_loss: 0.3681 - val_accuracy: 0.8596\n",
            "Epoch 130/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3446 - accuracy: 0.8752 - val_loss: 0.3681 - val_accuracy: 0.8596\n",
            "Epoch 131/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3096 - accuracy: 0.8929 - val_loss: 0.3683 - val_accuracy: 0.8596\n",
            "Epoch 132/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3394 - accuracy: 0.8774 - val_loss: 0.3690 - val_accuracy: 0.8596\n",
            "Epoch 133/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3156 - accuracy: 0.8928 - val_loss: 0.3700 - val_accuracy: 0.8596\n",
            "Epoch 134/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3401 - accuracy: 0.8757 - val_loss: 0.3689 - val_accuracy: 0.8596\n",
            "Epoch 135/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3372 - accuracy: 0.8778 - val_loss: 0.3684 - val_accuracy: 0.8596\n",
            "Epoch 136/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3124 - accuracy: 0.8922 - val_loss: 0.3688 - val_accuracy: 0.8596\n",
            "Epoch 137/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3370 - accuracy: 0.8795 - val_loss: 0.3691 - val_accuracy: 0.8596\n",
            "Epoch 138/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2743 - accuracy: 0.9163 - val_loss: 0.3696 - val_accuracy: 0.8596\n",
            "Epoch 139/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3377 - accuracy: 0.8785 - val_loss: 0.3683 - val_accuracy: 0.8596\n",
            "Epoch 140/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3335 - accuracy: 0.8795 - val_loss: 0.3675 - val_accuracy: 0.8596\n",
            "Epoch 141/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3410 - accuracy: 0.8816 - val_loss: 0.3682 - val_accuracy: 0.8596\n",
            "Epoch 142/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3247 - accuracy: 0.8860 - val_loss: 0.3683 - val_accuracy: 0.8596\n",
            "Epoch 143/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3144 - accuracy: 0.8884 - val_loss: 0.3682 - val_accuracy: 0.8596\n",
            "Epoch 144/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3395 - accuracy: 0.8789 - val_loss: 0.3686 - val_accuracy: 0.8596\n",
            "Epoch 145/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3302 - accuracy: 0.8806 - val_loss: 0.3690 - val_accuracy: 0.8596\n",
            "Epoch 146/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3405 - accuracy: 0.8760 - val_loss: 0.3693 - val_accuracy: 0.8596\n",
            "Epoch 147/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3391 - accuracy: 0.8796 - val_loss: 0.3698 - val_accuracy: 0.8596\n",
            "Epoch 148/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3442 - accuracy: 0.8745 - val_loss: 0.3687 - val_accuracy: 0.8596\n",
            "Epoch 149/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3404 - accuracy: 0.8788 - val_loss: 0.3686 - val_accuracy: 0.8596\n",
            "Epoch 150/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3057 - accuracy: 0.8953 - val_loss: 0.3687 - val_accuracy: 0.8596\n",
            "Epoch 151/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3310 - accuracy: 0.8822 - val_loss: 0.3681 - val_accuracy: 0.8596\n",
            "Epoch 152/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3403 - accuracy: 0.8775 - val_loss: 0.3676 - val_accuracy: 0.8596\n",
            "Epoch 153/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3642 - accuracy: 0.8646 - val_loss: 0.3675 - val_accuracy: 0.8596\n",
            "Epoch 154/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3242 - accuracy: 0.8857 - val_loss: 0.3681 - val_accuracy: 0.8596\n",
            "Epoch 155/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3195 - accuracy: 0.8902 - val_loss: 0.3695 - val_accuracy: 0.8596\n",
            "Epoch 156/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3455 - accuracy: 0.8742 - val_loss: 0.3695 - val_accuracy: 0.8596\n",
            "Epoch 157/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3374 - accuracy: 0.8800 - val_loss: 0.3695 - val_accuracy: 0.8596\n",
            "Epoch 158/200\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3368 - accuracy: 0.8829 - val_loss: 0.3693 - val_accuracy: 0.8596\n",
            "Epoch 159/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3536 - accuracy: 0.8686 - val_loss: 0.3681 - val_accuracy: 0.8596\n",
            "Epoch 160/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3118 - accuracy: 0.8945 - val_loss: 0.3689 - val_accuracy: 0.8596\n",
            "Epoch 161/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2938 - accuracy: 0.9013 - val_loss: 0.3690 - val_accuracy: 0.8596\n",
            "Epoch 162/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3392 - accuracy: 0.8784 - val_loss: 0.3679 - val_accuracy: 0.8596\n",
            "Epoch 163/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3335 - accuracy: 0.8828 - val_loss: 0.3677 - val_accuracy: 0.8596\n",
            "Epoch 164/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3136 - accuracy: 0.8931 - val_loss: 0.3678 - val_accuracy: 0.8596\n",
            "Epoch 165/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3362 - accuracy: 0.8789 - val_loss: 0.3678 - val_accuracy: 0.8596\n",
            "Epoch 166/200\n",
            "5/5 [==============================] - 0s 43ms/step - loss: 0.3387 - accuracy: 0.8761 - val_loss: 0.3677 - val_accuracy: 0.8596\n",
            "Epoch 167/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3404 - accuracy: 0.8800 - val_loss: 0.3692 - val_accuracy: 0.8596\n",
            "Epoch 168/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3345 - accuracy: 0.8799 - val_loss: 0.3688 - val_accuracy: 0.8596\n",
            "Epoch 169/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3645 - accuracy: 0.8650 - val_loss: 0.3688 - val_accuracy: 0.8596\n",
            "Epoch 170/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3166 - accuracy: 0.8888 - val_loss: 0.3689 - val_accuracy: 0.8596\n",
            "Epoch 171/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2944 - accuracy: 0.9049 - val_loss: 0.3694 - val_accuracy: 0.8596\n",
            "Epoch 172/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3489 - accuracy: 0.8716 - val_loss: 0.3678 - val_accuracy: 0.8596\n",
            "Epoch 173/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3544 - accuracy: 0.8707 - val_loss: 0.3675 - val_accuracy: 0.8596\n",
            "Epoch 174/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3185 - accuracy: 0.8885 - val_loss: 0.3678 - val_accuracy: 0.8596\n",
            "Epoch 175/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3450 - accuracy: 0.8770 - val_loss: 0.3682 - val_accuracy: 0.8596\n",
            "Epoch 176/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3497 - accuracy: 0.8743 - val_loss: 0.3683 - val_accuracy: 0.8596\n",
            "Epoch 177/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3326 - accuracy: 0.8834 - val_loss: 0.3688 - val_accuracy: 0.8596\n",
            "Epoch 178/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3590 - accuracy: 0.8667 - val_loss: 0.3682 - val_accuracy: 0.8596\n",
            "Epoch 179/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3799 - accuracy: 0.8561 - val_loss: 0.3679 - val_accuracy: 0.8596\n",
            "Epoch 180/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3120 - accuracy: 0.8928 - val_loss: 0.3687 - val_accuracy: 0.8596\n",
            "Epoch 181/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3442 - accuracy: 0.8735 - val_loss: 0.3681 - val_accuracy: 0.8596\n",
            "Epoch 182/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3439 - accuracy: 0.8764 - val_loss: 0.3684 - val_accuracy: 0.8596\n",
            "Epoch 183/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3440 - accuracy: 0.8724 - val_loss: 0.3682 - val_accuracy: 0.8596\n",
            "Epoch 184/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3471 - accuracy: 0.8724 - val_loss: 0.3683 - val_accuracy: 0.8596\n",
            "Epoch 185/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3586 - accuracy: 0.8664 - val_loss: 0.3679 - val_accuracy: 0.8596\n",
            "Epoch 186/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3290 - accuracy: 0.8838 - val_loss: 0.3681 - val_accuracy: 0.8596\n",
            "Epoch 187/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3231 - accuracy: 0.8882 - val_loss: 0.3686 - val_accuracy: 0.8596\n",
            "Epoch 188/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3140 - accuracy: 0.8929 - val_loss: 0.3686 - val_accuracy: 0.8596\n",
            "Epoch 189/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3181 - accuracy: 0.8892 - val_loss: 0.3684 - val_accuracy: 0.8596\n",
            "Epoch 190/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3698 - accuracy: 0.8596 - val_loss: 0.3678 - val_accuracy: 0.8596\n",
            "Epoch 191/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3213 - accuracy: 0.8875 - val_loss: 0.3683 - val_accuracy: 0.8596\n",
            "Epoch 192/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3308 - accuracy: 0.8806 - val_loss: 0.3685 - val_accuracy: 0.8596\n",
            "Epoch 193/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3038 - accuracy: 0.9014 - val_loss: 0.3690 - val_accuracy: 0.8596\n",
            "Epoch 194/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3332 - accuracy: 0.8793 - val_loss: 0.3675 - val_accuracy: 0.8596\n",
            "Epoch 195/200\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3396 - accuracy: 0.8772 - val_loss: 0.3671 - val_accuracy: 0.8596\n",
            "Epoch 196/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3261 - accuracy: 0.8832 - val_loss: 0.3682 - val_accuracy: 0.8596\n",
            "Epoch 197/200\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3542 - accuracy: 0.8702 - val_loss: 0.3690 - val_accuracy: 0.8596\n",
            "Epoch 198/200\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3359 - accuracy: 0.8764 - val_loss: 0.3691 - val_accuracy: 0.8596\n",
            "Epoch 199/200\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3449 - accuracy: 0.8734 - val_loss: 0.3692 - val_accuracy: 0.8596\n",
            "Epoch 200/200\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3228 - accuracy: 0.8877 - val_loss: 0.3699 - val_accuracy: 0.8596\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZLhihojpX7g"
      },
      "source": [
        "def vis_history(hist):\r\n",
        "  df = pd.DataFrame(hist.history)\r\n",
        "  df[['loss', 'val_loss']].plot(figsize=(12,8))\r\n",
        "  df[['accuracy', 'val_accuracy']].plot(figsize=(12,8))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e91KQiHqgGv7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "outputId": "d66bdaba-efcc-4f7e-95ff-fe8aa62a5e8e"
      },
      "source": [
        "vis_history(adam_hist)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoCs0ZJdpUGa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}