{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "Oscar_D77L2_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKSZ10Al0lsa"
      },
      "source": [
        "## Loss Functions\n",
        "\n",
        "In this assignment, we will learn about loss functions. We will use a create a neural network and measure the model's performance using different loss functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC8ZyHPq0lsb"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "pd.set_option('display.max_rows', 100)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqKRN1_O0lse"
      },
      "source": [
        "housing = pd.read_csv('https://tf-assets-prod.s3.amazonaws.com/tf-curric/data-science/housing.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5WgUX-I0lsh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "659e4f25-c235-4230-ae0d-e70e6971cbae"
      },
      "source": [
        "housing.info()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1460 entries, 0 to 1459\n",
            "Data columns (total 81 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Id             1460 non-null   int64  \n",
            " 1   MSSubClass     1460 non-null   int64  \n",
            " 2   MSZoning       1460 non-null   object \n",
            " 3   LotFrontage    1201 non-null   float64\n",
            " 4   LotArea        1460 non-null   int64  \n",
            " 5   Street         1460 non-null   object \n",
            " 6   Alley          91 non-null     object \n",
            " 7   LotShape       1460 non-null   object \n",
            " 8   LandContour    1460 non-null   object \n",
            " 9   Utilities      1460 non-null   object \n",
            " 10  LotConfig      1460 non-null   object \n",
            " 11  LandSlope      1460 non-null   object \n",
            " 12  Neighborhood   1460 non-null   object \n",
            " 13  Condition1     1460 non-null   object \n",
            " 14  Condition2     1460 non-null   object \n",
            " 15  BldgType       1460 non-null   object \n",
            " 16  HouseStyle     1460 non-null   object \n",
            " 17  OverallQual    1460 non-null   int64  \n",
            " 18  OverallCond    1460 non-null   int64  \n",
            " 19  YearBuilt      1460 non-null   int64  \n",
            " 20  YearRemodAdd   1460 non-null   int64  \n",
            " 21  RoofStyle      1460 non-null   object \n",
            " 22  RoofMatl       1460 non-null   object \n",
            " 23  Exterior1st    1460 non-null   object \n",
            " 24  Exterior2nd    1460 non-null   object \n",
            " 25  MasVnrType     1452 non-null   object \n",
            " 26  MasVnrArea     1452 non-null   float64\n",
            " 27  ExterQual      1460 non-null   object \n",
            " 28  ExterCond      1460 non-null   object \n",
            " 29  Foundation     1460 non-null   object \n",
            " 30  BsmtQual       1423 non-null   object \n",
            " 31  BsmtCond       1423 non-null   object \n",
            " 32  BsmtExposure   1422 non-null   object \n",
            " 33  BsmtFinType1   1423 non-null   object \n",
            " 34  BsmtFinSF1     1460 non-null   int64  \n",
            " 35  BsmtFinType2   1422 non-null   object \n",
            " 36  BsmtFinSF2     1460 non-null   int64  \n",
            " 37  BsmtUnfSF      1460 non-null   int64  \n",
            " 38  TotalBsmtSF    1460 non-null   int64  \n",
            " 39  Heating        1460 non-null   object \n",
            " 40  HeatingQC      1460 non-null   object \n",
            " 41  CentralAir     1460 non-null   object \n",
            " 42  Electrical     1459 non-null   object \n",
            " 43  1stFlrSF       1460 non-null   int64  \n",
            " 44  2ndFlrSF       1460 non-null   int64  \n",
            " 45  LowQualFinSF   1460 non-null   int64  \n",
            " 46  GrLivArea      1460 non-null   int64  \n",
            " 47  BsmtFullBath   1460 non-null   int64  \n",
            " 48  BsmtHalfBath   1460 non-null   int64  \n",
            " 49  FullBath       1460 non-null   int64  \n",
            " 50  HalfBath       1460 non-null   int64  \n",
            " 51  BedroomAbvGr   1460 non-null   int64  \n",
            " 52  KitchenAbvGr   1460 non-null   int64  \n",
            " 53  KitchenQual    1460 non-null   object \n",
            " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
            " 55  Functional     1460 non-null   object \n",
            " 56  Fireplaces     1460 non-null   int64  \n",
            " 57  FireplaceQu    770 non-null    object \n",
            " 58  GarageType     1379 non-null   object \n",
            " 59  GarageYrBlt    1379 non-null   float64\n",
            " 60  GarageFinish   1379 non-null   object \n",
            " 61  GarageCars     1460 non-null   int64  \n",
            " 62  GarageArea     1460 non-null   int64  \n",
            " 63  GarageQual     1379 non-null   object \n",
            " 64  GarageCond     1379 non-null   object \n",
            " 65  PavedDrive     1460 non-null   object \n",
            " 66  WoodDeckSF     1460 non-null   int64  \n",
            " 67  OpenPorchSF    1460 non-null   int64  \n",
            " 68  EnclosedPorch  1460 non-null   int64  \n",
            " 69  3SsnPorch      1460 non-null   int64  \n",
            " 70  ScreenPorch    1460 non-null   int64  \n",
            " 71  PoolArea       1460 non-null   int64  \n",
            " 72  PoolQC         7 non-null      object \n",
            " 73  Fence          281 non-null    object \n",
            " 74  MiscFeature    54 non-null     object \n",
            " 75  MiscVal        1460 non-null   int64  \n",
            " 76  MoSold         1460 non-null   int64  \n",
            " 77  YrSold         1460 non-null   int64  \n",
            " 78  SaleType       1460 non-null   object \n",
            " 79  SaleCondition  1460 non-null   object \n",
            " 80  SalePrice      1460 non-null   int64  \n",
            "dtypes: float64(3), int64(35), object(43)\n",
            "memory usage: 924.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYgIVabm0lsj"
      },
      "source": [
        "We will use the dataset above to predict housing prices using various features about each house. Our first step is to check for missing data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_gFN2cu0lsj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f6567d8-2695-4eb3-fe5e-8155422ef262"
      },
      "source": [
        "# Answer below:\n",
        "housing.isnull().sum()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Id                  0\n",
              "MSSubClass          0\n",
              "MSZoning            0\n",
              "LotFrontage       259\n",
              "LotArea             0\n",
              "Street              0\n",
              "Alley            1369\n",
              "LotShape            0\n",
              "LandContour         0\n",
              "Utilities           0\n",
              "LotConfig           0\n",
              "LandSlope           0\n",
              "Neighborhood        0\n",
              "Condition1          0\n",
              "Condition2          0\n",
              "BldgType            0\n",
              "HouseStyle          0\n",
              "OverallQual         0\n",
              "OverallCond         0\n",
              "YearBuilt           0\n",
              "YearRemodAdd        0\n",
              "RoofStyle           0\n",
              "RoofMatl            0\n",
              "Exterior1st         0\n",
              "Exterior2nd         0\n",
              "MasVnrType          8\n",
              "MasVnrArea          8\n",
              "ExterQual           0\n",
              "ExterCond           0\n",
              "Foundation          0\n",
              "BsmtQual           37\n",
              "BsmtCond           37\n",
              "BsmtExposure       38\n",
              "BsmtFinType1       37\n",
              "BsmtFinSF1          0\n",
              "BsmtFinType2       38\n",
              "BsmtFinSF2          0\n",
              "BsmtUnfSF           0\n",
              "TotalBsmtSF         0\n",
              "Heating             0\n",
              "HeatingQC           0\n",
              "CentralAir          0\n",
              "Electrical          1\n",
              "1stFlrSF            0\n",
              "2ndFlrSF            0\n",
              "LowQualFinSF        0\n",
              "GrLivArea           0\n",
              "BsmtFullBath        0\n",
              "BsmtHalfBath        0\n",
              "FullBath            0\n",
              "HalfBath            0\n",
              "BedroomAbvGr        0\n",
              "KitchenAbvGr        0\n",
              "KitchenQual         0\n",
              "TotRmsAbvGrd        0\n",
              "Functional          0\n",
              "Fireplaces          0\n",
              "FireplaceQu       690\n",
              "GarageType         81\n",
              "GarageYrBlt        81\n",
              "GarageFinish       81\n",
              "GarageCars          0\n",
              "GarageArea          0\n",
              "GarageQual         81\n",
              "GarageCond         81\n",
              "PavedDrive          0\n",
              "WoodDeckSF          0\n",
              "OpenPorchSF         0\n",
              "EnclosedPorch       0\n",
              "3SsnPorch           0\n",
              "ScreenPorch         0\n",
              "PoolArea            0\n",
              "PoolQC           1453\n",
              "Fence            1179\n",
              "MiscFeature      1406\n",
              "MiscVal             0\n",
              "MoSold              0\n",
              "YrSold              0\n",
              "SaleType            0\n",
              "SaleCondition       0\n",
              "SalePrice           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3uqsma30lsl"
      },
      "source": [
        "Remove columns that contain more than 30% of missing data. After removing those columns, remove the rows that contain at least one observation that is missing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYdSl4kh0lsm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51c2bae0-64ed-4ad1-fc91-70d28176a2f6"
      },
      "source": [
        "# Answer below:\n",
        "null_greater_than_30 = ((housing.isnull().sum() / housing.isnull().count()) *100)[lambda x: x > 30].index\n",
        "df = housing.drop(columns= null_greater_than_30)\n",
        "df.dropna(inplace=True, axis=0)\n",
        "df.isnull().sum()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Id               0\n",
              "MSSubClass       0\n",
              "MSZoning         0\n",
              "LotFrontage      0\n",
              "LotArea          0\n",
              "Street           0\n",
              "LotShape         0\n",
              "LandContour      0\n",
              "Utilities        0\n",
              "LotConfig        0\n",
              "LandSlope        0\n",
              "Neighborhood     0\n",
              "Condition1       0\n",
              "Condition2       0\n",
              "BldgType         0\n",
              "HouseStyle       0\n",
              "OverallQual      0\n",
              "OverallCond      0\n",
              "YearBuilt        0\n",
              "YearRemodAdd     0\n",
              "RoofStyle        0\n",
              "RoofMatl         0\n",
              "Exterior1st      0\n",
              "Exterior2nd      0\n",
              "MasVnrType       0\n",
              "MasVnrArea       0\n",
              "ExterQual        0\n",
              "ExterCond        0\n",
              "Foundation       0\n",
              "BsmtQual         0\n",
              "BsmtCond         0\n",
              "BsmtExposure     0\n",
              "BsmtFinType1     0\n",
              "BsmtFinSF1       0\n",
              "BsmtFinType2     0\n",
              "BsmtFinSF2       0\n",
              "BsmtUnfSF        0\n",
              "TotalBsmtSF      0\n",
              "Heating          0\n",
              "HeatingQC        0\n",
              "CentralAir       0\n",
              "Electrical       0\n",
              "1stFlrSF         0\n",
              "2ndFlrSF         0\n",
              "LowQualFinSF     0\n",
              "GrLivArea        0\n",
              "BsmtFullBath     0\n",
              "BsmtHalfBath     0\n",
              "FullBath         0\n",
              "HalfBath         0\n",
              "BedroomAbvGr     0\n",
              "KitchenAbvGr     0\n",
              "KitchenQual      0\n",
              "TotRmsAbvGrd     0\n",
              "Functional       0\n",
              "Fireplaces       0\n",
              "GarageType       0\n",
              "GarageYrBlt      0\n",
              "GarageFinish     0\n",
              "GarageCars       0\n",
              "GarageArea       0\n",
              "GarageQual       0\n",
              "GarageCond       0\n",
              "PavedDrive       0\n",
              "WoodDeckSF       0\n",
              "OpenPorchSF      0\n",
              "EnclosedPorch    0\n",
              "3SsnPorch        0\n",
              "ScreenPorch      0\n",
              "PoolArea         0\n",
              "MiscVal          0\n",
              "MoSold           0\n",
              "YrSold           0\n",
              "SaleType         0\n",
              "SaleCondition    0\n",
              "SalePrice        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dnm4HNYr0lso"
      },
      "source": [
        "There are some categorical variables that contain numeric data and some that do not. Print the type of each column to first see whether there is an issue with misclassification of column type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKKKIkaC0lsp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ad38bc4-2628-40a8-ff49-de8c73b0f222"
      },
      "source": [
        "# Answer below:\n",
        "df.dtypes.sort_index()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1stFlrSF           int64\n",
              "2ndFlrSF           int64\n",
              "3SsnPorch          int64\n",
              "BedroomAbvGr       int64\n",
              "BldgType          object\n",
              "BsmtCond          object\n",
              "BsmtExposure      object\n",
              "BsmtFinSF1         int64\n",
              "BsmtFinSF2         int64\n",
              "BsmtFinType1      object\n",
              "BsmtFinType2      object\n",
              "BsmtFullBath       int64\n",
              "BsmtHalfBath       int64\n",
              "BsmtQual          object\n",
              "BsmtUnfSF          int64\n",
              "CentralAir        object\n",
              "Condition1        object\n",
              "Condition2        object\n",
              "Electrical        object\n",
              "EnclosedPorch      int64\n",
              "ExterCond         object\n",
              "ExterQual         object\n",
              "Exterior1st       object\n",
              "Exterior2nd       object\n",
              "Fireplaces         int64\n",
              "Foundation        object\n",
              "FullBath           int64\n",
              "Functional        object\n",
              "GarageArea         int64\n",
              "GarageCars         int64\n",
              "GarageCond        object\n",
              "GarageFinish      object\n",
              "GarageQual        object\n",
              "GarageType        object\n",
              "GarageYrBlt      float64\n",
              "GrLivArea          int64\n",
              "HalfBath           int64\n",
              "Heating           object\n",
              "HeatingQC         object\n",
              "HouseStyle        object\n",
              "Id                 int64\n",
              "KitchenAbvGr       int64\n",
              "KitchenQual       object\n",
              "LandContour       object\n",
              "LandSlope         object\n",
              "LotArea            int64\n",
              "LotConfig         object\n",
              "LotFrontage      float64\n",
              "LotShape          object\n",
              "LowQualFinSF       int64\n",
              "MSSubClass         int64\n",
              "MSZoning          object\n",
              "MasVnrArea       float64\n",
              "MasVnrType        object\n",
              "MiscVal            int64\n",
              "MoSold             int64\n",
              "Neighborhood      object\n",
              "OpenPorchSF        int64\n",
              "OverallCond        int64\n",
              "OverallQual        int64\n",
              "PavedDrive        object\n",
              "PoolArea           int64\n",
              "RoofMatl          object\n",
              "RoofStyle         object\n",
              "SaleCondition     object\n",
              "SalePrice          int64\n",
              "SaleType          object\n",
              "ScreenPorch        int64\n",
              "Street            object\n",
              "TotRmsAbvGrd       int64\n",
              "TotalBsmtSF        int64\n",
              "Utilities         object\n",
              "WoodDeckSF         int64\n",
              "YearBuilt          int64\n",
              "YearRemodAdd       int64\n",
              "YrSold             int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZfA-TZu0lsq"
      },
      "source": [
        "We see that month sold and year sold are not variables that describe a feature of the house. While they do have relevance if we create a model containing a time series element, we will not include them here. Drop these columns. Also, remove the id column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVZUPSWm0lsr"
      },
      "source": [
        "# Answer below\n",
        "df.drop(columns=['MoSold', 'YrSold', 'Id'], inplace=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OxMXQ8g0lst"
      },
      "source": [
        "Using the information about the column types, identify all the variables that will be converted into dummy variables. Include at least one numeric variable that you think should be converted as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bORGylTC0lsv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "796e6433-d41d-4b3a-823b-bcf60be4fbb4"
      },
      "source": [
        "# Answer below:\n",
        "df.select_dtypes(include='O')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>Street</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>LandSlope</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>Condition1</th>\n",
              "      <th>Condition2</th>\n",
              "      <th>BldgType</th>\n",
              "      <th>HouseStyle</th>\n",
              "      <th>RoofStyle</th>\n",
              "      <th>RoofMatl</th>\n",
              "      <th>Exterior1st</th>\n",
              "      <th>Exterior2nd</th>\n",
              "      <th>MasVnrType</th>\n",
              "      <th>ExterQual</th>\n",
              "      <th>ExterCond</th>\n",
              "      <th>Foundation</th>\n",
              "      <th>BsmtQual</th>\n",
              "      <th>BsmtCond</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtFinType2</th>\n",
              "      <th>Heating</th>\n",
              "      <th>HeatingQC</th>\n",
              "      <th>CentralAir</th>\n",
              "      <th>Electrical</th>\n",
              "      <th>KitchenQual</th>\n",
              "      <th>Functional</th>\n",
              "      <th>GarageType</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>GarageQual</th>\n",
              "      <th>GarageCond</th>\n",
              "      <th>PavedDrive</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RL</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>Unf</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Typ</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>RFn</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RL</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Veenker</td>\n",
              "      <td>Feedr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>None</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>Unf</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>TA</td>\n",
              "      <td>Typ</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>RFn</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RL</td>\n",
              "      <td>Pave</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Mn</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>Unf</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Typ</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>RFn</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RL</td>\n",
              "      <td>Pave</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Crawfor</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>Wd Sdng</td>\n",
              "      <td>Wd Shng</td>\n",
              "      <td>None</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>BrkTil</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>No</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>Unf</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Typ</td>\n",
              "      <td>Detchd</td>\n",
              "      <td>Unf</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RL</td>\n",
              "      <td>Pave</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NoRidge</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Av</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>Unf</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Typ</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>RFn</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455</th>\n",
              "      <td>RL</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Gilbert</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>None</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>Unf</td>\n",
              "      <td>Unf</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>TA</td>\n",
              "      <td>Typ</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>RFn</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>RL</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NWAmes</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>Plywood</td>\n",
              "      <td>Plywood</td>\n",
              "      <td>Stone</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>Rec</td>\n",
              "      <td>GasA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>TA</td>\n",
              "      <td>Min1</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>Unf</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1457</th>\n",
              "      <td>RL</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Crawfor</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>CemntBd</td>\n",
              "      <td>CmentBd</td>\n",
              "      <td>None</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Stone</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>No</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>Unf</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Ex</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Typ</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>RFn</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1458</th>\n",
              "      <td>RL</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NAmes</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>Hip</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>None</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Mn</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>Rec</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Y</td>\n",
              "      <td>FuseA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Typ</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>Unf</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1459</th>\n",
              "      <td>RL</td>\n",
              "      <td>Pave</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Edwards</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>HdBoard</td>\n",
              "      <td>HdBoard</td>\n",
              "      <td>None</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>BLQ</td>\n",
              "      <td>LwQ</td>\n",
              "      <td>GasA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>TA</td>\n",
              "      <td>Typ</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>Fin</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1094 rows × 38 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     MSZoning Street LotShape  ... PavedDrive SaleType SaleCondition\n",
              "0          RL   Pave      Reg  ...          Y       WD        Normal\n",
              "1          RL   Pave      Reg  ...          Y       WD        Normal\n",
              "2          RL   Pave      IR1  ...          Y       WD        Normal\n",
              "3          RL   Pave      IR1  ...          Y       WD       Abnorml\n",
              "4          RL   Pave      IR1  ...          Y       WD        Normal\n",
              "...       ...    ...      ...  ...        ...      ...           ...\n",
              "1455       RL   Pave      Reg  ...          Y       WD        Normal\n",
              "1456       RL   Pave      Reg  ...          Y       WD        Normal\n",
              "1457       RL   Pave      Reg  ...          Y       WD        Normal\n",
              "1458       RL   Pave      Reg  ...          Y       WD        Normal\n",
              "1459       RL   Pave      Reg  ...          Y       WD        Normal\n",
              "\n",
              "[1094 rows x 38 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "BK2MefXQ9fJ6",
        "outputId": "b259b11f-be3e-470d-d3ae-e8adb3313aa4"
      },
      "source": [
        "df.select_dtypes(include='number')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>196.0</td>\n",
              "      <td>706</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>856</td>\n",
              "      <td>856</td>\n",
              "      <td>854</td>\n",
              "      <td>0</td>\n",
              "      <td>1710</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>2</td>\n",
              "      <td>548</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>0.0</td>\n",
              "      <td>978</td>\n",
              "      <td>0</td>\n",
              "      <td>284</td>\n",
              "      <td>1262</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1976.0</td>\n",
              "      <td>2</td>\n",
              "      <td>460</td>\n",
              "      <td>298</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>162.0</td>\n",
              "      <td>486</td>\n",
              "      <td>0</td>\n",
              "      <td>434</td>\n",
              "      <td>920</td>\n",
              "      <td>920</td>\n",
              "      <td>866</td>\n",
              "      <td>0</td>\n",
              "      <td>1786</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>2</td>\n",
              "      <td>608</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>70</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>0.0</td>\n",
              "      <td>216</td>\n",
              "      <td>0</td>\n",
              "      <td>540</td>\n",
              "      <td>756</td>\n",
              "      <td>961</td>\n",
              "      <td>756</td>\n",
              "      <td>0</td>\n",
              "      <td>1717</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>3</td>\n",
              "      <td>642</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>350.0</td>\n",
              "      <td>655</td>\n",
              "      <td>0</td>\n",
              "      <td>490</td>\n",
              "      <td>1145</td>\n",
              "      <td>1145</td>\n",
              "      <td>1053</td>\n",
              "      <td>0</td>\n",
              "      <td>2198</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>836</td>\n",
              "      <td>192</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455</th>\n",
              "      <td>60</td>\n",
              "      <td>62.0</td>\n",
              "      <td>7917</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>1999</td>\n",
              "      <td>2000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>953</td>\n",
              "      <td>953</td>\n",
              "      <td>953</td>\n",
              "      <td>694</td>\n",
              "      <td>0</td>\n",
              "      <td>1647</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1999.0</td>\n",
              "      <td>2</td>\n",
              "      <td>460</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>175000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>20</td>\n",
              "      <td>85.0</td>\n",
              "      <td>13175</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1978</td>\n",
              "      <td>1988</td>\n",
              "      <td>119.0</td>\n",
              "      <td>790</td>\n",
              "      <td>163</td>\n",
              "      <td>589</td>\n",
              "      <td>1542</td>\n",
              "      <td>2073</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2073</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>1978.0</td>\n",
              "      <td>2</td>\n",
              "      <td>500</td>\n",
              "      <td>349</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>210000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1457</th>\n",
              "      <td>70</td>\n",
              "      <td>66.0</td>\n",
              "      <td>9042</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>1941</td>\n",
              "      <td>2006</td>\n",
              "      <td>0.0</td>\n",
              "      <td>275</td>\n",
              "      <td>0</td>\n",
              "      <td>877</td>\n",
              "      <td>1152</td>\n",
              "      <td>1188</td>\n",
              "      <td>1152</td>\n",
              "      <td>0</td>\n",
              "      <td>2340</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>1941.0</td>\n",
              "      <td>1</td>\n",
              "      <td>252</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2500</td>\n",
              "      <td>266500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1458</th>\n",
              "      <td>20</td>\n",
              "      <td>68.0</td>\n",
              "      <td>9717</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>1950</td>\n",
              "      <td>1996</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49</td>\n",
              "      <td>1029</td>\n",
              "      <td>0</td>\n",
              "      <td>1078</td>\n",
              "      <td>1078</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1078</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1950.0</td>\n",
              "      <td>1</td>\n",
              "      <td>240</td>\n",
              "      <td>366</td>\n",
              "      <td>0</td>\n",
              "      <td>112</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>142125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1459</th>\n",
              "      <td>20</td>\n",
              "      <td>75.0</td>\n",
              "      <td>9937</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>1965</td>\n",
              "      <td>1965</td>\n",
              "      <td>0.0</td>\n",
              "      <td>830</td>\n",
              "      <td>290</td>\n",
              "      <td>136</td>\n",
              "      <td>1256</td>\n",
              "      <td>1256</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1256</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1965.0</td>\n",
              "      <td>1</td>\n",
              "      <td>276</td>\n",
              "      <td>736</td>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>147500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1094 rows × 35 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      MSSubClass  LotFrontage  LotArea  ...  PoolArea  MiscVal  SalePrice\n",
              "0             60         65.0     8450  ...         0        0     208500\n",
              "1             20         80.0     9600  ...         0        0     181500\n",
              "2             60         68.0    11250  ...         0        0     223500\n",
              "3             70         60.0     9550  ...         0        0     140000\n",
              "4             60         84.0    14260  ...         0        0     250000\n",
              "...          ...          ...      ...  ...       ...      ...        ...\n",
              "1455          60         62.0     7917  ...         0        0     175000\n",
              "1456          20         85.0    13175  ...         0        0     210000\n",
              "1457          70         66.0     9042  ...         0     2500     266500\n",
              "1458          20         68.0     9717  ...         0        0     142125\n",
              "1459          20         75.0     9937  ...         0        0     147500\n",
              "\n",
              "[1094 rows x 35 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6wVL2LA0lsv"
      },
      "source": [
        "Convert the columns you selected above into dummy variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVKWw1hw0lst",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "178bd479-1719-4cc6-99f5-f90d37a3197c"
      },
      "source": [
        "# Answer below:\n",
        "df = pd.get_dummies(data=df, columns=df.select_dtypes(include='O').columns, drop_first=True).copy()\n",
        "df = pd.get_dummies(data=df, columns=['OverallQual'], drop_first=True).copy()\n",
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>SalePrice</th>\n",
              "      <th>MSZoning_FV</th>\n",
              "      <th>MSZoning_RH</th>\n",
              "      <th>MSZoning_RL</th>\n",
              "      <th>MSZoning_RM</th>\n",
              "      <th>Street_Pave</th>\n",
              "      <th>LotShape_IR2</th>\n",
              "      <th>...</th>\n",
              "      <th>Functional_Mod</th>\n",
              "      <th>Functional_Typ</th>\n",
              "      <th>GarageType_Attchd</th>\n",
              "      <th>GarageType_Basment</th>\n",
              "      <th>GarageType_BuiltIn</th>\n",
              "      <th>GarageType_CarPort</th>\n",
              "      <th>GarageType_Detchd</th>\n",
              "      <th>GarageFinish_RFn</th>\n",
              "      <th>GarageFinish_Unf</th>\n",
              "      <th>GarageQual_Fa</th>\n",
              "      <th>GarageQual_Gd</th>\n",
              "      <th>GarageQual_Po</th>\n",
              "      <th>GarageQual_TA</th>\n",
              "      <th>GarageCond_Fa</th>\n",
              "      <th>GarageCond_Gd</th>\n",
              "      <th>GarageCond_Po</th>\n",
              "      <th>GarageCond_TA</th>\n",
              "      <th>PavedDrive_P</th>\n",
              "      <th>PavedDrive_Y</th>\n",
              "      <th>SaleType_CWD</th>\n",
              "      <th>SaleType_Con</th>\n",
              "      <th>SaleType_ConLD</th>\n",
              "      <th>SaleType_ConLI</th>\n",
              "      <th>SaleType_ConLw</th>\n",
              "      <th>SaleType_New</th>\n",
              "      <th>SaleType_Oth</th>\n",
              "      <th>SaleType_WD</th>\n",
              "      <th>SaleCondition_AdjLand</th>\n",
              "      <th>SaleCondition_Alloca</th>\n",
              "      <th>SaleCondition_Family</th>\n",
              "      <th>SaleCondition_Normal</th>\n",
              "      <th>SaleCondition_Partial</th>\n",
              "      <th>OverallQual_3</th>\n",
              "      <th>OverallQual_4</th>\n",
              "      <th>OverallQual_5</th>\n",
              "      <th>OverallQual_6</th>\n",
              "      <th>OverallQual_7</th>\n",
              "      <th>OverallQual_8</th>\n",
              "      <th>OverallQual_9</th>\n",
              "      <th>OverallQual_10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>5</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>196.0</td>\n",
              "      <td>706</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>856</td>\n",
              "      <td>856</td>\n",
              "      <td>854</td>\n",
              "      <td>0</td>\n",
              "      <td>1710</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>2</td>\n",
              "      <td>548</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>208500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>8</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>0.0</td>\n",
              "      <td>978</td>\n",
              "      <td>0</td>\n",
              "      <td>284</td>\n",
              "      <td>1262</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1976.0</td>\n",
              "      <td>2</td>\n",
              "      <td>460</td>\n",
              "      <td>298</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>181500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>5</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>162.0</td>\n",
              "      <td>486</td>\n",
              "      <td>0</td>\n",
              "      <td>434</td>\n",
              "      <td>920</td>\n",
              "      <td>920</td>\n",
              "      <td>866</td>\n",
              "      <td>0</td>\n",
              "      <td>1786</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>2</td>\n",
              "      <td>608</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>223500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>70</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>5</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>0.0</td>\n",
              "      <td>216</td>\n",
              "      <td>0</td>\n",
              "      <td>540</td>\n",
              "      <td>756</td>\n",
              "      <td>961</td>\n",
              "      <td>756</td>\n",
              "      <td>0</td>\n",
              "      <td>1717</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>3</td>\n",
              "      <td>642</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>140000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>5</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>350.0</td>\n",
              "      <td>655</td>\n",
              "      <td>0</td>\n",
              "      <td>490</td>\n",
              "      <td>1145</td>\n",
              "      <td>1145</td>\n",
              "      <td>1053</td>\n",
              "      <td>0</td>\n",
              "      <td>2198</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>836</td>\n",
              "      <td>192</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>250000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 227 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   MSSubClass  LotFrontage  ...  OverallQual_9  OverallQual_10\n",
              "0          60         65.0  ...              0               0\n",
              "1          20         80.0  ...              0               0\n",
              "2          60         68.0  ...              0               0\n",
              "3          70         60.0  ...              0               0\n",
              "4          60         84.0  ...              0               0\n",
              "\n",
              "[5 rows x 227 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQkbLG0e0lsx"
      },
      "source": [
        "Split the data into train and test with 20% of data in test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SivhGDOu0lsx"
      },
      "source": [
        "# Answer below\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = df.drop(columns='SalePrice')\n",
        "y = df['SalePrice']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujvHdv2z0lsz"
      },
      "source": [
        "Create a model with 5 layers. The first layer should be a dense layer that takes in the input, the last layer should be of size 1. You determine the remaining layer sizes.\n",
        "\n",
        "Use a linear activation for the output layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EvTExRC0lsz"
      },
      "source": [
        "# Answer below\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blQTwPWz0ls1"
      },
      "source": [
        "Compile the model with the RMSprop optimizer and mean square error loss. Use the MSE as a metric. Set batch size to 100 and epochs to 200. Fit the model and report the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjcqV1Zm0ls1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67c0ce29-33bb-4ef6-af5b-836631cbaf97"
      },
      "source": [
        "# Answer below:\n",
        "model.compile(loss='mse', optimizer='RMSprop', metrics=['mse'])\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=100, validation_data=(X_test, y_test))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "9/9 [==============================] - 1s 67ms/step - loss: 43452073984.0000 - mse: 43452073984.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 2/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42319337472.0000 - mse: 42319339110.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 3/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41920283852.8000 - mse: 41920283852.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 4/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 40945722982.4000 - mse: 40945722982.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 5/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42646541107.2000 - mse: 42646541516.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 6/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 39819656192.0000 - mse: 39819656192.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 7/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41189974425.6000 - mse: 41189974425.6000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 8/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41626956185.6000 - mse: 41626956185.6000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 9/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 45800452505.6000 - mse: 45800452505.6000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 10/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 41614961868.8000 - mse: 41614961459.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 11/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42196052787.2000 - mse: 42196051558.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 12/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41561401344.0000 - mse: 41561401344.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 13/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42967897702.4000 - mse: 42967898931.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 14/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42090729062.4000 - mse: 42090729062.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 15/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41211218329.6000 - mse: 41211215462.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 16/200\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 42297146163.2000 - mse: 42297144934.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 17/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 40679563673.6000 - mse: 40679564083.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 18/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 44182300672.0000 - mse: 44182300672.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 19/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41054601625.6000 - mse: 41054601625.6000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 20/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 40715275468.8000 - mse: 40715275468.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 21/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 43047299072.0000 - mse: 43047301939.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 22/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 40330475520.0000 - mse: 40330475520.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 23/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41901204275.2000 - mse: 41901204275.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 24/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42533424742.4000 - mse: 42533424742.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 25/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 43768097996.8000 - mse: 43768097996.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 26/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42568429568.0000 - mse: 42568429568.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 27/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 43923882803.2000 - mse: 43923882803.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 28/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41323950899.2000 - mse: 41323952128.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 29/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41458972672.0000 - mse: 41458970214.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 30/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42026482892.8000 - mse: 42026482892.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 31/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 43321570508.8000 - mse: 43321570508.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 32/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 43106105344.0000 - mse: 43106106163.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 33/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 40520040038.4000 - mse: 40520040038.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 34/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42555525939.2000 - mse: 42555525120.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 35/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41548342067.2000 - mse: 41548342067.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 36/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42278298419.2000 - mse: 42278298419.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 37/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42451110707.2000 - mse: 42451111116.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 38/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 44098989670.4000 - mse: 44098989670.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 39/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 43101187276.8000 - mse: 43101187686.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 40/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 42420849459.2000 - mse: 42420849459.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 41/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42308148428.8000 - mse: 42308148428.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 42/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 41201308057.6000 - mse: 41201308467.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 43/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 45017804800.0000 - mse: 45017804800.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 44/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 43096352358.4000 - mse: 43096350720.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 45/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41814452224.0000 - mse: 41814451814.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 46/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41181390028.8000 - mse: 41181390028.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 47/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 40636850176.0000 - mse: 40636850995.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 48/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 43079009075.2000 - mse: 43079009075.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 49/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41084132966.4000 - mse: 41084132147.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 50/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41793644544.0000 - mse: 41793642905.6000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 51/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 43260153856.0000 - mse: 43260154265.6000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 52/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 40316736716.8000 - mse: 40316736716.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 53/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 40935232307.2000 - mse: 40935232307.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 54/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 40356131635.2000 - mse: 40356131635.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 55/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41673366732.8000 - mse: 41673366323.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 56/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 43727497625.6000 - mse: 43727497625.6000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 57/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42381026099.2000 - mse: 42381026099.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 58/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 43211224268.8000 - mse: 43211224268.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 59/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42219536793.6000 - mse: 42219537203.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 60/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 40885232435.2000 - mse: 40885230387.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 61/200\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 42823063961.6000 - mse: 42823065600.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 62/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 41602081587.2000 - mse: 41602081587.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 63/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42272255590.4000 - mse: 42272258048.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 64/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 40974421606.4000 - mse: 40974421606.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 65/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 42001811456.0000 - mse: 42001811456.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 66/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41380175872.0000 - mse: 41380175872.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 67/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41580455526.4000 - mse: 41580455526.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 68/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 41391993651.2000 - mse: 41391993651.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 69/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42450867814.4000 - mse: 42450866995.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 70/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 40676755865.6000 - mse: 40676757094.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 71/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 39760097689.6000 - mse: 39760097689.6000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 72/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41584753459.2000 - mse: 41584753459.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 73/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 43777266073.6000 - mse: 43777266073.6000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 74/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42198623436.8000 - mse: 42198623436.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 75/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42198180659.2000 - mse: 42198180659.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 76/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42383456256.0000 - mse: 42383456256.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 77/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 44368031744.0000 - mse: 44368031744.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 78/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 42407075430.4000 - mse: 42407075430.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 79/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 44713662464.0000 - mse: 44713662464.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 80/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 41436806758.4000 - mse: 41436806758.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 81/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 44408356454.4000 - mse: 44408356454.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 82/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 39169106739.2000 - mse: 39169106739.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 83/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41716045414.4000 - mse: 41716045414.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 84/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 43602339020.8000 - mse: 43602337382.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 85/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42389396275.2000 - mse: 42389396275.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 86/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41171763609.6000 - mse: 41171763609.6000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 87/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 39458859008.0000 - mse: 39458859008.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 88/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 40919877222.4000 - mse: 40919877222.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 89/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 41005950976.0000 - mse: 41005950976.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 90/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41575024230.4000 - mse: 41575023820.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 91/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 42783694438.4000 - mse: 42783694438.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 92/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41764674355.2000 - mse: 41764674355.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 93/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42270450892.8000 - mse: 42270450892.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 94/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 43668936704.0000 - mse: 43668938342.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 95/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 42849619968.0000 - mse: 42849619968.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 96/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42198986752.0000 - mse: 42198989619.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 97/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42011461222.4000 - mse: 42011461222.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 98/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 40945543168.0000 - mse: 40945543168.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 99/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 40891344486.4000 - mse: 40891344486.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 100/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 40862205952.0000 - mse: 40862205952.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 101/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42177762918.4000 - mse: 42177762918.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 102/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 43024910336.0000 - mse: 43024907468.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 103/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 40390533120.0000 - mse: 40390533120.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 104/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42511217459.2000 - mse: 42511217459.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 105/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42224770662.4000 - mse: 42224767795.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 106/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 40792898355.2000 - mse: 40792899174.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 107/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 43210390732.8000 - mse: 43210390732.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 108/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 41984285081.6000 - mse: 41984285081.6000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 109/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 40498925568.0000 - mse: 40498929254.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 110/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41736599961.6000 - mse: 41736599961.6000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 111/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 41430219571.2000 - mse: 41430218752.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 112/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 40427874713.6000 - mse: 40427874713.6000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 113/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41749280358.4000 - mse: 41749278720.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 114/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41986614067.2000 - mse: 41986611609.6000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 115/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 43194008780.8000 - mse: 43194008780.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 116/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41911975526.4000 - mse: 41911975526.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 117/200\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 42898681856.0000 - mse: 42898683494.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 118/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 43118929920.0000 - mse: 43118929920.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 119/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42891266867.2000 - mse: 42891266867.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 120/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 45075207372.8000 - mse: 45075207372.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 121/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 41087035801.6000 - mse: 41087035801.6000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 122/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 39787171020.8000 - mse: 39787171020.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 123/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 42605313638.4000 - mse: 42605313638.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 124/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41342235033.6000 - mse: 41342235852.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 125/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41688405196.8000 - mse: 41688405196.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 126/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42477894041.6000 - mse: 42477894041.6000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 127/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 41128479129.6000 - mse: 41128479129.6000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 128/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 42113131724.8000 - mse: 42113131724.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 129/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42632726937.6000 - mse: 42632724889.6000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 130/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 40814580531.2000 - mse: 40814581350.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 131/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41108076544.0000 - mse: 41108076544.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 132/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 42284324044.8000 - mse: 42284324044.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 133/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 42376260812.8000 - mse: 42376259993.6000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 134/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42755738828.8000 - mse: 42755738828.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 135/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42617652019.2000 - mse: 42617652019.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 136/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 43675445657.6000 - mse: 43675445657.6000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 137/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42211196108.8000 - mse: 42211196108.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 138/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 43505853644.8000 - mse: 43505853644.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 139/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 40374600499.2000 - mse: 40374600499.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 140/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41756815769.6000 - mse: 41756815769.6000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 141/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 41360049356.8000 - mse: 41360049356.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 142/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41797019648.0000 - mse: 41797019648.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 143/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 44137394995.2000 - mse: 44137394995.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 144/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 41922808627.2000 - mse: 41922811904.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 145/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42534514688.0000 - mse: 42534514688.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 146/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 44177129062.4000 - mse: 44177129062.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 147/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42343503872.0000 - mse: 42343506739.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 148/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 43387950284.8000 - mse: 43387951104.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 149/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 40086218342.4000 - mse: 40086215475.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 150/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 43863584768.0000 - mse: 43863584768.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 151/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 44377889996.8000 - mse: 44377889996.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 152/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 41069168230.4000 - mse: 41069168230.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 153/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 41839779020.8000 - mse: 41839779020.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 154/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 41814910156.8000 - mse: 41814911795.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 155/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 41954488729.6000 - mse: 41954488729.6000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 156/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 39888955801.6000 - mse: 39888956211.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 157/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 42033582489.6000 - mse: 42033582489.6000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 158/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 42741503590.4000 - mse: 42741503590.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 159/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42892529254.4000 - mse: 42892529254.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 160/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 43266136883.2000 - mse: 43266136883.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 161/200\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 41120812236.8000 - mse: 41120812236.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 162/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 44356062003.2000 - mse: 44356060364.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 163/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41781011660.8000 - mse: 41781011660.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 164/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 43662180761.6000 - mse: 43662180761.6000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 165/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 41601075609.6000 - mse: 41601075609.6000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 166/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 40329063219.2000 - mse: 40329063219.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 167/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 44028034252.8000 - mse: 44028034252.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 168/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42755869491.2000 - mse: 42755866624.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 169/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 42020853350.4000 - mse: 42020853350.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 170/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 44184058675.2000 - mse: 44184058675.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 171/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 43157192294.4000 - mse: 43157192294.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 172/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 41884763750.4000 - mse: 41884763750.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 173/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 45031170457.6000 - mse: 45031170457.6000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 174/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 41779620249.6000 - mse: 41779620249.6000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 175/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 43247024537.6000 - mse: 43247021260.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 176/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 41537583513.6000 - mse: 41537582694.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 177/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 42817101004.8000 - mse: 42817096089.6000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 178/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 40949499904.0000 - mse: 40949500313.6000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 179/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 40581258854.4000 - mse: 40581259673.6000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 180/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 41845978316.8000 - mse: 41845975859.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 181/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 42987892326.4000 - mse: 42987892326.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 182/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 43405288243.2000 - mse: 43405288243.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 183/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42224427417.6000 - mse: 42224427417.6000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 184/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 42192866099.2000 - mse: 42192866099.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 185/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41960124006.4000 - mse: 41960123596.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 186/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 39536258252.8000 - mse: 39536258662.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 187/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 44276428390.4000 - mse: 44276428800.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 188/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 42615191142.4000 - mse: 42615193600.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 189/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 44791781376.0000 - mse: 44791781376.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 190/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 42522951680.0000 - mse: 42522950860.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 191/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 43549669785.6000 - mse: 43549669785.6000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 192/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 45287195443.2000 - mse: 45287195443.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 193/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41544308736.0000 - mse: 41544308736.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 194/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 40585653657.6000 - mse: 40585653248.0000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 195/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 40765099212.8000 - mse: 40765099212.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 196/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 42629409587.2000 - mse: 42629412044.8000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 197/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 41607479705.6000 - mse: 41607479705.6000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 198/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 40542178918.4000 - mse: 40542178918.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 199/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41935540633.6000 - mse: 41935541862.4000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n",
            "Epoch 200/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 40704104243.2000 - mse: 40704104243.2000 - val_loss: 41003831296.0000 - val_mse: 41003831296.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5221b81eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD1byILV0ls3"
      },
      "source": [
        "Next, do the same but with mean absolute error loss. Use both MSE and MAE as metrics. Compare the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xz0cnwUq0ls4"
      },
      "source": [
        "# Answer below:\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "model.compile(loss='mae', optimizer='RMSprop', metrics=['mse', 'mae'])\n",
        "\n",
        "# history = model.fit(X_train_scaled, y_train, validation_data=(X_test_scaled, y_test), epochs=1000, batch_size=50)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-NxNmbCGBAK",
        "outputId": "94cc913f-c03f-4e55-a87e-4677f3257993"
      },
      "source": [
        "model.fit(X_train, y_train, epochs=200, batch_size=100, validation_data=(X_test, y_test))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "9/9 [==============================] - 1s 34ms/step - loss: 189265.6516 - mse: 43746596864.0000 - mae: 189265.6516 - val_loss: 188397.3125 - val_mse: 40457920512.0000 - val_mae: 188397.3125\n",
            "Epoch 2/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 183103.7344 - mse: 41485268582.4000 - mae: 183103.7344 - val_loss: 184702.9375 - val_mse: 39015030784.0000 - val_mae: 184702.9375\n",
            "Epoch 3/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 177350.0516 - mse: 38197649408.0000 - mae: 177350.0516 - val_loss: 176549.0625 - val_mse: 35936731136.0000 - val_mae: 176549.0625\n",
            "Epoch 4/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 169907.1063 - mse: 36174714470.4000 - mae: 169907.1063 - val_loss: 160301.4219 - val_mse: 30220058624.0000 - val_mae: 160301.4062\n",
            "Epoch 5/200\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 151294.2266 - mse: 29259780096.0000 - mae: 151294.2266 - val_loss: 133658.7344 - val_mse: 22021834752.0000 - val_mae: 133658.7344\n",
            "Epoch 6/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 119214.2227 - mse: 20394695475.2000 - mae: 119214.2227 - val_loss: 94723.0234 - val_mse: 12456180736.0000 - val_mae: 94723.0234\n",
            "Epoch 7/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 81416.8633 - mse: 13501139763.2000 - mae: 81416.8617 - val_loss: 54272.2969 - val_mse: 5472819200.0000 - val_mae: 54272.2969\n",
            "Epoch 8/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 54679.2168 - mse: 9143145216.0000 - mae: 54679.2168 - val_loss: 46445.4961 - val_mse: 4065161984.0000 - val_mae: 46445.4961\n",
            "Epoch 9/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 49834.3977 - mse: 6168690022.4000 - mae: 49834.3977 - val_loss: 46935.2422 - val_mse: 4188691200.0000 - val_mae: 46935.2422\n",
            "Epoch 10/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 51852.2801 - mse: 10831337164.8000 - mae: 51852.2801 - val_loss: 45010.0586 - val_mse: 3833694720.0000 - val_mae: 45010.0586\n",
            "Epoch 11/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 48416.5586 - mse: 6557001420.8000 - mae: 48416.5586 - val_loss: 43693.0469 - val_mse: 3574881792.0000 - val_mae: 43693.0469\n",
            "Epoch 12/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 47801.3371 - mse: 9172111155.2000 - mae: 47801.3371 - val_loss: 43665.6445 - val_mse: 3634912000.0000 - val_mae: 43665.6445\n",
            "Epoch 13/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 50758.9965 - mse: 9693219891.2000 - mae: 50758.9965 - val_loss: 43519.1250 - val_mse: 3651716096.0000 - val_mae: 43519.1250\n",
            "Epoch 14/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 45937.5980 - mse: 5667162368.0000 - mae: 45937.5977 - val_loss: 42434.8398 - val_mse: 3480673024.0000 - val_mae: 42434.8438\n",
            "Epoch 15/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 46154.3754 - mse: 6192164864.0000 - mae: 46154.3754 - val_loss: 42236.6602 - val_mse: 3498017792.0000 - val_mae: 42236.6602\n",
            "Epoch 16/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 45727.0832 - mse: 6236479948.8000 - mae: 45727.0832 - val_loss: 40680.2500 - val_mse: 3231528192.0000 - val_mae: 40680.2500\n",
            "Epoch 17/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 48407.8984 - mse: 8426097049.6000 - mae: 48407.8984 - val_loss: 39914.6328 - val_mse: 3133791232.0000 - val_mae: 39914.6328\n",
            "Epoch 18/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 42843.0133 - mse: 4639975424.0000 - mae: 42843.0129 - val_loss: 37421.6406 - val_mse: 2646056448.0000 - val_mae: 37421.6406\n",
            "Epoch 19/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 44223.4148 - mse: 6393627699.2000 - mae: 44223.4148 - val_loss: 38623.2695 - val_mse: 3027466752.0000 - val_mae: 38623.2695\n",
            "Epoch 20/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 42173.7043 - mse: 4722924518.4000 - mae: 42173.7023 - val_loss: 36917.4219 - val_mse: 2747903232.0000 - val_mae: 36917.4219\n",
            "Epoch 21/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 40936.6402 - mse: 4710776294.4000 - mae: 40936.6402 - val_loss: 34762.3555 - val_mse: 2286045184.0000 - val_mae: 34762.3555\n",
            "Epoch 22/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 41412.1875 - mse: 5592490854.4000 - mae: 41412.1875 - val_loss: 34641.1992 - val_mse: 2441996032.0000 - val_mae: 34641.1992\n",
            "Epoch 23/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 40024.1094 - mse: 5023599769.6000 - mae: 40024.1094 - val_loss: 32858.2617 - val_mse: 2166094080.0000 - val_mae: 32858.2617\n",
            "Epoch 24/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 39150.3551 - mse: 4299451750.4000 - mae: 39150.3551 - val_loss: 31904.1914 - val_mse: 2067537152.0000 - val_mae: 31904.1934\n",
            "Epoch 25/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 37999.4844 - mse: 3887424128.0000 - mae: 37999.4848 - val_loss: 31569.2305 - val_mse: 2131094656.0000 - val_mae: 31569.2305\n",
            "Epoch 26/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 34341.5217 - mse: 2930166988.8000 - mae: 34341.5217 - val_loss: 30164.2480 - val_mse: 1842396416.0000 - val_mae: 30164.2480\n",
            "Epoch 27/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 35958.4219 - mse: 3187917260.8000 - mae: 35958.4219 - val_loss: 29806.3750 - val_mse: 1900743040.0000 - val_mae: 29806.3750\n",
            "Epoch 28/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 35712.9930 - mse: 3238567552.0000 - mae: 35712.9918 - val_loss: 28879.8457 - val_mse: 1756187648.0000 - val_mae: 28879.8457\n",
            "Epoch 29/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 33551.9826 - mse: 2739015232.0000 - mae: 33551.9826 - val_loss: 29210.2305 - val_mse: 1664966656.0000 - val_mae: 29210.2305\n",
            "Epoch 30/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 34851.4850 - mse: 3341151769.6000 - mae: 34851.4850 - val_loss: 28332.4727 - val_mse: 1737271808.0000 - val_mae: 28332.4727\n",
            "Epoch 31/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 32637.2418 - mse: 2908526208.0000 - mae: 32637.2418 - val_loss: 28405.5801 - val_mse: 1750278784.0000 - val_mae: 28405.5801\n",
            "Epoch 32/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 30620.8217 - mse: 2201257907.2000 - mae: 30620.8232 - val_loss: 27093.8594 - val_mse: 1575733504.0000 - val_mae: 27093.8594\n",
            "Epoch 33/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 32812.3457 - mse: 2868786560.0000 - mae: 32812.3457 - val_loss: 26776.1543 - val_mse: 1542069248.0000 - val_mae: 26776.1543\n",
            "Epoch 34/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 32299.2223 - mse: 2620134169.6000 - mae: 32299.2223 - val_loss: 27199.4102 - val_mse: 1616141824.0000 - val_mae: 27199.4102\n",
            "Epoch 35/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 32108.1197 - mse: 2565044966.4000 - mae: 32108.1197 - val_loss: 26350.0801 - val_mse: 1471073024.0000 - val_mae: 26350.0801\n",
            "Epoch 36/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 31535.5180 - mse: 2961323110.4000 - mae: 31535.5180 - val_loss: 28354.7695 - val_mse: 1693799424.0000 - val_mae: 28354.7695\n",
            "Epoch 37/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 31089.9094 - mse: 2412331417.6000 - mae: 31089.9094 - val_loss: 26055.4727 - val_mse: 1431986048.0000 - val_mae: 26055.4727\n",
            "Epoch 38/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 31468.3109 - mse: 2854709747.2000 - mae: 31468.3109 - val_loss: 25902.7461 - val_mse: 1407506176.0000 - val_mae: 25902.7441\n",
            "Epoch 39/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 32319.7418 - mse: 3075176768.0000 - mae: 32319.7418 - val_loss: 25933.7305 - val_mse: 1447926528.0000 - val_mae: 25933.7305\n",
            "Epoch 40/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 31042.4219 - mse: 2997468915.2000 - mae: 31042.4219 - val_loss: 26411.4004 - val_mse: 1381607296.0000 - val_mae: 26411.4004\n",
            "Epoch 41/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 31318.1791 - mse: 2966269849.6000 - mae: 31318.1791 - val_loss: 25713.2480 - val_mse: 1344445440.0000 - val_mae: 25713.2480\n",
            "Epoch 42/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 31956.7875 - mse: 2730026982.4000 - mae: 31956.7854 - val_loss: 25698.6484 - val_mse: 1335218688.0000 - val_mae: 25698.6484\n",
            "Epoch 43/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 30852.6043 - mse: 2616396019.2000 - mae: 30852.6043 - val_loss: 25378.8555 - val_mse: 1340799104.0000 - val_mae: 25378.8555\n",
            "Epoch 44/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 29524.5902 - mse: 2259690892.8000 - mae: 29524.5902 - val_loss: 25344.9492 - val_mse: 1330495744.0000 - val_mae: 25344.9492\n",
            "Epoch 45/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 28141.8252 - mse: 2344048563.2000 - mae: 28141.8252 - val_loss: 25255.2344 - val_mse: 1305936640.0000 - val_mae: 25255.2344\n",
            "Epoch 46/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 29531.4576 - mse: 2362651097.6000 - mae: 29531.4576 - val_loss: 25650.9727 - val_mse: 1316147840.0000 - val_mae: 25650.9727\n",
            "Epoch 47/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 31361.2396 - mse: 3538345676.8000 - mae: 31361.2396 - val_loss: 25302.2734 - val_mse: 1292422400.0000 - val_mae: 25302.2734\n",
            "Epoch 48/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 28832.2643 - mse: 2403798118.4000 - mae: 28832.2643 - val_loss: 25212.6582 - val_mse: 1283992960.0000 - val_mae: 25212.6582\n",
            "Epoch 49/200\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 30245.4594 - mse: 2327313779.2000 - mae: 30245.4594 - val_loss: 25079.3262 - val_mse: 1276711552.0000 - val_mae: 25079.3262\n",
            "Epoch 50/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 29567.5609 - mse: 2212562764.8000 - mae: 29567.5609 - val_loss: 25146.4004 - val_mse: 1270655104.0000 - val_mae: 25146.4004\n",
            "Epoch 51/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 29972.6883 - mse: 2972840550.4000 - mae: 29972.6883 - val_loss: 27343.9609 - val_mse: 1425162752.0000 - val_mae: 27343.9609\n",
            "Epoch 52/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 31766.0471 - mse: 4068680064.0000 - mae: 31766.0439 - val_loss: 25917.1367 - val_mse: 1319665024.0000 - val_mae: 25917.1367\n",
            "Epoch 53/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 29302.6348 - mse: 2645121126.4000 - mae: 29302.6348 - val_loss: 25264.3066 - val_mse: 1276186880.0000 - val_mae: 25264.3066\n",
            "Epoch 54/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 28718.5969 - mse: 2092907366.4000 - mae: 28718.5969 - val_loss: 24963.5156 - val_mse: 1266729600.0000 - val_mae: 24963.5156\n",
            "Epoch 55/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 27976.5031 - mse: 1894041024.0000 - mae: 27976.5031 - val_loss: 25021.1992 - val_mse: 1260268928.0000 - val_mae: 25021.1992\n",
            "Epoch 56/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 28595.2453 - mse: 2067496691.2000 - mae: 28595.2453 - val_loss: 24945.7617 - val_mse: 1262265984.0000 - val_mae: 24945.7617\n",
            "Epoch 57/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 27800.4818 - mse: 1885740684.8000 - mae: 27800.4818 - val_loss: 26048.8418 - val_mse: 1325631104.0000 - val_mae: 26048.8418\n",
            "Epoch 58/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 27473.9332 - mse: 1740075712.0000 - mae: 27473.9332 - val_loss: 25309.5156 - val_mse: 1295025536.0000 - val_mae: 25309.5156\n",
            "Epoch 59/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 28374.0941 - mse: 2260637273.6000 - mae: 28374.0941 - val_loss: 24963.3359 - val_mse: 1253103872.0000 - val_mae: 24963.3359\n",
            "Epoch 60/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 30298.3354 - mse: 2626813862.4000 - mae: 30298.3354 - val_loss: 24870.5391 - val_mse: 1255351296.0000 - val_mae: 24870.5391\n",
            "Epoch 61/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 28545.7303 - mse: 2461753472.0000 - mae: 28545.7303 - val_loss: 25780.7344 - val_mse: 1303963648.0000 - val_mae: 25780.7344\n",
            "Epoch 62/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 29006.9672 - mse: 2019392166.4000 - mae: 29006.9672 - val_loss: 26995.7793 - val_mse: 1396049408.0000 - val_mae: 26995.7793\n",
            "Epoch 63/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 28094.4047 - mse: 2109239616.0000 - mae: 28094.4047 - val_loss: 25759.6660 - val_mse: 1300594176.0000 - val_mae: 25759.6660\n",
            "Epoch 64/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 27796.6154 - mse: 1966861030.4000 - mae: 27796.6154 - val_loss: 26306.9277 - val_mse: 1340368256.0000 - val_mae: 26306.9277\n",
            "Epoch 65/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 29826.5340 - mse: 2521067392.0000 - mae: 29826.5354 - val_loss: 25179.3496 - val_mse: 1259116416.0000 - val_mae: 25179.3496\n",
            "Epoch 66/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 30365.3543 - mse: 3618692787.2000 - mae: 30365.3541 - val_loss: 25190.3691 - val_mse: 1258933504.0000 - val_mae: 25190.3691\n",
            "Epoch 67/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 28842.8887 - mse: 2746871910.4000 - mae: 28842.8887 - val_loss: 25143.3066 - val_mse: 1255117696.0000 - val_mae: 25143.3066\n",
            "Epoch 68/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 27357.6725 - mse: 2112129484.8000 - mae: 27357.6725 - val_loss: 24879.5312 - val_mse: 1239308544.0000 - val_mae: 24879.5312\n",
            "Epoch 69/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 28878.7418 - mse: 2350467123.2000 - mae: 28878.7418 - val_loss: 27435.4277 - val_mse: 1423093120.0000 - val_mae: 27435.4277\n",
            "Epoch 70/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 29214.3318 - mse: 3136084057.6000 - mae: 29214.3318 - val_loss: 24821.5312 - val_mse: 1236171136.0000 - val_mae: 24821.5312\n",
            "Epoch 71/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 28529.8215 - mse: 2200558476.8000 - mae: 28529.8215 - val_loss: 26189.0840 - val_mse: 1325920768.0000 - val_mae: 26189.0840\n",
            "Epoch 72/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 30618.1125 - mse: 3749169280.0000 - mae: 30618.1113 - val_loss: 25021.1582 - val_mse: 1262000128.0000 - val_mae: 25021.1582\n",
            "Epoch 73/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 29216.9895 - mse: 2406204620.8000 - mae: 29216.9895 - val_loss: 24748.4766 - val_mse: 1239477376.0000 - val_mae: 24748.4766\n",
            "Epoch 74/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 29489.8973 - mse: 2587949875.2000 - mae: 29489.8973 - val_loss: 24972.4141 - val_mse: 1239508864.0000 - val_mae: 24972.4141\n",
            "Epoch 75/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 31289.5281 - mse: 3914103552.0000 - mae: 31289.5281 - val_loss: 26570.7617 - val_mse: 1355692160.0000 - val_mae: 26570.7617\n",
            "Epoch 76/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 28222.8350 - mse: 2345767654.4000 - mae: 28222.8350 - val_loss: 25163.3633 - val_mse: 1267996928.0000 - val_mae: 25163.3633\n",
            "Epoch 77/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 28045.0281 - mse: 2320917184.0000 - mae: 28045.0268 - val_loss: 24935.3945 - val_mse: 1238931072.0000 - val_mae: 24935.3945\n",
            "Epoch 78/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 27724.8648 - mse: 2733854016.0000 - mae: 27724.8648 - val_loss: 25049.8457 - val_mse: 1246236800.0000 - val_mae: 25049.8457\n",
            "Epoch 79/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 27237.0055 - mse: 2221447257.6000 - mae: 27237.0055 - val_loss: 24612.1328 - val_mse: 1221386752.0000 - val_mae: 24612.1328\n",
            "Epoch 80/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 29337.1664 - mse: 3135074457.6000 - mae: 29337.1664 - val_loss: 25192.1465 - val_mse: 1254297600.0000 - val_mae: 25192.1465\n",
            "Epoch 81/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 29188.7021 - mse: 2651006681.6000 - mae: 29188.7021 - val_loss: 24546.0273 - val_mse: 1220911104.0000 - val_mae: 24546.0273\n",
            "Epoch 82/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 28528.9789 - mse: 2193538547.2000 - mae: 28528.9789 - val_loss: 24620.5098 - val_mse: 1221044864.0000 - val_mae: 24620.5098\n",
            "Epoch 83/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 28581.7168 - mse: 2790416819.2000 - mae: 28581.7168 - val_loss: 25982.0508 - val_mse: 1310104192.0000 - val_mae: 25982.0508\n",
            "Epoch 84/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 30493.3855 - mse: 3017118412.8000 - mae: 30493.3855 - val_loss: 24503.5938 - val_mse: 1219336704.0000 - val_mae: 24503.5938\n",
            "Epoch 85/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 27266.8893 - mse: 2098362355.2000 - mae: 27266.8893 - val_loss: 24912.0898 - val_mse: 1235980800.0000 - val_mae: 24912.0898\n",
            "Epoch 86/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 28329.4539 - mse: 2113294220.8000 - mae: 28329.4539 - val_loss: 24470.5645 - val_mse: 1218703744.0000 - val_mae: 24470.5645\n",
            "Epoch 87/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 28072.7482 - mse: 2552737523.2000 - mae: 28072.7482 - val_loss: 25061.2754 - val_mse: 1245609344.0000 - val_mae: 25061.2754\n",
            "Epoch 88/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 27534.1201 - mse: 2104746790.4000 - mae: 27534.1215 - val_loss: 26874.8691 - val_mse: 1380183680.0000 - val_mae: 26874.8691\n",
            "Epoch 89/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 27380.2783 - mse: 1971522982.4000 - mae: 27380.2783 - val_loss: 24469.0898 - val_mse: 1212782208.0000 - val_mae: 24469.0898\n",
            "Epoch 90/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 27239.4275 - mse: 2188648064.0000 - mae: 27239.4275 - val_loss: 24686.9043 - val_mse: 1233457152.0000 - val_mae: 24686.9043\n",
            "Epoch 91/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 27649.2807 - mse: 1981741491.2000 - mae: 27649.2807 - val_loss: 25826.4199 - val_mse: 1298344448.0000 - val_mae: 25826.4199\n",
            "Epoch 92/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 28741.4154 - mse: 4089690112.0000 - mae: 28741.4154 - val_loss: 26185.0977 - val_mse: 1325442304.0000 - val_mae: 26185.0977\n",
            "Epoch 93/200\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 28411.9865 - mse: 2107390259.2000 - mae: 28411.9865 - val_loss: 25641.4609 - val_mse: 1283328384.0000 - val_mae: 25641.4609\n",
            "Epoch 94/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 29311.0863 - mse: 2825092505.6000 - mae: 29311.0863 - val_loss: 25219.7285 - val_mse: 1254102016.0000 - val_mae: 25219.7285\n",
            "Epoch 95/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 26954.9645 - mse: 1803644147.2000 - mae: 26954.9645 - val_loss: 24788.7539 - val_mse: 1235646592.0000 - val_mae: 24788.7539\n",
            "Epoch 96/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 27220.9275 - mse: 1983567475.2000 - mae: 27220.9275 - val_loss: 24627.8027 - val_mse: 1214722944.0000 - val_mae: 24627.8027\n",
            "Epoch 97/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 28140.9285 - mse: 2717601228.8000 - mae: 28140.9285 - val_loss: 24324.6797 - val_mse: 1200660864.0000 - val_mae: 24324.6797\n",
            "Epoch 98/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 26560.7434 - mse: 1735490355.2000 - mae: 26560.7434 - val_loss: 24322.4727 - val_mse: 1200129792.0000 - val_mae: 24322.4727\n",
            "Epoch 99/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 29022.6330 - mse: 3493464652.8000 - mae: 29022.6330 - val_loss: 24398.5723 - val_mse: 1202651648.0000 - val_mae: 24398.5723\n",
            "Epoch 100/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 26809.4633 - mse: 2013665344.0000 - mae: 26809.4633 - val_loss: 25743.8066 - val_mse: 1290612480.0000 - val_mae: 25743.8066\n",
            "Epoch 101/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 28796.7428 - mse: 2990987712.0000 - mae: 28796.7428 - val_loss: 24233.9199 - val_mse: 1197679488.0000 - val_mae: 24233.9199\n",
            "Epoch 102/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 27939.1588 - mse: 2821919756.8000 - mae: 27939.1592 - val_loss: 24628.1641 - val_mse: 1212332032.0000 - val_mae: 24628.1641\n",
            "Epoch 103/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 27641.9662 - mse: 2446724441.6000 - mae: 27641.9662 - val_loss: 25519.9746 - val_mse: 1272615424.0000 - val_mae: 25519.9746\n",
            "Epoch 104/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 28963.4818 - mse: 2187635212.8000 - mae: 28963.4807 - val_loss: 24179.9316 - val_mse: 1194075904.0000 - val_mae: 24179.9316\n",
            "Epoch 105/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 29858.4229 - mse: 3533859712.0000 - mae: 29858.4229 - val_loss: 24469.3066 - val_mse: 1201612032.0000 - val_mae: 24469.3066\n",
            "Epoch 106/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 28519.1730 - mse: 2379043840.0000 - mae: 28519.1730 - val_loss: 24539.7305 - val_mse: 1215426944.0000 - val_mae: 24539.7305\n",
            "Epoch 107/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 29939.4172 - mse: 3519370649.6000 - mae: 29939.4172 - val_loss: 24667.0410 - val_mse: 1212208000.0000 - val_mae: 24667.0410\n",
            "Epoch 108/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 26901.5270 - mse: 1975412876.8000 - mae: 26901.5270 - val_loss: 24949.8691 - val_mse: 1237810176.0000 - val_mae: 24949.8691\n",
            "Epoch 109/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 27182.9791 - mse: 2300707520.0000 - mae: 27182.9791 - val_loss: 24253.0781 - val_mse: 1202367744.0000 - val_mae: 24253.0781\n",
            "Epoch 110/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 29414.9639 - mse: 3527657728.0000 - mae: 29414.9639 - val_loss: 24080.2715 - val_mse: 1190811136.0000 - val_mae: 24080.2715\n",
            "Epoch 111/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 26856.7719 - mse: 2082078886.4000 - mae: 26856.7719 - val_loss: 24342.8887 - val_mse: 1194723584.0000 - val_mae: 24342.8887\n",
            "Epoch 112/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 29283.9559 - mse: 3311640064.0000 - mae: 29283.9559 - val_loss: 26453.8926 - val_mse: 1347431040.0000 - val_mae: 26453.8926\n",
            "Epoch 113/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 27581.7547 - mse: 2505783948.8000 - mae: 27581.7547 - val_loss: 24050.4062 - val_mse: 1190928256.0000 - val_mae: 24050.4062\n",
            "Epoch 114/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 28365.6146 - mse: 2950179878.4000 - mae: 28365.6146 - val_loss: 24112.6484 - val_mse: 1184231040.0000 - val_mae: 24112.6484\n",
            "Epoch 115/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 27029.3576 - mse: 2019893734.4000 - mae: 27029.3576 - val_loss: 25381.7168 - val_mse: 1263133568.0000 - val_mae: 25381.7168\n",
            "Epoch 116/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 28790.2289 - mse: 3213158643.2000 - mae: 28790.2289 - val_loss: 24093.4922 - val_mse: 1182843136.0000 - val_mae: 24093.4922\n",
            "Epoch 117/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 27216.8553 - mse: 2111382464.0000 - mae: 27216.8553 - val_loss: 24661.8730 - val_mse: 1214477440.0000 - val_mae: 24661.8730\n",
            "Epoch 118/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 26284.0824 - mse: 2535326419.2000 - mae: 26284.0824 - val_loss: 25941.5137 - val_mse: 1306359552.0000 - val_mae: 25941.5137\n",
            "Epoch 119/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 26969.3947 - mse: 2072336281.6000 - mae: 26969.3947 - val_loss: 25628.2520 - val_mse: 1281237760.0000 - val_mae: 25628.2520\n",
            "Epoch 120/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 27480.9551 - mse: 1982273036.8000 - mae: 27480.9551 - val_loss: 26570.0957 - val_mse: 1352972416.0000 - val_mae: 26570.0957\n",
            "Epoch 121/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 30922.1063 - mse: 4087678848.0000 - mae: 30922.1063 - val_loss: 24932.4980 - val_mse: 1230536448.0000 - val_mae: 24932.4980\n",
            "Epoch 122/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 27566.0873 - mse: 2553439667.2000 - mae: 27566.0873 - val_loss: 25094.6992 - val_mse: 1242339968.0000 - val_mae: 25094.6992\n",
            "Epoch 123/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 29097.2250 - mse: 3229992832.0000 - mae: 29097.2250 - val_loss: 29523.7402 - val_mse: 1599395456.0000 - val_mae: 29523.7402\n",
            "Epoch 124/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 31468.9367 - mse: 4366769740.8000 - mae: 31468.9367 - val_loss: 24911.9414 - val_mse: 1233704960.0000 - val_mae: 24911.9414\n",
            "Epoch 125/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 27344.4164 - mse: 2248624768.0000 - mae: 27344.4164 - val_loss: 23985.0781 - val_mse: 1177051264.0000 - val_mae: 23985.0781\n",
            "Epoch 126/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 26825.9250 - mse: 2450541580.8000 - mae: 26825.9250 - val_loss: 24713.3945 - val_mse: 1218626944.0000 - val_mae: 24713.3945\n",
            "Epoch 127/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 27488.6727 - mse: 2336582220.8000 - mae: 27488.6727 - val_loss: 24730.0840 - val_mse: 1218158592.0000 - val_mae: 24730.0840\n",
            "Epoch 128/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 28035.8176 - mse: 2880002675.2000 - mae: 28035.8176 - val_loss: 26702.1914 - val_mse: 1363596672.0000 - val_mae: 26702.1914\n",
            "Epoch 129/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 26430.7395 - mse: 1791577657.6000 - mae: 26430.7395 - val_loss: 25116.9824 - val_mse: 1238715648.0000 - val_mae: 25116.9824\n",
            "Epoch 130/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 27338.1969 - mse: 2692315417.6000 - mae: 27338.1967 - val_loss: 23980.9023 - val_mse: 1173459456.0000 - val_mae: 23980.9023\n",
            "Epoch 131/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 26982.1029 - mse: 2111054732.8000 - mae: 26982.1029 - val_loss: 23909.4336 - val_mse: 1169985664.0000 - val_mae: 23909.4336\n",
            "Epoch 132/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 28080.5535 - mse: 2268345881.6000 - mae: 28080.5535 - val_loss: 24847.6055 - val_mse: 1227983488.0000 - val_mae: 24847.6055\n",
            "Epoch 133/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 27507.0980 - mse: 2495718195.2000 - mae: 27507.0980 - val_loss: 25002.7031 - val_mse: 1239248000.0000 - val_mae: 25002.7031\n",
            "Epoch 134/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 28504.9871 - mse: 3039325158.4000 - mae: 28504.9871 - val_loss: 24797.3066 - val_mse: 1222268288.0000 - val_mae: 24797.3066\n",
            "Epoch 135/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 29342.0650 - mse: 3673665331.2000 - mae: 29342.0650 - val_loss: 24479.7012 - val_mse: 1200295040.0000 - val_mae: 24479.7012\n",
            "Epoch 136/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 25843.1441 - mse: 1909851148.8000 - mae: 25843.1441 - val_loss: 25473.6895 - val_mse: 1273445760.0000 - val_mae: 25473.6895\n",
            "Epoch 137/200\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 29406.6680 - mse: 3924490470.4000 - mae: 29406.6680 - val_loss: 23903.1211 - val_mse: 1170060928.0000 - val_mae: 23903.1211\n",
            "Epoch 138/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 26155.4633 - mse: 1798417689.6000 - mae: 26155.4633 - val_loss: 23963.7559 - val_mse: 1171151232.0000 - val_mae: 23963.7559\n",
            "Epoch 139/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 28681.5820 - mse: 2593066675.2000 - mae: 28681.5820 - val_loss: 24279.1602 - val_mse: 1194998656.0000 - val_mae: 24279.1602\n",
            "Epoch 140/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 29239.7547 - mse: 3704995609.6000 - mae: 29239.7543 - val_loss: 24253.0684 - val_mse: 1189169024.0000 - val_mae: 24253.0684\n",
            "Epoch 141/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 30211.9723 - mse: 4291045836.8000 - mae: 30211.9727 - val_loss: 23909.0000 - val_mse: 1167725312.0000 - val_mae: 23909.0000\n",
            "Epoch 142/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 27448.0432 - mse: 2445683852.8000 - mae: 27448.0432 - val_loss: 24746.8340 - val_mse: 1220973824.0000 - val_mae: 24746.8340\n",
            "Epoch 143/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 27430.3387 - mse: 2239315033.6000 - mae: 27430.3387 - val_loss: 26582.5156 - val_mse: 1356929792.0000 - val_mae: 26582.5156\n",
            "Epoch 144/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 29444.3391 - mse: 3097783040.0000 - mae: 29444.3391 - val_loss: 23739.9082 - val_mse: 1162642560.0000 - val_mae: 23739.9082\n",
            "Epoch 145/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 27850.9051 - mse: 3484256537.6000 - mae: 27850.9051 - val_loss: 23762.8750 - val_mse: 1162151680.0000 - val_mae: 23762.8750\n",
            "Epoch 146/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 28878.7887 - mse: 3597526502.4000 - mae: 28878.7887 - val_loss: 23999.6582 - val_mse: 1169875072.0000 - val_mae: 23999.6582\n",
            "Epoch 147/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 27451.8363 - mse: 3437655372.8000 - mae: 27451.8363 - val_loss: 24877.3281 - val_mse: 1232255360.0000 - val_mae: 24877.3281\n",
            "Epoch 148/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 26079.7070 - mse: 1907344409.6000 - mae: 26079.7070 - val_loss: 24351.4180 - val_mse: 1202553728.0000 - val_mae: 24351.4180\n",
            "Epoch 149/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 27087.7975 - mse: 2031225740.8000 - mae: 27087.7975 - val_loss: 23694.1523 - val_mse: 1160469632.0000 - val_mae: 23694.1523\n",
            "Epoch 150/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 29022.1262 - mse: 2411909171.2000 - mae: 29022.1262 - val_loss: 23971.4141 - val_mse: 1169125760.0000 - val_mae: 23971.4141\n",
            "Epoch 151/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 27015.8400 - mse: 1969652761.6000 - mae: 27015.8400 - val_loss: 24316.1875 - val_mse: 1191517824.0000 - val_mae: 24316.1875\n",
            "Epoch 152/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 25832.1842 - mse: 1698553318.4000 - mae: 25832.1840 - val_loss: 24015.6250 - val_mse: 1169068160.0000 - val_mae: 24015.6250\n",
            "Epoch 153/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 25898.6631 - mse: 1827867520.0000 - mae: 25898.6631 - val_loss: 23739.4219 - val_mse: 1162074880.0000 - val_mae: 23739.4219\n",
            "Epoch 154/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 26339.4340 - mse: 2300067353.6000 - mae: 26339.4340 - val_loss: 23782.6992 - val_mse: 1160158080.0000 - val_mae: 23782.6992\n",
            "Epoch 155/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 27346.2727 - mse: 3532691916.8000 - mae: 27346.2727 - val_loss: 24539.2168 - val_mse: 1211469568.0000 - val_mae: 24539.2168\n",
            "Epoch 156/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 27123.1355 - mse: 2584860825.6000 - mae: 27123.1355 - val_loss: 23837.9355 - val_mse: 1165220480.0000 - val_mae: 23837.9355\n",
            "Epoch 157/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 27221.4553 - mse: 2501010227.2000 - mae: 27221.4553 - val_loss: 23652.7871 - val_mse: 1155545472.0000 - val_mae: 23652.7871\n",
            "Epoch 158/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 26455.2662 - mse: 1824206950.4000 - mae: 26455.2662 - val_loss: 23933.1367 - val_mse: 1168516864.0000 - val_mae: 23933.1367\n",
            "Epoch 159/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 28087.8730 - mse: 3522298470.4000 - mae: 28087.8730 - val_loss: 23985.7266 - val_mse: 1173060096.0000 - val_mae: 23985.7266\n",
            "Epoch 160/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 25655.5299 - mse: 1954602009.6000 - mae: 25655.5299 - val_loss: 24458.4219 - val_mse: 1203182592.0000 - val_mae: 24458.4219\n",
            "Epoch 161/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 26438.2861 - mse: 2164928576.0000 - mae: 26438.2861 - val_loss: 27762.8652 - val_mse: 1462013184.0000 - val_mae: 27762.8652\n",
            "Epoch 162/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 27453.6652 - mse: 2246803379.2000 - mae: 27453.6652 - val_loss: 23633.6660 - val_mse: 1153615104.0000 - val_mae: 23633.6660\n",
            "Epoch 163/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 27028.5617 - mse: 2423368665.6000 - mae: 27028.5617 - val_loss: 24217.7422 - val_mse: 1184544256.0000 - val_mae: 24217.7422\n",
            "Epoch 164/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 27675.9791 - mse: 2426912051.2000 - mae: 27675.9791 - val_loss: 23669.6309 - val_mse: 1154864640.0000 - val_mae: 23669.6309\n",
            "Epoch 165/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 27967.8637 - mse: 2663272486.4000 - mae: 27967.8637 - val_loss: 25492.8887 - val_mse: 1276168064.0000 - val_mae: 25492.8887\n",
            "Epoch 166/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 26252.1141 - mse: 2327784934.4000 - mae: 26252.1141 - val_loss: 23628.6406 - val_mse: 1146988800.0000 - val_mae: 23628.6406\n",
            "Epoch 167/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 25269.7715 - mse: 1785002956.8000 - mae: 25269.7715 - val_loss: 24785.7676 - val_mse: 1224656896.0000 - val_mae: 24785.7676\n",
            "Epoch 168/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 26464.8680 - mse: 1907112204.8000 - mae: 26464.8680 - val_loss: 25285.4785 - val_mse: 1261937920.0000 - val_mae: 25285.4785\n",
            "Epoch 169/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 26455.5908 - mse: 2630206438.4000 - mae: 26455.5908 - val_loss: 24269.4160 - val_mse: 1186964864.0000 - val_mae: 24269.4160\n",
            "Epoch 170/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 26829.7223 - mse: 2320968960.0000 - mae: 26829.7223 - val_loss: 24026.2051 - val_mse: 1169260288.0000 - val_mae: 24026.2051\n",
            "Epoch 171/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 26292.7736 - mse: 2442745715.2000 - mae: 26292.7736 - val_loss: 23586.5547 - val_mse: 1146596224.0000 - val_mae: 23586.5547\n",
            "Epoch 172/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 27065.8389 - mse: 2647254899.2000 - mae: 27065.8389 - val_loss: 25250.8555 - val_mse: 1261927808.0000 - val_mae: 25250.8555\n",
            "Epoch 173/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 26564.0619 - mse: 2102023884.8000 - mae: 26564.0619 - val_loss: 26452.9336 - val_mse: 1354171904.0000 - val_mae: 26452.9336\n",
            "Epoch 174/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 26467.7297 - mse: 2003066208.0000 - mae: 26467.7297 - val_loss: 23987.9199 - val_mse: 1169061504.0000 - val_mae: 23987.9199\n",
            "Epoch 175/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 27410.9992 - mse: 2530187110.4000 - mae: 27410.9992 - val_loss: 23549.4844 - val_mse: 1140740992.0000 - val_mae: 23549.4844\n",
            "Epoch 176/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 28026.2609 - mse: 3601212211.2000 - mae: 28026.2613 - val_loss: 27346.0000 - val_mse: 1431904000.0000 - val_mae: 27346.0000\n",
            "Epoch 177/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 28236.3584 - mse: 2529234508.8000 - mae: 28236.3584 - val_loss: 26101.4492 - val_mse: 1328021760.0000 - val_mae: 26101.4492\n",
            "Epoch 178/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 26339.8043 - mse: 1936391180.8000 - mae: 26339.8043 - val_loss: 23969.9180 - val_mse: 1168483328.0000 - val_mae: 23969.9180\n",
            "Epoch 179/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 27689.0207 - mse: 2811202918.4000 - mae: 27689.0207 - val_loss: 23499.5449 - val_mse: 1138595840.0000 - val_mae: 23499.5449\n",
            "Epoch 180/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 27225.3703 - mse: 3061413299.2000 - mae: 27225.3703 - val_loss: 23709.9238 - val_mse: 1150223872.0000 - val_mae: 23709.9238\n",
            "Epoch 181/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 27502.1596 - mse: 3397234380.8000 - mae: 27502.1596 - val_loss: 25626.1758 - val_mse: 1294305024.0000 - val_mae: 25626.1758\n",
            "Epoch 182/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 27209.6578 - mse: 3796861849.6000 - mae: 27209.6578 - val_loss: 24064.3555 - val_mse: 1172720128.0000 - val_mae: 24064.3555\n",
            "Epoch 183/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 26436.0146 - mse: 2192461209.6000 - mae: 26436.0146 - val_loss: 24050.8535 - val_mse: 1170492032.0000 - val_mae: 24050.8535\n",
            "Epoch 184/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 25431.8604 - mse: 1890963942.4000 - mae: 25431.8604 - val_loss: 24999.2266 - val_mse: 1241762816.0000 - val_mae: 24999.2266\n",
            "Epoch 185/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 27803.3215 - mse: 2804780761.6000 - mae: 27803.3215 - val_loss: 29930.9863 - val_mse: 1661646848.0000 - val_mae: 29930.9863\n",
            "Epoch 186/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 27527.6297 - mse: 2211928179.2000 - mae: 27527.6297 - val_loss: 25067.5801 - val_mse: 1246920448.0000 - val_mae: 25067.5801\n",
            "Epoch 187/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 28738.5582 - mse: 3026089216.0000 - mae: 28738.5582 - val_loss: 23571.2461 - val_mse: 1138434560.0000 - val_mae: 23571.2461\n",
            "Epoch 188/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 26271.4732 - mse: 1987403238.4000 - mae: 26271.4732 - val_loss: 23533.6602 - val_mse: 1132400384.0000 - val_mae: 23533.6602\n",
            "Epoch 189/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 26137.9342 - mse: 1759661312.0000 - mae: 26137.9342 - val_loss: 23631.1406 - val_mse: 1144878464.0000 - val_mae: 23631.1406\n",
            "Epoch 190/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 25388.9320 - mse: 1706878464.0000 - mae: 25388.9320 - val_loss: 24194.5645 - val_mse: 1178684672.0000 - val_mae: 24194.5645\n",
            "Epoch 191/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 27207.2236 - mse: 2196294054.4000 - mae: 27207.2236 - val_loss: 23508.2266 - val_mse: 1137645312.0000 - val_mae: 23508.2266\n",
            "Epoch 192/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 27400.5955 - mse: 2438929241.6000 - mae: 27400.5955 - val_loss: 23315.3242 - val_mse: 1127490304.0000 - val_mae: 23315.3242\n",
            "Epoch 193/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 26324.1986 - mse: 2315189824.0000 - mae: 26324.1986 - val_loss: 24335.3379 - val_mse: 1192406784.0000 - val_mae: 24335.3379\n",
            "Epoch 194/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 27885.3221 - mse: 3218136960.0000 - mae: 27885.3221 - val_loss: 23372.0859 - val_mse: 1126986624.0000 - val_mae: 23372.0859\n",
            "Epoch 195/200\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 25469.8445 - mse: 1842472576.0000 - mae: 25469.8445 - val_loss: 23399.7520 - val_mse: 1128668288.0000 - val_mae: 23399.7520\n",
            "Epoch 196/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 24959.5785 - mse: 1787837798.4000 - mae: 24959.5785 - val_loss: 24334.6465 - val_mse: 1193548416.0000 - val_mae: 24334.6465\n",
            "Epoch 197/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 26162.6174 - mse: 2678933824.0000 - mae: 26162.6186 - val_loss: 23546.5078 - val_mse: 1137389568.0000 - val_mae: 23546.5078\n",
            "Epoch 198/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 26555.7568 - mse: 2161390476.8000 - mae: 26555.7568 - val_loss: 23489.5078 - val_mse: 1135774208.0000 - val_mae: 23489.5039\n",
            "Epoch 199/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 28018.3920 - mse: 3701707929.6000 - mae: 28018.3914 - val_loss: 24415.8730 - val_mse: 1201180160.0000 - val_mae: 24415.8730\n",
            "Epoch 200/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 25391.5904 - mse: 1633786880.0000 - mae: 25391.5904 - val_loss: 23423.8281 - val_mse: 1129463936.0000 - val_mae: 23423.8281\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f521e1d0470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUtnWyC60ls5"
      },
      "source": [
        "Finally, try your model using mean squared logarithmic error. Compare the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyTsb-4a0ls5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0e23ee1-e8dc-4816-8bf3-18c166d65bee"
      },
      "source": [
        "# Answer below:\n",
        "\n",
        "model.compile(loss='msle', optimizer='RMSprop', metrics=['msle', 'mae'])\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=100, validation_data=(X_test, y_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "9/9 [==============================] - 1s 37ms/step - loss: 0.0483 - msle: 0.0483 - mae: 29201.4818 - val_loss: 0.0342 - val_msle: 0.0342 - val_mae: 23342.9512\n",
            "Epoch 2/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0447 - msle: 0.0447 - mae: 28024.7842 - val_loss: 0.0340 - val_msle: 0.0340 - val_mae: 23294.2988\n",
            "Epoch 3/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0421 - msle: 0.0421 - mae: 27714.7426 - val_loss: 0.0363 - val_msle: 0.0363 - val_mae: 24063.7891\n",
            "Epoch 4/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0402 - msle: 0.0402 - mae: 26194.3273 - val_loss: 0.0360 - val_msle: 0.0360 - val_mae: 25370.1914\n",
            "Epoch 5/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0436 - msle: 0.0436 - mae: 27867.8225 - val_loss: 0.0389 - val_msle: 0.0389 - val_mae: 25043.0781\n",
            "Epoch 6/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0421 - msle: 0.0421 - mae: 27253.3045 - val_loss: 0.0341 - val_msle: 0.0341 - val_mae: 23574.0996\n",
            "Epoch 7/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0358 - msle: 0.0358 - mae: 26149.9736 - val_loss: 0.0340 - val_msle: 0.0340 - val_mae: 23421.5566\n",
            "Epoch 8/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0377 - msle: 0.0377 - mae: 26978.1180 - val_loss: 0.0346 - val_msle: 0.0346 - val_mae: 24212.0176\n",
            "Epoch 9/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0391 - msle: 0.0391 - mae: 26173.5869 - val_loss: 0.0362 - val_msle: 0.0362 - val_mae: 23950.2715\n",
            "Epoch 10/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0461 - msle: 0.0461 - mae: 27648.2750 - val_loss: 0.0346 - val_msle: 0.0346 - val_mae: 23368.2383\n",
            "Epoch 11/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0444 - msle: 0.0444 - mae: 27697.5451 - val_loss: 0.0380 - val_msle: 0.0380 - val_mae: 24567.2012\n",
            "Epoch 12/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0418 - msle: 0.0418 - mae: 26047.6008 - val_loss: 0.0344 - val_msle: 0.0344 - val_mae: 24035.1719\n",
            "Epoch 13/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0459 - msle: 0.0459 - mae: 29437.1350 - val_loss: 0.0350 - val_msle: 0.0350 - val_mae: 23471.3809\n",
            "Epoch 14/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0373 - msle: 0.0373 - mae: 24824.5473 - val_loss: 0.0354 - val_msle: 0.0354 - val_mae: 23607.5703\n",
            "Epoch 15/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0382 - msle: 0.0382 - mae: 26853.6441 - val_loss: 0.0369 - val_msle: 0.0369 - val_mae: 24194.1758\n",
            "Epoch 16/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0417 - msle: 0.0417 - mae: 27564.5258 - val_loss: 0.0380 - val_msle: 0.0380 - val_mae: 24572.0352\n",
            "Epoch 17/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0403 - msle: 0.0403 - mae: 27332.9287 - val_loss: 0.0343 - val_msle: 0.0343 - val_mae: 23276.3672\n",
            "Epoch 18/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0412 - msle: 0.0412 - mae: 27267.9678 - val_loss: 0.0349 - val_msle: 0.0349 - val_mae: 24416.9766\n",
            "Epoch 19/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0457 - msle: 0.0457 - mae: 29321.8889 - val_loss: 0.0343 - val_msle: 0.0343 - val_mae: 23726.3555\n",
            "Epoch 20/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0459 - msle: 0.0459 - mae: 28659.6428 - val_loss: 0.0354 - val_msle: 0.0354 - val_mae: 24847.3945\n",
            "Epoch 21/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0381 - msle: 0.0381 - mae: 26387.4299 - val_loss: 0.0359 - val_msle: 0.0359 - val_mae: 25320.6074\n",
            "Epoch 22/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0365 - msle: 0.0365 - mae: 26463.0426 - val_loss: 0.0346 - val_msle: 0.0346 - val_mae: 23281.6094\n",
            "Epoch 23/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0401 - msle: 0.0401 - mae: 27075.3172 - val_loss: 0.0373 - val_msle: 0.0373 - val_mae: 24296.6914\n",
            "Epoch 24/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0361 - msle: 0.0361 - mae: 25736.0254 - val_loss: 0.0370 - val_msle: 0.0370 - val_mae: 26086.6074\n",
            "Epoch 25/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0414 - msle: 0.0414 - mae: 27850.1398 - val_loss: 0.0346 - val_msle: 0.0346 - val_mae: 24016.5430\n",
            "Epoch 26/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0387 - msle: 0.0387 - mae: 26464.6326 - val_loss: 0.0344 - val_msle: 0.0344 - val_mae: 23301.0527\n",
            "Epoch 27/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0434 - msle: 0.0434 - mae: 27662.6506 - val_loss: 0.0358 - val_msle: 0.0358 - val_mae: 25173.0977\n",
            "Epoch 28/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0418 - msle: 0.0418 - mae: 27939.1500 - val_loss: 0.0355 - val_msle: 0.0355 - val_mae: 24909.8770\n",
            "Epoch 29/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0452 - msle: 0.0452 - mae: 28779.3430 - val_loss: 0.0350 - val_msle: 0.0350 - val_mae: 23437.5352\n",
            "Epoch 30/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0486 - msle: 0.0486 - mae: 29017.4109 - val_loss: 0.0346 - val_msle: 0.0346 - val_mae: 23359.5488\n",
            "Epoch 31/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0474 - msle: 0.0474 - mae: 28246.6885 - val_loss: 0.0366 - val_msle: 0.0366 - val_mae: 24086.2461\n",
            "Epoch 32/200\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 0.0437 - msle: 0.0437 - mae: 27776.2869 - val_loss: 0.0360 - val_msle: 0.0360 - val_mae: 23801.8867\n",
            "Epoch 33/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0372 - msle: 0.0372 - mae: 25099.1326 - val_loss: 0.0345 - val_msle: 0.0345 - val_mae: 23754.9902\n",
            "Epoch 34/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0355 - msle: 0.0355 - mae: 26219.0633 - val_loss: 0.0363 - val_msle: 0.0363 - val_mae: 25548.7422\n",
            "Epoch 35/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0409 - msle: 0.0409 - mae: 28029.1855 - val_loss: 0.0344 - val_msle: 0.0344 - val_mae: 23545.3008\n",
            "Epoch 36/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0385 - msle: 0.0385 - mae: 26613.7266 - val_loss: 0.0344 - val_msle: 0.0344 - val_mae: 23647.9004\n",
            "Epoch 37/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0387 - msle: 0.0387 - mae: 26213.3508 - val_loss: 0.0365 - val_msle: 0.0365 - val_mae: 24009.0527\n",
            "Epoch 38/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0399 - msle: 0.0399 - mae: 26696.8338 - val_loss: 0.0359 - val_msle: 0.0359 - val_mae: 23767.8027\n",
            "Epoch 39/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0432 - msle: 0.0432 - mae: 27923.7566 - val_loss: 0.0396 - val_msle: 0.0396 - val_mae: 25121.2852\n",
            "Epoch 40/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0498 - msle: 0.0498 - mae: 29379.8699 - val_loss: 0.0364 - val_msle: 0.0364 - val_mae: 25552.4492\n",
            "Epoch 41/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0415 - msle: 0.0415 - mae: 27638.8854 - val_loss: 0.0348 - val_msle: 0.0348 - val_mae: 24140.3516\n",
            "Epoch 42/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0368 - msle: 0.0368 - mae: 25854.1553 - val_loss: 0.0350 - val_msle: 0.0350 - val_mae: 23486.5625\n",
            "Epoch 43/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0431 - msle: 0.0431 - mae: 26218.5832 - val_loss: 0.0393 - val_msle: 0.0393 - val_mae: 24989.8203\n",
            "Epoch 44/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0409 - msle: 0.0409 - mae: 26565.7432 - val_loss: 0.0377 - val_msle: 0.0377 - val_mae: 24452.1836\n",
            "Epoch 45/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0366 - msle: 0.0366 - mae: 25382.4898 - val_loss: 0.0346 - val_msle: 0.0346 - val_mae: 23340.7188\n",
            "Epoch 46/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0404 - msle: 0.0404 - mae: 26896.2863 - val_loss: 0.0361 - val_msle: 0.0361 - val_mae: 23859.6855\n",
            "Epoch 47/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0428 - msle: 0.0428 - mae: 26876.8139 - val_loss: 0.0345 - val_msle: 0.0345 - val_mae: 23621.2324\n",
            "Epoch 48/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0370 - msle: 0.0370 - mae: 26497.4969 - val_loss: 0.0349 - val_msle: 0.0349 - val_mae: 23438.3008\n",
            "Epoch 49/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0453 - msle: 0.0453 - mae: 27455.8107 - val_loss: 0.0352 - val_msle: 0.0352 - val_mae: 23492.7012\n",
            "Epoch 50/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0365 - msle: 0.0365 - mae: 25576.5074 - val_loss: 0.0358 - val_msle: 0.0358 - val_mae: 23750.1777\n",
            "Epoch 51/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0354 - msle: 0.0354 - mae: 26408.4453 - val_loss: 0.0349 - val_msle: 0.0349 - val_mae: 23397.4961\n",
            "Epoch 52/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0359 - msle: 0.0359 - mae: 25209.1273 - val_loss: 0.0362 - val_msle: 0.0362 - val_mae: 23907.8926\n",
            "Epoch 53/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0373 - msle: 0.0373 - mae: 26768.7852 - val_loss: 0.0345 - val_msle: 0.0345 - val_mae: 23524.8672\n",
            "Epoch 54/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0359 - msle: 0.0359 - mae: 25196.1730 - val_loss: 0.0358 - val_msle: 0.0358 - val_mae: 23689.0273\n",
            "Epoch 55/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0384 - msle: 0.0384 - mae: 25622.4941 - val_loss: 0.0345 - val_msle: 0.0345 - val_mae: 23601.6602\n",
            "Epoch 56/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0334 - msle: 0.0334 - mae: 25300.1859 - val_loss: 0.0369 - val_msle: 0.0369 - val_mae: 25908.4629\n",
            "Epoch 57/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0397 - msle: 0.0397 - mae: 27025.9609 - val_loss: 0.0352 - val_msle: 0.0352 - val_mae: 24408.5020\n",
            "Epoch 58/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0353 - msle: 0.0353 - mae: 24968.1939 - val_loss: 0.0353 - val_msle: 0.0353 - val_mae: 24487.6094\n",
            "Epoch 59/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0366 - msle: 0.0366 - mae: 26006.9469 - val_loss: 0.0346 - val_msle: 0.0346 - val_mae: 23351.2148\n",
            "Epoch 60/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0399 - msle: 0.0399 - mae: 27223.7729 - val_loss: 0.0348 - val_msle: 0.0348 - val_mae: 23380.5156\n",
            "Epoch 61/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0407 - msle: 0.0407 - mae: 27192.9193 - val_loss: 0.0345 - val_msle: 0.0345 - val_mae: 23416.5820\n",
            "Epoch 62/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0371 - msle: 0.0371 - mae: 26123.8084 - val_loss: 0.0352 - val_msle: 0.0352 - val_mae: 24399.4824\n",
            "Epoch 63/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0367 - msle: 0.0367 - mae: 26121.7586 - val_loss: 0.0348 - val_msle: 0.0348 - val_mae: 23372.0293\n",
            "Epoch 64/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0372 - msle: 0.0372 - mae: 25222.6844 - val_loss: 0.0365 - val_msle: 0.0365 - val_mae: 25562.6465\n",
            "Epoch 65/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0372 - msle: 0.0372 - mae: 26647.8545 - val_loss: 0.0355 - val_msle: 0.0355 - val_mae: 23615.0625\n",
            "Epoch 66/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0386 - msle: 0.0386 - mae: 26601.2434 - val_loss: 0.0349 - val_msle: 0.0349 - val_mae: 24073.2617\n",
            "Epoch 67/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0359 - msle: 0.0359 - mae: 25640.7568 - val_loss: 0.0347 - val_msle: 0.0347 - val_mae: 23582.3340\n",
            "Epoch 68/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0427 - msle: 0.0427 - mae: 28844.9424 - val_loss: 0.0352 - val_msle: 0.0352 - val_mae: 24291.2441\n",
            "Epoch 69/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0388 - msle: 0.0388 - mae: 25855.8135 - val_loss: 0.0357 - val_msle: 0.0357 - val_mae: 23797.0762\n",
            "Epoch 70/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0427 - msle: 0.0427 - mae: 27013.2391 - val_loss: 0.0346 - val_msle: 0.0346 - val_mae: 23721.0000\n",
            "Epoch 71/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0391 - msle: 0.0391 - mae: 27434.9662 - val_loss: 0.0361 - val_msle: 0.0361 - val_mae: 23859.2285\n",
            "Epoch 72/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0371 - msle: 0.0371 - mae: 26394.8674 - val_loss: 0.0350 - val_msle: 0.0350 - val_mae: 24101.0254\n",
            "Epoch 73/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0411 - msle: 0.0411 - mae: 27824.2332 - val_loss: 0.0346 - val_msle: 0.0346 - val_mae: 23707.3496\n",
            "Epoch 74/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0424 - msle: 0.0424 - mae: 28040.1779 - val_loss: 0.0346 - val_msle: 0.0346 - val_mae: 23620.5371\n",
            "Epoch 75/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0405 - msle: 0.0405 - mae: 27074.5953 - val_loss: 0.0347 - val_msle: 0.0347 - val_mae: 23395.5215\n",
            "Epoch 76/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0406 - msle: 0.0406 - mae: 26321.0779 - val_loss: 0.0360 - val_msle: 0.0360 - val_mae: 23834.5430\n",
            "Epoch 77/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0445 - msle: 0.0445 - mae: 28476.9301 - val_loss: 0.0347 - val_msle: 0.0347 - val_mae: 23463.3750\n",
            "Epoch 78/200\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 0.0381 - msle: 0.0381 - mae: 26525.5451 - val_loss: 0.0367 - val_msle: 0.0367 - val_mae: 24199.1328\n",
            "Epoch 79/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0421 - msle: 0.0421 - mae: 27184.0812 - val_loss: 0.0366 - val_msle: 0.0366 - val_mae: 24026.0488\n",
            "Epoch 80/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0373 - msle: 0.0373 - mae: 25637.7873 - val_loss: 0.0349 - val_msle: 0.0349 - val_mae: 23406.3301\n",
            "Epoch 81/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0356 - msle: 0.0356 - mae: 26204.5893 - val_loss: 0.0346 - val_msle: 0.0346 - val_mae: 23618.2070\n",
            "Epoch 82/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0354 - msle: 0.0354 - mae: 25556.2646 - val_loss: 0.0354 - val_msle: 0.0354 - val_mae: 24498.2578\n",
            "Epoch 83/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0390 - msle: 0.0390 - mae: 27008.0912 - val_loss: 0.0360 - val_msle: 0.0360 - val_mae: 23845.5781\n",
            "Epoch 84/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0353 - msle: 0.0353 - mae: 25341.5051 - val_loss: 0.0350 - val_msle: 0.0350 - val_mae: 23488.9316\n",
            "Epoch 85/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0377 - msle: 0.0377 - mae: 26432.7229 - val_loss: 0.0354 - val_msle: 0.0354 - val_mae: 24518.1172\n",
            "Epoch 86/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0412 - msle: 0.0412 - mae: 27433.3650 - val_loss: 0.0356 - val_msle: 0.0356 - val_mae: 23748.9473\n",
            "Epoch 87/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0419 - msle: 0.0419 - mae: 26742.6070 - val_loss: 0.0347 - val_msle: 0.0347 - val_mae: 23416.6055\n",
            "Epoch 88/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0365 - msle: 0.0365 - mae: 24787.4527 - val_loss: 0.0354 - val_msle: 0.0354 - val_mae: 24544.8535\n",
            "Epoch 89/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0408 - msle: 0.0408 - mae: 28427.8387 - val_loss: 0.0349 - val_msle: 0.0349 - val_mae: 23458.6582\n",
            "Epoch 90/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0376 - msle: 0.0376 - mae: 26057.5527 - val_loss: 0.0346 - val_msle: 0.0346 - val_mae: 23614.8340\n",
            "Epoch 91/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0392 - msle: 0.0392 - mae: 27332.8119 - val_loss: 0.0345 - val_msle: 0.0345 - val_mae: 23403.0430\n",
            "Epoch 92/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0457 - msle: 0.0457 - mae: 27474.1295 - val_loss: 0.0345 - val_msle: 0.0345 - val_mae: 23511.4844\n",
            "Epoch 93/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0332 - msle: 0.0332 - mae: 24823.0523 - val_loss: 0.0347 - val_msle: 0.0347 - val_mae: 23808.5430\n",
            "Epoch 94/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0320 - msle: 0.0320 - mae: 24532.2627 - val_loss: 0.0357 - val_msle: 0.0357 - val_mae: 24774.5039\n",
            "Epoch 95/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0338 - msle: 0.0338 - mae: 24900.9533 - val_loss: 0.0345 - val_msle: 0.0345 - val_mae: 23451.7461\n",
            "Epoch 96/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0329 - msle: 0.0329 - mae: 24431.4871 - val_loss: 0.0348 - val_msle: 0.0348 - val_mae: 23368.5234\n",
            "Epoch 97/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0411 - msle: 0.0411 - mae: 27270.6852 - val_loss: 0.0411 - val_msle: 0.0411 - val_mae: 25821.3379\n",
            "Epoch 98/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0350 - msle: 0.0350 - mae: 25693.7613 - val_loss: 0.0363 - val_msle: 0.0363 - val_mae: 25348.2461\n",
            "Epoch 99/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0345 - msle: 0.0345 - mae: 25232.1916 - val_loss: 0.0345 - val_msle: 0.0345 - val_mae: 23584.2578\n",
            "Epoch 100/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0355 - msle: 0.0355 - mae: 25331.0830 - val_loss: 0.0355 - val_msle: 0.0355 - val_mae: 23630.7520\n",
            "Epoch 101/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0350 - msle: 0.0350 - mae: 24861.2283 - val_loss: 0.0354 - val_msle: 0.0354 - val_mae: 23619.8535\n",
            "Epoch 102/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0397 - msle: 0.0397 - mae: 26210.2994 - val_loss: 0.0361 - val_msle: 0.0361 - val_mae: 23867.8887\n",
            "Epoch 103/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0331 - msle: 0.0331 - mae: 24275.8197 - val_loss: 0.0351 - val_msle: 0.0351 - val_mae: 23495.4980\n",
            "Epoch 104/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0315 - msle: 0.0315 - mae: 24206.8525 - val_loss: 0.0345 - val_msle: 0.0345 - val_mae: 23660.3164\n",
            "Epoch 105/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0422 - msle: 0.0422 - mae: 27418.2490 - val_loss: 0.0359 - val_msle: 0.0359 - val_mae: 23850.0957\n",
            "Epoch 106/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0404 - msle: 0.0404 - mae: 25825.4789 - val_loss: 0.0350 - val_msle: 0.0350 - val_mae: 23464.2754\n",
            "Epoch 107/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0407 - msle: 0.0407 - mae: 28448.8430 - val_loss: 0.0373 - val_msle: 0.0373 - val_mae: 24420.9785\n",
            "Epoch 108/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0345 - msle: 0.0345 - mae: 24732.6885 - val_loss: 0.0406 - val_msle: 0.0406 - val_mae: 28009.4980\n",
            "Epoch 109/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0411 - msle: 0.0411 - mae: 29344.8484 - val_loss: 0.0348 - val_msle: 0.0348 - val_mae: 23474.6719\n",
            "Epoch 110/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0392 - msle: 0.0392 - mae: 25319.3445 - val_loss: 0.0346 - val_msle: 0.0346 - val_mae: 23727.2715\n",
            "Epoch 111/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0426 - msle: 0.0426 - mae: 27105.8684 - val_loss: 0.0373 - val_msle: 0.0373 - val_mae: 24386.4512\n",
            "Epoch 112/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0377 - msle: 0.0377 - mae: 25819.5354 - val_loss: 0.0355 - val_msle: 0.0355 - val_mae: 23737.3516\n",
            "Epoch 113/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0380 - msle: 0.0380 - mae: 26898.5453 - val_loss: 0.0366 - val_msle: 0.0366 - val_mae: 24161.3281\n",
            "Epoch 114/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0369 - msle: 0.0369 - mae: 25666.7973 - val_loss: 0.0357 - val_msle: 0.0357 - val_mae: 23723.4375\n",
            "Epoch 115/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0407 - msle: 0.0407 - mae: 27161.8520 - val_loss: 0.0356 - val_msle: 0.0356 - val_mae: 24699.2070\n",
            "Epoch 116/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0402 - msle: 0.0402 - mae: 26635.5062 - val_loss: 0.0344 - val_msle: 0.0344 - val_mae: 23400.6973\n",
            "Epoch 117/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0460 - msle: 0.0460 - mae: 27842.7092 - val_loss: 0.0362 - val_msle: 0.0362 - val_mae: 25188.1230\n",
            "Epoch 118/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0401 - msle: 0.0401 - mae: 26969.2705 - val_loss: 0.0357 - val_msle: 0.0357 - val_mae: 24755.4238\n",
            "Epoch 119/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0363 - msle: 0.0363 - mae: 25537.8104 - val_loss: 0.0353 - val_msle: 0.0353 - val_mae: 24479.6250\n",
            "Epoch 120/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0436 - msle: 0.0436 - mae: 27520.3697 - val_loss: 0.0343 - val_msle: 0.0343 - val_mae: 23376.9043\n",
            "Epoch 121/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0434 - msle: 0.0434 - mae: 26945.8949 - val_loss: 0.0349 - val_msle: 0.0349 - val_mae: 23473.3125\n",
            "Epoch 122/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0355 - msle: 0.0355 - mae: 25732.0938 - val_loss: 0.0350 - val_msle: 0.0350 - val_mae: 24174.3887\n",
            "Epoch 123/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0358 - msle: 0.0358 - mae: 24816.0430 - val_loss: 0.0346 - val_msle: 0.0346 - val_mae: 23365.1406\n",
            "Epoch 124/200\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 0.0385 - msle: 0.0385 - mae: 25973.5363 - val_loss: 0.0351 - val_msle: 0.0351 - val_mae: 24260.5938\n",
            "Epoch 125/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0338 - msle: 0.0338 - mae: 24682.3242 - val_loss: 0.0346 - val_msle: 0.0346 - val_mae: 23771.2188\n",
            "Epoch 126/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0412 - msle: 0.0412 - mae: 27599.5115 - val_loss: 0.0360 - val_msle: 0.0360 - val_mae: 23902.0898\n",
            "Epoch 127/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0350 - msle: 0.0350 - mae: 25217.6879 - val_loss: 0.0347 - val_msle: 0.0347 - val_mae: 23876.3008\n",
            "Epoch 128/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0380 - msle: 0.0380 - mae: 27559.3684 - val_loss: 0.0365 - val_msle: 0.0365 - val_mae: 24085.7012\n",
            "Epoch 129/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0375 - msle: 0.0375 - mae: 25488.8574 - val_loss: 0.0348 - val_msle: 0.0348 - val_mae: 23380.1465\n",
            "Epoch 130/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0424 - msle: 0.0424 - mae: 26950.3230 - val_loss: 0.0378 - val_msle: 0.0378 - val_mae: 24614.1523\n",
            "Epoch 131/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0399 - msle: 0.0399 - mae: 25974.7793 - val_loss: 0.0353 - val_msle: 0.0353 - val_mae: 24387.7969\n",
            "Epoch 132/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0353 - msle: 0.0353 - mae: 25646.7551 - val_loss: 0.0345 - val_msle: 0.0345 - val_mae: 23675.0586\n",
            "Epoch 133/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0343 - msle: 0.0343 - mae: 25509.5760 - val_loss: 0.0347 - val_msle: 0.0347 - val_mae: 23872.9824\n",
            "Epoch 134/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0339 - msle: 0.0339 - mae: 24996.1023 - val_loss: 0.0343 - val_msle: 0.0343 - val_mae: 23426.0527\n",
            "Epoch 135/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0381 - msle: 0.0381 - mae: 26453.7166 - val_loss: 0.0343 - val_msle: 0.0343 - val_mae: 23465.7812\n",
            "Epoch 136/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0392 - msle: 0.0392 - mae: 26643.9982 - val_loss: 0.0364 - val_msle: 0.0364 - val_mae: 24023.2793\n",
            "Epoch 137/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0336 - msle: 0.0336 - mae: 24447.4025 - val_loss: 0.0349 - val_msle: 0.0349 - val_mae: 23496.9629\n",
            "Epoch 138/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0345 - msle: 0.0345 - mae: 25289.9785 - val_loss: 0.0345 - val_msle: 0.0345 - val_mae: 23290.7402\n",
            "Epoch 139/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0367 - msle: 0.0367 - mae: 26256.8984 - val_loss: 0.0344 - val_msle: 0.0344 - val_mae: 23301.5723\n",
            "Epoch 140/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0439 - msle: 0.0439 - mae: 28264.7887 - val_loss: 0.0343 - val_msle: 0.0343 - val_mae: 23303.6582\n",
            "Epoch 141/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0337 - msle: 0.0337 - mae: 24795.4572 - val_loss: 0.0345 - val_msle: 0.0345 - val_mae: 23279.8008\n",
            "Epoch 142/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0405 - msle: 0.0405 - mae: 26369.0318 - val_loss: 0.0342 - val_msle: 0.0342 - val_mae: 23426.4727\n",
            "Epoch 143/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0392 - msle: 0.0392 - mae: 26803.0361 - val_loss: 0.0383 - val_msle: 0.0383 - val_mae: 26599.2109\n",
            "Epoch 144/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0336 - msle: 0.0336 - mae: 24388.4043 - val_loss: 0.0348 - val_msle: 0.0348 - val_mae: 24003.2988\n",
            "Epoch 145/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0431 - msle: 0.0431 - mae: 27294.4783 - val_loss: 0.0364 - val_msle: 0.0364 - val_mae: 24063.6309\n",
            "Epoch 146/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0338 - msle: 0.0338 - mae: 25041.3305 - val_loss: 0.0348 - val_msle: 0.0348 - val_mae: 23470.3105\n",
            "Epoch 147/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0349 - msle: 0.0349 - mae: 25221.0893 - val_loss: 0.0374 - val_msle: 0.0374 - val_mae: 26043.0625\n",
            "Epoch 148/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0422 - msle: 0.0422 - mae: 27288.8121 - val_loss: 0.0364 - val_msle: 0.0364 - val_mae: 24091.2246\n",
            "Epoch 149/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0334 - msle: 0.0334 - mae: 24347.3979 - val_loss: 0.0418 - val_msle: 0.0418 - val_mae: 26242.1699\n",
            "Epoch 150/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0389 - msle: 0.0389 - mae: 26022.7068 - val_loss: 0.0350 - val_msle: 0.0350 - val_mae: 23540.7617\n",
            "Epoch 151/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0379 - msle: 0.0379 - mae: 26891.4313 - val_loss: 0.0344 - val_msle: 0.0344 - val_mae: 23249.6777\n",
            "Epoch 152/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0334 - msle: 0.0334 - mae: 24309.5203 - val_loss: 0.0348 - val_msle: 0.0348 - val_mae: 23379.7852\n",
            "Epoch 153/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0353 - msle: 0.0353 - mae: 24824.2926 - val_loss: 0.0378 - val_msle: 0.0378 - val_mae: 24600.0957\n",
            "Epoch 154/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0396 - msle: 0.0396 - mae: 26057.4484 - val_loss: 0.0349 - val_msle: 0.0349 - val_mae: 24152.6621\n",
            "Epoch 155/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0295 - msle: 0.0295 - mae: 23287.5451 - val_loss: 0.0369 - val_msle: 0.0369 - val_mae: 25527.8242\n",
            "Epoch 156/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0397 - msle: 0.0397 - mae: 26510.5957 - val_loss: 0.0387 - val_msle: 0.0387 - val_mae: 24950.0430\n",
            "Epoch 157/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0438 - msle: 0.0438 - mae: 27284.1830 - val_loss: 0.0346 - val_msle: 0.0346 - val_mae: 23386.8066\n",
            "Epoch 158/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0344 - msle: 0.0344 - mae: 24667.5912 - val_loss: 0.0370 - val_msle: 0.0370 - val_mae: 24295.5762\n",
            "Epoch 159/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0338 - msle: 0.0338 - mae: 25170.9611 - val_loss: 0.0348 - val_msle: 0.0348 - val_mae: 23455.1543\n",
            "Epoch 160/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0329 - msle: 0.0329 - mae: 24735.2924 - val_loss: 0.0344 - val_msle: 0.0344 - val_mae: 23661.3926\n",
            "Epoch 161/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0336 - msle: 0.0336 - mae: 25518.5934 - val_loss: 0.0362 - val_msle: 0.0362 - val_mae: 23959.5117\n",
            "Epoch 162/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0345 - msle: 0.0345 - mae: 25186.8340 - val_loss: 0.0343 - val_msle: 0.0343 - val_mae: 23600.6660\n",
            "Epoch 163/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0403 - msle: 0.0403 - mae: 26674.8977 - val_loss: 0.0341 - val_msle: 0.0341 - val_mae: 23273.3770\n",
            "Epoch 164/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0366 - msle: 0.0366 - mae: 26329.2943 - val_loss: 0.0352 - val_msle: 0.0352 - val_mae: 23682.0352\n",
            "Epoch 165/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0362 - msle: 0.0362 - mae: 24406.8049 - val_loss: 0.0370 - val_msle: 0.0370 - val_mae: 25719.9609\n",
            "Epoch 166/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0348 - msle: 0.0348 - mae: 24957.5977 - val_loss: 0.0342 - val_msle: 0.0342 - val_mae: 23171.7207\n",
            "Epoch 167/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0325 - msle: 0.0325 - mae: 24504.1889 - val_loss: 0.0372 - val_msle: 0.0372 - val_mae: 24360.2051\n",
            "Epoch 168/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0353 - msle: 0.0353 - mae: 24995.7631 - val_loss: 0.0393 - val_msle: 0.0393 - val_mae: 25204.2266\n",
            "Epoch 169/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0401 - msle: 0.0401 - mae: 25989.8799 - val_loss: 0.0345 - val_msle: 0.0345 - val_mae: 23363.1387\n",
            "Epoch 170/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0354 - msle: 0.0354 - mae: 24530.5254 - val_loss: 0.0344 - val_msle: 0.0344 - val_mae: 23775.3555\n",
            "Epoch 171/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0314 - msle: 0.0314 - mae: 25550.4799 - val_loss: 0.0386 - val_msle: 0.0386 - val_mae: 26690.1934\n",
            "Epoch 172/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0356 - msle: 0.0356 - mae: 26669.3289 - val_loss: 0.0342 - val_msle: 0.0342 - val_mae: 23175.4355\n",
            "Epoch 173/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0348 - msle: 0.0348 - mae: 24245.0781 - val_loss: 0.0343 - val_msle: 0.0343 - val_mae: 23191.1914\n",
            "Epoch 174/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0328 - msle: 0.0328 - mae: 24409.2922 - val_loss: 0.0348 - val_msle: 0.0348 - val_mae: 24138.5840\n",
            "Epoch 175/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0433 - msle: 0.0433 - mae: 27099.9078 - val_loss: 0.0340 - val_msle: 0.0340 - val_mae: 23288.6406\n",
            "Epoch 176/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0350 - msle: 0.0350 - mae: 24907.7992 - val_loss: 0.0397 - val_msle: 0.0397 - val_mae: 25318.9180\n",
            "Epoch 177/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0325 - msle: 0.0325 - mae: 24390.2309 - val_loss: 0.0378 - val_msle: 0.0378 - val_mae: 24630.5352\n",
            "Epoch 178/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0340 - msle: 0.0340 - mae: 26462.9697 - val_loss: 0.0342 - val_msle: 0.0342 - val_mae: 23632.9785\n",
            "Epoch 179/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0376 - msle: 0.0376 - mae: 26872.6902 - val_loss: 0.0347 - val_msle: 0.0347 - val_mae: 23387.9629\n",
            "Epoch 180/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0361 - msle: 0.0361 - mae: 25478.7441 - val_loss: 0.0340 - val_msle: 0.0340 - val_mae: 23322.0977\n",
            "Epoch 181/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0360 - msle: 0.0360 - mae: 24012.1984 - val_loss: 0.0340 - val_msle: 0.0340 - val_mae: 23199.6582\n",
            "Epoch 182/200\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 0.0333 - msle: 0.0333 - mae: 24232.3486 - val_loss: 0.0351 - val_msle: 0.0351 - val_mae: 23606.2070\n",
            "Epoch 183/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0303 - msle: 0.0303 - mae: 23675.0879 - val_loss: 0.0342 - val_msle: 0.0342 - val_mae: 23194.5410\n",
            "Epoch 184/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0351 - msle: 0.0351 - mae: 24304.6406 - val_loss: 0.0340 - val_msle: 0.0340 - val_mae: 23336.6035\n",
            "Epoch 185/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0361 - msle: 0.0361 - mae: 26377.0893 - val_loss: 0.0339 - val_msle: 0.0339 - val_mae: 23361.6621\n",
            "Epoch 186/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0346 - msle: 0.0346 - mae: 24617.1180 - val_loss: 0.0360 - val_msle: 0.0360 - val_mae: 23949.8008\n",
            "Epoch 187/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0442 - msle: 0.0442 - mae: 27550.9717 - val_loss: 0.0351 - val_msle: 0.0351 - val_mae: 23698.4727\n",
            "Epoch 188/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0361 - msle: 0.0361 - mae: 25457.9697 - val_loss: 0.0338 - val_msle: 0.0338 - val_mae: 23300.4238\n",
            "Epoch 189/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0420 - msle: 0.0420 - mae: 26501.9482 - val_loss: 0.0340 - val_msle: 0.0340 - val_mae: 23264.2480\n",
            "Epoch 190/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0410 - msle: 0.0410 - mae: 26266.3986 - val_loss: 0.0383 - val_msle: 0.0383 - val_mae: 26543.9414\n",
            "Epoch 191/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0414 - msle: 0.0414 - mae: 27870.7277 - val_loss: 0.0362 - val_msle: 0.0362 - val_mae: 24006.7031\n",
            "Epoch 192/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0405 - msle: 0.0405 - mae: 26079.6471 - val_loss: 0.0354 - val_msle: 0.0354 - val_mae: 23740.9336\n",
            "Epoch 193/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0344 - msle: 0.0344 - mae: 24420.6459 - val_loss: 0.0341 - val_msle: 0.0341 - val_mae: 23545.5645\n",
            "Epoch 194/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0334 - msle: 0.0334 - mae: 24708.6287 - val_loss: 0.0337 - val_msle: 0.0337 - val_mae: 23220.3965\n",
            "Epoch 195/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0366 - msle: 0.0366 - mae: 24425.3775 - val_loss: 0.0361 - val_msle: 0.0361 - val_mae: 25125.2285\n",
            "Epoch 196/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0357 - msle: 0.0357 - mae: 26243.0664 - val_loss: 0.0347 - val_msle: 0.0347 - val_mae: 23476.1777\n",
            "Epoch 197/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0316 - msle: 0.0316 - mae: 24413.5264 - val_loss: 0.0337 - val_msle: 0.0337 - val_mae: 23262.5000\n",
            "Epoch 198/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0336 - msle: 0.0336 - mae: 25644.6164 - val_loss: 0.0347 - val_msle: 0.0347 - val_mae: 23599.5488\n",
            "Epoch 199/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0334 - msle: 0.0334 - mae: 24471.3352 - val_loss: 0.0344 - val_msle: 0.0344 - val_mae: 23853.2520\n",
            "Epoch 200/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.0384 - msle: 0.0384 - mae: 25766.0193 - val_loss: 0.0348 - val_msle: 0.0348 - val_mae: 24203.0859\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5221b2f198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-NmgMGg0ls7"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}