{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "Gee_D77_L2_Loss_Functions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKSZ10Al0lsa"
      },
      "source": [
        "## Loss Functions\n",
        "\n",
        "In this assignment, we will learn about loss functions. We will use a create a neural network and measure the model's performance using different loss functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC8ZyHPq0lsb"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "pd.set_option('display.max_rows', 100)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqKRN1_O0lse"
      },
      "source": [
        "df = pd.read_csv('https://tf-assets-prod.s3.amazonaws.com/tf-curric/data-science/housing.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "7jmB3XScFEaI",
        "outputId": "be97bdfc-4c8e-4ee7-9f15-938dd08fb96e"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>LotConfig</th>\n",
              "      <th>LandSlope</th>\n",
              "      <th>Neighborhood</th>\n",
              "      <th>Condition1</th>\n",
              "      <th>Condition2</th>\n",
              "      <th>BldgType</th>\n",
              "      <th>HouseStyle</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>RoofStyle</th>\n",
              "      <th>RoofMatl</th>\n",
              "      <th>Exterior1st</th>\n",
              "      <th>Exterior2nd</th>\n",
              "      <th>MasVnrType</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>ExterQual</th>\n",
              "      <th>ExterCond</th>\n",
              "      <th>Foundation</th>\n",
              "      <th>BsmtQual</th>\n",
              "      <th>BsmtCond</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinType2</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>Heating</th>\n",
              "      <th>...</th>\n",
              "      <th>CentralAir</th>\n",
              "      <th>Electrical</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>BsmtFullBath</th>\n",
              "      <th>BsmtHalfBath</th>\n",
              "      <th>FullBath</th>\n",
              "      <th>HalfBath</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>KitchenAbvGr</th>\n",
              "      <th>KitchenQual</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>Functional</th>\n",
              "      <th>Fireplaces</th>\n",
              "      <th>FireplaceQu</th>\n",
              "      <th>GarageType</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>GarageCars</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>GarageQual</th>\n",
              "      <th>GarageCond</th>\n",
              "      <th>PavedDrive</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>196.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>No</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>706</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>856</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>856</td>\n",
              "      <td>854</td>\n",
              "      <td>0</td>\n",
              "      <td>1710</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>8</td>\n",
              "      <td>Typ</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>548</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Veenker</td>\n",
              "      <td>Feedr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>1Story</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>MetalSd</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>CBlock</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>978</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>284</td>\n",
              "      <td>1262</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>1976.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>460</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>298</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Inside</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>CollgCr</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>162.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Mn</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>486</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>434</td>\n",
              "      <td>920</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>920</td>\n",
              "      <td>866</td>\n",
              "      <td>0</td>\n",
              "      <td>1786</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>6</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2</td>\n",
              "      <td>608</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>Corner</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>Crawfor</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>Wd Sdng</td>\n",
              "      <td>Wd Shng</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>BrkTil</td>\n",
              "      <td>TA</td>\n",
              "      <td>Gd</td>\n",
              "      <td>No</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>216</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>540</td>\n",
              "      <td>756</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>961</td>\n",
              "      <td>756</td>\n",
              "      <td>0</td>\n",
              "      <td>1717</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>7</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>Detchd</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>Unf</td>\n",
              "      <td>3</td>\n",
              "      <td>642</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>FR2</td>\n",
              "      <td>Gtl</td>\n",
              "      <td>NoRidge</td>\n",
              "      <td>Norm</td>\n",
              "      <td>Norm</td>\n",
              "      <td>1Fam</td>\n",
              "      <td>2Story</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>Gable</td>\n",
              "      <td>CompShg</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>VinylSd</td>\n",
              "      <td>BrkFace</td>\n",
              "      <td>350.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>PConc</td>\n",
              "      <td>Gd</td>\n",
              "      <td>TA</td>\n",
              "      <td>Av</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>655</td>\n",
              "      <td>Unf</td>\n",
              "      <td>0</td>\n",
              "      <td>490</td>\n",
              "      <td>1145</td>\n",
              "      <td>GasA</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>SBrkr</td>\n",
              "      <td>1145</td>\n",
              "      <td>1053</td>\n",
              "      <td>0</td>\n",
              "      <td>2198</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Gd</td>\n",
              "      <td>9</td>\n",
              "      <td>Typ</td>\n",
              "      <td>1</td>\n",
              "      <td>TA</td>\n",
              "      <td>Attchd</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>RFn</td>\n",
              "      <td>3</td>\n",
              "      <td>836</td>\n",
              "      <td>TA</td>\n",
              "      <td>TA</td>\n",
              "      <td>Y</td>\n",
              "      <td>192</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 81 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  MSSubClass MSZoning  ...  SaleType  SaleCondition SalePrice\n",
              "0   1          60       RL  ...        WD         Normal    208500\n",
              "1   2          20       RL  ...        WD         Normal    181500\n",
              "2   3          60       RL  ...        WD         Normal    223500\n",
              "3   4          70       RL  ...        WD        Abnorml    140000\n",
              "4   5          60       RL  ...        WD         Normal    250000\n",
              "\n",
              "[5 rows x 81 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwTtppLYFQTF"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYgIVabm0lsj"
      },
      "source": [
        "We will use the dataset above to predict housing prices using various features about each house. Our first step is to check for missing data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_gFN2cu0lsj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4f7f466-42d6-4bf2-c610-68e08fd27944"
      },
      "source": [
        "# Answer below:\n",
        "df.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1460 entries, 0 to 1459\n",
            "Data columns (total 81 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Id             1460 non-null   int64  \n",
            " 1   MSSubClass     1460 non-null   int64  \n",
            " 2   MSZoning       1460 non-null   object \n",
            " 3   LotFrontage    1201 non-null   float64\n",
            " 4   LotArea        1460 non-null   int64  \n",
            " 5   Street         1460 non-null   object \n",
            " 6   Alley          91 non-null     object \n",
            " 7   LotShape       1460 non-null   object \n",
            " 8   LandContour    1460 non-null   object \n",
            " 9   Utilities      1460 non-null   object \n",
            " 10  LotConfig      1460 non-null   object \n",
            " 11  LandSlope      1460 non-null   object \n",
            " 12  Neighborhood   1460 non-null   object \n",
            " 13  Condition1     1460 non-null   object \n",
            " 14  Condition2     1460 non-null   object \n",
            " 15  BldgType       1460 non-null   object \n",
            " 16  HouseStyle     1460 non-null   object \n",
            " 17  OverallQual    1460 non-null   int64  \n",
            " 18  OverallCond    1460 non-null   int64  \n",
            " 19  YearBuilt      1460 non-null   int64  \n",
            " 20  YearRemodAdd   1460 non-null   int64  \n",
            " 21  RoofStyle      1460 non-null   object \n",
            " 22  RoofMatl       1460 non-null   object \n",
            " 23  Exterior1st    1460 non-null   object \n",
            " 24  Exterior2nd    1460 non-null   object \n",
            " 25  MasVnrType     1452 non-null   object \n",
            " 26  MasVnrArea     1452 non-null   float64\n",
            " 27  ExterQual      1460 non-null   object \n",
            " 28  ExterCond      1460 non-null   object \n",
            " 29  Foundation     1460 non-null   object \n",
            " 30  BsmtQual       1423 non-null   object \n",
            " 31  BsmtCond       1423 non-null   object \n",
            " 32  BsmtExposure   1422 non-null   object \n",
            " 33  BsmtFinType1   1423 non-null   object \n",
            " 34  BsmtFinSF1     1460 non-null   int64  \n",
            " 35  BsmtFinType2   1422 non-null   object \n",
            " 36  BsmtFinSF2     1460 non-null   int64  \n",
            " 37  BsmtUnfSF      1460 non-null   int64  \n",
            " 38  TotalBsmtSF    1460 non-null   int64  \n",
            " 39  Heating        1460 non-null   object \n",
            " 40  HeatingQC      1460 non-null   object \n",
            " 41  CentralAir     1460 non-null   object \n",
            " 42  Electrical     1459 non-null   object \n",
            " 43  1stFlrSF       1460 non-null   int64  \n",
            " 44  2ndFlrSF       1460 non-null   int64  \n",
            " 45  LowQualFinSF   1460 non-null   int64  \n",
            " 46  GrLivArea      1460 non-null   int64  \n",
            " 47  BsmtFullBath   1460 non-null   int64  \n",
            " 48  BsmtHalfBath   1460 non-null   int64  \n",
            " 49  FullBath       1460 non-null   int64  \n",
            " 50  HalfBath       1460 non-null   int64  \n",
            " 51  BedroomAbvGr   1460 non-null   int64  \n",
            " 52  KitchenAbvGr   1460 non-null   int64  \n",
            " 53  KitchenQual    1460 non-null   object \n",
            " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
            " 55  Functional     1460 non-null   object \n",
            " 56  Fireplaces     1460 non-null   int64  \n",
            " 57  FireplaceQu    770 non-null    object \n",
            " 58  GarageType     1379 non-null   object \n",
            " 59  GarageYrBlt    1379 non-null   float64\n",
            " 60  GarageFinish   1379 non-null   object \n",
            " 61  GarageCars     1460 non-null   int64  \n",
            " 62  GarageArea     1460 non-null   int64  \n",
            " 63  GarageQual     1379 non-null   object \n",
            " 64  GarageCond     1379 non-null   object \n",
            " 65  PavedDrive     1460 non-null   object \n",
            " 66  WoodDeckSF     1460 non-null   int64  \n",
            " 67  OpenPorchSF    1460 non-null   int64  \n",
            " 68  EnclosedPorch  1460 non-null   int64  \n",
            " 69  3SsnPorch      1460 non-null   int64  \n",
            " 70  ScreenPorch    1460 non-null   int64  \n",
            " 71  PoolArea       1460 non-null   int64  \n",
            " 72  PoolQC         7 non-null      object \n",
            " 73  Fence          281 non-null    object \n",
            " 74  MiscFeature    54 non-null     object \n",
            " 75  MiscVal        1460 non-null   int64  \n",
            " 76  MoSold         1460 non-null   int64  \n",
            " 77  YrSold         1460 non-null   int64  \n",
            " 78  SaleType       1460 non-null   object \n",
            " 79  SaleCondition  1460 non-null   object \n",
            " 80  SalePrice      1460 non-null   int64  \n",
            "dtypes: float64(3), int64(35), object(43)\n",
            "memory usage: 924.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3uqsma30lsl"
      },
      "source": [
        "Remove columns that contain more than 30% of missing data. After removing those columns, remove the rows that contain at least one observation that is missing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzV9PrpnQ4GY",
        "outputId": "a823612f-f264-4794-8930-725899ff0b83"
      },
      "source": [
        "# Answer below:\r\n",
        "df.isnull().sum()*100/df.isnull().count()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Id                0.000000\n",
              "MSSubClass        0.000000\n",
              "MSZoning          0.000000\n",
              "LotFrontage      17.739726\n",
              "LotArea           0.000000\n",
              "Street            0.000000\n",
              "Alley            93.767123\n",
              "LotShape          0.000000\n",
              "LandContour       0.000000\n",
              "Utilities         0.000000\n",
              "LotConfig         0.000000\n",
              "LandSlope         0.000000\n",
              "Neighborhood      0.000000\n",
              "Condition1        0.000000\n",
              "Condition2        0.000000\n",
              "BldgType          0.000000\n",
              "HouseStyle        0.000000\n",
              "OverallQual       0.000000\n",
              "OverallCond       0.000000\n",
              "YearBuilt         0.000000\n",
              "YearRemodAdd      0.000000\n",
              "RoofStyle         0.000000\n",
              "RoofMatl          0.000000\n",
              "Exterior1st       0.000000\n",
              "Exterior2nd       0.000000\n",
              "MasVnrType        0.547945\n",
              "MasVnrArea        0.547945\n",
              "ExterQual         0.000000\n",
              "ExterCond         0.000000\n",
              "Foundation        0.000000\n",
              "BsmtQual          2.534247\n",
              "BsmtCond          2.534247\n",
              "BsmtExposure      2.602740\n",
              "BsmtFinType1      2.534247\n",
              "BsmtFinSF1        0.000000\n",
              "BsmtFinType2      2.602740\n",
              "BsmtFinSF2        0.000000\n",
              "BsmtUnfSF         0.000000\n",
              "TotalBsmtSF       0.000000\n",
              "Heating           0.000000\n",
              "HeatingQC         0.000000\n",
              "CentralAir        0.000000\n",
              "Electrical        0.068493\n",
              "1stFlrSF          0.000000\n",
              "2ndFlrSF          0.000000\n",
              "LowQualFinSF      0.000000\n",
              "GrLivArea         0.000000\n",
              "BsmtFullBath      0.000000\n",
              "BsmtHalfBath      0.000000\n",
              "FullBath          0.000000\n",
              "HalfBath          0.000000\n",
              "BedroomAbvGr      0.000000\n",
              "KitchenAbvGr      0.000000\n",
              "KitchenQual       0.000000\n",
              "TotRmsAbvGrd      0.000000\n",
              "Functional        0.000000\n",
              "Fireplaces        0.000000\n",
              "FireplaceQu      47.260274\n",
              "GarageType        5.547945\n",
              "GarageYrBlt       5.547945\n",
              "GarageFinish      5.547945\n",
              "GarageCars        0.000000\n",
              "GarageArea        0.000000\n",
              "GarageQual        5.547945\n",
              "GarageCond        5.547945\n",
              "PavedDrive        0.000000\n",
              "WoodDeckSF        0.000000\n",
              "OpenPorchSF       0.000000\n",
              "EnclosedPorch     0.000000\n",
              "3SsnPorch         0.000000\n",
              "ScreenPorch       0.000000\n",
              "PoolArea          0.000000\n",
              "PoolQC           99.520548\n",
              "Fence            80.753425\n",
              "MiscFeature      96.301370\n",
              "MiscVal           0.000000\n",
              "MoSold            0.000000\n",
              "YrSold            0.000000\n",
              "SaleType          0.000000\n",
              "SaleCondition     0.000000\n",
              "SalePrice         0.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYdSl4kh0lsm"
      },
      "source": [
        "df.drop(columns=['MiscFeature','Fence','PoolQC','FireplaceQu','Alley'], inplace=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YUx_ZPJwhpk"
      },
      "source": [
        "df.dropna(inplace=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oo7lbm-lwlab",
        "outputId": "2f081cec-ff12-4764-d5bd-c56238fb0ab6"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1094 entries, 0 to 1459\n",
            "Data columns (total 76 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Id             1094 non-null   int64  \n",
            " 1   MSSubClass     1094 non-null   int64  \n",
            " 2   MSZoning       1094 non-null   object \n",
            " 3   LotFrontage    1094 non-null   float64\n",
            " 4   LotArea        1094 non-null   int64  \n",
            " 5   Street         1094 non-null   object \n",
            " 6   LotShape       1094 non-null   object \n",
            " 7   LandContour    1094 non-null   object \n",
            " 8   Utilities      1094 non-null   object \n",
            " 9   LotConfig      1094 non-null   object \n",
            " 10  LandSlope      1094 non-null   object \n",
            " 11  Neighborhood   1094 non-null   object \n",
            " 12  Condition1     1094 non-null   object \n",
            " 13  Condition2     1094 non-null   object \n",
            " 14  BldgType       1094 non-null   object \n",
            " 15  HouseStyle     1094 non-null   object \n",
            " 16  OverallQual    1094 non-null   int64  \n",
            " 17  OverallCond    1094 non-null   int64  \n",
            " 18  YearBuilt      1094 non-null   int64  \n",
            " 19  YearRemodAdd   1094 non-null   int64  \n",
            " 20  RoofStyle      1094 non-null   object \n",
            " 21  RoofMatl       1094 non-null   object \n",
            " 22  Exterior1st    1094 non-null   object \n",
            " 23  Exterior2nd    1094 non-null   object \n",
            " 24  MasVnrType     1094 non-null   object \n",
            " 25  MasVnrArea     1094 non-null   float64\n",
            " 26  ExterQual      1094 non-null   object \n",
            " 27  ExterCond      1094 non-null   object \n",
            " 28  Foundation     1094 non-null   object \n",
            " 29  BsmtQual       1094 non-null   object \n",
            " 30  BsmtCond       1094 non-null   object \n",
            " 31  BsmtExposure   1094 non-null   object \n",
            " 32  BsmtFinType1   1094 non-null   object \n",
            " 33  BsmtFinSF1     1094 non-null   int64  \n",
            " 34  BsmtFinType2   1094 non-null   object \n",
            " 35  BsmtFinSF2     1094 non-null   int64  \n",
            " 36  BsmtUnfSF      1094 non-null   int64  \n",
            " 37  TotalBsmtSF    1094 non-null   int64  \n",
            " 38  Heating        1094 non-null   object \n",
            " 39  HeatingQC      1094 non-null   object \n",
            " 40  CentralAir     1094 non-null   object \n",
            " 41  Electrical     1094 non-null   object \n",
            " 42  1stFlrSF       1094 non-null   int64  \n",
            " 43  2ndFlrSF       1094 non-null   int64  \n",
            " 44  LowQualFinSF   1094 non-null   int64  \n",
            " 45  GrLivArea      1094 non-null   int64  \n",
            " 46  BsmtFullBath   1094 non-null   int64  \n",
            " 47  BsmtHalfBath   1094 non-null   int64  \n",
            " 48  FullBath       1094 non-null   int64  \n",
            " 49  HalfBath       1094 non-null   int64  \n",
            " 50  BedroomAbvGr   1094 non-null   int64  \n",
            " 51  KitchenAbvGr   1094 non-null   int64  \n",
            " 52  KitchenQual    1094 non-null   object \n",
            " 53  TotRmsAbvGrd   1094 non-null   int64  \n",
            " 54  Functional     1094 non-null   object \n",
            " 55  Fireplaces     1094 non-null   int64  \n",
            " 56  GarageType     1094 non-null   object \n",
            " 57  GarageYrBlt    1094 non-null   float64\n",
            " 58  GarageFinish   1094 non-null   object \n",
            " 59  GarageCars     1094 non-null   int64  \n",
            " 60  GarageArea     1094 non-null   int64  \n",
            " 61  GarageQual     1094 non-null   object \n",
            " 62  GarageCond     1094 non-null   object \n",
            " 63  PavedDrive     1094 non-null   object \n",
            " 64  WoodDeckSF     1094 non-null   int64  \n",
            " 65  OpenPorchSF    1094 non-null   int64  \n",
            " 66  EnclosedPorch  1094 non-null   int64  \n",
            " 67  3SsnPorch      1094 non-null   int64  \n",
            " 68  ScreenPorch    1094 non-null   int64  \n",
            " 69  PoolArea       1094 non-null   int64  \n",
            " 70  MiscVal        1094 non-null   int64  \n",
            " 71  MoSold         1094 non-null   int64  \n",
            " 72  YrSold         1094 non-null   int64  \n",
            " 73  SaleType       1094 non-null   object \n",
            " 74  SaleCondition  1094 non-null   object \n",
            " 75  SalePrice      1094 non-null   int64  \n",
            "dtypes: float64(3), int64(35), object(38)\n",
            "memory usage: 658.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dnm4HNYr0lso"
      },
      "source": [
        "There are some categorical variables that contain numeric data and some that do not. Print the type of each column to first see whether there is an issue with misclassification of column type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKKKIkaC0lsp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d94fd628-fd45-462f-bdea-ccc278b1ab5b"
      },
      "source": [
        "# Answer below:\n",
        "for x in df.columns:\n",
        "  print(x, df[x].dtype)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Id int64\n",
            "MSSubClass int64\n",
            "MSZoning object\n",
            "LotFrontage float64\n",
            "LotArea int64\n",
            "Street object\n",
            "LotShape object\n",
            "LandContour object\n",
            "Utilities object\n",
            "LotConfig object\n",
            "LandSlope object\n",
            "Neighborhood object\n",
            "Condition1 object\n",
            "Condition2 object\n",
            "BldgType object\n",
            "HouseStyle object\n",
            "OverallQual int64\n",
            "OverallCond int64\n",
            "YearBuilt int64\n",
            "YearRemodAdd int64\n",
            "RoofStyle object\n",
            "RoofMatl object\n",
            "Exterior1st object\n",
            "Exterior2nd object\n",
            "MasVnrType object\n",
            "MasVnrArea float64\n",
            "ExterQual object\n",
            "ExterCond object\n",
            "Foundation object\n",
            "BsmtQual object\n",
            "BsmtCond object\n",
            "BsmtExposure object\n",
            "BsmtFinType1 object\n",
            "BsmtFinSF1 int64\n",
            "BsmtFinType2 object\n",
            "BsmtFinSF2 int64\n",
            "BsmtUnfSF int64\n",
            "TotalBsmtSF int64\n",
            "Heating object\n",
            "HeatingQC object\n",
            "CentralAir object\n",
            "Electrical object\n",
            "1stFlrSF int64\n",
            "2ndFlrSF int64\n",
            "LowQualFinSF int64\n",
            "GrLivArea int64\n",
            "BsmtFullBath int64\n",
            "BsmtHalfBath int64\n",
            "FullBath int64\n",
            "HalfBath int64\n",
            "BedroomAbvGr int64\n",
            "KitchenAbvGr int64\n",
            "KitchenQual object\n",
            "TotRmsAbvGrd int64\n",
            "Functional object\n",
            "Fireplaces int64\n",
            "GarageType object\n",
            "GarageYrBlt float64\n",
            "GarageFinish object\n",
            "GarageCars int64\n",
            "GarageArea int64\n",
            "GarageQual object\n",
            "GarageCond object\n",
            "PavedDrive object\n",
            "WoodDeckSF int64\n",
            "OpenPorchSF int64\n",
            "EnclosedPorch int64\n",
            "3SsnPorch int64\n",
            "ScreenPorch int64\n",
            "PoolArea int64\n",
            "MiscVal int64\n",
            "MoSold int64\n",
            "YrSold int64\n",
            "SaleType object\n",
            "SaleCondition object\n",
            "SalePrice int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZfA-TZu0lsq"
      },
      "source": [
        "We see that month sold and year sold are not variables that describe a feature of the house. While they do have relevance if we create a model containing a time series element, we will not include them here. Drop these columns. Also, remove the id column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVZUPSWm0lsr"
      },
      "source": [
        "# Answer below\n",
        "df.drop(columns=['Id','MoSold','YrSold'],inplace=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OxMXQ8g0lst"
      },
      "source": [
        "Using the information about the column types, identify all the variables that will be converted into dummy variables. Include at least one numeric variable that you think should be converted as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_SgL-09Ps3E"
      },
      "source": [
        "# Answer below:\r\n",
        "cat_col = []\r\n",
        "for x in df.columns:\r\n",
        "  if df[x].dtype == object:\r\n",
        "    cat_col.append(x)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQBc5p-gPvbL"
      },
      "source": [
        "num_cat = []\r\n",
        "for x in df.columns:\r\n",
        "  if df[x].dtype != object:\r\n",
        "    if len(df[x].value_counts()) < 10:\r\n",
        "      #print(x, len(df[x].value_counts()))\r\n",
        "      num_cat.append(x)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8bgfPXfPBFm"
      },
      "source": [
        "dum_col = []\r\n",
        "dum_col.extend(cat_col)\r\n",
        "dum_col.extend(num_cat)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6wVL2LA0lsv"
      },
      "source": [
        "Convert the columns you selected above into dummy variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bORGylTC0lsv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e154fc55-3b8c-4dfc-a6c0-d1ef8f113ac3"
      },
      "source": [
        "# Answer below:\n",
        "dummy = pd.get_dummies(df, columns=dum_col, drop_first=True)\n",
        "dummy.info()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1094 entries, 0 to 1459\n",
            "Columns: 253 entries, MSSubClass to PoolArea_648\n",
            "dtypes: float64(3), int64(21), uint8(229)\n",
            "memory usage: 458.3 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "7wh3XfH8K1Lh",
        "outputId": "e8293efc-176e-4597-c6cc-b554b2ed0f56"
      },
      "source": [
        "dummy.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>LowQualFinSF</th>\n",
              "      <th>GrLivArea</th>\n",
              "      <th>TotRmsAbvGrd</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>SalePrice</th>\n",
              "      <th>MSZoning_FV</th>\n",
              "      <th>MSZoning_RH</th>\n",
              "      <th>MSZoning_RL</th>\n",
              "      <th>MSZoning_RM</th>\n",
              "      <th>Street_Pave</th>\n",
              "      <th>LotShape_IR2</th>\n",
              "      <th>LotShape_IR3</th>\n",
              "      <th>LotShape_Reg</th>\n",
              "      <th>LandContour_HLS</th>\n",
              "      <th>LandContour_Low</th>\n",
              "      <th>LandContour_Lvl</th>\n",
              "      <th>LotConfig_CulDSac</th>\n",
              "      <th>LotConfig_FR2</th>\n",
              "      <th>LotConfig_FR3</th>\n",
              "      <th>LotConfig_Inside</th>\n",
              "      <th>LandSlope_Mod</th>\n",
              "      <th>...</th>\n",
              "      <th>OverallQual_7</th>\n",
              "      <th>OverallQual_8</th>\n",
              "      <th>OverallQual_9</th>\n",
              "      <th>OverallQual_10</th>\n",
              "      <th>OverallCond_3</th>\n",
              "      <th>OverallCond_4</th>\n",
              "      <th>OverallCond_5</th>\n",
              "      <th>OverallCond_6</th>\n",
              "      <th>OverallCond_7</th>\n",
              "      <th>OverallCond_8</th>\n",
              "      <th>OverallCond_9</th>\n",
              "      <th>BsmtFullBath_1</th>\n",
              "      <th>BsmtFullBath_2</th>\n",
              "      <th>BsmtHalfBath_1</th>\n",
              "      <th>BsmtHalfBath_2</th>\n",
              "      <th>FullBath_1</th>\n",
              "      <th>FullBath_2</th>\n",
              "      <th>FullBath_3</th>\n",
              "      <th>HalfBath_1</th>\n",
              "      <th>HalfBath_2</th>\n",
              "      <th>BedroomAbvGr_1</th>\n",
              "      <th>BedroomAbvGr_2</th>\n",
              "      <th>BedroomAbvGr_3</th>\n",
              "      <th>BedroomAbvGr_4</th>\n",
              "      <th>BedroomAbvGr_5</th>\n",
              "      <th>BedroomAbvGr_6</th>\n",
              "      <th>KitchenAbvGr_2</th>\n",
              "      <th>KitchenAbvGr_3</th>\n",
              "      <th>Fireplaces_1</th>\n",
              "      <th>Fireplaces_2</th>\n",
              "      <th>Fireplaces_3</th>\n",
              "      <th>GarageCars_2</th>\n",
              "      <th>GarageCars_3</th>\n",
              "      <th>GarageCars_4</th>\n",
              "      <th>PoolArea_480</th>\n",
              "      <th>PoolArea_512</th>\n",
              "      <th>PoolArea_519</th>\n",
              "      <th>PoolArea_555</th>\n",
              "      <th>PoolArea_576</th>\n",
              "      <th>PoolArea_648</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>196.0</td>\n",
              "      <td>706</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>856</td>\n",
              "      <td>856</td>\n",
              "      <td>854</td>\n",
              "      <td>0</td>\n",
              "      <td>1710</td>\n",
              "      <td>8</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>548</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>208500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>0.0</td>\n",
              "      <td>978</td>\n",
              "      <td>0</td>\n",
              "      <td>284</td>\n",
              "      <td>1262</td>\n",
              "      <td>1262</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1262</td>\n",
              "      <td>6</td>\n",
              "      <td>1976.0</td>\n",
              "      <td>460</td>\n",
              "      <td>298</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>181500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>162.0</td>\n",
              "      <td>486</td>\n",
              "      <td>0</td>\n",
              "      <td>434</td>\n",
              "      <td>920</td>\n",
              "      <td>920</td>\n",
              "      <td>866</td>\n",
              "      <td>0</td>\n",
              "      <td>1786</td>\n",
              "      <td>6</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>608</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>223500</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>70</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>0.0</td>\n",
              "      <td>216</td>\n",
              "      <td>0</td>\n",
              "      <td>540</td>\n",
              "      <td>756</td>\n",
              "      <td>961</td>\n",
              "      <td>756</td>\n",
              "      <td>0</td>\n",
              "      <td>1717</td>\n",
              "      <td>7</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>642</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>140000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>350.0</td>\n",
              "      <td>655</td>\n",
              "      <td>0</td>\n",
              "      <td>490</td>\n",
              "      <td>1145</td>\n",
              "      <td>1145</td>\n",
              "      <td>1053</td>\n",
              "      <td>0</td>\n",
              "      <td>2198</td>\n",
              "      <td>9</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>836</td>\n",
              "      <td>192</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>250000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 253 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   MSSubClass  LotFrontage  LotArea  ...  PoolArea_555  PoolArea_576  PoolArea_648\n",
              "0          60         65.0     8450  ...             0             0             0\n",
              "1          20         80.0     9600  ...             0             0             0\n",
              "2          60         68.0    11250  ...             0             0             0\n",
              "3          70         60.0     9550  ...             0             0             0\n",
              "4          60         84.0    14260  ...             0             0             0\n",
              "\n",
              "[5 rows x 253 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQkbLG0e0lsx"
      },
      "source": [
        "Split the data into train and test with 20% of data in test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5M0d81CRUMn"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SivhGDOu0lsx"
      },
      "source": [
        "# Answer below\n",
        "X = dummy.drop(columns=['SalePrice'])\n",
        "Y = dummy.SalePrice\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujvHdv2z0lsz"
      },
      "source": [
        "Create a model with 5 layers. The first layer should be a dense layer that takes in the input, the last layer should be of size 1. You determine the remaining layer sizes.\n",
        "\n",
        "Use a linear activation for the output layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EvTExRC0lsz"
      },
      "source": [
        "# Answer below\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(4, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blQTwPWz0ls1"
      },
      "source": [
        "Compile the model with the RMSprop optimizer and mean square error loss. Use the MSE as a metric. Set batch size to 100 and epochs to 200. Fit the model and report the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjcqV1Zm0ls1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7d07203-5497-47ea-d5bc-09af5ab66daf"
      },
      "source": [
        "# Answer below:\n",
        "model.compile(optimizer='RMSprop', loss='mean_squared_error', metrics=['mse','mae'])\n",
        "his_mse = model.fit(X_train, y_train, batch_size=100, epochs=200, validation_data=(X_test, y_test))\n",
        "df_mse = pd.DataFrame(his_mse.history)\n",
        "avg_mse_mae = df_mse.val_mae.mean()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "9/9 [==============================] - 1s 44ms/step - loss: 40155130265.6000 - mse: 40155130265.6000 - mae: 182931.0094 - val_loss: 32191608832.0000 - val_mse: 32191608832.0000 - val_mae: 161694.0312\n",
            "Epoch 2/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 27744163225.6000 - mse: 27744163225.6000 - mae: 146436.6703 - val_loss: 16017031168.0000 - val_mse: 16017031168.0000 - val_mae: 92135.5781\n",
            "Epoch 3/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 8867157196.8000 - mse: 8867157196.8000 - mae: 70296.8391 - val_loss: 17197699072.0000 - val_mse: 17197699072.0000 - val_mae: 55021.8828\n",
            "Epoch 4/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 6291097446.4000 - mse: 6291097446.4000 - mae: 49756.4727 - val_loss: 15873760256.0000 - val_mse: 15873760256.0000 - val_mae: 53548.5469\n",
            "Epoch 5/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 4428415232.0000 - mse: 4428415232.0000 - mae: 45572.4555 - val_loss: 12598710272.0000 - val_mse: 12598710272.0000 - val_mae: 51457.2383\n",
            "Epoch 6/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 4363948902.4000 - mse: 4363948902.4000 - mae: 43980.1051 - val_loss: 12751447040.0000 - val_mse: 12751447040.0000 - val_mae: 51468.3320\n",
            "Epoch 7/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 4353763430.4000 - mse: 4353763737.6000 - mae: 46318.6262 - val_loss: 10568664064.0000 - val_mse: 10568663040.0000 - val_mae: 49130.6289\n",
            "Epoch 8/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 4016753433.6000 - mse: 4016753433.6000 - mae: 43338.8711 - val_loss: 8694263808.0000 - val_mse: 8694263808.0000 - val_mae: 46723.7773\n",
            "Epoch 9/200\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 3800747315.2000 - mse: 3800747315.2000 - mae: 41799.5117 - val_loss: 8039276544.0000 - val_mse: 8039276544.0000 - val_mae: 46674.8906\n",
            "Epoch 10/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 3711216000.0000 - mse: 3711216102.4000 - mae: 42902.4539 - val_loss: 7999629312.0000 - val_mse: 7999629312.0000 - val_mae: 48859.0195\n",
            "Epoch 11/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 4089077376.0000 - mse: 4089077376.0000 - mae: 42328.9543 - val_loss: 6728697344.0000 - val_mse: 6728696832.0000 - val_mae: 45201.5469\n",
            "Epoch 12/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2869665638.4000 - mse: 2869665638.4000 - mae: 38533.2770 - val_loss: 5655746048.0000 - val_mse: 5655746048.0000 - val_mae: 41895.5938\n",
            "Epoch 13/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 3624110540.8000 - mse: 3624110540.8000 - mae: 39907.1840 - val_loss: 5154468864.0000 - val_mse: 5154468864.0000 - val_mae: 40462.5078\n",
            "Epoch 14/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 3756254054.4000 - mse: 3756254054.4000 - mae: 39117.8594 - val_loss: 5035956224.0000 - val_mse: 5035956224.0000 - val_mae: 40619.5664\n",
            "Epoch 15/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2794769868.8000 - mse: 2794769868.8000 - mae: 36792.0629 - val_loss: 4843405824.0000 - val_mse: 4843405824.0000 - val_mae: 40930.4414\n",
            "Epoch 16/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 3176092902.4000 - mse: 3176093209.6000 - mae: 37984.7082 - val_loss: 4515428352.0000 - val_mse: 4515428352.0000 - val_mae: 39894.2109\n",
            "Epoch 17/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2843059404.8000 - mse: 2843059712.0000 - mae: 36728.6582 - val_loss: 4415438848.0000 - val_mse: 4415438848.0000 - val_mae: 39736.0859\n",
            "Epoch 18/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 3232491750.4000 - mse: 3232491750.4000 - mae: 36660.4520 - val_loss: 3899212032.0000 - val_mse: 3899212032.0000 - val_mae: 35922.1914\n",
            "Epoch 19/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2492895219.2000 - mse: 2492895219.2000 - mae: 33730.3578 - val_loss: 4178202368.0000 - val_mse: 4178202368.0000 - val_mae: 39961.6406\n",
            "Epoch 20/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 2449420915.2000 - mse: 2449420915.2000 - mae: 33501.9920 - val_loss: 3924375040.0000 - val_mse: 3924375040.0000 - val_mae: 38243.3750\n",
            "Epoch 21/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2918983603.2000 - mse: 2918983603.2000 - mae: 34569.4461 - val_loss: 3809485056.0000 - val_mse: 3809485056.0000 - val_mae: 35943.1406\n",
            "Epoch 22/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 2539637913.6000 - mse: 2539637836.8000 - mae: 33364.3936 - val_loss: 3592653568.0000 - val_mse: 3592653568.0000 - val_mae: 34267.1484\n",
            "Epoch 23/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 3009643750.4000 - mse: 3009643750.4000 - mae: 33072.8672 - val_loss: 4558798336.0000 - val_mse: 4558798336.0000 - val_mae: 42289.4609\n",
            "Epoch 24/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 4072138521.6000 - mse: 4072138521.6000 - mae: 37254.5359 - val_loss: 3853991936.0000 - val_mse: 3853991936.0000 - val_mae: 36208.8281\n",
            "Epoch 25/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2316206963.2000 - mse: 2316206963.2000 - mae: 32016.6629 - val_loss: 3422015232.0000 - val_mse: 3422015488.0000 - val_mae: 33180.6758\n",
            "Epoch 26/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 2315917900.8000 - mse: 2315917875.2000 - mae: 30792.9238 - val_loss: 3965204736.0000 - val_mse: 3965204736.0000 - val_mae: 37506.6602\n",
            "Epoch 27/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 2297875251.2000 - mse: 2297875225.6000 - mae: 32276.0709 - val_loss: 3606175488.0000 - val_mse: 3606175488.0000 - val_mae: 38139.7188\n",
            "Epoch 28/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2822686080.0000 - mse: 2822686080.0000 - mae: 32330.2504 - val_loss: 3722160896.0000 - val_mse: 3722160896.0000 - val_mae: 35555.9219\n",
            "Epoch 29/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1960705638.4000 - mse: 1960705625.6000 - mae: 29520.9576 - val_loss: 3522878208.0000 - val_mse: 3522878208.0000 - val_mae: 38268.1875\n",
            "Epoch 30/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 2891259673.6000 - mse: 2891259673.6000 - mae: 33565.8332 - val_loss: 3263234048.0000 - val_mse: 3263234048.0000 - val_mae: 32495.3887\n",
            "Epoch 31/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2934322201.6000 - mse: 2934322227.2000 - mae: 31689.8123 - val_loss: 3476229632.0000 - val_mse: 3476229632.0000 - val_mae: 33700.1992\n",
            "Epoch 32/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 2633701760.0000 - mse: 2633701888.0000 - mae: 31130.8289 - val_loss: 3345770496.0000 - val_mse: 3345770496.0000 - val_mae: 32472.1465\n",
            "Epoch 33/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2456359763.2000 - mse: 2456359763.2000 - mae: 30102.0891 - val_loss: 3504118272.0000 - val_mse: 3504118272.0000 - val_mae: 33628.5312\n",
            "Epoch 34/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2368292531.2000 - mse: 2368292531.2000 - mae: 30349.4545 - val_loss: 3246442496.0000 - val_mse: 3246442496.0000 - val_mae: 32204.1309\n",
            "Epoch 35/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2984964096.0000 - mse: 2984964096.0000 - mae: 31027.8771 - val_loss: 3710665984.0000 - val_mse: 3710665984.0000 - val_mae: 35085.6992\n",
            "Epoch 36/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 3201750604.8000 - mse: 3201750604.8000 - mae: 31577.7488 - val_loss: 3122872064.0000 - val_mse: 3122872064.0000 - val_mae: 32641.3496\n",
            "Epoch 37/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 2075934515.2000 - mse: 2075934515.2000 - mae: 30119.8822 - val_loss: 3058251776.0000 - val_mse: 3058251776.0000 - val_mae: 32215.9336\n",
            "Epoch 38/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1999587635.2000 - mse: 1999587635.2000 - mae: 29399.1111 - val_loss: 3106111232.0000 - val_mse: 3106111232.0000 - val_mae: 32155.6855\n",
            "Epoch 39/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 2364099776.0000 - mse: 2364099776.0000 - mae: 29711.6871 - val_loss: 3186833920.0000 - val_mse: 3186833920.0000 - val_mae: 32666.1074\n",
            "Epoch 40/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1975111078.4000 - mse: 1975111078.4000 - mae: 28669.8662 - val_loss: 3543132928.0000 - val_mse: 3543132928.0000 - val_mae: 34760.0039\n",
            "Epoch 41/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2420181926.4000 - mse: 2420181926.4000 - mae: 31439.8074 - val_loss: 3357190912.0000 - val_mse: 3357190400.0000 - val_mae: 33641.3008\n",
            "Epoch 42/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2463354240.0000 - mse: 2463354240.0000 - mae: 30355.7033 - val_loss: 2965642240.0000 - val_mse: 2965642240.0000 - val_mae: 32243.7832\n",
            "Epoch 43/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2112912665.6000 - mse: 2112912665.6000 - mae: 29409.6158 - val_loss: 3022100224.0000 - val_mse: 3022100224.0000 - val_mae: 31792.7305\n",
            "Epoch 44/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 2697300659.2000 - mse: 2697300787.2000 - mae: 29442.8912 - val_loss: 3198297088.0000 - val_mse: 3198297088.0000 - val_mae: 32852.4922\n",
            "Epoch 45/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2629292313.6000 - mse: 2629292313.6000 - mae: 29714.6391 - val_loss: 2996694016.0000 - val_mse: 2996694016.0000 - val_mae: 32147.7891\n",
            "Epoch 46/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 2266959974.4000 - mse: 2266959974.4000 - mae: 30506.6162 - val_loss: 3881700352.0000 - val_mse: 3881700352.0000 - val_mae: 37637.0859\n",
            "Epoch 47/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2174762496.0000 - mse: 2174762406.4000 - mae: 31449.6244 - val_loss: 3145511424.0000 - val_mse: 3145511424.0000 - val_mae: 36528.6836\n",
            "Epoch 48/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2440458867.2000 - mse: 2440458892.8000 - mae: 31220.9014 - val_loss: 3010399232.0000 - val_mse: 3010399232.0000 - val_mae: 32213.8262\n",
            "Epoch 49/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 2443478476.8000 - mse: 2443478476.8000 - mae: 29853.4123 - val_loss: 2893248512.0000 - val_mse: 2893248512.0000 - val_mae: 31841.7305\n",
            "Epoch 50/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1899243712.0000 - mse: 1899243712.0000 - mae: 29239.7424 - val_loss: 3145888512.0000 - val_mse: 3145888512.0000 - val_mae: 37516.0234\n",
            "Epoch 51/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2725991398.4000 - mse: 2725991398.4000 - mae: 32358.4346 - val_loss: 3169694976.0000 - val_mse: 3169694976.0000 - val_mae: 33639.7383\n",
            "Epoch 52/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1999626816.0000 - mse: 1999626816.0000 - mae: 29895.0709 - val_loss: 3155900416.0000 - val_mse: 3155900416.0000 - val_mae: 37634.7617\n",
            "Epoch 53/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 2930573670.4000 - mse: 2930573670.4000 - mae: 33584.7711 - val_loss: 3144568320.0000 - val_mse: 3144568320.0000 - val_mae: 33303.7109\n",
            "Epoch 54/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2203782284.8000 - mse: 2203782156.8000 - mae: 28684.6729 - val_loss: 2787903744.0000 - val_mse: 2787903488.0000 - val_mae: 31890.5547\n",
            "Epoch 55/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2007046220.8000 - mse: 2007046144.0000 - mae: 28772.6910 - val_loss: 3057655808.0000 - val_mse: 3057655808.0000 - val_mae: 32920.5078\n",
            "Epoch 56/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1716979398.4000 - mse: 1716979398.4000 - mae: 26616.2771 - val_loss: 2827883776.0000 - val_mse: 2827884032.0000 - val_mae: 31705.2676\n",
            "Epoch 57/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 2247048115.2000 - mse: 2247048115.2000 - mae: 30224.2027 - val_loss: 2846058752.0000 - val_mse: 2846058752.0000 - val_mae: 31669.3789\n",
            "Epoch 58/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2153946419.2000 - mse: 2153946419.2000 - mae: 28154.2357 - val_loss: 2940652800.0000 - val_mse: 2940652800.0000 - val_mae: 32174.7129\n",
            "Epoch 59/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2477463500.8000 - mse: 2477463244.8000 - mae: 28688.5979 - val_loss: 3110377984.0000 - val_mse: 3110377984.0000 - val_mae: 33144.1133\n",
            "Epoch 60/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1594871238.4000 - mse: 1594871238.4000 - mae: 26998.5293 - val_loss: 3002468352.0000 - val_mse: 3002468352.0000 - val_mae: 36388.8867\n",
            "Epoch 61/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 2526006297.6000 - mse: 2526006297.6000 - mae: 31655.6949 - val_loss: 2695225856.0000 - val_mse: 2695225856.0000 - val_mae: 31158.5527\n",
            "Epoch 62/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1764731648.0000 - mse: 1764731648.0000 - mae: 28493.2148 - val_loss: 2706185472.0000 - val_mse: 2706185728.0000 - val_mae: 32581.5918\n",
            "Epoch 63/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1873697587.2000 - mse: 1873697587.2000 - mae: 28494.0232 - val_loss: 2884093440.0000 - val_mse: 2884093440.0000 - val_mae: 35894.5156\n",
            "Epoch 64/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 2025192384.0000 - mse: 2025192384.0000 - mae: 29879.4178 - val_loss: 2598276352.0000 - val_mse: 2598276352.0000 - val_mae: 31342.6895\n",
            "Epoch 65/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1848125184.0000 - mse: 1848125184.0000 - mae: 27737.4781 - val_loss: 2734792704.0000 - val_mse: 2734792704.0000 - val_mae: 32251.6660\n",
            "Epoch 66/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1887126988.8000 - mse: 1887126988.8000 - mae: 28537.6041 - val_loss: 2596006656.0000 - val_mse: 2596006656.0000 - val_mae: 31075.7188\n",
            "Epoch 67/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2564638233.6000 - mse: 2564638233.6000 - mae: 31144.0480 - val_loss: 2698742016.0000 - val_mse: 2698741760.0000 - val_mae: 31632.7617\n",
            "Epoch 68/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1839792838.4000 - mse: 1839792838.4000 - mae: 26882.7617 - val_loss: 2508889344.0000 - val_mse: 2508889344.0000 - val_mae: 30972.3672\n",
            "Epoch 69/200\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 1704577856.0000 - mse: 1704577856.0000 - mae: 27479.3719 - val_loss: 3030379520.0000 - val_mse: 3030379520.0000 - val_mae: 38273.6328\n",
            "Epoch 70/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1913166438.4000 - mse: 1913166438.4000 - mae: 30372.6937 - val_loss: 2858270720.0000 - val_mse: 2858270720.0000 - val_mae: 36419.1719\n",
            "Epoch 71/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 2453331059.2000 - mse: 2453331059.2000 - mae: 31099.8027 - val_loss: 2449174016.0000 - val_mse: 2449174016.0000 - val_mae: 30567.1738\n",
            "Epoch 72/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2053046323.2000 - mse: 2053046323.2000 - mae: 28238.7361 - val_loss: 2730276096.0000 - val_mse: 2730276096.0000 - val_mae: 34534.8203\n",
            "Epoch 73/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 2214457190.4000 - mse: 2214457190.4000 - mae: 30461.0863 - val_loss: 2447359232.0000 - val_mse: 2447359232.0000 - val_mae: 30581.6035\n",
            "Epoch 74/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1864894476.8000 - mse: 1864894476.8000 - mae: 26845.0541 - val_loss: 2605584384.0000 - val_mse: 2605584384.0000 - val_mae: 32873.5508\n",
            "Epoch 75/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2555303616.0000 - mse: 2555303616.0000 - mae: 30230.4152 - val_loss: 2774425088.0000 - val_mse: 2774425088.0000 - val_mae: 32474.6191\n",
            "Epoch 76/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1848291212.8000 - mse: 1848291212.8000 - mae: 27648.2584 - val_loss: 2558118656.0000 - val_mse: 2558118656.0000 - val_mae: 31066.0957\n",
            "Epoch 77/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2137526809.6000 - mse: 2137526668.8000 - mae: 28961.1865 - val_loss: 2897726208.0000 - val_mse: 2897726208.0000 - val_mae: 33464.0391\n",
            "Epoch 78/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 2033637555.2000 - mse: 2033637555.2000 - mae: 27626.3348 - val_loss: 2644840960.0000 - val_mse: 2644840960.0000 - val_mae: 31703.3965\n",
            "Epoch 79/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 2072108633.6000 - mse: 2072108633.6000 - mae: 27288.2158 - val_loss: 2596209152.0000 - val_mse: 2596209152.0000 - val_mae: 31423.5625\n",
            "Epoch 80/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1754201792.0000 - mse: 1754201792.0000 - mae: 27396.3928 - val_loss: 2459848448.0000 - val_mse: 2459848448.0000 - val_mae: 31048.6914\n",
            "Epoch 81/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 2475615948.8000 - mse: 2475615948.8000 - mae: 28800.5852 - val_loss: 2466603008.0000 - val_mse: 2466603008.0000 - val_mae: 30475.3555\n",
            "Epoch 82/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1956426880.0000 - mse: 1956426880.0000 - mae: 28083.2230 - val_loss: 2445445888.0000 - val_mse: 2445445888.0000 - val_mae: 30424.4199\n",
            "Epoch 83/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1687768819.2000 - mse: 1687768883.2000 - mae: 26735.0465 - val_loss: 2758356992.0000 - val_mse: 2758356992.0000 - val_mae: 33502.4766\n",
            "Epoch 84/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2132609587.2000 - mse: 2132609587.2000 - mae: 28993.6221 - val_loss: 2353720576.0000 - val_mse: 2353720576.0000 - val_mae: 30494.4746\n",
            "Epoch 85/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 2058366643.2000 - mse: 2058366643.2000 - mae: 28624.8977 - val_loss: 2371179776.0000 - val_mse: 2371180032.0000 - val_mae: 30198.5820\n",
            "Epoch 86/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 2035879628.8000 - mse: 2035879628.8000 - mae: 28393.7146 - val_loss: 2688296960.0000 - val_mse: 2688296960.0000 - val_mae: 31996.1543\n",
            "Epoch 87/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 2204811622.4000 - mse: 2204811622.4000 - mae: 28336.7354 - val_loss: 2428314368.0000 - val_mse: 2428314368.0000 - val_mae: 30255.1504\n",
            "Epoch 88/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2284717811.2000 - mse: 2284717811.2000 - mae: 29510.7258 - val_loss: 2540333312.0000 - val_mse: 2540333312.0000 - val_mae: 32862.4219\n",
            "Epoch 89/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1982835507.2000 - mse: 1982835481.6000 - mae: 27908.8689 - val_loss: 2905529600.0000 - val_mse: 2905529600.0000 - val_mae: 37556.0898\n",
            "Epoch 90/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1856821939.2000 - mse: 1856821939.2000 - mae: 29348.6469 - val_loss: 2723680000.0000 - val_mse: 2723680000.0000 - val_mae: 35760.4258\n",
            "Epoch 91/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2025390668.8000 - mse: 2025390668.8000 - mae: 28663.1594 - val_loss: 2250299392.0000 - val_mse: 2250299392.0000 - val_mae: 30078.9727\n",
            "Epoch 92/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1817238848.0000 - mse: 1817238886.4000 - mae: 27419.6318 - val_loss: 2251357696.0000 - val_mse: 2251357696.0000 - val_mae: 30118.9629\n",
            "Epoch 93/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1789933440.0000 - mse: 1789933516.8000 - mae: 26586.1602 - val_loss: 2330097664.0000 - val_mse: 2330097664.0000 - val_mae: 31038.3242\n",
            "Epoch 94/200\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 1726344832.0000 - mse: 1726344832.0000 - mae: 27180.8350 - val_loss: 2651455744.0000 - val_mse: 2651455744.0000 - val_mae: 34105.2305\n",
            "Epoch 95/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 2074836390.4000 - mse: 2074836364.8000 - mae: 28568.2670 - val_loss: 2206636544.0000 - val_mse: 2206636544.0000 - val_mae: 30062.6973\n",
            "Epoch 96/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 2660235443.2000 - mse: 2660235468.8000 - mae: 29924.7047 - val_loss: 2288991232.0000 - val_mse: 2288991232.0000 - val_mae: 30399.4609\n",
            "Epoch 97/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1786235955.2000 - mse: 1786235993.6000 - mae: 27153.2775 - val_loss: 2783412992.0000 - val_mse: 2783412992.0000 - val_mae: 36553.7383\n",
            "Epoch 98/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1863315161.6000 - mse: 1863315097.6000 - mae: 28593.8521 - val_loss: 2175086336.0000 - val_mse: 2175086336.0000 - val_mae: 29711.0781\n",
            "Epoch 99/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1601339539.2000 - mse: 1601339577.6000 - mae: 25658.2764 - val_loss: 2180521472.0000 - val_mse: 2180521472.0000 - val_mae: 29682.4355\n",
            "Epoch 100/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2323890444.8000 - mse: 2323890444.8000 - mae: 28869.6523 - val_loss: 2346891008.0000 - val_mse: 2346891008.0000 - val_mae: 30854.1465\n",
            "Epoch 101/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1883951206.4000 - mse: 1883951206.4000 - mae: 26386.8529 - val_loss: 2544544000.0000 - val_mse: 2544544000.0000 - val_mae: 31857.5391\n",
            "Epoch 102/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1656084185.6000 - mse: 1656084224.0000 - mae: 26212.1063 - val_loss: 2192049408.0000 - val_mse: 2192049408.0000 - val_mae: 29732.0586\n",
            "Epoch 103/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1742374387.2000 - mse: 1742374387.2000 - mae: 26665.3937 - val_loss: 2182135552.0000 - val_mse: 2182135552.0000 - val_mae: 30026.0098\n",
            "Epoch 104/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 1747429427.2000 - mse: 1747429427.2000 - mae: 26478.9303 - val_loss: 2487345664.0000 - val_mse: 2487345920.0000 - val_mae: 33777.7070\n",
            "Epoch 105/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 2348278284.8000 - mse: 2348278284.8000 - mae: 29721.7607 - val_loss: 2151630848.0000 - val_mse: 2151630848.0000 - val_mae: 29732.2598\n",
            "Epoch 106/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1678429324.8000 - mse: 1678429312.0000 - mae: 26221.2713 - val_loss: 2127005056.0000 - val_mse: 2127005056.0000 - val_mae: 29635.3418\n",
            "Epoch 107/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1692104230.4000 - mse: 1692104230.4000 - mae: 26229.3402 - val_loss: 2056801280.0000 - val_mse: 2056801280.0000 - val_mae: 29374.9062\n",
            "Epoch 108/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 2350673689.6000 - mse: 2350673689.6000 - mae: 29879.3555 - val_loss: 2101703040.0000 - val_mse: 2101703040.0000 - val_mae: 29478.5898\n",
            "Epoch 109/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1614617728.0000 - mse: 1614617728.0000 - mae: 26326.9840 - val_loss: 2488757760.0000 - val_mse: 2488757760.0000 - val_mae: 33809.0352\n",
            "Epoch 110/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1951236198.4000 - mse: 1951236211.2000 - mae: 28277.1705 - val_loss: 2010139136.0000 - val_mse: 2010139136.0000 - val_mae: 29274.2441\n",
            "Epoch 111/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 1952964774.4000 - mse: 1952964774.4000 - mae: 27494.6293 - val_loss: 2075039232.0000 - val_mse: 2075039232.0000 - val_mae: 29423.0762\n",
            "Epoch 112/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1924932838.4000 - mse: 1924932838.4000 - mae: 26802.9283 - val_loss: 2493152512.0000 - val_mse: 2493152512.0000 - val_mae: 33000.8164\n",
            "Epoch 113/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1689448755.2000 - mse: 1689448755.2000 - mae: 27112.7871 - val_loss: 2042898304.0000 - val_mse: 2042898304.0000 - val_mae: 29224.0977\n",
            "Epoch 114/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 1761903321.6000 - mse: 1761903321.6000 - mae: 26354.3422 - val_loss: 2079220864.0000 - val_mse: 2079220864.0000 - val_mae: 29350.3496\n",
            "Epoch 115/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1539502528.0000 - mse: 1539502528.0000 - mae: 24624.5436 - val_loss: 2121880704.0000 - val_mse: 2121880704.0000 - val_mae: 29621.0566\n",
            "Epoch 116/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1897689984.0000 - mse: 1897689984.0000 - mae: 27144.1268 - val_loss: 2203001856.0000 - val_mse: 2203002112.0000 - val_mae: 30272.4863\n",
            "Epoch 117/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1978100633.6000 - mse: 1978100633.6000 - mae: 28058.6863 - val_loss: 1989772160.0000 - val_mse: 1989772160.0000 - val_mae: 29070.2988\n",
            "Epoch 118/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2141241548.8000 - mse: 2141241651.2000 - mae: 28208.0041 - val_loss: 2091565568.0000 - val_mse: 2091565568.0000 - val_mae: 29522.5430\n",
            "Epoch 119/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1860483852.8000 - mse: 1860483852.8000 - mae: 26742.0164 - val_loss: 2082252416.0000 - val_mse: 2082252416.0000 - val_mae: 29516.0723\n",
            "Epoch 120/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1848254899.2000 - mse: 1848254899.2000 - mae: 27118.1557 - val_loss: 2084914176.0000 - val_mse: 2084914176.0000 - val_mae: 29327.9277\n",
            "Epoch 121/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1767165350.4000 - mse: 1767165350.4000 - mae: 26442.1859 - val_loss: 2065932800.0000 - val_mse: 2065932800.0000 - val_mae: 29732.0430\n",
            "Epoch 122/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1853125964.8000 - mse: 1853125964.8000 - mae: 27041.7064 - val_loss: 2614393344.0000 - val_mse: 2614393344.0000 - val_mae: 35569.4609\n",
            "Epoch 123/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 2242021350.4000 - mse: 2242021350.4000 - mae: 30573.3563 - val_loss: 1985826688.0000 - val_mse: 1985826688.0000 - val_mae: 29016.0508\n",
            "Epoch 124/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1887524044.8000 - mse: 1887524044.8000 - mae: 26587.4156 - val_loss: 1997803264.0000 - val_mse: 1997803264.0000 - val_mae: 29282.1387\n",
            "Epoch 125/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1927450099.2000 - mse: 1927450099.2000 - mae: 27734.7145 - val_loss: 2020833536.0000 - val_mse: 2020833536.0000 - val_mae: 28799.9746\n",
            "Epoch 126/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1756229696.0000 - mse: 1756229696.0000 - mae: 27336.6975 - val_loss: 2173743360.0000 - val_mse: 2173743360.0000 - val_mae: 30596.8398\n",
            "Epoch 127/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1866089715.2000 - mse: 1866089715.2000 - mae: 27420.1363 - val_loss: 2026888192.0000 - val_mse: 2026888192.0000 - val_mae: 29037.4492\n",
            "Epoch 128/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 2074787699.2000 - mse: 2074787699.2000 - mae: 27290.4592 - val_loss: 2673709568.0000 - val_mse: 2673709568.0000 - val_mae: 34561.6172\n",
            "Epoch 129/200\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 1827890201.6000 - mse: 1827890201.6000 - mae: 28208.8148 - val_loss: 2131672320.0000 - val_mse: 2131672064.0000 - val_mae: 29743.0664\n",
            "Epoch 130/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2052289126.4000 - mse: 2052289126.4000 - mae: 27179.5322 - val_loss: 2030205312.0000 - val_mse: 2030205312.0000 - val_mae: 28837.3125\n",
            "Epoch 131/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1752935212.8000 - mse: 1752935212.8000 - mae: 26336.7723 - val_loss: 2005994752.0000 - val_mse: 2005994880.0000 - val_mae: 28680.2168\n",
            "Epoch 132/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1455492326.4000 - mse: 1455492326.4000 - mae: 25223.5625 - val_loss: 1922340096.0000 - val_mse: 1922340096.0000 - val_mae: 28515.7031\n",
            "Epoch 133/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1972481958.4000 - mse: 1972481958.4000 - mae: 27710.8035 - val_loss: 1968963584.0000 - val_mse: 1968963584.0000 - val_mae: 28963.4414\n",
            "Epoch 134/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1684932857.6000 - mse: 1684932857.6000 - mae: 25993.7441 - val_loss: 1998135296.0000 - val_mse: 1998135296.0000 - val_mae: 29030.5352\n",
            "Epoch 135/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1962007820.8000 - mse: 1962007820.8000 - mae: 27300.3732 - val_loss: 2141534592.0000 - val_mse: 2141534592.0000 - val_mae: 30157.2930\n",
            "Epoch 136/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1574457856.0000 - mse: 1574457856.0000 - mae: 24896.4119 - val_loss: 1971983360.0000 - val_mse: 1971983360.0000 - val_mae: 28593.7266\n",
            "Epoch 137/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1815427916.8000 - mse: 1815427916.8000 - mae: 26066.5561 - val_loss: 1880486528.0000 - val_mse: 1880486400.0000 - val_mae: 28245.2285\n",
            "Epoch 138/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1478321881.6000 - mse: 1478321881.6000 - mae: 25813.5691 - val_loss: 2321326592.0000 - val_mse: 2321326592.0000 - val_mae: 32869.1445\n",
            "Epoch 139/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1784330009.6000 - mse: 1784330176.0000 - mae: 28192.4887 - val_loss: 2381202944.0000 - val_mse: 2381202944.0000 - val_mae: 32274.7617\n",
            "Epoch 140/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1716749849.6000 - mse: 1716749849.6000 - mae: 26344.2773 - val_loss: 2209015296.0000 - val_mse: 2209015296.0000 - val_mae: 31104.1621\n",
            "Epoch 141/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1644893516.8000 - mse: 1644893516.8000 - mae: 27373.0934 - val_loss: 2001366656.0000 - val_mse: 2001366656.0000 - val_mae: 28468.5078\n",
            "Epoch 142/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1479701312.0000 - mse: 1479701312.0000 - mae: 26101.1125 - val_loss: 1908490496.0000 - val_mse: 1908490496.0000 - val_mae: 28275.8145\n",
            "Epoch 143/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1983138022.4000 - mse: 1983138022.4000 - mae: 26429.2398 - val_loss: 1888062592.0000 - val_mse: 1888062592.0000 - val_mae: 28539.5410\n",
            "Epoch 144/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 1760042009.6000 - mse: 1760042009.6000 - mae: 26440.8770 - val_loss: 1843290368.0000 - val_mse: 1843290368.0000 - val_mae: 27973.2832\n",
            "Epoch 145/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1568644812.8000 - mse: 1568644812.8000 - mae: 26118.2256 - val_loss: 1982395008.0000 - val_mse: 1982395008.0000 - val_mae: 29640.1250\n",
            "Epoch 146/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1639080051.2000 - mse: 1639080115.2000 - mae: 27383.5377 - val_loss: 1922242432.0000 - val_mse: 1922242432.0000 - val_mae: 28789.0293\n",
            "Epoch 147/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1664384985.6000 - mse: 1664384985.6000 - mae: 26784.8479 - val_loss: 1815376512.0000 - val_mse: 1815376512.0000 - val_mae: 27845.9297\n",
            "Epoch 148/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1735594892.8000 - mse: 1735594892.8000 - mae: 25789.4340 - val_loss: 1930747136.0000 - val_mse: 1930747136.0000 - val_mae: 28792.3926\n",
            "Epoch 149/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1668909248.0000 - mse: 1668909248.0000 - mae: 25829.2873 - val_loss: 1940920320.0000 - val_mse: 1940920320.0000 - val_mae: 28823.2578\n",
            "Epoch 150/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1889161216.0000 - mse: 1889161203.2000 - mae: 27172.5658 - val_loss: 2027888128.0000 - val_mse: 2027888128.0000 - val_mae: 28282.5645\n",
            "Epoch 151/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1573265152.0000 - mse: 1573265152.0000 - mae: 26232.4244 - val_loss: 2037838592.0000 - val_mse: 2037838592.0000 - val_mae: 29823.5996\n",
            "Epoch 152/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1646698099.2000 - mse: 1646698099.2000 - mae: 25738.9930 - val_loss: 1893721984.0000 - val_mse: 1893721984.0000 - val_mae: 28280.3789\n",
            "Epoch 153/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1657268838.4000 - mse: 1657268851.2000 - mae: 25823.9803 - val_loss: 2035549824.0000 - val_mse: 2035549696.0000 - val_mae: 29044.0254\n",
            "Epoch 154/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 1667370892.8000 - mse: 1667370892.8000 - mae: 26796.7490 - val_loss: 1888636288.0000 - val_mse: 1888636288.0000 - val_mae: 28152.5488\n",
            "Epoch 155/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1592475187.2000 - mse: 1592475123.2000 - mae: 25788.5631 - val_loss: 1858611840.0000 - val_mse: 1858611840.0000 - val_mae: 27697.0566\n",
            "Epoch 156/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1518509555.2000 - mse: 1518509555.2000 - mae: 25942.9646 - val_loss: 2251117824.0000 - val_mse: 2251117824.0000 - val_mae: 32646.1836\n",
            "Epoch 157/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 1616785702.4000 - mse: 1616785792.0000 - mae: 26911.2844 - val_loss: 1979794176.0000 - val_mse: 1979794176.0000 - val_mae: 28970.5645\n",
            "Epoch 158/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1482191955.2000 - mse: 1482191955.2000 - mae: 24985.7660 - val_loss: 1857179648.0000 - val_mse: 1857179648.0000 - val_mae: 27816.3301\n",
            "Epoch 159/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1628370169.6000 - mse: 1628370169.6000 - mae: 25474.3385 - val_loss: 1842934656.0000 - val_mse: 1842934656.0000 - val_mae: 27786.0273\n",
            "Epoch 160/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1344581305.6000 - mse: 1344581305.6000 - mae: 24064.4918 - val_loss: 1903915904.0000 - val_mse: 1903915904.0000 - val_mae: 28549.0547\n",
            "Epoch 161/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1518576320.0000 - mse: 1518576320.0000 - mae: 24828.3586 - val_loss: 1842814976.0000 - val_mse: 1842814976.0000 - val_mae: 27620.8594\n",
            "Epoch 162/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1352804531.2000 - mse: 1352804531.2000 - mae: 24071.4039 - val_loss: 1823226368.0000 - val_mse: 1823226368.0000 - val_mae: 27975.2754\n",
            "Epoch 163/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1562977728.0000 - mse: 1562977728.0000 - mae: 25612.6627 - val_loss: 1799211008.0000 - val_mse: 1799211008.0000 - val_mae: 27431.6797\n",
            "Epoch 164/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1756623731.2000 - mse: 1756623692.8000 - mae: 26568.1449 - val_loss: 2132409216.0000 - val_mse: 2132409216.0000 - val_mae: 31502.2578\n",
            "Epoch 165/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1523690464.0000 - mse: 1523690464.0000 - mae: 24890.5148 - val_loss: 1842253824.0000 - val_mse: 1842253824.0000 - val_mae: 28339.6602\n",
            "Epoch 166/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1561366041.6000 - mse: 1561366041.6000 - mae: 26377.6664 - val_loss: 1710408064.0000 - val_mse: 1710408064.0000 - val_mae: 27055.2441\n",
            "Epoch 167/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1407677427.2000 - mse: 1407677414.4000 - mae: 25591.9238 - val_loss: 2090615424.0000 - val_mse: 2090615424.0000 - val_mae: 30791.6797\n",
            "Epoch 168/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 1771074099.2000 - mse: 1771074099.2000 - mae: 26563.6125 - val_loss: 1780944512.0000 - val_mse: 1780944512.0000 - val_mae: 27628.2422\n",
            "Epoch 169/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1320716185.6000 - mse: 1320716185.6000 - mae: 24832.8986 - val_loss: 2894739968.0000 - val_mse: 2894739968.0000 - val_mae: 36816.4375\n",
            "Epoch 170/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 1846290675.2000 - mse: 1846290675.2000 - mae: 27748.2717 - val_loss: 2372139520.0000 - val_mse: 2372139520.0000 - val_mae: 31875.4570\n",
            "Epoch 171/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 1805058611.2000 - mse: 1805058611.2000 - mae: 27604.6344 - val_loss: 2039875072.0000 - val_mse: 2039875072.0000 - val_mae: 30426.0137\n",
            "Epoch 172/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 1787794944.0000 - mse: 1787794944.0000 - mae: 28040.9951 - val_loss: 1829132800.0000 - val_mse: 1829132800.0000 - val_mae: 27650.8730\n",
            "Epoch 173/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1485441561.6000 - mse: 1485441561.6000 - mae: 24683.2971 - val_loss: 2048653056.0000 - val_mse: 2048653056.0000 - val_mae: 30092.1387\n",
            "Epoch 174/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1464873561.6000 - mse: 1464873561.6000 - mae: 25567.1490 - val_loss: 1991632000.0000 - val_mse: 1991632000.0000 - val_mae: 30039.7266\n",
            "Epoch 175/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1473087468.8000 - mse: 1473087468.8000 - mae: 26532.0279 - val_loss: 1701214848.0000 - val_mse: 1701214848.0000 - val_mae: 26837.4824\n",
            "Epoch 176/200\n",
            "9/9 [==============================] - 0s 17ms/step - loss: 1522721484.8000 - mse: 1522721484.8000 - mae: 25318.0279 - val_loss: 1889225856.0000 - val_mse: 1889225856.0000 - val_mae: 29198.9746\n",
            "Epoch 177/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1397296332.8000 - mse: 1397296332.8000 - mae: 24402.5094 - val_loss: 1773990400.0000 - val_mse: 1773990400.0000 - val_mae: 27295.2344\n",
            "Epoch 178/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1537147417.6000 - mse: 1537147417.6000 - mae: 25998.4555 - val_loss: 1785994752.0000 - val_mse: 1785994752.0000 - val_mae: 27118.9551\n",
            "Epoch 179/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1252169990.4000 - mse: 1252169926.4000 - mae: 24126.6822 - val_loss: 1889631104.0000 - val_mse: 1889631104.0000 - val_mae: 29560.4766\n",
            "Epoch 180/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1760309504.0000 - mse: 1760309504.0000 - mae: 27197.3166 - val_loss: 1800665600.0000 - val_mse: 1800665600.0000 - val_mae: 27064.8809\n",
            "Epoch 181/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1570863833.6000 - mse: 1570863744.0000 - mae: 25757.9105 - val_loss: 2310146304.0000 - val_mse: 2310146304.0000 - val_mae: 32070.5430\n",
            "Epoch 182/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1394983232.0000 - mse: 1394983232.0000 - mae: 25057.0619 - val_loss: 1834983936.0000 - val_mse: 1834983936.0000 - val_mae: 27553.4844\n",
            "Epoch 183/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 1706067366.4000 - mse: 1706067366.4000 - mae: 26726.7387 - val_loss: 2208286720.0000 - val_mse: 2208286720.0000 - val_mae: 30050.6094\n",
            "Epoch 184/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1318778163.2000 - mse: 1318778163.2000 - mae: 24284.1115 - val_loss: 1740086144.0000 - val_mse: 1740086144.0000 - val_mae: 27060.1934\n",
            "Epoch 185/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1411934515.2000 - mse: 1411934540.8000 - mae: 25199.2439 - val_loss: 1601821184.0000 - val_mse: 1601821184.0000 - val_mae: 26185.9023\n",
            "Epoch 186/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1603378380.8000 - mse: 1603378380.8000 - mae: 26136.2219 - val_loss: 1718721792.0000 - val_mse: 1718721792.0000 - val_mae: 27514.1777\n",
            "Epoch 187/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1359485920.0000 - mse: 1359485920.0000 - mae: 24304.1303 - val_loss: 1696168192.0000 - val_mse: 1696168192.0000 - val_mae: 26626.9766\n",
            "Epoch 188/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1346542931.2000 - mse: 1346542931.2000 - mae: 24932.9795 - val_loss: 2139232512.0000 - val_mse: 2139232512.0000 - val_mae: 31823.2520\n",
            "Epoch 189/200\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 1497840716.8000 - mse: 1497840678.4000 - mae: 26301.4168 - val_loss: 1735459328.0000 - val_mse: 1735459328.0000 - val_mae: 27074.9043\n",
            "Epoch 190/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1421313356.8000 - mse: 1421313356.8000 - mae: 23541.6881 - val_loss: 1885766144.0000 - val_mse: 1885766144.0000 - val_mae: 27773.1777\n",
            "Epoch 191/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1389383065.6000 - mse: 1389383065.6000 - mae: 24808.5391 - val_loss: 1906817024.0000 - val_mse: 1906817024.0000 - val_mae: 27394.1992\n",
            "Epoch 192/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 1473187974.4000 - mse: 1473187987.2000 - mae: 26205.7033 - val_loss: 2046548992.0000 - val_mse: 2046548736.0000 - val_mae: 29436.4629\n",
            "Epoch 193/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1385883929.6000 - mse: 1385883942.4000 - mae: 24630.1047 - val_loss: 3190333952.0000 - val_mse: 3190333952.0000 - val_mae: 35752.8867\n",
            "Epoch 194/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 2056113766.4000 - mse: 2056113766.4000 - mae: 28981.9059 - val_loss: 1972230272.0000 - val_mse: 1972230272.0000 - val_mae: 27126.5312\n",
            "Epoch 195/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1510642028.8000 - mse: 1510642028.8000 - mae: 25601.3139 - val_loss: 1750551296.0000 - val_mse: 1750551296.0000 - val_mae: 27001.1797\n",
            "Epoch 196/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1431520985.6000 - mse: 1431520985.6000 - mae: 25202.1098 - val_loss: 2314128640.0000 - val_mse: 2314128640.0000 - val_mae: 30656.9316\n",
            "Epoch 197/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1483124812.8000 - mse: 1483124812.8000 - mae: 26368.7096 - val_loss: 1778233984.0000 - val_mse: 1778233984.0000 - val_mae: 26748.9551\n",
            "Epoch 198/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1428262502.4000 - mse: 1428262502.4000 - mae: 25322.8693 - val_loss: 1835972352.0000 - val_mse: 1835972352.0000 - val_mae: 27281.4512\n",
            "Epoch 199/200\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 1239863084.8000 - mse: 1239863084.8000 - mae: 23407.6344 - val_loss: 1574753408.0000 - val_mse: 1574753408.0000 - val_mae: 25824.7891\n",
            "Epoch 200/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1230061318.4000 - mse: 1230061318.4000 - mae: 23467.5959 - val_loss: 1939310592.0000 - val_mse: 1939310592.0000 - val_mae: 30261.1836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD1byILV0ls3"
      },
      "source": [
        "Next, do the same but with mean absolute error loss. Use both MSE and MAE as metrics. Compare the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xz0cnwUq0ls4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3903819-7502-4e96-df59-72dd164f9d38"
      },
      "source": [
        "# Answer below:\n",
        "model1 = Sequential()\n",
        "model1.add(Dense(512, input_dim=X_train.shape[1], activation='relu'))\n",
        "model1.add(Dense(256, activation='relu'))\n",
        "model1.add(Dense(16, activation='relu'))\n",
        "model1.add(Dense(4, activation='relu'))\n",
        "model1.add(Dense(1, activation='linear'))\n",
        "model1.compile(optimizer='RMSprop', loss='mean_absolute_error', metrics=['mse','mae'])\n",
        "his_mae = model1.fit(X_train, y_train, batch_size=100, epochs=200, validation_data=(X_test, y_test))\n",
        "df_mae = pd.DataFrame(his_mae.history)\n",
        "avg_mae_mae = df_mae.val_mae.mean()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "9/9 [==============================] - 1s 42ms/step - loss: 182576.0250 - mse: 39897117900.8000 - mae: 182576.0250 - val_loss: 151530.9062 - val_mse: 28705499136.0000 - val_mae: 151530.9062\n",
            "Epoch 2/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 134340.9289 - mse: 25311985049.6000 - mae: 134340.9289 - val_loss: 72086.8203 - val_mse: 15598356480.0000 - val_mae: 72086.8203\n",
            "Epoch 3/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 55992.5574 - mse: 7038972364.8000 - mae: 55992.5574 - val_loss: 55672.1719 - val_mse: 19106134016.0000 - val_mae: 55672.1719\n",
            "Epoch 4/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 47837.9066 - mse: 5561636300.8000 - mae: 47837.9066 - val_loss: 54144.0156 - val_mse: 17384460288.0000 - val_mae: 54144.0156\n",
            "Epoch 5/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 46904.9043 - mse: 5165620070.4000 - mae: 46904.9043 - val_loss: 53305.7852 - val_mse: 16360335360.0000 - val_mae: 53305.7852\n",
            "Epoch 6/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 45168.0168 - mse: 4817477452.8000 - mae: 45168.0168 - val_loss: 50053.4375 - val_mse: 11746191360.0000 - val_mae: 50053.4375\n",
            "Epoch 7/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 43845.6219 - mse: 4391480729.6000 - mae: 43845.6227 - val_loss: 47420.4961 - val_mse: 10510420992.0000 - val_mae: 47420.4961\n",
            "Epoch 8/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 40614.6715 - mse: 3722286489.6000 - mae: 40614.6715 - val_loss: 45500.9023 - val_mse: 9150349312.0000 - val_mae: 45500.9023\n",
            "Epoch 9/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 41946.8375 - mse: 4542039500.8000 - mae: 41946.8367 - val_loss: 44441.0625 - val_mse: 7971979264.0000 - val_mae: 44441.0625\n",
            "Epoch 10/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 37923.8719 - mse: 3646806323.2000 - mae: 37923.8719 - val_loss: 42375.9453 - val_mse: 7682885120.0000 - val_mae: 42375.9453\n",
            "Epoch 11/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 39449.8523 - mse: 3488035635.2000 - mae: 39449.8527 - val_loss: 40260.3203 - val_mse: 6401832960.0000 - val_mae: 40260.3203\n",
            "Epoch 12/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 37029.6246 - mse: 3539816320.0000 - mae: 37029.6246 - val_loss: 39984.0508 - val_mse: 6422858752.0000 - val_mae: 39984.0508\n",
            "Epoch 13/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 36670.1660 - mse: 3210278041.6000 - mae: 36670.1664 - val_loss: 38217.5078 - val_mse: 5782818304.0000 - val_mae: 38217.5078\n",
            "Epoch 14/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 34519.0719 - mse: 2864921216.0000 - mae: 34519.0719 - val_loss: 40158.1914 - val_mse: 6174721024.0000 - val_mae: 40158.1914\n",
            "Epoch 15/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 35443.3309 - mse: 3589814553.6000 - mae: 35443.3309 - val_loss: 37555.2500 - val_mse: 4890998784.0000 - val_mae: 37555.2500\n",
            "Epoch 16/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 35714.5426 - mse: 3320647091.2000 - mae: 35714.5430 - val_loss: 35717.4375 - val_mse: 4814020608.0000 - val_mae: 35717.4375\n",
            "Epoch 17/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 32319.1535 - mse: 2928861478.4000 - mae: 32319.1531 - val_loss: 34965.3320 - val_mse: 4784049664.0000 - val_mae: 34965.3320\n",
            "Epoch 18/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 31473.0701 - mse: 2453310361.6000 - mae: 31473.0693 - val_loss: 37396.1406 - val_mse: 5254610432.0000 - val_mae: 37396.1406\n",
            "Epoch 19/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 31292.8701 - mse: 2342583500.8000 - mae: 31292.8701 - val_loss: 34236.2344 - val_mse: 4559717888.0000 - val_mae: 34236.2344\n",
            "Epoch 20/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 29962.4139 - mse: 2461150528.0000 - mae: 29962.4139 - val_loss: 34622.9648 - val_mse: 4231995392.0000 - val_mae: 34622.9570\n",
            "Epoch 21/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 30841.0105 - mse: 2311364953.6000 - mae: 30841.0105 - val_loss: 35143.3867 - val_mse: 4184360448.0000 - val_mae: 35143.3867\n",
            "Epoch 22/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 30273.3090 - mse: 2318826265.6000 - mae: 30273.3102 - val_loss: 34383.6562 - val_mse: 4164652032.0000 - val_mae: 34383.6562\n",
            "Epoch 23/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 30221.1385 - mse: 2748966105.6000 - mae: 30221.1385 - val_loss: 34726.6055 - val_mse: 4646500352.0000 - val_mae: 34726.6055\n",
            "Epoch 24/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 31083.3637 - mse: 3509832780.8000 - mae: 31083.3637 - val_loss: 32625.9707 - val_mse: 4037910016.0000 - val_mae: 32625.9707\n",
            "Epoch 25/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 28870.7203 - mse: 2343954636.8000 - mae: 28870.7203 - val_loss: 35980.5703 - val_mse: 4866111488.0000 - val_mae: 35980.5703\n",
            "Epoch 26/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 31488.1437 - mse: 2628001728.0000 - mae: 31488.1437 - val_loss: 34776.3789 - val_mse: 4796307456.0000 - val_mae: 34776.3828\n",
            "Epoch 27/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 29841.0301 - mse: 2505514432.0000 - mae: 29841.0301 - val_loss: 32916.2695 - val_mse: 3939165184.0000 - val_mae: 32916.2695\n",
            "Epoch 28/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 28753.4686 - mse: 1993392384.0000 - mae: 28753.4688 - val_loss: 33643.0781 - val_mse: 4514132992.0000 - val_mae: 33643.0781\n",
            "Epoch 29/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 29984.6172 - mse: 3377321318.4000 - mae: 29984.6172 - val_loss: 33300.6445 - val_mse: 4367754752.0000 - val_mae: 33300.6484\n",
            "Epoch 30/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 30126.0859 - mse: 2804256038.4000 - mae: 30126.0859 - val_loss: 32265.9902 - val_mse: 3762154752.0000 - val_mae: 32265.9902\n",
            "Epoch 31/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 28945.2881 - mse: 2994062489.6000 - mae: 28945.2881 - val_loss: 35168.3125 - val_mse: 3767267328.0000 - val_mae: 35168.3125\n",
            "Epoch 32/200\n",
            "9/9 [==============================] - 0s 33ms/step - loss: 29329.5604 - mse: 2993727820.8000 - mae: 29329.5604 - val_loss: 32106.8145 - val_mse: 4049917184.0000 - val_mae: 32106.8145\n",
            "Epoch 33/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 28538.4053 - mse: 2460463897.6000 - mae: 28538.4053 - val_loss: 31958.6934 - val_mse: 4013138432.0000 - val_mae: 31958.6973\n",
            "Epoch 34/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 29007.9221 - mse: 3258004249.6000 - mae: 29007.9221 - val_loss: 31920.1758 - val_mse: 3964738304.0000 - val_mae: 31920.1758\n",
            "Epoch 35/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 27448.6877 - mse: 2097448480.0000 - mae: 27448.6877 - val_loss: 36745.9219 - val_mse: 5020646912.0000 - val_mae: 36745.9219\n",
            "Epoch 36/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 29798.7568 - mse: 2039635891.2000 - mae: 29798.7533 - val_loss: 33883.8164 - val_mse: 4476343808.0000 - val_mae: 33883.8164\n",
            "Epoch 37/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 28278.9439 - mse: 2033553228.8000 - mae: 28278.9439 - val_loss: 32853.8984 - val_mse: 4308583424.0000 - val_mae: 32853.8984\n",
            "Epoch 38/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 29950.2287 - mse: 3708723942.4000 - mae: 29950.2287 - val_loss: 35586.5156 - val_mse: 4631462400.0000 - val_mae: 35586.5156\n",
            "Epoch 39/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 30028.1725 - mse: 2897392102.4000 - mae: 30028.1686 - val_loss: 31696.4082 - val_mse: 3623041024.0000 - val_mae: 31696.4082\n",
            "Epoch 40/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 26886.5551 - mse: 1937583334.4000 - mae: 26886.5551 - val_loss: 31726.6621 - val_mse: 3901787136.0000 - val_mae: 31726.6621\n",
            "Epoch 41/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 29479.1842 - mse: 3367299558.4000 - mae: 29479.1842 - val_loss: 33682.1680 - val_mse: 4341737472.0000 - val_mae: 33682.1680\n",
            "Epoch 42/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 28662.1375 - mse: 2801158259.2000 - mae: 28662.1396 - val_loss: 32664.8340 - val_mse: 3488431616.0000 - val_mae: 32664.8340\n",
            "Epoch 43/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 28431.2906 - mse: 2076561612.8000 - mae: 28431.2906 - val_loss: 31378.8457 - val_mse: 3669992448.0000 - val_mae: 31378.8457\n",
            "Epoch 44/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 28194.6422 - mse: 2062015398.4000 - mae: 28194.6434 - val_loss: 32368.5078 - val_mse: 3931288576.0000 - val_mae: 32368.5039\n",
            "Epoch 45/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 27044.9203 - mse: 2034102771.2000 - mae: 27044.9203 - val_loss: 31019.6582 - val_mse: 3488812032.0000 - val_mae: 31019.6582\n",
            "Epoch 46/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 28082.0623 - mse: 1803606246.4000 - mae: 28082.0623 - val_loss: 31058.2129 - val_mse: 3591501824.0000 - val_mae: 31058.2148\n",
            "Epoch 47/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 28178.5855 - mse: 2311600806.4000 - mae: 28178.5855 - val_loss: 35024.4805 - val_mse: 4288735488.0000 - val_mae: 35024.4805\n",
            "Epoch 48/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 28061.9654 - mse: 2479064742.4000 - mae: 28061.9654 - val_loss: 30815.1035 - val_mse: 3366082816.0000 - val_mae: 30815.1035\n",
            "Epoch 49/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 29306.0453 - mse: 3446615526.4000 - mae: 29306.0453 - val_loss: 32807.4492 - val_mse: 3907807488.0000 - val_mae: 32807.4492\n",
            "Epoch 50/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 26238.8434 - mse: 1747237139.2000 - mae: 26238.8434 - val_loss: 31691.7480 - val_mse: 3714141952.0000 - val_mae: 31691.7480\n",
            "Epoch 51/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 27176.3996 - mse: 2126368819.2000 - mae: 27176.3996 - val_loss: 31380.3535 - val_mse: 3617408512.0000 - val_mae: 31380.3535\n",
            "Epoch 52/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 27146.3768 - mse: 1970746163.2000 - mae: 27146.3768 - val_loss: 31536.1094 - val_mse: 3668416256.0000 - val_mae: 31536.1094\n",
            "Epoch 53/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 26841.0918 - mse: 2006419520.0000 - mae: 26841.0918 - val_loss: 30654.3555 - val_mse: 3259394304.0000 - val_mae: 30654.3555\n",
            "Epoch 54/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 28879.4719 - mse: 2279297216.0000 - mae: 28879.4719 - val_loss: 30779.8633 - val_mse: 3325008128.0000 - val_mae: 30779.8633\n",
            "Epoch 55/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 27067.4363 - mse: 2085613644.8000 - mae: 27067.4363 - val_loss: 31011.9414 - val_mse: 3487019264.0000 - val_mae: 31011.9414\n",
            "Epoch 56/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 27107.2855 - mse: 2019614656.0000 - mae: 27107.2855 - val_loss: 31449.6113 - val_mse: 3626991872.0000 - val_mae: 31449.6113\n",
            "Epoch 57/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 25567.5021 - mse: 2342213753.6000 - mae: 25567.5021 - val_loss: 30905.4238 - val_mse: 3147499008.0000 - val_mae: 30905.4238\n",
            "Epoch 58/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 30386.4473 - mse: 3384099840.0000 - mae: 30386.4473 - val_loss: 30784.2559 - val_mse: 3123446784.0000 - val_mae: 30784.2559\n",
            "Epoch 59/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 30456.5379 - mse: 3726702515.2000 - mae: 30456.5379 - val_loss: 30441.6602 - val_mse: 3188305664.0000 - val_mae: 30441.6602\n",
            "Epoch 60/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 26528.5057 - mse: 2363891673.6000 - mae: 26528.5057 - val_loss: 30505.7949 - val_mse: 3120183296.0000 - val_mae: 30505.7949\n",
            "Epoch 61/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 29427.2248 - mse: 3806359014.4000 - mae: 29427.2248 - val_loss: 30808.1973 - val_mse: 3377280768.0000 - val_mae: 30808.1973\n",
            "Epoch 62/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 26662.1746 - mse: 2565920153.6000 - mae: 26662.1746 - val_loss: 30424.6719 - val_mse: 2925846528.0000 - val_mae: 30424.6719\n",
            "Epoch 63/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 28945.1191 - mse: 2926486886.4000 - mae: 28945.1191 - val_loss: 31088.1641 - val_mse: 3353264384.0000 - val_mae: 31088.1641\n",
            "Epoch 64/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 27573.4195 - mse: 2519613414.4000 - mae: 27573.4195 - val_loss: 32746.8477 - val_mse: 3623060224.0000 - val_mae: 32746.8477\n",
            "Epoch 65/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 28147.0416 - mse: 2678651584.0000 - mae: 28147.0416 - val_loss: 30374.0508 - val_mse: 3185911808.0000 - val_mae: 30374.0508\n",
            "Epoch 66/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 28142.2898 - mse: 3452600396.8000 - mae: 28142.2898 - val_loss: 30356.1445 - val_mse: 3140787968.0000 - val_mae: 30356.1445\n",
            "Epoch 67/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 29079.9846 - mse: 3249823462.4000 - mae: 29079.9846 - val_loss: 30204.0176 - val_mse: 3036603648.0000 - val_mae: 30204.0176\n",
            "Epoch 68/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 25828.6002 - mse: 1741109171.2000 - mae: 25828.6002 - val_loss: 31744.1641 - val_mse: 3283687680.0000 - val_mae: 31744.1641\n",
            "Epoch 69/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 27490.2383 - mse: 2076720576.0000 - mae: 27490.2383 - val_loss: 30833.5098 - val_mse: 3134632704.0000 - val_mae: 30833.5098\n",
            "Epoch 70/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 26420.3459 - mse: 2139277824.0000 - mae: 26420.3459 - val_loss: 30020.3887 - val_mse: 2821329920.0000 - val_mae: 30020.3887\n",
            "Epoch 71/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 28770.6318 - mse: 2666314956.8000 - mae: 28770.6318 - val_loss: 29925.4863 - val_mse: 2830836480.0000 - val_mae: 29925.4863\n",
            "Epoch 72/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 26287.8338 - mse: 2331913638.4000 - mae: 26287.8338 - val_loss: 31398.6113 - val_mse: 3197077760.0000 - val_mae: 31398.6113\n",
            "Epoch 73/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 27841.2029 - mse: 2867992204.8000 - mae: 27841.2039 - val_loss: 29588.8359 - val_mse: 2878171648.0000 - val_mae: 29588.8359\n",
            "Epoch 74/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 26606.5133 - mse: 2891446438.4000 - mae: 26606.5133 - val_loss: 30288.2559 - val_mse: 2771726592.0000 - val_mae: 30288.2559\n",
            "Epoch 75/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 27322.6678 - mse: 2824726508.8000 - mae: 27322.6678 - val_loss: 29523.9102 - val_mse: 2839158784.0000 - val_mae: 29523.9102\n",
            "Epoch 76/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 26252.1391 - mse: 1733183833.6000 - mae: 26252.1391 - val_loss: 31867.6641 - val_mse: 3218165248.0000 - val_mae: 31867.6641\n",
            "Epoch 77/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 27219.0805 - mse: 2065809920.0000 - mae: 27219.0805 - val_loss: 29398.0898 - val_mse: 2791059968.0000 - val_mae: 29398.0898\n",
            "Epoch 78/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 26356.0236 - mse: 2101405606.4000 - mae: 26356.0236 - val_loss: 29308.5645 - val_mse: 2695410944.0000 - val_mae: 29308.5645\n",
            "Epoch 79/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 25573.3187 - mse: 2237379840.0000 - mae: 25573.3187 - val_loss: 31136.2207 - val_mse: 3088267776.0000 - val_mae: 31136.2207\n",
            "Epoch 80/200\n",
            "9/9 [==============================] - 0s 29ms/step - loss: 26972.5107 - mse: 1783865625.6000 - mae: 26972.5107 - val_loss: 29171.4648 - val_mse: 2686324480.0000 - val_mae: 29171.4648\n",
            "Epoch 81/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 27499.4473 - mse: 3232986240.0000 - mae: 27499.4473 - val_loss: 29616.4902 - val_mse: 2764205312.0000 - val_mae: 29616.4902\n",
            "Epoch 82/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 26804.7146 - mse: 1958926643.2000 - mae: 26804.7146 - val_loss: 29077.3516 - val_mse: 2634450176.0000 - val_mae: 29077.3516\n",
            "Epoch 83/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 26115.1424 - mse: 2666997491.2000 - mae: 26115.1424 - val_loss: 29014.8945 - val_mse: 2598836992.0000 - val_mae: 29014.8945\n",
            "Epoch 84/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 25285.1197 - mse: 1749024972.8000 - mae: 25285.1197 - val_loss: 29584.1348 - val_mse: 2547970816.0000 - val_mae: 29584.1348\n",
            "Epoch 85/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 26197.1947 - mse: 2293990310.4000 - mae: 26197.1947 - val_loss: 31336.0352 - val_mse: 2937753856.0000 - val_mae: 31336.0352\n",
            "Epoch 86/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 23870.7379 - mse: 1597345497.6000 - mae: 23870.7379 - val_loss: 29623.7070 - val_mse: 2574421760.0000 - val_mae: 29623.7070\n",
            "Epoch 87/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 26766.7854 - mse: 2635135385.6000 - mae: 26766.7854 - val_loss: 29383.0996 - val_mse: 2565808128.0000 - val_mae: 29383.0996\n",
            "Epoch 88/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 24963.8561 - mse: 1743235475.2000 - mae: 24963.8561 - val_loss: 29328.1699 - val_mse: 2610258688.0000 - val_mae: 29328.1699\n",
            "Epoch 89/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 25290.0697 - mse: 1762271334.4000 - mae: 25290.0697 - val_loss: 28578.8066 - val_mse: 2395789568.0000 - val_mae: 28578.8066\n",
            "Epoch 90/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 25885.2273 - mse: 1845009868.8000 - mae: 25885.2273 - val_loss: 34254.6719 - val_mse: 3144585216.0000 - val_mae: 34254.6719\n",
            "Epoch 91/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 27282.8145 - mse: 1900480153.6000 - mae: 27282.8141 - val_loss: 28984.1973 - val_mse: 2497679872.0000 - val_mae: 28984.1973\n",
            "Epoch 92/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 27102.5596 - mse: 2944224448.0000 - mae: 27102.5596 - val_loss: 29212.1328 - val_mse: 2501864960.0000 - val_mae: 29212.1328\n",
            "Epoch 93/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 27453.7412 - mse: 2199113420.8000 - mae: 27453.7412 - val_loss: 31658.5723 - val_mse: 2813568512.0000 - val_mae: 31658.5723\n",
            "Epoch 94/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 26706.0059 - mse: 2585590752.0000 - mae: 26706.0035 - val_loss: 29459.4219 - val_mse: 2518710784.0000 - val_mae: 29459.4219\n",
            "Epoch 95/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 24993.5459 - mse: 1992693376.0000 - mae: 24993.5459 - val_loss: 30478.4785 - val_mse: 2631053568.0000 - val_mae: 30478.4785\n",
            "Epoch 96/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 27613.5189 - mse: 2295970880.0000 - mae: 27613.5189 - val_loss: 28600.9590 - val_mse: 2360322304.0000 - val_mae: 28600.9590\n",
            "Epoch 97/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 26633.6982 - mse: 3107418240.0000 - mae: 26633.6982 - val_loss: 28675.7734 - val_mse: 2331328512.0000 - val_mae: 28675.7734\n",
            "Epoch 98/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 25442.0428 - mse: 1836657612.8000 - mae: 25442.0428 - val_loss: 30747.4180 - val_mse: 2677716480.0000 - val_mae: 30747.4180\n",
            "Epoch 99/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 28103.4096 - mse: 3893424614.4000 - mae: 28103.4096 - val_loss: 31844.0527 - val_mse: 2820327680.0000 - val_mae: 31844.0527\n",
            "Epoch 100/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 27195.2768 - mse: 2820484454.4000 - mae: 27195.2768 - val_loss: 29428.2441 - val_mse: 2367782400.0000 - val_mae: 29428.2441\n",
            "Epoch 101/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 25711.5316 - mse: 2000075289.6000 - mae: 25711.5316 - val_loss: 29234.8418 - val_mse: 2488322560.0000 - val_mae: 29234.8418\n",
            "Epoch 102/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 25120.3900 - mse: 1650583308.8000 - mae: 25120.3900 - val_loss: 28546.4082 - val_mse: 2329203200.0000 - val_mae: 28546.4082\n",
            "Epoch 103/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 27955.6086 - mse: 2990893145.6000 - mae: 27955.6086 - val_loss: 28677.9473 - val_mse: 2409795840.0000 - val_mae: 28677.9473\n",
            "Epoch 104/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 25720.8318 - mse: 2409777216.0000 - mae: 25720.8318 - val_loss: 28898.7969 - val_mse: 2238768896.0000 - val_mae: 28898.7969\n",
            "Epoch 105/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 25795.6656 - mse: 1707804582.4000 - mae: 25795.6656 - val_loss: 28222.6074 - val_mse: 2243356160.0000 - val_mae: 28222.6074\n",
            "Epoch 106/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 24260.4285 - mse: 1728335884.8000 - mae: 24260.4285 - val_loss: 31580.8555 - val_mse: 2376439296.0000 - val_mae: 31580.8555\n",
            "Epoch 107/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 29030.4393 - mse: 3237449420.8000 - mae: 29030.4393 - val_loss: 28447.0449 - val_mse: 2232127232.0000 - val_mae: 28447.0449\n",
            "Epoch 108/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 25694.8586 - mse: 1752238835.2000 - mae: 25694.8586 - val_loss: 28181.2051 - val_mse: 2303796224.0000 - val_mae: 28181.2051\n",
            "Epoch 109/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 26497.3258 - mse: 2563366374.4000 - mae: 26497.3258 - val_loss: 28162.5977 - val_mse: 2282638080.0000 - val_mae: 28162.5977\n",
            "Epoch 110/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 24953.9428 - mse: 2003594099.2000 - mae: 24953.9428 - val_loss: 28142.7598 - val_mse: 2287879168.0000 - val_mae: 28142.7598\n",
            "Epoch 111/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 24896.1895 - mse: 2040043200.0000 - mae: 24896.1895 - val_loss: 29091.7754 - val_mse: 2406129152.0000 - val_mae: 29091.7754\n",
            "Epoch 112/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 25118.8068 - mse: 1879243571.2000 - mae: 25118.8068 - val_loss: 28450.2520 - val_mse: 2317804288.0000 - val_mae: 28450.2520\n",
            "Epoch 113/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 27057.0160 - mse: 3737542272.0000 - mae: 27057.0160 - val_loss: 27989.6328 - val_mse: 2262400000.0000 - val_mae: 27989.6328\n",
            "Epoch 114/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 24931.3211 - mse: 1878159526.4000 - mae: 24931.3219 - val_loss: 29352.0898 - val_mse: 2481700608.0000 - val_mae: 29352.0898\n",
            "Epoch 115/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 26926.0158 - mse: 2989735091.2000 - mae: 26926.0158 - val_loss: 27855.6406 - val_mse: 2230523648.0000 - val_mae: 27855.6406\n",
            "Epoch 116/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 24996.5998 - mse: 2046766976.0000 - mae: 24996.5998 - val_loss: 27875.4336 - val_mse: 2210387712.0000 - val_mae: 27875.4336\n",
            "Epoch 117/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 25026.4484 - mse: 2047507750.4000 - mae: 25026.4484 - val_loss: 30638.9590 - val_mse: 2565475584.0000 - val_mae: 30638.9590\n",
            "Epoch 118/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 25715.5330 - mse: 1824497932.8000 - mae: 25715.5330 - val_loss: 28420.9453 - val_mse: 2178217728.0000 - val_mae: 28420.9453\n",
            "Epoch 119/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 25203.6270 - mse: 2058267878.4000 - mae: 25203.6270 - val_loss: 28546.3867 - val_mse: 2140720512.0000 - val_mae: 28546.3867\n",
            "Epoch 120/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 27834.8664 - mse: 3729565619.2000 - mae: 27834.8672 - val_loss: 27713.7891 - val_mse: 2106517504.0000 - val_mae: 27713.7891\n",
            "Epoch 121/200\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 24915.2383 - mse: 2282303385.6000 - mae: 24915.2383 - val_loss: 28314.5254 - val_mse: 2266259968.0000 - val_mae: 28314.5254\n",
            "Epoch 122/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 26668.9742 - mse: 1992006246.4000 - mae: 26668.9742 - val_loss: 27690.6113 - val_mse: 2170856704.0000 - val_mae: 27690.6113\n",
            "Epoch 123/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 27436.0729 - mse: 4038150784.0000 - mae: 27436.0727 - val_loss: 27866.1621 - val_mse: 2238605312.0000 - val_mae: 27866.1621\n",
            "Epoch 124/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 23755.5350 - mse: 1841411552.0000 - mae: 23755.5350 - val_loss: 28044.5293 - val_mse: 2195035136.0000 - val_mae: 28044.5293\n",
            "Epoch 125/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 26440.9955 - mse: 2911582681.6000 - mae: 26440.9955 - val_loss: 27836.3633 - val_mse: 2206098944.0000 - val_mae: 27836.3633\n",
            "Epoch 126/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 26558.1699 - mse: 2340717836.8000 - mae: 26558.1699 - val_loss: 28835.2930 - val_mse: 2387954432.0000 - val_mae: 28835.2930\n",
            "Epoch 127/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 24465.8355 - mse: 1681947968.0000 - mae: 24465.8361 - val_loss: 28114.6074 - val_mse: 2183510016.0000 - val_mae: 28114.6074\n",
            "Epoch 128/200\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 26112.9225 - mse: 2216771507.2000 - mae: 26112.9225 - val_loss: 27658.5156 - val_mse: 2144799360.0000 - val_mae: 27658.5156\n",
            "Epoch 129/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 24594.1787 - mse: 1657398227.2000 - mae: 24594.1787 - val_loss: 28505.8457 - val_mse: 2251218688.0000 - val_mae: 28505.8457\n",
            "Epoch 130/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 28115.1949 - mse: 3927071769.6000 - mae: 28115.1949 - val_loss: 31720.4551 - val_mse: 2702168576.0000 - val_mae: 31720.4551\n",
            "Epoch 131/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 27052.0246 - mse: 2165709260.8000 - mae: 27052.0246 - val_loss: 29283.4297 - val_mse: 2403348736.0000 - val_mae: 29283.4297\n",
            "Epoch 132/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 26169.4146 - mse: 2158139468.8000 - mae: 26169.4146 - val_loss: 28080.0508 - val_mse: 2260543744.0000 - val_mae: 28080.0508\n",
            "Epoch 133/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 26445.4541 - mse: 3709566720.0000 - mae: 26445.4541 - val_loss: 28604.9414 - val_mse: 2283952128.0000 - val_mae: 28604.9414\n",
            "Epoch 134/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 26000.3531 - mse: 2673691340.8000 - mae: 26000.3531 - val_loss: 27949.0625 - val_mse: 2106620544.0000 - val_mae: 27949.0625\n",
            "Epoch 135/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 26584.1889 - mse: 3378260147.2000 - mae: 26584.1889 - val_loss: 27388.7461 - val_mse: 2066424576.0000 - val_mae: 27388.7461\n",
            "Epoch 136/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 26116.5666 - mse: 1965141632.0000 - mae: 26116.5666 - val_loss: 27333.5078 - val_mse: 2068978688.0000 - val_mae: 27333.5078\n",
            "Epoch 137/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 24394.1992 - mse: 2951367481.6000 - mae: 24394.1992 - val_loss: 28368.8691 - val_mse: 2058700032.0000 - val_mae: 28368.8691\n",
            "Epoch 138/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 25762.9789 - mse: 2538470515.2000 - mae: 25762.9789 - val_loss: 27561.9199 - val_mse: 1986409344.0000 - val_mae: 27561.9199\n",
            "Epoch 139/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 25863.5383 - mse: 1848356851.2000 - mae: 25863.5383 - val_loss: 27444.1211 - val_mse: 2046259200.0000 - val_mae: 27444.1211\n",
            "Epoch 140/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 24834.9672 - mse: 1733061286.4000 - mae: 24834.9672 - val_loss: 27418.2715 - val_mse: 2021142272.0000 - val_mae: 27418.2715\n",
            "Epoch 141/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 25450.8609 - mse: 2118832640.0000 - mae: 25450.8609 - val_loss: 27495.1484 - val_mse: 2110549888.0000 - val_mae: 27495.1484\n",
            "Epoch 142/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 24902.6568 - mse: 2508033292.8000 - mae: 24902.6568 - val_loss: 27233.8672 - val_mse: 1995525888.0000 - val_mae: 27233.8672\n",
            "Epoch 143/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 25211.4439 - mse: 2081545068.8000 - mae: 25211.4439 - val_loss: 29251.0625 - val_mse: 2092824192.0000 - val_mae: 29251.0625\n",
            "Epoch 144/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 26639.7006 - mse: 2462265548.8000 - mae: 26639.7006 - val_loss: 27440.7891 - val_mse: 2007172608.0000 - val_mae: 27440.7891\n",
            "Epoch 145/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 23044.0164 - mse: 1625736844.8000 - mae: 23044.0164 - val_loss: 27207.7715 - val_mse: 2040734080.0000 - val_mae: 27207.7715\n",
            "Epoch 146/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 24971.4951 - mse: 2264033100.8000 - mae: 24971.4951 - val_loss: 27416.2539 - val_mse: 1994890496.0000 - val_mae: 27416.2539\n",
            "Epoch 147/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 26083.4918 - mse: 2290306035.2000 - mae: 26083.4918 - val_loss: 28099.6914 - val_mse: 2136778240.0000 - val_mae: 28099.6914\n",
            "Epoch 148/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 26016.0863 - mse: 2444690611.2000 - mae: 26016.0863 - val_loss: 26996.9844 - val_mse: 1926938880.0000 - val_mae: 26996.9844\n",
            "Epoch 149/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 24737.5279 - mse: 1839192422.4000 - mae: 24737.5279 - val_loss: 27605.4570 - val_mse: 1936484992.0000 - val_mae: 27605.4570\n",
            "Epoch 150/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 25043.6051 - mse: 1880417651.2000 - mae: 25043.6051 - val_loss: 27330.9316 - val_mse: 1938783488.0000 - val_mae: 27330.9316\n",
            "Epoch 151/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 26054.5312 - mse: 2176272883.2000 - mae: 26054.5312 - val_loss: 27215.2793 - val_mse: 1917983616.0000 - val_mae: 27215.2793\n",
            "Epoch 152/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 25107.9600 - mse: 2514904230.4000 - mae: 25107.9600 - val_loss: 26918.3086 - val_mse: 1994104832.0000 - val_mae: 26918.3086\n",
            "Epoch 153/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 23324.6498 - mse: 2310058905.6000 - mae: 23324.6498 - val_loss: 27254.8496 - val_mse: 2020886400.0000 - val_mae: 27254.8496\n",
            "Epoch 154/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 23040.6982 - mse: 1621360313.6000 - mae: 23040.6982 - val_loss: 26757.6660 - val_mse: 1921878272.0000 - val_mae: 26757.6660\n",
            "Epoch 155/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 27564.5789 - mse: 3997172787.2000 - mae: 27564.5791 - val_loss: 27034.3633 - val_mse: 1941890688.0000 - val_mae: 27034.3633\n",
            "Epoch 156/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 26182.4086 - mse: 2905533068.8000 - mae: 26182.4086 - val_loss: 29132.8906 - val_mse: 2263153664.0000 - val_mae: 29132.8906\n",
            "Epoch 157/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 29299.0789 - mse: 4203004083.2000 - mae: 29299.0789 - val_loss: 28374.9434 - val_mse: 2245107456.0000 - val_mae: 28374.9434\n",
            "Epoch 158/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 23469.5701 - mse: 1961458457.6000 - mae: 23469.5701 - val_loss: 26884.7402 - val_mse: 1970127616.0000 - val_mae: 26884.7402\n",
            "Epoch 159/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 27075.1154 - mse: 3896090777.6000 - mae: 27075.1154 - val_loss: 27337.0020 - val_mse: 1894201472.0000 - val_mae: 27337.0020\n",
            "Epoch 160/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 26381.9469 - mse: 3414150912.0000 - mae: 26381.9469 - val_loss: 27470.8555 - val_mse: 1907911296.0000 - val_mae: 27470.8555\n",
            "Epoch 161/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 27692.4484 - mse: 2685800448.0000 - mae: 27692.4484 - val_loss: 29129.6055 - val_mse: 2192858624.0000 - val_mae: 29129.6055\n",
            "Epoch 162/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 24129.1971 - mse: 1524191660.8000 - mae: 24129.1971 - val_loss: 27401.0781 - val_mse: 1946804352.0000 - val_mae: 27401.0781\n",
            "Epoch 163/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 24444.7158 - mse: 1885319001.6000 - mae: 24444.7158 - val_loss: 27922.9863 - val_mse: 2091625472.0000 - val_mae: 27922.9863\n",
            "Epoch 164/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 27519.1793 - mse: 4476246784.0000 - mae: 27519.1793 - val_loss: 29257.5371 - val_mse: 2295205632.0000 - val_mae: 29257.5371\n",
            "Epoch 165/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 25409.9199 - mse: 2341531539.2000 - mae: 25409.9199 - val_loss: 26709.4141 - val_mse: 1988668928.0000 - val_mae: 26709.4141\n",
            "Epoch 166/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 23615.2814 - mse: 1951203628.8000 - mae: 23615.2812 - val_loss: 27483.6738 - val_mse: 2052021376.0000 - val_mae: 27483.6738\n",
            "Epoch 167/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 24739.0680 - mse: 1697120211.2000 - mae: 24739.0680 - val_loss: 26767.2812 - val_mse: 1956602880.0000 - val_mae: 26767.2812\n",
            "Epoch 168/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 27585.7896 - mse: 4255971788.8000 - mae: 27585.7898 - val_loss: 26690.0000 - val_mse: 1952368896.0000 - val_mae: 26690.0000\n",
            "Epoch 169/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 24682.8516 - mse: 2473412364.8000 - mae: 24682.8516 - val_loss: 27649.3457 - val_mse: 2090161792.0000 - val_mae: 27649.3457\n",
            "Epoch 170/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 25038.5785 - mse: 2174407283.2000 - mae: 25038.5785 - val_loss: 30737.2891 - val_mse: 2460938240.0000 - val_mae: 30737.2891\n",
            "Epoch 171/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 24818.8520 - mse: 1662783833.6000 - mae: 24818.8520 - val_loss: 27673.3203 - val_mse: 1964629120.0000 - val_mae: 27673.3203\n",
            "Epoch 172/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 24486.7910 - mse: 2472567078.4000 - mae: 24486.7910 - val_loss: 27705.5703 - val_mse: 2072751488.0000 - val_mae: 27705.5703\n",
            "Epoch 173/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 25846.1713 - mse: 2734651763.2000 - mae: 25846.1713 - val_loss: 26595.0137 - val_mse: 1946923776.0000 - val_mae: 26595.0137\n",
            "Epoch 174/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 25072.0312 - mse: 2925195200.0000 - mae: 25072.0312 - val_loss: 26810.3809 - val_mse: 1980792064.0000 - val_mae: 26810.3809\n",
            "Epoch 175/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 23761.7029 - mse: 2453063961.6000 - mae: 23761.7029 - val_loss: 27357.7285 - val_mse: 2146784256.0000 - val_mae: 27357.7285\n",
            "Epoch 176/200\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 24723.6484 - mse: 1962989107.2000 - mae: 24723.6484 - val_loss: 28901.0820 - val_mse: 2024242304.0000 - val_mae: 28901.0820\n",
            "Epoch 177/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 25613.5793 - mse: 2514664256.0000 - mae: 25613.5793 - val_loss: 27579.2188 - val_mse: 1912876288.0000 - val_mae: 27579.2188\n",
            "Epoch 178/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 25440.4773 - mse: 2581232345.6000 - mae: 25440.4773 - val_loss: 26702.3008 - val_mse: 1942757248.0000 - val_mae: 26702.3008\n",
            "Epoch 179/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 23401.2447 - mse: 1642609593.6000 - mae: 23401.2447 - val_loss: 28016.3281 - val_mse: 2096366336.0000 - val_mae: 28016.3281\n",
            "Epoch 180/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 24967.3100 - mse: 2001240460.8000 - mae: 24967.3100 - val_loss: 26407.8516 - val_mse: 1902202624.0000 - val_mae: 26407.8516\n",
            "Epoch 181/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 25683.9643 - mse: 2987562931.2000 - mae: 25683.9643 - val_loss: 26694.1406 - val_mse: 1867690112.0000 - val_mae: 26694.1406\n",
            "Epoch 182/200\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 27369.6830 - mse: 3319840281.6000 - mae: 27369.6830 - val_loss: 26446.9570 - val_mse: 1893036672.0000 - val_mae: 26446.9570\n",
            "Epoch 183/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 23508.1582 - mse: 1620554201.6000 - mae: 23508.1582 - val_loss: 26883.9824 - val_mse: 1897678336.0000 - val_mae: 26883.9824\n",
            "Epoch 184/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 23950.1750 - mse: 1830189196.8000 - mae: 23950.1750 - val_loss: 26631.9883 - val_mse: 1941437312.0000 - val_mae: 26631.9883\n",
            "Epoch 185/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 23559.4469 - mse: 2142189433.6000 - mae: 23559.4469 - val_loss: 28415.0586 - val_mse: 2302329600.0000 - val_mae: 28415.0586\n",
            "Epoch 186/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 23002.2291 - mse: 1520017747.2000 - mae: 23002.2291 - val_loss: 26624.6621 - val_mse: 1994106496.0000 - val_mae: 26624.6621\n",
            "Epoch 187/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 24970.5049 - mse: 3599168537.6000 - mae: 24970.5049 - val_loss: 29155.2969 - val_mse: 2250683136.0000 - val_mae: 29155.2969\n",
            "Epoch 188/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 25290.8408 - mse: 1894419449.6000 - mae: 25290.8408 - val_loss: 26602.7656 - val_mse: 1951435392.0000 - val_mae: 26602.7656\n",
            "Epoch 189/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 24875.6721 - mse: 2885867020.8000 - mae: 24875.6721 - val_loss: 28035.9414 - val_mse: 2093249664.0000 - val_mae: 28035.9414\n",
            "Epoch 190/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 22762.5750 - mse: 1639517638.4000 - mae: 22762.5750 - val_loss: 26107.7012 - val_mse: 1841864320.0000 - val_mae: 26107.7012\n",
            "Epoch 191/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 24178.5844 - mse: 1868963769.6000 - mae: 24178.5844 - val_loss: 26349.6445 - val_mse: 1840456192.0000 - val_mae: 26349.6445\n",
            "Epoch 192/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 24819.1809 - mse: 2292703872.0000 - mae: 24819.1809 - val_loss: 26072.8770 - val_mse: 1791733888.0000 - val_mae: 26072.8770\n",
            "Epoch 193/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 24859.9373 - mse: 3035023180.8000 - mae: 24859.9369 - val_loss: 26398.7402 - val_mse: 1869481984.0000 - val_mae: 26398.7402\n",
            "Epoch 194/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 23914.3438 - mse: 1988306009.6000 - mae: 23914.3438 - val_loss: 26902.1992 - val_mse: 2007259776.0000 - val_mae: 26902.1992\n",
            "Epoch 195/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 25404.0236 - mse: 3040523033.6000 - mae: 25404.0236 - val_loss: 26188.1113 - val_mse: 1832020608.0000 - val_mae: 26188.1113\n",
            "Epoch 196/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 26166.5564 - mse: 3125198208.0000 - mae: 26166.5553 - val_loss: 26751.9629 - val_mse: 1839559808.0000 - val_mae: 26751.9629\n",
            "Epoch 197/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 24407.2645 - mse: 3385807974.4000 - mae: 24407.2645 - val_loss: 27864.1797 - val_mse: 2144792832.0000 - val_mae: 27864.1797\n",
            "Epoch 198/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 24473.8063 - mse: 2079398140.8000 - mae: 24473.8063 - val_loss: 26295.8633 - val_mse: 1918077824.0000 - val_mae: 26295.8633\n",
            "Epoch 199/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 25183.6643 - mse: 2925970828.8000 - mae: 25183.6643 - val_loss: 27444.3379 - val_mse: 2072515584.0000 - val_mae: 27444.3379\n",
            "Epoch 200/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 24433.1045 - mse: 1684588556.8000 - mae: 24433.1045 - val_loss: 26870.8730 - val_mse: 1991953408.0000 - val_mae: 26870.8730\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUtnWyC60ls5"
      },
      "source": [
        "Finally, try your model using mean squared logarithmic error. Compare the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyTsb-4a0ls5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe27249d-9b19-4882-9359-053bdedcf405"
      },
      "source": [
        "# Answer below:\n",
        "model2 = Sequential()\n",
        "model2.add(Dense(512, input_dim=X_train.shape[1], activation='relu'))\n",
        "model2.add(Dense(256, activation='relu'))\n",
        "model2.add(Dense(16, activation='relu'))\n",
        "model2.add(Dense(4, activation='relu'))\n",
        "model2.add(Dense(1, activation='linear'))\n",
        "model2.compile(optimizer='RMSprop', loss='mean_squared_logarithmic_error', metrics=['mse','mae'])\n",
        "his_msle = model2.fit(X_train, y_train, batch_size=100, epochs=200, validation_data=(X_test, y_test))\n",
        "df_msle = pd.DataFrame(his_msle.history)\n",
        "avg_msle_mae = df_msle.val_mae.mean()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "9/9 [==============================] - 1s 44ms/step - loss: 26.9415 - mse: 41091291545.6000 - mae: 184913.1641 - val_loss: 11.0740 - val_mse: 38982860800.0000 - val_mae: 180660.7188\n",
            "Epoch 2/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 9.7831 - mse: 36731074764.8000 - mae: 174798.7422 - val_loss: 6.9191 - val_mse: 36372893696.0000 - val_mae: 173745.0156\n",
            "Epoch 3/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 6.1398 - mse: 35440216678.4000 - mae: 169605.2250 - val_loss: 4.4191 - val_mse: 33012903936.0000 - val_mae: 164197.8281\n",
            "Epoch 4/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 3.9262 - mse: 31592122368.0000 - mae: 158844.5516 - val_loss: 2.7514 - val_mse: 28830345216.0000 - val_mae: 151731.2656\n",
            "Epoch 5/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 2.4204 - mse: 28572188876.8000 - mae: 148405.8766 - val_loss: 1.6217 - val_mse: 23987865600.0000 - val_mae: 135848.1719\n",
            "Epoch 6/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1.4361 - mse: 22169222553.6000 - mae: 130317.0242 - val_loss: 0.9163 - val_mse: 19291117568.0000 - val_mae: 116758.5781\n",
            "Epoch 7/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.7950 - mse: 17347941990.4000 - mae: 109572.6938 - val_loss: 0.4841 - val_mse: 15340062720.0000 - val_mae: 95371.0938\n",
            "Epoch 8/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.4076 - mse: 12043869081.6000 - mae: 86147.1109 - val_loss: 0.2484 - val_mse: 12939323392.0000 - val_mae: 74285.1094\n",
            "Epoch 9/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.2133 - mse: 8963753062.4000 - mae: 66837.8305 - val_loss: 0.1443 - val_mse: 12344528896.0000 - val_mae: 59146.0352\n",
            "Epoch 10/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.1210 - mse: 5698646886.4000 - mae: 49894.3617 - val_loss: 0.1069 - val_mse: 12921805824.0000 - val_mae: 52939.2461\n",
            "Epoch 11/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.1069 - mse: 5596145459.2000 - mae: 48020.2613 - val_loss: 0.1001 - val_mse: 13409762304.0000 - val_mae: 52254.6953\n",
            "Epoch 12/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0958 - mse: 5006069504.0000 - mae: 45628.6000 - val_loss: 0.0978 - val_mse: 12794042368.0000 - val_mae: 51569.9961\n",
            "Epoch 13/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0987 - mse: 5050093465.6000 - mae: 47411.1789 - val_loss: 0.0950 - val_mse: 11845609472.0000 - val_mae: 50621.8086\n",
            "Epoch 14/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.1013 - mse: 5470388275.2000 - mae: 46826.9125 - val_loss: 0.0920 - val_mse: 11453328384.0000 - val_mae: 49827.6016\n",
            "Epoch 15/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0906 - mse: 4365657190.4000 - mae: 43406.0383 - val_loss: 0.0883 - val_mse: 10351583232.0000 - val_mae: 48559.9570\n",
            "Epoch 16/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0857 - mse: 3971777587.2000 - mae: 42540.4770 - val_loss: 0.0822 - val_mse: 8384422912.0000 - val_mae: 46251.8203\n",
            "Epoch 17/200\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0782 - mse: 4285498547.2000 - mae: 41557.5254 - val_loss: 0.0762 - val_mse: 7337570304.0000 - val_mae: 44333.9531\n",
            "Epoch 18/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0751 - mse: 4347363532.8000 - mae: 41561.6207 - val_loss: 0.0716 - val_mse: 6363833856.0000 - val_mae: 42602.5859\n",
            "Epoch 19/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.0681 - mse: 3802238259.2000 - mae: 39882.4055 - val_loss: 0.0687 - val_mse: 5772927488.0000 - val_mae: 41337.4609\n",
            "Epoch 20/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0723 - mse: 3955465600.0000 - mae: 39694.4590 - val_loss: 0.0667 - val_mse: 5096445440.0000 - val_mae: 41019.1367\n",
            "Epoch 21/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0660 - mse: 3149706675.2000 - mae: 36540.0523 - val_loss: 0.0633 - val_mse: 4681905152.0000 - val_mae: 39847.7344\n",
            "Epoch 22/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0584 - mse: 3523436620.8000 - mae: 36341.4367 - val_loss: 0.0583 - val_mse: 4284864256.0000 - val_mae: 37751.1836\n",
            "Epoch 23/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0601 - mse: 3075921433.6000 - mae: 35574.2848 - val_loss: 0.0576 - val_mse: 4131315456.0000 - val_mae: 36768.3672\n",
            "Epoch 24/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.0568 - mse: 2779058252.8000 - mae: 34156.5729 - val_loss: 0.0556 - val_mse: 3894528256.0000 - val_mae: 37172.3359\n",
            "Epoch 25/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0541 - mse: 2959013683.2000 - mae: 34380.7873 - val_loss: 0.0559 - val_mse: 3801155328.0000 - val_mae: 35714.5234\n",
            "Epoch 26/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0495 - mse: 2643768716.8000 - mae: 32451.0686 - val_loss: 0.0514 - val_mse: 3561213440.0000 - val_mae: 35052.2500\n",
            "Epoch 27/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0539 - mse: 3238736460.8000 - mae: 34088.7789 - val_loss: 0.0537 - val_mse: 3614110976.0000 - val_mae: 34649.9414\n",
            "Epoch 28/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0489 - mse: 2741089664.0000 - mae: 31714.5463 - val_loss: 0.0528 - val_mse: 3471075840.0000 - val_mae: 36479.2734\n",
            "Epoch 29/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0519 - mse: 2899735040.0000 - mae: 31853.2467 - val_loss: 0.0484 - val_mse: 3226349824.0000 - val_mae: 33525.8594\n",
            "Epoch 30/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0529 - mse: 2688006912.0000 - mae: 32250.9621 - val_loss: 0.0484 - val_mse: 3193063168.0000 - val_mae: 33876.8438\n",
            "Epoch 31/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0469 - mse: 2309605094.4000 - mae: 30434.9459 - val_loss: 0.0495 - val_mse: 3265773568.0000 - val_mae: 32883.1602\n",
            "Epoch 32/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0484 - mse: 2685861312.0000 - mae: 30516.2086 - val_loss: 0.0473 - val_mse: 3116069632.0000 - val_mae: 33204.6523\n",
            "Epoch 33/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0408 - mse: 1953106380.8000 - mae: 28339.6914 - val_loss: 0.0503 - val_mse: 3230745600.0000 - val_mae: 32789.8359\n",
            "Epoch 34/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0471 - mse: 2379265881.6000 - mae: 31572.7148 - val_loss: 0.0503 - val_mse: 3198878720.0000 - val_mae: 32732.1074\n",
            "Epoch 35/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0432 - mse: 2068143206.4000 - mae: 28810.3582 - val_loss: 0.0564 - val_mse: 3553341696.0000 - val_mae: 34684.0078\n",
            "Epoch 36/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0439 - mse: 2001867315.2000 - mae: 29254.2426 - val_loss: 0.0463 - val_mse: 2870679040.0000 - val_mae: 32497.3008\n",
            "Epoch 37/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0477 - mse: 3285888972.8000 - mae: 31082.7516 - val_loss: 0.0522 - val_mse: 3264301568.0000 - val_mae: 33266.1484\n",
            "Epoch 38/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0470 - mse: 2429197004.8000 - mae: 29446.7994 - val_loss: 0.0510 - val_mse: 3161809408.0000 - val_mae: 32781.7656\n",
            "Epoch 39/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0458 - mse: 2644184844.8000 - mae: 30186.4461 - val_loss: 0.0507 - val_mse: 3143896832.0000 - val_mae: 32652.8633\n",
            "Epoch 40/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0385 - mse: 2107146643.2000 - mae: 27664.1963 - val_loss: 0.0459 - val_mse: 2786049280.0000 - val_mae: 32106.8965\n",
            "Epoch 41/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0381 - mse: 1928296985.6000 - mae: 28382.5049 - val_loss: 0.0470 - val_mse: 2740171264.0000 - val_mae: 32825.9922\n",
            "Epoch 42/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0426 - mse: 2203787840.0000 - mae: 29488.4998 - val_loss: 0.0534 - val_mse: 2915860992.0000 - val_mae: 35834.3047\n",
            "Epoch 43/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0414 - mse: 1778299161.6000 - mae: 28777.5750 - val_loss: 0.0481 - val_mse: 2910767360.0000 - val_mae: 31796.8906\n",
            "Epoch 44/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0397 - mse: 1776051648.0000 - mae: 27157.0625 - val_loss: 0.0505 - val_mse: 2794702336.0000 - val_mae: 34583.7891\n",
            "Epoch 45/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0479 - mse: 2858684876.8000 - mae: 30641.2652 - val_loss: 0.0454 - val_mse: 2719455744.0000 - val_mae: 31099.4688\n",
            "Epoch 46/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0371 - mse: 2013969164.8000 - mae: 27511.0371 - val_loss: 0.0450 - val_mse: 2647386624.0000 - val_mae: 31087.5215\n",
            "Epoch 47/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.0509 - mse: 3445960499.2000 - mae: 31054.7391 - val_loss: 0.0447 - val_mse: 2631620352.0000 - val_mae: 31059.2383\n",
            "Epoch 48/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.0439 - mse: 2733277900.8000 - mae: 29272.8502 - val_loss: 0.0452 - val_mse: 2624982528.0000 - val_mae: 31809.4102\n",
            "Epoch 49/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0402 - mse: 1970981401.6000 - mae: 28035.2826 - val_loss: 0.0456 - val_mse: 2535233024.0000 - val_mae: 31988.9238\n",
            "Epoch 50/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0462 - mse: 2703968332.8000 - mae: 30464.7820 - val_loss: 0.0444 - val_mse: 2529901568.0000 - val_mae: 30812.6582\n",
            "Epoch 51/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0421 - mse: 2404861606.4000 - mae: 28473.6729 - val_loss: 0.0457 - val_mse: 2598399488.0000 - val_mae: 30847.2422\n",
            "Epoch 52/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0513 - mse: 3809793177.6000 - mae: 31971.4092 - val_loss: 0.0442 - val_mse: 2558587648.0000 - val_mae: 30974.9102\n",
            "Epoch 53/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0417 - mse: 2259621376.0000 - mae: 27767.5469 - val_loss: 0.0524 - val_mse: 2966247168.0000 - val_mae: 33220.9062\n",
            "Epoch 54/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0480 - mse: 2378900697.6000 - mae: 29866.4717 - val_loss: 0.0454 - val_mse: 2612522496.0000 - val_mae: 30721.0762\n",
            "Epoch 55/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0404 - mse: 1942574796.8000 - mae: 27947.7371 - val_loss: 0.0485 - val_mse: 2636279040.0000 - val_mae: 33598.3008\n",
            "Epoch 56/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0417 - mse: 2764727347.2000 - mae: 29939.4297 - val_loss: 0.0467 - val_mse: 2642607104.0000 - val_mae: 31064.9629\n",
            "Epoch 57/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0418 - mse: 2199542233.6000 - mae: 28074.6662 - val_loss: 0.0453 - val_mse: 2478873088.0000 - val_mae: 31821.6582\n",
            "Epoch 58/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0466 - mse: 2803701542.4000 - mae: 29854.2268 - val_loss: 0.0480 - val_mse: 2658170624.0000 - val_mae: 31480.3242\n",
            "Epoch 59/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0418 - mse: 2020862924.8000 - mae: 27803.9650 - val_loss: 0.0461 - val_mse: 2559176192.0000 - val_mae: 30809.0371\n",
            "Epoch 60/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0397 - mse: 1907348249.6000 - mae: 27640.4988 - val_loss: 0.0447 - val_mse: 2450503680.0000 - val_mae: 30404.1230\n",
            "Epoch 61/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0418 - mse: 2469023788.8000 - mae: 27683.0426 - val_loss: 0.0480 - val_mse: 2621540608.0000 - val_mae: 31443.6641\n",
            "Epoch 62/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0384 - mse: 1869836224.0000 - mae: 27176.1924 - val_loss: 0.0457 - val_mse: 2446348544.0000 - val_mae: 32060.5723\n",
            "Epoch 63/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0445 - mse: 2759510297.6000 - mae: 29828.4316 - val_loss: 0.0433 - val_mse: 2402210560.0000 - val_mae: 30247.4883\n",
            "Epoch 64/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0432 - mse: 2257334336.0000 - mae: 28700.6781 - val_loss: 0.0433 - val_mse: 2418945536.0000 - val_mae: 30177.9551\n",
            "Epoch 65/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0444 - mse: 2498493420.8000 - mae: 28005.8623 - val_loss: 0.0447 - val_mse: 2418834432.0000 - val_mae: 31525.4570\n",
            "Epoch 66/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0400 - mse: 2000754048.0000 - mae: 27928.5195 - val_loss: 0.0429 - val_mse: 2355289344.0000 - val_mae: 30166.4141\n",
            "Epoch 67/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0412 - mse: 1845111897.6000 - mae: 28420.6176 - val_loss: 0.0437 - val_mse: 2362465792.0000 - val_mae: 30981.4180\n",
            "Epoch 68/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0399 - mse: 2150256281.6000 - mae: 27555.1322 - val_loss: 0.0447 - val_mse: 2405474816.0000 - val_mae: 30280.6973\n",
            "Epoch 69/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0362 - mse: 1764032972.8000 - mae: 26131.6695 - val_loss: 0.0502 - val_mse: 2558875392.0000 - val_mae: 34001.8008\n",
            "Epoch 70/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0436 - mse: 2448368371.2000 - mae: 28942.2637 - val_loss: 0.0464 - val_mse: 2490357504.0000 - val_mae: 30797.7559\n",
            "Epoch 71/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0415 - mse: 2493140825.6000 - mae: 28169.2473 - val_loss: 0.0427 - val_mse: 2337171712.0000 - val_mae: 29909.2559\n",
            "Epoch 72/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0393 - mse: 2103309491.2000 - mae: 26939.4977 - val_loss: 0.0433 - val_mse: 2386076672.0000 - val_mae: 29930.0840\n",
            "Epoch 73/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0401 - mse: 2104456448.0000 - mae: 27022.1252 - val_loss: 0.0422 - val_mse: 2239007744.0000 - val_mae: 29863.8555\n",
            "Epoch 74/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0412 - mse: 2037874291.2000 - mae: 27750.9406 - val_loss: 0.0452 - val_mse: 2358604544.0000 - val_mae: 31811.2168\n",
            "Epoch 75/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0454 - mse: 2281271283.2000 - mae: 29139.8971 - val_loss: 0.0460 - val_mse: 2386104832.0000 - val_mae: 30621.2617\n",
            "Epoch 76/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0359 - mse: 2011103129.6000 - mae: 26528.6971 - val_loss: 0.0523 - val_mse: 2612635904.0000 - val_mae: 34786.4961\n",
            "Epoch 77/200\n",
            "9/9 [==============================] - 0s 28ms/step - loss: 0.0433 - mse: 2312371699.2000 - mae: 28944.2408 - val_loss: 0.0421 - val_mse: 2288287488.0000 - val_mae: 29819.2754\n",
            "Epoch 78/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0366 - mse: 2340213836.8000 - mae: 27583.3734 - val_loss: 0.0443 - val_mse: 2328078336.0000 - val_mae: 31362.2832\n",
            "Epoch 79/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0422 - mse: 2303973196.8000 - mae: 28306.5051 - val_loss: 0.0440 - val_mse: 2312928000.0000 - val_mae: 29930.6719\n",
            "Epoch 80/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0397 - mse: 2054760672.0000 - mae: 26303.3828 - val_loss: 0.0444 - val_mse: 2351889152.0000 - val_mae: 30036.5234\n",
            "Epoch 81/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0461 - mse: 2389049344.0000 - mae: 29000.8369 - val_loss: 0.0426 - val_mse: 2254966272.0000 - val_mae: 29547.4082\n",
            "Epoch 82/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0417 - mse: 2181615923.2000 - mae: 27594.3113 - val_loss: 0.0422 - val_mse: 2276208384.0000 - val_mae: 29556.8398\n",
            "Epoch 83/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0387 - mse: 2182835264.0000 - mae: 27375.9361 - val_loss: 0.0439 - val_mse: 2310542080.0000 - val_mae: 31170.7070\n",
            "Epoch 84/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0443 - mse: 2362291942.4000 - mae: 29529.1088 - val_loss: 0.0463 - val_mse: 2413310976.0000 - val_mae: 30695.7969\n",
            "Epoch 85/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0512 - mse: 3397858636.8000 - mae: 29494.9006 - val_loss: 0.0427 - val_mse: 2244802560.0000 - val_mae: 29514.8379\n",
            "Epoch 86/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0468 - mse: 3199048473.6000 - mae: 29203.2842 - val_loss: 0.0425 - val_mse: 2274066688.0000 - val_mae: 29467.9414\n",
            "Epoch 87/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0375 - mse: 1656767283.2000 - mae: 25766.7334 - val_loss: 0.0419 - val_mse: 2141686400.0000 - val_mae: 29241.9336\n",
            "Epoch 88/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0418 - mse: 2295648000.0000 - mae: 27649.7225 - val_loss: 0.0444 - val_mse: 2278662656.0000 - val_mae: 30006.8828\n",
            "Epoch 89/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0426 - mse: 2624240332.8000 - mae: 28160.5594 - val_loss: 0.0441 - val_mse: 2299652608.0000 - val_mae: 29881.4590\n",
            "Epoch 90/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0417 - mse: 2216004953.6000 - mae: 28373.9631 - val_loss: 0.0419 - val_mse: 2223072000.0000 - val_mae: 29253.0234\n",
            "Epoch 91/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0387 - mse: 1986905830.4000 - mae: 27118.1945 - val_loss: 0.0417 - val_mse: 2169970176.0000 - val_mae: 29159.1172\n",
            "Epoch 92/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0448 - mse: 2196952268.8000 - mae: 27894.9383 - val_loss: 0.0414 - val_mse: 2139495936.0000 - val_mae: 29106.6035\n",
            "Epoch 93/200\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.0385 - mse: 1972518745.6000 - mae: 26323.6273 - val_loss: 0.0418 - val_mse: 2130528384.0000 - val_mae: 29155.9648\n",
            "Epoch 94/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0417 - mse: 2643085568.0000 - mae: 28032.3357 - val_loss: 0.0412 - val_mse: 2150221824.0000 - val_mae: 29110.5918\n",
            "Epoch 95/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0383 - mse: 2228512908.8000 - mae: 26502.8063 - val_loss: 0.0410 - val_mse: 2106403712.0000 - val_mae: 29236.1855\n",
            "Epoch 96/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0434 - mse: 2832143385.6000 - mae: 28278.5680 - val_loss: 0.0415 - val_mse: 2118195968.0000 - val_mae: 29088.0430\n",
            "Epoch 97/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0408 - mse: 2143635059.2000 - mae: 28607.6494 - val_loss: 0.0409 - val_mse: 2084947456.0000 - val_mae: 28979.3281\n",
            "Epoch 98/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0373 - mse: 1686051238.4000 - mae: 26028.8883 - val_loss: 0.0408 - val_mse: 2114360448.0000 - val_mae: 29120.4062\n",
            "Epoch 99/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0338 - mse: 1469628307.2000 - mae: 24869.5107 - val_loss: 0.0424 - val_mse: 2184572416.0000 - val_mae: 30373.6133\n",
            "Epoch 100/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0428 - mse: 2212746355.2000 - mae: 28436.6428 - val_loss: 0.0406 - val_mse: 2100536960.0000 - val_mae: 29094.7891\n",
            "Epoch 101/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0439 - mse: 2572830272.0000 - mae: 28005.1180 - val_loss: 0.0409 - val_mse: 2145131264.0000 - val_mae: 29463.7754\n",
            "Epoch 102/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0417 - mse: 2010301747.2000 - mae: 28020.4967 - val_loss: 0.0408 - val_mse: 2118948224.0000 - val_mae: 29323.7578\n",
            "Epoch 103/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0397 - mse: 2140205376.0000 - mae: 28931.2691 - val_loss: 0.0413 - val_mse: 2089571328.0000 - val_mae: 28931.0664\n",
            "Epoch 104/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0405 - mse: 2131140569.6000 - mae: 26380.3148 - val_loss: 0.0424 - val_mse: 2203457792.0000 - val_mae: 30480.9004\n",
            "Epoch 105/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0385 - mse: 2046958796.8000 - mae: 26790.9564 - val_loss: 0.0427 - val_mse: 2209584640.0000 - val_mae: 30617.0938\n",
            "Epoch 106/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0419 - mse: 2316673728.0000 - mae: 27256.9945 - val_loss: 0.0454 - val_mse: 2303678464.0000 - val_mae: 31840.4023\n",
            "Epoch 107/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0376 - mse: 1961505612.8000 - mae: 26699.2910 - val_loss: 0.0420 - val_mse: 2132048256.0000 - val_mae: 29988.6738\n",
            "Epoch 108/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0420 - mse: 2461362137.6000 - mae: 27459.2533 - val_loss: 0.0403 - val_mse: 2032967808.0000 - val_mae: 28857.5586\n",
            "Epoch 109/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0338 - mse: 1620055820.8000 - mae: 25656.6494 - val_loss: 0.0429 - val_mse: 2175182848.0000 - val_mae: 30458.2148\n",
            "Epoch 110/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0422 - mse: 2610360716.8000 - mae: 28047.0117 - val_loss: 0.0406 - val_mse: 2060137600.0000 - val_mae: 29174.1172\n",
            "Epoch 111/200\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.0392 - mse: 1793431680.0000 - mae: 26981.4537 - val_loss: 0.0409 - val_mse: 2113937280.0000 - val_mae: 29557.5977\n",
            "Epoch 112/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0397 - mse: 2363871116.8000 - mae: 28588.7477 - val_loss: 0.0401 - val_mse: 2047592960.0000 - val_mae: 28848.6914\n",
            "Epoch 113/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0435 - mse: 2925589401.6000 - mae: 27763.4355 - val_loss: 0.0425 - val_mse: 2164788992.0000 - val_mae: 30438.5234\n",
            "Epoch 114/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0409 - mse: 1864187097.6000 - mae: 27372.8580 - val_loss: 0.0434 - val_mse: 2211550720.0000 - val_mae: 29590.2871\n",
            "Epoch 115/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0419 - mse: 1886104614.4000 - mae: 27736.2484 - val_loss: 0.0442 - val_mse: 2194906112.0000 - val_mae: 29828.2695\n",
            "Epoch 116/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0382 - mse: 2371739315.2000 - mae: 27169.0514 - val_loss: 0.0466 - val_mse: 2322039296.0000 - val_mae: 30741.5371\n",
            "Epoch 117/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0395 - mse: 1927861363.2000 - mae: 25472.8014 - val_loss: 0.0423 - val_mse: 2167150848.0000 - val_mae: 30340.2852\n",
            "Epoch 118/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0415 - mse: 2395753408.0000 - mae: 28385.9039 - val_loss: 0.0398 - val_mse: 2011690240.0000 - val_mae: 28654.7969\n",
            "Epoch 119/200\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.0370 - mse: 1907016723.2000 - mae: 26210.2457 - val_loss: 0.0398 - val_mse: 2025807872.0000 - val_mae: 28436.8828\n",
            "Epoch 120/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0342 - mse: 1891331328.0000 - mae: 25873.1176 - val_loss: 0.0402 - val_mse: 2044044800.0000 - val_mae: 29036.6113\n",
            "Epoch 121/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0405 - mse: 2287523820.8000 - mae: 26640.4574 - val_loss: 0.0408 - val_mse: 2056531712.0000 - val_mae: 29404.0098\n",
            "Epoch 122/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0351 - mse: 1729882240.0000 - mae: 26425.7801 - val_loss: 0.0421 - val_mse: 2046007296.0000 - val_mae: 28980.3418\n",
            "Epoch 123/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0377 - mse: 1983055840.0000 - mae: 26086.8299 - val_loss: 0.0400 - val_mse: 2028102656.0000 - val_mae: 28383.9727\n",
            "Epoch 124/200\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.0351 - mse: 1483983987.2000 - mae: 24861.4625 - val_loss: 0.0400 - val_mse: 1963160448.0000 - val_mae: 28272.8750\n",
            "Epoch 125/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0367 - mse: 1941246873.6000 - mae: 26098.8861 - val_loss: 0.0426 - val_mse: 2103341440.0000 - val_mae: 29202.7598\n",
            "Epoch 126/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0430 - mse: 2152893491.2000 - mae: 27656.4916 - val_loss: 0.0442 - val_mse: 2164299008.0000 - val_mae: 29718.9570\n",
            "Epoch 127/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0389 - mse: 1909550348.8000 - mae: 26642.5508 - val_loss: 0.0408 - val_mse: 2008297472.0000 - val_mae: 28499.9160\n",
            "Epoch 128/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0380 - mse: 1807391014.4000 - mae: 25934.4646 - val_loss: 0.0392 - val_mse: 1975805184.0000 - val_mae: 28205.8770\n",
            "Epoch 129/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0403 - mse: 2100748339.2000 - mae: 26850.8287 - val_loss: 0.0453 - val_mse: 2263382016.0000 - val_mae: 30226.3867\n",
            "Epoch 130/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0412 - mse: 1922056166.4000 - mae: 27326.2707 - val_loss: 0.0396 - val_mse: 1993723776.0000 - val_mae: 28652.7754\n",
            "Epoch 131/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0355 - mse: 2080472768.0000 - mae: 25365.7240 - val_loss: 0.0393 - val_mse: 1942059648.0000 - val_mae: 28056.5957\n",
            "Epoch 132/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0383 - mse: 2140134118.4000 - mae: 27064.1318 - val_loss: 0.0392 - val_mse: 2000509184.0000 - val_mae: 28383.8887\n",
            "Epoch 133/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0436 - mse: 2777003865.6000 - mae: 28477.4076 - val_loss: 0.0392 - val_mse: 1978316800.0000 - val_mae: 28327.2793\n",
            "Epoch 134/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0380 - mse: 2097713779.2000 - mae: 26246.8906 - val_loss: 0.0416 - val_mse: 2035953152.0000 - val_mae: 28761.0215\n",
            "Epoch 135/200\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.0378 - mse: 1937458777.6000 - mae: 26493.4055 - val_loss: 0.0399 - val_mse: 2013484800.0000 - val_mae: 28239.3535\n",
            "Epoch 136/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0357 - mse: 1742212160.0000 - mae: 24980.6379 - val_loss: 0.0421 - val_mse: 2121524224.0000 - val_mae: 30230.8633\n",
            "Epoch 137/200\n",
            "9/9 [==============================] - 0s 30ms/step - loss: 0.0401 - mse: 2042462912.0000 - mae: 28149.8363 - val_loss: 0.0423 - val_mse: 2103746688.0000 - val_mae: 30130.6504\n",
            "Epoch 138/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0354 - mse: 1872124889.6000 - mae: 25556.1930 - val_loss: 0.0388 - val_mse: 1912486272.0000 - val_mae: 27866.0586\n",
            "Epoch 139/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0397 - mse: 2348703398.4000 - mae: 26442.2916 - val_loss: 0.0400 - val_mse: 2032494208.0000 - val_mae: 29068.2422\n",
            "Epoch 140/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0406 - mse: 2259104640.0000 - mae: 26846.2590 - val_loss: 0.0391 - val_mse: 2006679424.0000 - val_mae: 28052.0312\n",
            "Epoch 141/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0404 - mse: 1943076979.2000 - mae: 26589.7816 - val_loss: 0.0397 - val_mse: 1968844928.0000 - val_mae: 28114.6504\n",
            "Epoch 142/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0379 - mse: 2152008204.8000 - mae: 26801.7863 - val_loss: 0.0392 - val_mse: 1996137472.0000 - val_mae: 27970.5898\n",
            "Epoch 143/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0376 - mse: 1796247513.6000 - mae: 26320.0033 - val_loss: 0.0392 - val_mse: 1985523968.0000 - val_mae: 28577.3496\n",
            "Epoch 144/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0367 - mse: 1893908544.0000 - mae: 26056.0551 - val_loss: 0.0385 - val_mse: 1928419968.0000 - val_mae: 27932.8633\n",
            "Epoch 145/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0381 - mse: 2000474291.2000 - mae: 26371.6379 - val_loss: 0.0385 - val_mse: 1933963648.0000 - val_mae: 27947.1270\n",
            "Epoch 146/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0376 - mse: 2463101670.4000 - mae: 26899.7129 - val_loss: 0.0388 - val_mse: 1922742016.0000 - val_mae: 27786.2930\n",
            "Epoch 147/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0381 - mse: 2059788646.4000 - mae: 26465.4500 - val_loss: 0.0388 - val_mse: 1931349632.0000 - val_mae: 27815.7656\n",
            "Epoch 148/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0385 - mse: 2423215500.8000 - mae: 25600.0982 - val_loss: 0.0397 - val_mse: 1957716224.0000 - val_mae: 28061.0625\n",
            "Epoch 149/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0358 - mse: 1621369747.2000 - mae: 25433.4492 - val_loss: 0.0404 - val_mse: 2007984128.0000 - val_mae: 28970.0527\n",
            "Epoch 150/200\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.0382 - mse: 2054516416.0000 - mae: 27452.0756 - val_loss: 0.0402 - val_mse: 1937551744.0000 - val_mae: 28141.9434\n",
            "Epoch 151/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0379 - mse: 2096886822.4000 - mae: 26675.6279 - val_loss: 0.0415 - val_mse: 2100897152.0000 - val_mae: 29922.2012\n",
            "Epoch 152/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0414 - mse: 2221142553.6000 - mae: 27463.4055 - val_loss: 0.0389 - val_mse: 1880013184.0000 - val_mae: 27729.2266\n",
            "Epoch 153/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0416 - mse: 2083758259.2000 - mae: 26660.2096 - val_loss: 0.0447 - val_mse: 2096669440.0000 - val_mae: 29969.1172\n",
            "Epoch 154/200\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.0401 - mse: 2107967596.8000 - mae: 26873.4600 - val_loss: 0.0388 - val_mse: 1881230976.0000 - val_mae: 27661.8066\n",
            "Epoch 155/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0396 - mse: 1836448243.2000 - mae: 25898.0961 - val_loss: 0.0390 - val_mse: 1904692608.0000 - val_mae: 27749.2656\n",
            "Epoch 156/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0437 - mse: 2578536294.4000 - mae: 28033.8305 - val_loss: 0.0422 - val_mse: 2063798784.0000 - val_mae: 29004.5723\n",
            "Epoch 157/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0378 - mse: 1844508928.0000 - mae: 26591.8939 - val_loss: 0.0383 - val_mse: 1893553920.0000 - val_mae: 27727.0137\n",
            "Epoch 158/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0382 - mse: 1865549734.4000 - mae: 26441.7369 - val_loss: 0.0427 - val_mse: 2133047296.0000 - val_mae: 30399.2598\n",
            "Epoch 159/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0416 - mse: 2462229760.0000 - mae: 27767.0127 - val_loss: 0.0413 - val_mse: 2035820672.0000 - val_mae: 28729.6035\n",
            "Epoch 160/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0340 - mse: 1515582451.2000 - mae: 24061.9691 - val_loss: 0.0401 - val_mse: 1953530752.0000 - val_mae: 28176.2051\n",
            "Epoch 161/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0372 - mse: 1902807961.6000 - mae: 26209.2373 - val_loss: 0.0384 - val_mse: 1963197184.0000 - val_mae: 28141.2285\n",
            "Epoch 162/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0363 - mse: 1710977958.4000 - mae: 25042.1926 - val_loss: 0.0386 - val_mse: 1968978048.0000 - val_mae: 28223.2695\n",
            "Epoch 163/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0365 - mse: 2112062809.6000 - mae: 26443.1826 - val_loss: 0.0393 - val_mse: 1876045568.0000 - val_mae: 27776.8945\n",
            "Epoch 164/200\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.0405 - mse: 2374800345.6000 - mae: 26167.4426 - val_loss: 0.0383 - val_mse: 1954115840.0000 - val_mae: 27620.0527\n",
            "Epoch 165/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0404 - mse: 2493959411.2000 - mae: 26230.1760 - val_loss: 0.0404 - val_mse: 2030584576.0000 - val_mae: 28350.1172\n",
            "Epoch 166/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0358 - mse: 1807251033.6000 - mae: 25251.3170 - val_loss: 0.0393 - val_mse: 1997747328.0000 - val_mae: 27975.7793\n",
            "Epoch 167/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0417 - mse: 2659141376.0000 - mae: 26979.6816 - val_loss: 0.0381 - val_mse: 1978027264.0000 - val_mae: 27980.0566\n",
            "Epoch 168/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0375 - mse: 2472443212.8000 - mae: 26750.8990 - val_loss: 0.0380 - val_mse: 1918343424.0000 - val_mae: 27722.7793\n",
            "Epoch 169/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0400 - mse: 1954026796.8000 - mae: 26814.8148 - val_loss: 0.0415 - val_mse: 2101468544.0000 - val_mae: 29900.7012\n",
            "Epoch 170/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0371 - mse: 1812412505.6000 - mae: 25669.8719 - val_loss: 0.0379 - val_mse: 1959392896.0000 - val_mae: 27742.7930\n",
            "Epoch 171/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0340 - mse: 1804741030.4000 - mae: 25599.7627 - val_loss: 0.0390 - val_mse: 1951831424.0000 - val_mae: 27798.4473\n",
            "Epoch 172/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0361 - mse: 1764234086.4000 - mae: 24590.0605 - val_loss: 0.0384 - val_mse: 1954326272.0000 - val_mae: 27648.8145\n",
            "Epoch 173/200\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 0.0339 - mse: 1594615974.4000 - mae: 24417.6928 - val_loss: 0.0398 - val_mse: 2034212096.0000 - val_mae: 29052.7949\n",
            "Epoch 174/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0388 - mse: 1770957862.4000 - mae: 26811.6971 - val_loss: 0.0396 - val_mse: 1931149568.0000 - val_mae: 27968.8301\n",
            "Epoch 175/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0391 - mse: 2207370496.0000 - mae: 25101.0189 - val_loss: 0.0387 - val_mse: 1912821248.0000 - val_mae: 27677.8809\n",
            "Epoch 176/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0356 - mse: 1666590720.0000 - mae: 25177.7711 - val_loss: 0.0375 - val_mse: 1941350016.0000 - val_mae: 27567.7852\n",
            "Epoch 177/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0376 - mse: 1983601100.8000 - mae: 25527.4057 - val_loss: 0.0391 - val_mse: 1995298944.0000 - val_mae: 27883.7812\n",
            "Epoch 178/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0354 - mse: 2143583564.8000 - mae: 25113.8758 - val_loss: 0.0375 - val_mse: 1980416640.0000 - val_mae: 27556.8535\n",
            "Epoch 179/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0382 - mse: 2180054067.2000 - mae: 26264.2748 - val_loss: 0.0382 - val_mse: 1931824768.0000 - val_mae: 27953.4238\n",
            "Epoch 180/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0353 - mse: 2012512256.0000 - mae: 26601.0045 - val_loss: 0.0403 - val_mse: 2057324672.0000 - val_mae: 28375.0488\n",
            "Epoch 181/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0316 - mse: 1637692044.8000 - mae: 24030.2273 - val_loss: 0.0411 - val_mse: 2045840000.0000 - val_mae: 28595.8809\n",
            "Epoch 182/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0388 - mse: 2330689228.8000 - mae: 25535.5246 - val_loss: 0.0379 - val_mse: 1898702720.0000 - val_mae: 27354.7285\n",
            "Epoch 183/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0321 - mse: 1724576704.0000 - mae: 25378.9941 - val_loss: 0.0386 - val_mse: 1908449280.0000 - val_mae: 27556.2617\n",
            "Epoch 184/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0342 - mse: 1608492172.8000 - mae: 24462.9639 - val_loss: 0.0381 - val_mse: 1916096384.0000 - val_mae: 27841.6582\n",
            "Epoch 185/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0343 - mse: 1476607116.8000 - mae: 24602.1133 - val_loss: 0.0389 - val_mse: 1940744960.0000 - val_mae: 27760.4434\n",
            "Epoch 186/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0412 - mse: 2371258585.6000 - mae: 26888.0717 - val_loss: 0.0373 - val_mse: 1909332736.0000 - val_mae: 27174.3535\n",
            "Epoch 187/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0341 - mse: 1698224345.6000 - mae: 24630.4354 - val_loss: 0.0526 - val_mse: 2566444032.0000 - val_mae: 33490.8867\n",
            "Epoch 188/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0339 - mse: 1503631475.2000 - mae: 24462.0604 - val_loss: 0.0384 - val_mse: 1853962624.0000 - val_mae: 27363.3594\n",
            "Epoch 189/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0359 - mse: 1868313920.0000 - mae: 24913.1258 - val_loss: 0.0418 - val_mse: 2088798208.0000 - val_mae: 28929.0723\n",
            "Epoch 190/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0386 - mse: 2355110028.8000 - mae: 26154.4760 - val_loss: 0.0415 - val_mse: 2032794112.0000 - val_mae: 28792.4980\n",
            "Epoch 191/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0338 - mse: 1594717932.8000 - mae: 23992.1225 - val_loss: 0.0457 - val_mse: 2160188416.0000 - val_mae: 30580.0801\n",
            "Epoch 192/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0433 - mse: 2098080947.2000 - mae: 27374.4020 - val_loss: 0.0374 - val_mse: 1918261504.0000 - val_mae: 27257.3926\n",
            "Epoch 193/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0317 - mse: 1592201497.6000 - mae: 24237.7111 - val_loss: 0.0376 - val_mse: 1914460288.0000 - val_mae: 27709.9551\n",
            "Epoch 194/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0374 - mse: 2333731084.8000 - mae: 26429.7477 - val_loss: 0.0374 - val_mse: 1942573312.0000 - val_mae: 27291.7480\n",
            "Epoch 195/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0351 - mse: 1663624192.0000 - mae: 24962.9299 - val_loss: 0.0370 - val_mse: 1879859584.0000 - val_mae: 27218.7461\n",
            "Epoch 196/200\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.0401 - mse: 2192199820.8000 - mae: 26759.4910 - val_loss: 0.0373 - val_mse: 1915622272.0000 - val_mae: 27153.4766\n",
            "Epoch 197/200\n",
            "9/9 [==============================] - 0s 31ms/step - loss: 0.0339 - mse: 1677761868.8000 - mae: 24587.1146 - val_loss: 0.0369 - val_mse: 1894041216.0000 - val_mae: 27066.2129\n",
            "Epoch 198/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0345 - mse: 1519715980.8000 - mae: 24882.7541 - val_loss: 0.0368 - val_mse: 1881037568.0000 - val_mae: 26982.0918\n",
            "Epoch 199/200\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.0306 - mse: 1392992556.8000 - mae: 22812.5535 - val_loss: 0.0441 - val_mse: 2191083264.0000 - val_mae: 31103.6367\n",
            "Epoch 200/200\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.0384 - mse: 1858357772.8000 - mae: 27628.9049 - val_loss: 0.0369 - val_mse: 1955867520.0000 - val_mae: 27167.1367\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aS4cs14SWYds",
        "outputId": "9280f125-f888-4c09-aa49-96040948ec82"
      },
      "source": [
        "print('MSE MAE Error  :',avg_mse_mae)\r\n",
        "print('MAE MAE Error  :',avg_mae_mae)\r\n",
        "print('MSLE MAE Error :',avg_msle_mae)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE MAE Error  : 33258.480185546876\n",
            "MAE MAE Error  : 31424.25966796875\n",
            "MSLE MAE Error : 35384.1065234375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-NmgMGg0ls7"
      },
      "source": [
        "def modeling(optimizer='adam', loss='mae', metrics='mae'):\r\n",
        "  model = Sequential()\r\n",
        "  model.add(Dense(512, input_dim=X_train.shape[1], activation='relu'))\r\n",
        "  model.add(Dense(256, activation='relu'))\r\n",
        "  model.add(Dense(16, activation='relu'))\r\n",
        "  model.add(Dense(4, activation='relu'))\r\n",
        "  model.add(Dense(1, activation='linear'))\r\n",
        "  model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\r\n",
        "  history = model.fit(X_train, y_train, batch_size=100, epochs=200, validation_data=(X_test, y_test))\r\n",
        "  return history"
      ],
      "execution_count": 29,
      "outputs": []
    }
  ]
}