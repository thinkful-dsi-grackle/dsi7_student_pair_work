{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "NR Day 79 Lecture 1 Assignment",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuT0K8LDKm45"
      },
      "source": [
        "## Convolutional Neural Networks\n",
        "\n",
        "In this assignment, we will learn about convolutional neural networks. We will create a CNN and learn to classify image data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMD7Nr8hKm47"
      },
      "source": [
        "In this lecture, we will use the image data generator to classify our data. The data is loaded below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dMoxIG1Tucn",
        "outputId": "fb9551bc-808e-454d-97a5-2e5cfbe532f4"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6swIc-rGKm47"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization \n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "import time"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxuDmAQlKm4-"
      },
      "source": [
        "train_data_dir = '/content/drive/MyDrive/python_for_data_scientists/DSI07/DataSets/dogs-vs-cats-processed/train'\n",
        "validation_data_dir = '/content/drive/MyDrive/python_for_data_scientists/DSI07/DataSets/dogs-vs-cats-processed/test'\n",
        "\n",
        "img_width, img_height = 150, 150\n",
        "batch_size = 80"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCfRV8VGKm5A"
      },
      "source": [
        "#This block of code is used to ensure the input shape is correct\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_shape = (img_width, img_height, 3)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4x9el54Km5C"
      },
      "source": [
        "Define a train data generator with shear range of 0.3, zoom range of 0.1 and rescale to 1./255 (note that we must make 1 a float to produce a correct fraction). Use the ImageDataGenerator function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfKBxGZpKm5D"
      },
      "source": [
        "# Answer below:\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.1, \n",
        ")"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oQJZOxNKm5E"
      },
      "source": [
        "Define a test data generator that only rescales to 1./255. Use the ImageDataGenerator function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_U3XQZVLKm5F"
      },
      "source": [
        "# Answer below:\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0NCOxrCKm5G"
      },
      "source": [
        "The train generator and the test generator are defined below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDgonF6uKm5H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "bdb4d5fe-6921-4849-88ae-aa09f96d0979"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    #shuffle=False,\n",
        "    class_mode='binary')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-6912aeaa7c82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     class_mode='binary')\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m validation_generator = test_datagen.flow_from_directory(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    956\u001b[0m         \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m         interpolation=interpolation)\n\u001b[0m\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m   def flow_from_dataframe(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/python_for_data_scientists/DSI07/DataSets/dogs-vs-cats-processed/train'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lq09r31Km5K"
      },
      "source": [
        "We'll start with a simple model. In CNNs, we first convolve the to extract features and then we add the dense layers. \n",
        "\n",
        "Create a model with one layer of convolution of size 64, one layer of activation, one layer of max pooling with pool size (2,2) and then one flattening layer, one dense layer of unit size 64 with a ReLU activation and one dense output layer. The output layer should have a sigmoid activation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJqkMx3tKm5K"
      },
      "source": [
        "# Answer below:\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3,3), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0A4t-ZJkUx50",
        "outputId": "e5d706d0-5eeb-455a-afcf-5d7a2531d9c3"
      },
      "source": [
        "model.summary()\r\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 148, 148, 64)      1792      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 148, 148, 64)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 74, 74, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 350464)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                22429760  \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 22,431,617\n",
            "Trainable params: 22,431,617\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEBJ5GXcKm5M"
      },
      "source": [
        "Compile the model using RMSprop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85uyZ1yTKm5M"
      },
      "source": [
        "# Answer below:\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['accuracy'])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIKSpMe-Km5O"
      },
      "source": [
        "Fit the model using a fit generator. Use 50 epochs, 25 training steps and 15 validation steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFfKyhLzKm5O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "81cdcfc0-59a6-40e4-b4c5-d0df851e55dd"
      },
      "source": [
        "# Answer below:\n",
        "\n",
        "model.fit(train_generator, \n",
        "          steps_per_epoch=25, \n",
        "          epochs=50, \n",
        "          validation_data=validation_generator, \n",
        "          validation_steps=5)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-292e1d1231ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Answer below:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m model.fit(train_generator, \n\u001b[0m\u001b[1;32m      4\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_generator' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAZ1IeybKm5Q"
      },
      "source": [
        "Create a new model by adding an additional group of convolution, activation and max pooling layers before the flatten layer. Make the convolution layer of unit size 32. Keep everything else the same."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "651SH4QGKm5Q"
      },
      "source": [
        "# Answer below:\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3,3), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(32, (3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHfpSfgyKm5S"
      },
      "source": [
        "Fit and compile the model in the same way you did with the previous model. How did the results improve?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5nPg_LmKm5S"
      },
      "source": [
        "# Answer below:\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "\n",
        "# fit model\n",
        "## had to use validation steps of 5 to prevent running out of validation data\n",
        "model.fit(train_generator, \n",
        "          steps_per_epoch=25, \n",
        "          epochs=50, \n",
        "          validation_data=validation_generator, \n",
        "          validation_steps=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgKv1_tCKm5U"
      },
      "source": [
        "Create a new model based on the model above. Add an additional dense layer of size 64 with a ReLU activation after the flatten layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlzEuIt3Km5U"
      },
      "source": [
        "# Answer below:\n",
        "\n",
        "# make cnn model with two conv layers and two dense layers\n",
        "# instantiate model\n",
        "model = Sequential()\n",
        "# convolution layer 1\n",
        "model.add(Conv2D(64, (3,3), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "# convolution layer 2\n",
        "model.add(Conv2D(32, (3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#flatten layer\n",
        "model.add(Flatten())\n",
        "# dense layer 1\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "#dense layer 2\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "#dense layer 3 / output layer\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMg6k7tHKm5W"
      },
      "source": [
        "Fit and compile in the same way as above. Describe the difference in performance and speed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqIEZC6YKm5W"
      },
      "source": [
        "# Answer below:\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "\n",
        "# fit model\n",
        "## had to use validation steps of 5 to prevent running out of validation data\n",
        "model.fit(train_generator, \n",
        "          steps_per_epoch=25, \n",
        "          epochs=50, \n",
        "          validation_data=validation_generator, \n",
        "          validation_steps=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRCyPKJfKm5Y"
      },
      "source": [
        "Fit and compile using the Adam optimizer. Describe the difference in performance between the Adam and RMSprop optimizers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqzQbCl8Km5Z"
      },
      "source": [
        "# Answer below:\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "\n",
        "# fit model\n",
        "## had to use validation steps of 5 to prevent running out of validation data\n",
        "model.fit(train_generator, \n",
        "          steps_per_epoch=25, \n",
        "          epochs=50, \n",
        "          validation_data=validation_generator, \n",
        "          validation_steps=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drRBa855Km5a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}