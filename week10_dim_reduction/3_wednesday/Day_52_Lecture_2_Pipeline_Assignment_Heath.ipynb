{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Day 52 Lecture 2 Pipeline Assignment.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzcLuZowoMar"
      },
      "source": [
        "# Machine Learning Best Practices Assignment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpBBfm3toMat"
      },
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfqS_cMWoMa1"
      },
      "source": [
        "### Import the [Pima Indians Diabetes data set](https://tf-assets-prod.s3.amazonaws.com/tf-curric/data-science/pima_indians_diabetes.csv)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO-4LVM7oMa1"
      },
      "source": [
        "data = pd.read_csv('https://tf-assets-prod.s3.amazonaws.com/tf-curric/data-science/pima_indians_diabetes.csv')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtNhl2RCoMa5"
      },
      "source": [
        "### Split the data into training and test sets, with the target variable being the outcome column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awGD68-2oMa5"
      },
      "source": [
        "X = data.drop('outcome', axis=1)\n",
        "y = data.outcome\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6uDW6gSoMa9"
      },
      "source": [
        "### Train a Random Forest Classifier on the data without doing any transformations and print a classification report.\n",
        "\n",
        "This will provide us with a basis for comparison."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_TU-W51oMa-"
      },
      "source": [
        "model = RandomForestClassifier(random_state=1)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o8P7OeooMbC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "315b5e22-0017-47b7-ea8f-a0b6f093408a"
      },
      "source": [
        "model.fit(X_train, y_train)\n",
        "pred = model.predict(X_test)\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.86      0.80       119\n",
            "           1       0.70      0.55      0.62        73\n",
            "\n",
            "    accuracy                           0.74       192\n",
            "   macro avg       0.73      0.70      0.71       192\n",
            "weighted avg       0.74      0.74      0.73       192\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44gMhQKRoMbG"
      },
      "source": [
        "### Reduce the data down to 3 dimensions using PCA. Then do the train-test split, fit the model, and print a classification report.\n",
        "\n",
        "Compare these results to the previous ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbJpUBrgoMbH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e31384a-23fb-43ef-9cbe-d68ad7d2c61f"
      },
      "source": [
        "pca = PCA(n_components=3)\n",
        "pca_X = pca.fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(pca_X, y)\n",
        "model.fit(X_train, y_train)\n",
        "pred = model.predict(X_test)\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.83      0.77       120\n",
            "           1       0.62      0.46      0.53        72\n",
            "\n",
            "    accuracy                           0.69       192\n",
            "   macro avg       0.67      0.65      0.65       192\n",
            "weighted avg       0.68      0.69      0.68       192\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PSJ9pLRoMbL"
      },
      "source": [
        "### Fit the model and print a classification report again, but this time, perform the train-test split before you transform the data using PCA.\n",
        "\n",
        "Compare these results to the previous ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2kjPbPKoMbM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e815c72e-5776-4c1a-b94e-f26032c8f106"
      },
      "source": [
        "pca = PCA(n_components=3)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "pca_X_train = pca.fit_transform(X_train)\n",
        "pca_X_test = pca.transform(X_test)\n",
        "model.fit(pca_X_train, y_train)\n",
        "pred = model.predict(pca_X_test)\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.79      0.81       134\n",
            "           1       0.56      0.60      0.58        58\n",
            "\n",
            "    accuracy                           0.73       192\n",
            "   macro avg       0.69      0.70      0.69       192\n",
            "weighted avg       0.74      0.73      0.74       192\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5QOmml0oMbO"
      },
      "source": [
        "### Using the Random Forest Classifier, perform 10-fold cross validation on the training set and print the mean cross validation score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ci-V57_oMbP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a492f21b-17e1-4cbb-e168-f7fd8ee1371b"
      },
      "source": [
        "rf = RandomForestClassifier()\n",
        "print(cross_val_score(rf, X_train, y_train, cv=10).mean())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7343617664851784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7W_6glHPoMbT"
      },
      "source": [
        "### Create a pipeline with a PCA step and a Random Forest Classifier step. Perform the train-test split again, fit the pipeline, and then generate a classification report.\n",
        "\n",
        "Compare these results to the previous ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sy4DFzsoMbU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b500c560-1e18-482a-f8ad-58e2869f6e5a"
      },
      "source": [
        "pca_rf_pipeline = Pipeline([('pca', PCA(n_components=3)), ('rf', RandomForestClassifier())])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "pca_rf_pipeline.fit(X_train, y_train)\n",
        "pred = pca_rf_pipeline.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.85      0.80       118\n",
            "           1       0.69      0.55      0.62        74\n",
            "\n",
            "    accuracy                           0.73       192\n",
            "   macro avg       0.72      0.70      0.71       192\n",
            "weighted avg       0.73      0.73      0.73       192\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0RpnV0xoMbX"
      },
      "source": [
        "### Using the pipeline you built, perform 10-fold cross validation on the training set and print the mean cross validation score.\n",
        "\n",
        "How does this score compare to the previous one?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IKeBBZXoMbY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f915a9e-3679-4e53-b68d-76f1d1e29f21"
      },
      "source": [
        "print(cross_val_score(pca_rf_pipeline, X_train, y_train, cv=10).mean())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7392921960072596\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WH7luhm7oINN"
      },
      "source": [
        "#slight increase in score, but very similar and could be due to random splitting"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DLDuyOqoMba"
      },
      "source": [
        "### Use GridSearchCV to find the optimal set of parameters from the ones below.\n",
        "\n",
        "- PCA Number of Components: 2, 3, 4, 5, 6, 7, 8\n",
        "- Random Forest Number of Estimators: 10, 20, 50, 100, 200"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbsRhIdZoMbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebae8a57-83bd-4de3-9d64-004bf83c51bb"
      },
      "source": [
        "parameters = {'pca__n_components': [2, 3, 4, 5, 6, 7, 8], \n",
        "              'rf__n_estimators': [10, 20, 50, 100, 200]}\n",
        "search = GridSearchCV(pca_rf_pipeline, parameters, cv=10)\n",
        "search.fit(X_train, y_train)\n",
        "\n",
        "print('search best score:', search.best_score_)\n",
        "print('search best parameters:', search.best_params_)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "search best score: 0.7724742891712039\n",
            "search best parameters: {'pca__n_components': 8, 'rf__n_estimators': 50}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cVJ994qoMbd"
      },
      "source": [
        "### Using the best estimator pipeline from above, fit the pipeline to the training set and generate a classification report showing the results.\n",
        "\n",
        "Compare these results to the previous ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0N6Mv3KoMbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5495802-adfe-46f3-8587-90a306cf102f"
      },
      "source": [
        "pca_rf_pipeline = Pipeline([('pca', PCA(n_components=8)), ('rf', RandomForestClassifier(n_estimators=50))])\n",
        "pca_rf_pipeline.fit(X_train, y_train)\n",
        "pred = pca_rf_pipeline.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.86      0.80       118\n",
            "           1       0.71      0.54      0.62        74\n",
            "\n",
            "    accuracy                           0.74       192\n",
            "   macro avg       0.73      0.70      0.71       192\n",
            "weighted avg       0.74      0.74      0.73       192\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loHniiPLoMbj"
      },
      "source": [
        "### Fit the best estimator pipeline to the entire data set and save your model to disk using pickle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Y8ESntxoMbk"
      },
      "source": [
        "pca_rf_pipeline.fit(X, y)\n",
        "with open('model.pkl', 'wb') as f:\n",
        "  pickle.dump(pca_rf_pipeline, f)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HdA-rQGoMbn"
      },
      "source": [
        "### Load the model you saved to disk, create a copy of the features in the data, and generate a set of predictions for those features. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBnP7dKhoMbn"
      },
      "source": [
        "with open('model.pkl', 'rb') as f:\n",
        "  load_pipe = pickle.load(f)\n",
        "\n",
        "data_copy = X.copy()\n",
        "preds = load_pipe.predict(data_copy)"
      ],
      "execution_count": 42,
      "outputs": []
    }
  ]
}