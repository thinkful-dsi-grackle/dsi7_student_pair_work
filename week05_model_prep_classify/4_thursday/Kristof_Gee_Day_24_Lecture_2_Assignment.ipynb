{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7OBYmw2rsHe"
   },
   "source": [
    "## Day 24 Lecture 2 Assignment\n",
    "\n",
    "In this assignment, we will build our a more complex logistic regression model, this time on both numeric and categorical data. We will use the Chicago traffic crashes dataset loaded below and analyze the model generated for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "u3rUv9PKrsHf"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "cJ-qRkctUvv6"
   },
   "outputs": [],
   "source": [
    "def missingness_summary(df, print_log=False, sort='none'):\n",
    "    summary = df.apply(lambda x: x.isna().sum() / x.shape[0])\n",
    "    \n",
    "    if print_log == True:\n",
    "        if sort == 'none':\n",
    "            print(summary)\n",
    "        elif sort == 'ascending':\n",
    "            print(summary.sort_values())\n",
    "        elif sort == 'descending':\n",
    "            print(summary.sort_values(ascending=False))\n",
    "        else:\n",
    "            print('Invalid value for sort parameter.')\n",
    "        \n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "V_hlXXYwrsHh"
   },
   "outputs": [],
   "source": [
    "crash = pd.read_csv('https://tf-assets-prod.s3.amazonaws.com/tf-curric/data-science/traffic_crashes_chicago.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "bJV8A_OQrsHj",
    "outputId": "9a64e2c5-a17c-429d-f55a-8bc72ce72a75"
   },
   "outputs": [],
   "source": [
    "#crash.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7kel3hRUvwA"
   },
   "source": [
    "First, create a binary response column by modifying the \"DAMAGE\" column. Consider \"OVER \\$1500\" to be the positive class, and under \\$1500 to be the negative class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lVXRdsWPUvwB"
   },
   "outputs": [],
   "source": [
    "# answer goes here\n",
    "\n",
    "#crash['NEW_DAMAGE'] = (crash['DAMAGE'] == 'OVER $1,500').astype(int)\n",
    "\n",
    "crash['NEW_DAMAGE'] = np.where(crash['DAMAGE'] == 'OVER $1,500', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    209921\n",
       "0    162664\n",
       "Name: NEW_DAMAGE, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crash['NEW_DAMAGE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5QQUxRPMrsHl"
   },
   "source": [
    "Using the code from Day 21, Lecture 1 as a starting point, devise an appropriate way to address missing values. You have a lot of freedom here; we will proceed by taking the following steps:\n",
    "\n",
    "- Dropping all columns with more than 5% missing data\n",
    "- Imputing the median for numeric columns with less than 5% missing data (except for STREET_NO; imputing it in this manner would not make any sense)\n",
    "- Dropping rows with missing data for categorical columns that have less than 5% missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "X7DmjvgXrsHl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\juss\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\pandas\\core\\generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "# answer goes here\n",
    "# crash = crash.drop(labels=[['LANE_CNT','INTERSECTION_RELATED_I','NOT_RIGHT_OF_WAY_I', 'HIT_AND_RUN_I','PHOTOS_TAKEN_I', 'STATEMENTS_TAKEN_I','DOORING_I', 'WORK_ZONE_I', 'WORK_ZONE_TYPE', 'WORKERS_PRESENT_I']], axis=1, inplace=True) \n",
    "\n",
    "filtered = crash.dropna(thresh=crash.shape[0]*0.95,how='all',axis=1)\n",
    "\n",
    "#cols = ['BEAT_OF_OCCURRENCE', 'NUM_UNITS', 'INJURIES_TOTAL', 'INJURIES_FATAL', 'INJURIES_INCAPACITATING', 'INJURIES_NON_INCAPACITATING', 'INJURIES_REPORTED_NOT_EVIDENT',\n",
    "#       'INJURIES_NO_INDICATION', 'INJURIES_UNKNOWN']\n",
    "\n",
    "for col in filtered.columns:\n",
    "#    filtered[col] = filtered[col].fillna(filtered[col].median())\n",
    "    if filtered[col].dtypes != 'O': \n",
    "        filtered[col].fillna(filtered[col].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-51919896a2e5>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "filtered.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RD_NO                            0.0\n",
       "CRASH_DATE                       0.0\n",
       "POSTED_SPEED_LIMIT               0.0\n",
       "TRAFFIC_CONTROL_DEVICE           0.0\n",
       "DEVICE_CONDITION                 0.0\n",
       "WEATHER_CONDITION                0.0\n",
       "LIGHTING_CONDITION               0.0\n",
       "FIRST_CRASH_TYPE                 0.0\n",
       "TRAFFICWAY_TYPE                  0.0\n",
       "ALIGNMENT                        0.0\n",
       "ROADWAY_SURFACE_COND             0.0\n",
       "ROAD_DEFECT                      0.0\n",
       "REPORT_TYPE                      0.0\n",
       "CRASH_TYPE                       0.0\n",
       "DAMAGE                           0.0\n",
       "DATE_POLICE_NOTIFIED             0.0\n",
       "PRIM_CONTRIBUTORY_CAUSE          0.0\n",
       "SEC_CONTRIBUTORY_CAUSE           0.0\n",
       "STREET_NO                        0.0\n",
       "STREET_DIRECTION                 0.0\n",
       "STREET_NAME                      0.0\n",
       "BEAT_OF_OCCURRENCE               0.0\n",
       "NUM_UNITS                        0.0\n",
       "MOST_SEVERE_INJURY               0.0\n",
       "INJURIES_TOTAL                   0.0\n",
       "INJURIES_FATAL                   0.0\n",
       "INJURIES_INCAPACITATING          0.0\n",
       "INJURIES_NON_INCAPACITATING      0.0\n",
       "INJURIES_REPORTED_NOT_EVIDENT    0.0\n",
       "INJURIES_NO_INDICATION           0.0\n",
       "INJURIES_UNKNOWN                 0.0\n",
       "NEW_DAMAGE                       0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missingness_summary(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M66r2mytUvwF"
   },
   "source": [
    "Finally, choose a few numeric and categorical features (2-3 of each) to include in the model. (You can definitely include more than this, but too many features, especially categorical ones, will most likely lead to convergence issues). One hot encode the chosen categorical features, being sure to omit one of the categories (which will serve as a \"reference\" level) to avoid perfect multicollinearity.\n",
    "\n",
    "Again, you have a lot of freedom here; we will proceed with the following features, dropping the most commonly occurring category for the two categorical variables (\"CLEAR\" for weather, \"REAR END\" for first crash type):\n",
    "POSTED_SPEED_LIMIT, WEATHER_CONDITION, INJURIES_TOTAL, FIRST_CRASH_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_scenario = filtered.filter(['POSTED_SPEED_LIMIT', 'INJURIES_TOTAL','NEW_DAMAGE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ja_Vaq2CUvwF"
   },
   "outputs": [],
   "source": [
    "# answer goes here\n",
    "\n",
    "weather = pd.get_dummies(filtered['WEATHER_CONDITION'], drop_first=True)\n",
    "crash_scenario = pd.concat([crash_scenario, weather], axis=1)\n",
    "\n",
    "\n",
    "crash_type = pd.get_dummies(filtered['FIRST_CRASH_TYPE'], drop_first=True)\n",
    "crash_scenario = pd.concat([crash_scenario, crash_type], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 362483 entries, 6 to 372584\n",
      "Data columns (total 30 columns):\n",
      " #   Column                        Non-Null Count   Dtype  \n",
      "---  ------                        --------------   -----  \n",
      " 0   POSTED_SPEED_LIMIT            362483 non-null  int64  \n",
      " 1   INJURIES_TOTAL                362483 non-null  float64\n",
      " 2   NEW_DAMAGE                    362483 non-null  int32  \n",
      " 3   CLEAR                         362483 non-null  uint8  \n",
      " 4   CLOUDY/OVERCAST               362483 non-null  uint8  \n",
      " 5   FOG/SMOKE/HAZE                362483 non-null  uint8  \n",
      " 6   FREEZING RAIN/DRIZZLE         362483 non-null  uint8  \n",
      " 7   OTHER                         362483 non-null  uint8  \n",
      " 8   RAIN                          362483 non-null  uint8  \n",
      " 9   SEVERE CROSS WIND GATE        362483 non-null  uint8  \n",
      " 10  SLEET/HAIL                    362483 non-null  uint8  \n",
      " 11  SNOW                          362483 non-null  uint8  \n",
      " 12  UNKNOWN                       362483 non-null  uint8  \n",
      " 13  ANIMAL                        362483 non-null  uint8  \n",
      " 14  FIXED OBJECT                  362483 non-null  uint8  \n",
      " 15  HEAD ON                       362483 non-null  uint8  \n",
      " 16  OTHER NONCOLLISION            362483 non-null  uint8  \n",
      " 17  OTHER OBJECT                  362483 non-null  uint8  \n",
      " 18  OVERTURNED                    362483 non-null  uint8  \n",
      " 19  PARKED MOTOR VEHICLE          362483 non-null  uint8  \n",
      " 20  PEDALCYCLIST                  362483 non-null  uint8  \n",
      " 21  PEDESTRIAN                    362483 non-null  uint8  \n",
      " 22  REAR END                      362483 non-null  uint8  \n",
      " 23  REAR TO FRONT                 362483 non-null  uint8  \n",
      " 24  REAR TO REAR                  362483 non-null  uint8  \n",
      " 25  REAR TO SIDE                  362483 non-null  uint8  \n",
      " 26  SIDESWIPE OPPOSITE DIRECTION  362483 non-null  uint8  \n",
      " 27  SIDESWIPE SAME DIRECTION      362483 non-null  uint8  \n",
      " 28  TRAIN                         362483 non-null  uint8  \n",
      " 29  TURNING                       362483 non-null  uint8  \n",
      "dtypes: float64(1), int32(1), int64(1), uint8(27)\n",
      "memory usage: 19.0 MB\n"
     ]
    }
   ],
   "source": [
    "crash_scenario.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRuNJsTSrsHn"
   },
   "source": [
    "Split the data into train and test, with 80% training and 20% testing. By default, the LR output from statsmodels does not include an intercept terms; add a constant column to the training data so that an intercept term is calculated for the LR model (hint: sm.add_constant() is a useful function to accomplish this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "fhpHIZBjrsHn"
   },
   "outputs": [],
   "source": [
    "# answer goes here\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = crash_scenario.drop('NEW_DAMAGE', axis=1)\n",
    "Y = crash_scenario['NEW_DAMAGE']\n",
    "\n",
    "X_train, x_test, Y_train, y_test = train_test_split(X, Y, test_size=0.20)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X_train_con = sm.add_constant(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ggXxmOLTrsHq"
   },
   "source": [
    "Fit the logistic regression model using the statsmodels package and print out the coefficient summary. Which variables (in particular, which categories of our categorical variables) appear to be the most important, and what effect do they have on the probability of a crash resulting in $1500 or more in damages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "7pFgRLNErsHq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.657865\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>NEW_DAMAGE</td>    <th>  No. Observations:  </th>   <td>289986</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>289956</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>    29</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 15 Oct 2020</td> <th>  Pseudo R-squ.:     </th>   <td>0.04008</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>15:36:31</td>     <th>  Log-Likelihood:    </th> <td>-1.9077e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td>-1.9874e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>   <td> 0.000</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                <td></td>                  <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                        <td>    0.9866</td> <td>    0.652</td> <td>    1.513</td> <td> 0.130</td> <td>   -0.291</td> <td>    2.264</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>POSTED_SPEED_LIMIT</th>           <td>    0.0108</td> <td>    0.001</td> <td>   18.345</td> <td> 0.000</td> <td>    0.010</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>INJURIES_TOTAL</th>               <td>    0.7365</td> <td>    0.012</td> <td>   61.925</td> <td> 0.000</td> <td>    0.713</td> <td>    0.760</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CLEAR</th>                        <td>   -0.6376</td> <td>    0.652</td> <td>   -0.979</td> <td> 0.328</td> <td>   -1.915</td> <td>    0.639</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CLOUDY/OVERCAST</th>              <td>   -0.5529</td> <td>    0.652</td> <td>   -0.848</td> <td> 0.396</td> <td>   -1.831</td> <td>    0.725</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FOG/SMOKE/HAZE</th>               <td>   -0.4289</td> <td>    0.658</td> <td>   -0.652</td> <td> 0.514</td> <td>   -1.718</td> <td>    0.860</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FREEZING RAIN/DRIZZLE</th>        <td>   -0.1339</td> <td>    0.680</td> <td>   -0.197</td> <td> 0.844</td> <td>   -1.466</td> <td>    1.198</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OTHER</th>                        <td>   -0.3442</td> <td>    0.655</td> <td>   -0.525</td> <td> 0.599</td> <td>   -1.629</td> <td>    0.940</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RAIN</th>                         <td>   -0.5122</td> <td>    0.652</td> <td>   -0.786</td> <td> 0.432</td> <td>   -1.789</td> <td>    0.765</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SEVERE CROSS WIND GATE</th>       <td>   -0.1574</td> <td>    0.710</td> <td>   -0.222</td> <td> 0.825</td> <td>   -1.549</td> <td>    1.234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SLEET/HAIL</th>                   <td>   -0.5346</td> <td>    0.659</td> <td>   -0.811</td> <td> 0.417</td> <td>   -1.826</td> <td>    0.757</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SNOW</th>                         <td>   -0.5109</td> <td>    0.652</td> <td>   -0.784</td> <td> 0.433</td> <td>   -1.789</td> <td>    0.767</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UNKNOWN</th>                      <td>   -0.4666</td> <td>    0.652</td> <td>   -0.716</td> <td> 0.474</td> <td>   -1.744</td> <td>    0.811</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ANIMAL</th>                       <td>   -1.1042</td> <td>    0.150</td> <td>   -7.344</td> <td> 0.000</td> <td>   -1.399</td> <td>   -0.810</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FIXED OBJECT</th>                 <td>    0.0510</td> <td>    0.024</td> <td>    2.163</td> <td> 0.031</td> <td>    0.005</td> <td>    0.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HEAD ON</th>                      <td>   -0.0426</td> <td>    0.047</td> <td>   -0.900</td> <td> 0.368</td> <td>   -0.135</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OTHER NONCOLLISION</th>           <td>   -1.1407</td> <td>    0.065</td> <td>  -17.506</td> <td> 0.000</td> <td>   -1.268</td> <td>   -1.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OTHER OBJECT</th>                 <td>   -0.6568</td> <td>    0.042</td> <td>  -15.796</td> <td> 0.000</td> <td>   -0.738</td> <td>   -0.575</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OVERTURNED</th>                   <td>    0.7704</td> <td>    0.251</td> <td>    3.075</td> <td> 0.002</td> <td>    0.279</td> <td>    1.261</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PARKED MOTOR VEHICLE</th>         <td>   -0.4837</td> <td>    0.015</td> <td>  -31.925</td> <td> 0.000</td> <td>   -0.513</td> <td>   -0.454</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PEDALCYCLIST</th>                 <td>   -2.4742</td> <td>    0.040</td> <td>  -61.867</td> <td> 0.000</td> <td>   -2.553</td> <td>   -2.396</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PEDESTRIAN</th>                   <td>   -2.3787</td> <td>    0.032</td> <td>  -74.125</td> <td> 0.000</td> <td>   -2.442</td> <td>   -2.316</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>REAR END</th>                     <td>   -0.6836</td> <td>    0.015</td> <td>  -45.993</td> <td> 0.000</td> <td>   -0.713</td> <td>   -0.654</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>REAR TO FRONT</th>                <td>   -0.6834</td> <td>    0.067</td> <td>  -10.134</td> <td> 0.000</td> <td>   -0.816</td> <td>   -0.551</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>REAR TO REAR</th>                 <td>   -0.9281</td> <td>    0.138</td> <td>   -6.737</td> <td> 0.000</td> <td>   -1.198</td> <td>   -0.658</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>REAR TO SIDE</th>                 <td>   -0.5686</td> <td>    0.085</td> <td>   -6.727</td> <td> 0.000</td> <td>   -0.734</td> <td>   -0.403</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SIDESWIPE OPPOSITE DIRECTION</th> <td>   -0.6305</td> <td>    0.033</td> <td>  -18.892</td> <td> 0.000</td> <td>   -0.696</td> <td>   -0.565</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SIDESWIPE SAME DIRECTION</th>     <td>   -0.6608</td> <td>    0.016</td> <td>  -41.736</td> <td> 0.000</td> <td>   -0.692</td> <td>   -0.630</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TRAIN</th>                        <td>    0.7197</td> <td>    0.771</td> <td>    0.934</td> <td> 0.350</td> <td>   -0.791</td> <td>    2.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TURNING</th>                      <td>   -0.1965</td> <td>    0.017</td> <td>  -11.871</td> <td> 0.000</td> <td>   -0.229</td> <td>   -0.164</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:             NEW_DAMAGE   No. Observations:               289986\n",
       "Model:                          Logit   Df Residuals:                   289956\n",
       "Method:                           MLE   Df Model:                           29\n",
       "Date:                Thu, 15 Oct 2020   Pseudo R-squ.:                 0.04008\n",
       "Time:                        15:36:31   Log-Likelihood:            -1.9077e+05\n",
       "converged:                       True   LL-Null:                   -1.9874e+05\n",
       "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
       "================================================================================================\n",
       "                                   coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------\n",
       "const                            0.9866      0.652      1.513      0.130      -0.291       2.264\n",
       "POSTED_SPEED_LIMIT               0.0108      0.001     18.345      0.000       0.010       0.012\n",
       "INJURIES_TOTAL                   0.7365      0.012     61.925      0.000       0.713       0.760\n",
       "CLEAR                           -0.6376      0.652     -0.979      0.328      -1.915       0.639\n",
       "CLOUDY/OVERCAST                 -0.5529      0.652     -0.848      0.396      -1.831       0.725\n",
       "FOG/SMOKE/HAZE                  -0.4289      0.658     -0.652      0.514      -1.718       0.860\n",
       "FREEZING RAIN/DRIZZLE           -0.1339      0.680     -0.197      0.844      -1.466       1.198\n",
       "OTHER                           -0.3442      0.655     -0.525      0.599      -1.629       0.940\n",
       "RAIN                            -0.5122      0.652     -0.786      0.432      -1.789       0.765\n",
       "SEVERE CROSS WIND GATE          -0.1574      0.710     -0.222      0.825      -1.549       1.234\n",
       "SLEET/HAIL                      -0.5346      0.659     -0.811      0.417      -1.826       0.757\n",
       "SNOW                            -0.5109      0.652     -0.784      0.433      -1.789       0.767\n",
       "UNKNOWN                         -0.4666      0.652     -0.716      0.474      -1.744       0.811\n",
       "ANIMAL                          -1.1042      0.150     -7.344      0.000      -1.399      -0.810\n",
       "FIXED OBJECT                     0.0510      0.024      2.163      0.031       0.005       0.097\n",
       "HEAD ON                         -0.0426      0.047     -0.900      0.368      -0.135       0.050\n",
       "OTHER NONCOLLISION              -1.1407      0.065    -17.506      0.000      -1.268      -1.013\n",
       "OTHER OBJECT                    -0.6568      0.042    -15.796      0.000      -0.738      -0.575\n",
       "OVERTURNED                       0.7704      0.251      3.075      0.002       0.279       1.261\n",
       "PARKED MOTOR VEHICLE            -0.4837      0.015    -31.925      0.000      -0.513      -0.454\n",
       "PEDALCYCLIST                    -2.4742      0.040    -61.867      0.000      -2.553      -2.396\n",
       "PEDESTRIAN                      -2.3787      0.032    -74.125      0.000      -2.442      -2.316\n",
       "REAR END                        -0.6836      0.015    -45.993      0.000      -0.713      -0.654\n",
       "REAR TO FRONT                   -0.6834      0.067    -10.134      0.000      -0.816      -0.551\n",
       "REAR TO REAR                    -0.9281      0.138     -6.737      0.000      -1.198      -0.658\n",
       "REAR TO SIDE                    -0.5686      0.085     -6.727      0.000      -0.734      -0.403\n",
       "SIDESWIPE OPPOSITE DIRECTION    -0.6305      0.033    -18.892      0.000      -0.696      -0.565\n",
       "SIDESWIPE SAME DIRECTION        -0.6608      0.016    -41.736      0.000      -0.692      -0.630\n",
       "TRAIN                            0.7197      0.771      0.934      0.350      -0.791       2.230\n",
       "TURNING                         -0.1965      0.017    -11.871      0.000      -0.229      -0.164\n",
       "================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer goes here\n",
    "\n",
    "model1 = sm.Logit(Y_train, X_train_con).fit()\n",
    "model1.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which variables (in particular, which categories of our categorical variables) appear to be the most important, and what effect do they have on the probability of a crash resulting in $1500 or more in damages?\n",
    "\n",
    "Injury totals and overturning the vehicle leads to a higher probabity of damamges beind more than 1500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "si6gV51qrsHs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer goes here\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logit = LogisticRegression(max_iter=1000)\n",
    "logit.fit(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5832798824770851"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.582782735837345"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Sf0UuUwjIzg"
   },
   "source": [
    "Create a LogisticRegression model with sklearn. Use the .predict() method (using X_test) to get a y_pred. Create a confusion matrix comparing your actual y_test to your prediction. What do you notice about your type of error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = logit.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9797, 22113],\n",
       "       [ 8134, 32453]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are lots of false positives and the number of true postitives is also high. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Day 24 Lecture 2 Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
