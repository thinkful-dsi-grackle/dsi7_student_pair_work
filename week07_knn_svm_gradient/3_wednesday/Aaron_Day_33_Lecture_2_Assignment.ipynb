{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cHTqUTbNpuwZ"
   },
   "source": [
    "## Day 33 Lecture 2 Assignment\n",
    "\n",
    "In this assignment, we will learn about non linear SVM models. We will use the heart disease dataset loaded below and analyze the model generated for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kQBDnjBLpuwZ"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z1EskWSrpuwb"
   },
   "outputs": [],
   "source": [
    "heart = pd.read_csv('https://tf-assets-prod.s3.amazonaws.com/tf-curric/data-science/framingham_heart_disease.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1609,
     "status": "ok",
     "timestamp": 1584658858336,
     "user": {
      "displayName": "Mike Swirsky",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhmOYfcQD1f_xzYU-OiJt5evVtjJAzwGU9bNAG1=s64",
      "userId": "09733430627481200667"
     },
     "user_tz": 420
    },
    "id": "zwYPk78tBrBy",
    "outputId": "987a771f-2758-4121-a2bb-30f68d6e4ced"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4238, 16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tw1yj9Ehpuwd",
    "outputId": "e5bfacec-0a6a-42a2-8413-f75b876cd762"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "1     0   46        2.0              0         0.0     0.0                0   \n",
       "2     1   48        1.0              1        20.0     0.0                0   \n",
       "3     0   61        3.0              1        30.0     0.0                0   \n",
       "4     0   46        3.0              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q6--xRehpuwf"
   },
   "source": [
    "This dataset helps us predict the probability of coronary heart diease (CHD) in the next 10 years given the risk factors for each subject in the study. Our target variable is `TenYearCHD`.\n",
    "\n",
    "We'll start off by removing any rows containing missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H7pOIvimpuwg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male                 0\n",
       "age                  0\n",
       "education          105\n",
       "currentSmoker        0\n",
       "cigsPerDay          29\n",
       "BPMeds              53\n",
       "prevalentStroke      0\n",
       "prevalentHyp         0\n",
       "diabetes             0\n",
       "totChol             50\n",
       "sysBP                0\n",
       "diaBP                0\n",
       "BMI                 19\n",
       "heartRate            1\n",
       "glucose            388\n",
       "TenYearCHD           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# answer below:\n",
    "heart.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male               0\n",
       "age                0\n",
       "education          0\n",
       "currentSmoker      0\n",
       "cigsPerDay         0\n",
       "BPMeds             0\n",
       "prevalentStroke    0\n",
       "prevalentHyp       0\n",
       "diabetes           0\n",
       "totChol            0\n",
       "sysBP              0\n",
       "diaBP              0\n",
       "BMI                0\n",
       "heartRate          0\n",
       "glucose            0\n",
       "TenYearCHD         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart.dropna(inplace=True)\n",
    "heart.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3TYgJuyxpuwj"
   },
   "source": [
    "Then, we split the data into train and test with 20% of the data in the test subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MpeydIKspuwi"
   },
   "outputs": [],
   "source": [
    "# answer below:\n",
    "\n",
    "X = heart.drop('TenYearCHD', axis=1)\n",
    "y = heart.TenYearCHD\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a-3wmJJupuwh"
   },
   "source": [
    "We will then scale the data using the standard scaler. Do this in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DeYucn7Spuwk"
   },
   "outputs": [],
   "source": [
    "# answer below:\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "X_train_scale = scale.fit_transform(X_train, y_train)\n",
    "X_test_scale = scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k0iL3Twepuwn"
   },
   "source": [
    "Generate a polynomial SVC model and a RBF SVC model. Compare the performance, and the runtime, for the two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mRkYJIPvpuwn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polynomial SVC train time: 0.7230021953582764 seconds\n",
      "\n",
      "polynomial training score: 0.8820109439124487\n",
      "polynomial test score: 0.860655737704918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# answer below:\n",
    "from sklearn.svm import SVC\n",
    "import time\n",
    "\n",
    "poly_svc = SVC(kernel='poly', C=10, degree=3)\n",
    "rbf_svc = SVC(kernel='rbf')\n",
    "\n",
    "star_time = time.time()\n",
    "poly_svc.fit(X_train_scale, y_train)\n",
    "print(f'polynomial SVC train time: {time.time()-star_time} seconds\\n')\n",
    "\n",
    "print(\n",
    "    f'polynomial training score: {poly_svc.score(X_train_scale, y_train)}\\n'\n",
    "    f'polynomial test score: {poly_svc.score(X_test_scale, y_test)}\\n'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rbf SVC train time: 0.24553489685058594 seconds\n",
      "\n",
      "rbf training score: 0.8584131326949385\n",
      "rbf test score: 0.8579234972677595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "star_time = time.time()\n",
    "rbf_svc.fit(X_train_scale, y_train)\n",
    "print(f'rbf SVC train time: {time.time()-star_time} seconds\\n')\n",
    "\n",
    "print(\n",
    "    f'rbf training score: {rbf_svc.score(X_train_scale, y_train)}\\n'\n",
    "    f'rbf test score: {rbf_svc.score(X_test_scale, y_test)}\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BapGqwHvpuwp"
   },
   "source": [
    "Which model overfits more? How would you improve the overfitting?\n",
    "\n",
    "Look at a classification report and confusion matrix. How does the class balance affect your results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4GJSWe6Ipuwp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Polynomial SVC --------------\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93      2470\n",
      "           1       0.96      0.25      0.40       454\n",
      "\n",
      "    accuracy                           0.88      2924\n",
      "   macro avg       0.92      0.62      0.67      2924\n",
      "weighted avg       0.89      0.88      0.85      2924\n",
      "\n",
      "confusion matrix\n",
      "[[2465    5]\n",
      " [ 340  114]]\n",
      "\n",
      "Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92       629\n",
      "           1       0.52      0.13      0.20       103\n",
      "\n",
      "    accuracy                           0.86       732\n",
      "   macro avg       0.70      0.55      0.56       732\n",
      "weighted avg       0.82      0.86      0.82       732\n",
      "\n",
      "confusion matrix\n",
      "[[617  12]\n",
      " [ 90  13]]\n",
      "\n",
      "\n",
      "--------------- rbf SVC --------------\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92      2470\n",
      "           1       0.98      0.09      0.17       454\n",
      "\n",
      "    accuracy                           0.86      2924\n",
      "   macro avg       0.92      0.54      0.54      2924\n",
      "weighted avg       0.88      0.86      0.81      2924\n",
      "\n",
      "confusion matrix\n",
      "[[2469    1]\n",
      " [ 413   41]]\n",
      "\n",
      "Test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       629\n",
      "           1       0.00      0.00      0.00       103\n",
      "\n",
      "    accuracy                           0.86       732\n",
      "   macro avg       0.43      0.50      0.46       732\n",
      "weighted avg       0.74      0.86      0.79       732\n",
      "\n",
      "confusion matrix\n",
      "[[628   1]\n",
      " [103   0]]\n"
     ]
    }
   ],
   "source": [
    "# answer below:\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "poly_train_pred = poly_svc.predict(X_train_scale)\n",
    "poly_test_pred = poly_svc.predict(X_test_scale)\n",
    "\n",
    "rbf_train_pred = rbf_svc.predict(X_train_scale)\n",
    "rbf_test_pred = rbf_svc.predict(X_test_scale)\n",
    "\n",
    "\n",
    "print(\n",
    "    f'--------------- Polynomial SVC --------------\\n'\n",
    "    f'Train\\n'\n",
    "    f'{classification_report(y_train, poly_train_pred)}\\n'\n",
    "    f'confusion matrix\\n'\n",
    "    f'{confusion_matrix(y_train, poly_train_pred)}\\n'\n",
    "    f'\\nTest\\n'\n",
    "    f'{classification_report(y_test, poly_test_pred)}\\n'\n",
    "    f'confusion matrix\\n'\n",
    "    f'{confusion_matrix(y_test, poly_test_pred)}\\n\\n'\n",
    ")\n",
    "\n",
    "print(\n",
    "    f'--------------- rbf SVC --------------\\n'\n",
    "    f'Train\\n'\n",
    "    f'{classification_report(y_train, rbf_train_pred)}\\n'\n",
    "    f'confusion matrix\\n'\n",
    "    f'{confusion_matrix(y_train, rbf_train_pred)}\\n'\n",
    "    f'\\nTest\\n'\n",
    "    f'{classification_report(y_test, rbf_test_pred)}\\n'\n",
    "    f'confusion matrix\\n'\n",
    "    f'{confusion_matrix(y_test, rbf_test_pred)}'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because there are so few observations of the positive class both both models are not verry\n",
    "# good at predicting the positive class, but the polynomial model is better. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Day 33 Lecture 2 Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
